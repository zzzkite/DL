#!/usr/bin/env python3
"""
ControlNet 1.1 512x512è®­ç»ƒè„šæœ¬
é’ˆå¯¹é«˜åˆ†è¾¨ç‡æ•°æ®çš„ä¼˜åŒ–ç‰ˆæœ¬
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset, ConcatDataset
import torch.optim as optim
import cv2
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import sys
import os
import gc
import time
from typing import Dict, List, Optional, Tuple
from PIL import Image  # æ·»åŠ PILå¯¼å…¥

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

try:
    from diffusers import DDPMScheduler, AutoencoderKL, UNet2DConditionModel
    from transformers import CLIPTokenizer, CLIPTextModel
    from loaderData512 import create_task_specific_loaders  # ä¿®æ”¹ä¸º512æ•°æ®åŠ è½½å™¨
    
    try:
        from cldm.model import create_model, load_state_dict
        CONTROLNET_AVAILABLE = True
        print("âœ… æˆåŠŸå¯¼å…¥ControlNetæ¨¡å—")
    except ImportError as e:
        print(f"âš ï¸  æ— æ³•å¯¼å…¥cldm: {e}")
        CONTROLNET_AVAILABLE = False
        
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

class ControlNet512Trainer:

    def log_validation(self, val_loader, epoch, save_dir):
        """ç”Ÿæˆé¢„è§ˆå›¾ - ä¿®å¤ç‰ˆæœ¬ï¼šåŒ…å«å†…å®¹å‚è€ƒ"""
        print(f"ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆ Epoch {epoch} çš„é¢„è§ˆå›¾...")
        self.controlnet.eval()
        self.unet.eval()

        # ä¸´æ—¶æ„å»ºä¸€ä¸ª pipeline ç”¨äºæ¨ç†
        from diffusers import StableDiffusionControlNetPipeline

        pipeline = StableDiffusionControlNetPipeline(
            vae=self.vae,
            text_encoder=self.text_encoder,
            tokenizer=self.tokenizer,
            unet=self.unet,
            controlnet=self.controlnet,
            scheduler=self.noise_scheduler,
            safety_checker=None,
            feature_extractor=None,
            requires_safety_checker=False
        )
        pipeline.set_progress_bar_config(disable=True)
        pipeline = pipeline.to(self.device)

        # åªå–éªŒè¯é›†çš„ç¬¬ä¸€æ‰¹æ•°æ®æ¥åšæ¼”ç¤º
        batch = next(iter(val_loader))

        # å‡†å¤‡æ•°æ®
        # ç¬¬20å¸§ï¼šä½œä¸ºå†…å®¹å‚è€ƒå’Œæ¡ä»¶è¾“å…¥
        current_frame_20 = batch['input_frames'][:, -1].to(self.device)
        # ç¬¬25å¸§ï¼šçœŸå®ç›®æ ‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        target_frame_25 = batch['target_frame'].to(self.device)
        prompts = batch.get('label_text', ['interaction'] * len(current_frame_20))

        # å‡†å¤‡ Canny æ¡ä»¶å›¾
        control_cond = self.get_canny_edges(current_frame_20, training=False)

        image_logs = []
        num_images = min(len(current_frame_20), 4)

        for i in range(num_images):
            # å…³é”®æ”¹è¿›ï¼šä½¿ç”¨ç¬¬20å¸§ä½œä¸ºåˆå§‹æ½œå˜é‡ï¼Œæä¾›å†…å®¹å‚è€ƒ
            with torch.no_grad():
                # å°†ç¬¬20å¸§ç¼–ç ä¸ºæ½œå˜é‡ï¼Œä½œä¸ºç”Ÿæˆçš„èµ·ç‚¹
                current_frame_prepared = self.prepare_images_for_vae(current_frame_20[i:i+1])
                init_latents = self.vae.encode(current_frame_prepared).latent_dist.sample()
                init_latents = init_latents * self.vae.config.scaling_factor

            # 1. æ¨¡å‹ç”Ÿæˆ - ä½¿ç”¨åˆå§‹æ½œå˜é‡æä¾›å†…å®¹å‚è€ƒ
            with torch.autocast("cuda"):
                # ä¿®æ”¹ï¼šä¼ å…¥åˆå§‹æ½œå˜é‡ï¼Œè®©ç”Ÿæˆè¿‡ç¨‹æœ‰å†…å®¹åŸºç¡€
                generated_image = pipeline(
                    prompt=prompts[i],
                    image=control_cond[i:i + 1],
                    num_inference_steps=20,
                    guidance_scale=7.5,
                    controlnet_conditioning_scale=1.0,
                    # å…³é”®ï¼šæ·»åŠ åˆå§‹æ½œå˜é‡ï¼Œè®©ç”ŸæˆåŸºäºç¬¬20å¸§çš„å†…å®¹
                    latents=init_latents,
                    strength=0.5  # æ§åˆ¶åˆå§‹æ½œå˜é‡çš„å½±å“åŠ›
                ).images[0]

            # 2. å¤„ç†å¯¹æ¯”å›¾åƒ
            # ç¬¬20å¸§åŸå§‹å›¾åƒï¼ˆå†…å®¹å‚è€ƒï¼‰
            frame_20_np = current_frame_20[i].permute(1, 2, 0).cpu().numpy()
            frame_20_img = ((frame_20_np + 1) / 2 * 255).astype(np.uint8)
            
            # Canny æ¡ä»¶å›¾
            canny_np = control_cond[i].permute(1, 2, 0).cpu().numpy()
            if canny_np.shape[2] == 1: 
                canny_np = np.concatenate([canny_np] * 3, axis=2)
            canny_pil = Image.fromarray((canny_np * 255).astype(np.uint8))
            
            # çœŸå®ç¬¬25å¸§
            gt_np = target_frame_25[i].permute(1, 2, 0).cpu().numpy()
            gt_img = ((gt_np + 1) / 2 * 255).astype(np.uint8)

            # æ‹¼æ¥ï¼šç¬¬20å¸§ | Cannyæ¡ä»¶ | ç”Ÿæˆç»“æœ | çœŸå®ç¬¬25å¸§
            combined_img = Image.new('RGB', (512 * 4, 512))
            combined_img.paste(Image.fromarray(frame_20_img), (0, 0))
            combined_img.paste(canny_pil, (512, 0))
            combined_img.paste(generated_image, (1024, 0))
            combined_img.paste(Image.fromarray(gt_img), (1536, 0))

            # ä¿å­˜
            save_path = Path(save_dir) / f"epoch_{epoch}_sample_{i}.jpg"
            combined_img.save(save_path)

        print(f"âœ¨ é¢„è§ˆå›¾å·²ä¿å­˜åˆ° {save_dir}")

        # é‡Šæ”¾æ˜¾å­˜
        del pipeline
        torch.cuda.empty_cache()



    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.task_name = config.get('task_name', 'unknown_task')
        
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ¯ ä»»åŠ¡: {self.task_name}")
        print(f"ğŸ“ åˆ†è¾¨ç‡: 512x512")
        
        # è®­ç»ƒçŠ¶æ€
        self.best_val_loss = float('inf')
        
        # æ¢¯åº¦ç¼©æ”¾å™¨
        self.scaler = torch.amp.GradScaler('cuda')
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.setup_models()
        self.setup_optimizers()
        
    def setup_models(self):
        """æ¨¡å‹åˆå§‹åŒ–"""
        print("ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...")
        
        # 1. åŠ è½½ç»„ä»¶
        self.tokenizer = CLIPTokenizer.from_pretrained("stable-diffusion-v1-5/tokenizer", local_files_only=True)
        self.text_encoder = CLIPTextModel.from_pretrained("stable-diffusion-v1-5/text_encoder", local_files_only=True).to(self.device)
        self.vae = AutoencoderKL.from_pretrained("stable-diffusion-v1-5/vae", local_files_only=True).to(self.device)
        self.unet = UNet2DConditionModel.from_pretrained("stable-diffusion-v1-5/unet", local_files_only=True).to(self.device)
        self.noise_scheduler = DDPMScheduler.from_pretrained("stable-diffusion-v1-5/scheduler", local_files_only=True)
        
        # 2. åŠ è½½ ControlNet
        self.controlnet = self.load_controlnet().to(self.device)
        
        # 3. å†»ç»“å‚æ•°
        self.text_encoder.requires_grad_(False)
        self.vae.requires_grad_(False)
        self.unet.requires_grad_(False)
        self.controlnet.requires_grad_(True)
        
        # æ‰“å°å‚æ•°é‡
        trainable_params = sum(p.numel() for p in self.controlnet.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in self.controlnet.parameters())
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå¯è®­ç»ƒå‚æ•°: {trainable_params:,} / æ€»å‚æ•°: {total_params:,}")
        
        # æ£€æŸ¥VAEè¾“å…¥å°ºå¯¸å…¼å®¹æ€§
        vae_sample_size = self.vae.config.sample_size
        print(f"ğŸ” VAEæ ·æœ¬å°ºå¯¸: {vae_sample_size}")
        if vae_sample_size != 512:
            print(f"âš ï¸  VAEé¢„æœŸè¾“å…¥å°ºå¯¸ä¸º{vae_sample_size}x{vae_sample_size}ï¼Œä½†æ•°æ®ä¸º512x512")

    def load_controlnet(self):
        """åŠ è½½ControlNetæ¨¡å‹"""
        try:
            if CONTROLNET_AVAILABLE:
                controlnet_dir = Path("ControlNet-v1-1")
                model_path = controlnet_dir / "control_sd15_canny.pth"
                config_path = controlnet_dir / "cldm_v15.yaml"
                
                if model_path.exists():
                    print(f"ğŸ“‚ åŠ è½½é¢„è®­ç»ƒæƒé‡: {model_path}")
                    model = create_model(str(config_path)).to(self.device)
                    model.load_state_dict(load_state_dict(str(model_path), location='cpu'))
                    return model.control_model
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œå°†å°è¯•ä»UNetåˆå§‹åŒ–")
            
            # å¤‡é€‰æ–¹æ¡ˆï¼šä» UNet åˆå§‹åŒ–
            from diffusers import ControlNetModel
            print("ğŸ†• ä» UNet å¤åˆ¶æƒé‡åˆå§‹åŒ– ControlNet")
            controlnet = ControlNetModel.from_unet(self.unet, conditioning_channels=3)
            return controlnet
                
        except Exception as e:
            print(f"âŒ åŠ è½½ControlNetå¤±è´¥: {e}")
            raise

    def setup_optimizers(self):
        """ä¼˜åŒ–å™¨é…ç½®"""
        # ä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡
        no_decay = ["bias", "LayerNorm.weight"]
        optimizer_grouped_parameters = [
            {
                "params": [p for n, p in self.controlnet.named_parameters() 
                          if not any(nd in n for nd in no_decay) and p.requires_grad],
                "weight_decay": self.config.get('weight_decay', 1e-2),
                "lr": self.config.get('learning_rate', 8e-6),  # é™ä½å­¦ä¹ ç‡é€‚åº”é«˜åˆ†è¾¨ç‡
            },
            {
                "params": [p for n, p in self.controlnet.named_parameters() 
                          if any(nd in n for nd in no_decay) and p.requires_grad],
                "weight_decay": 0.0,
                "lr": self.config.get('learning_rate', 8e-6),
            },
        ]
        
        self.optimizer = optim.AdamW(
            optimizer_grouped_parameters,
            betas=(0.9, 0.999),
            eps=1e-8
        )
        
        # ä½¿ç”¨ç®€å•çš„ä½™å¼¦é€€ç«
        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, 
            T_max=self.config.get('num_epochs', 30),  # å‡å°‘è®­ç»ƒè½®æ•°
            eta_min=1e-7  # æ›´ä½çš„æœ€å°å­¦ä¹ ç‡
        )

    def prepare_images_for_vae(self, images):
        """å‡†å¤‡å›¾åƒä»¥é€‚åº”VAEè¾“å…¥"""
        # ç¡®ä¿å›¾åƒåœ¨[-1, 1]èŒƒå›´å†…
        if torch.max(images) <= 1.0 and torch.min(images) >= 0.0:
            images = images * 2.0 - 1.0
        
        # å¦‚æœVAEéœ€è¦ç‰¹å®šå°ºå¯¸ï¼Œè¿›è¡Œè°ƒæ•´
        vae_sample_size = self.vae.config.sample_size
        if images.shape[-1] != vae_sample_size or images.shape[-2] != vae_sample_size:
            print(f"âš ï¸  è°ƒæ•´å›¾åƒå°ºå¯¸ä» {images.shape[-2:]} åˆ° {vae_sample_size}x{vae_sample_size}")
            images = F.interpolate(images, size=(vae_sample_size, vae_sample_size), mode='bilinear', align_corners=False)
        
        return images

    def get_canny_edges(self, image_tensor, training=False):
        """
        Cannyè¾¹ç¼˜æ£€æµ‹ - é€‚é…512x512
        """
        batch_size = image_tensor.shape[0]
        
        # ç¡®ä¿è¾“å…¥åœ¨ [0, 1] èŒƒå›´å†…
        if torch.max(image_tensor) > 1.0:
            image_tensor = (image_tensor + 1.0) / 2.0
        
        images_np = image_tensor.permute(0, 2, 3, 1).cpu().numpy()
        images_np = (images_np * 255).astype(np.uint8)
        
        edges_list = []
        for i in range(batch_size):
            img_gray = cv2.cvtColor(images_np[i], cv2.COLOR_RGB2GRAY)
            
            # å¯¹äº512x512é«˜åˆ†è¾¨ç‡ï¼Œä½¿ç”¨æ›´ç²¾ç»†çš„Cannyå‚æ•°
            v = np.median(img_gray)
            # è°ƒæ•´é˜ˆå€¼ä»¥é€‚åº”é«˜åˆ†è¾¨ç‡
            sigma = 0.33
            lower = int(max(0, (1.0 - sigma) * v))
            upper = int(min(255, (1.0 + sigma) * v))
            
            # ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
            edge = cv2.Canny(img_gray, lower, upper)
            
            # å¯é€‰ï¼šå¯¹è¾¹ç¼˜è¿›è¡Œå½¢æ€å­¦æ“ä½œä»¥æ”¹å–„è¿ç»­æ€§
            if training and np.random.random() > 0.7:
                kernel = np.ones((2, 2), np.uint8)
                edge = cv2.morphologyEx(edge, cv2.MORPH_CLOSE, kernel)
            
            # æ‰©å±•å›3é€šé“
            edge = np.stack([edge] * 3, axis=-1)
            edges_list.append(edge)
            
        edges_np = np.stack(edges_list)
        edges_tensor = torch.from_numpy(edges_np).float() / 255.0
        return edges_tensor.permute(0, 3, 1, 2).to(self.device)

    def compute_loss(self, batch, training=True):
        """ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° - é€‚é…512x512"""
        # 1. å‡†å¤‡æ•°æ®
        current_frame_20 = batch['input_frames'][:, -1].to(self.device) 
        target_frame_25 = batch['target_frame'].to(self.device)
        text_descriptions = batch.get('label_text', ['interaction'] * len(current_frame_20))
        
        # 2. VAEç¼–ç ç›®æ ‡å›¾ - é€‚é…å°ºå¯¸
        target_frame_prepared = self.prepare_images_for_vae(target_frame_25)
        target_latents = self.vae.encode(target_frame_prepared).latent_dist.sample()
        target_latents = target_latents * self.vae.config.scaling_factor
        
        # 3. CLIPç¼–ç æ–‡æœ¬
        inputs = self.tokenizer(
            text_descriptions, 
            max_length=77, 
            padding="max_length", 
            truncation=True, 
            return_tensors="pt"
        ).to(self.device)
        encoder_hidden_states = self.text_encoder(inputs.input_ids)[0]
        
        # 4. å‡†å¤‡ControlNetæ¡ä»¶
        control_cond = self.get_canny_edges(current_frame_20, training=training)
        
        # 5. é‡‡æ ·timestepå’Œå™ªå£° - ä½¿ç”¨å›ºå®šçš„å…¨èŒƒå›´
        timesteps = torch.randint(
            0, 
            self.noise_scheduler.config.num_train_timesteps, 
            (target_latents.shape[0],), 
            device=self.device
        ).long()
        
        noise = torch.randn_like(target_latents)
        noisy_latents = self.noise_scheduler.add_noise(target_latents, noise, timesteps)
        
        # 6. ControlNetå‰å‘
        down_block_res_samples, mid_block_res_sample = self.controlnet(
            noisy_latents,
            timesteps,
            encoder_hidden_states=encoder_hidden_states,
            controlnet_cond=control_cond,
            return_dict=False,
        )
        
        # 7. UNeté¢„æµ‹
        noise_pred = self.unet(
            noisy_latents,
            timesteps,
            encoder_hidden_states=encoder_hidden_states,
            down_block_additional_residuals=down_block_res_samples,
            mid_block_additional_residual=mid_block_res_sample,
        ).sample
        
        # 8. è®¡ç®—æŸå¤±
        loss = F.mse_loss(noise_pred, noise)
        
        return loss

    def train_epoch(self, train_loader, epoch):
        """è®­ç»ƒepoch - é€‚é…512x512"""
        self.controlnet.train()
        total_loss = 0
        num_batches = 0
        
        accumulation_steps = self.config.get('accumulation_steps', 2)
        
        print(f"ğŸ“š å¼€å§‹ç¬¬ {epoch} è½®è®­ç»ƒï¼Œå…±æœ‰ {len(train_loader)} ä¸ªæ‰¹æ¬¡")
        
        for batch_idx, batch in enumerate(train_loader):
            if batch is None: 
                continue
                
            # é‡ç½®æ¢¯åº¦
            self.optimizer.zero_grad()
            
            try:
                # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦
                with torch.amp.autocast('cuda'):
                    loss = self.compute_loss(batch, training=True)
                
                # æ¢¯åº¦ç´¯ç§¯
                loss = loss / accumulation_steps
                
                # åå‘ä¼ æ’­
                self.scaler.scale(loss).backward()
                
                if (batch_idx + 1) % accumulation_steps == 0:
                    # æ¢¯åº¦è£å‰ª
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.controlnet.parameters(), max_norm=0.5)  # æ›´ä¸¥æ ¼çš„æ¢¯åº¦è£å‰ª
                    
                    # ä¼˜åŒ–å™¨æ­¥è¿›
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()
                
                # è®°å½•æŸå¤±
                loss_value = loss.item() * accumulation_steps
                total_loss += loss_value
                num_batches += 1
                
                # æ‰“å°è¿›åº¦
                if batch_idx % 5 == 0:  # æ›´é¢‘ç¹çš„æ—¥å¿—
                    current_lr = self.optimizer.param_groups[0]['lr']
                    print(f"Epoch {epoch} | Batch {batch_idx}/{len(train_loader)} | "
                          f"Loss: {loss_value:.6f} | LR: {current_lr:.2e}")
                
                # æ›´é¢‘ç¹çš„æ¸…ç†æ˜¾å­˜
                if batch_idx % 10 == 0 and self.device.type == 'cuda':
                    torch.cuda.empty_cache()
                    if batch_idx % 20 == 0:
                        self._log_gpu_memory(f"Epoch{epoch} Batch{batch_idx}")
                    
            except Exception as e:
                print(f"âŒ è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                continue
        
        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')
        print(f"âœ… ç¬¬ {epoch} è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
        return avg_loss

    def _log_gpu_memory(self, label: str = ""):
        """GPUå†…å­˜ç›‘æ§"""
        if self.device.type != 'cuda':
            return
        try:
            allocated = torch.cuda.memory_allocated() / 1024**3  # GB
            reserved = torch.cuda.memory_reserved() / 1024**3    # GB
            print(f"[GPU MEM] {label} allocated={allocated:.2f}GB reserved={reserved:.2f}GB")
        except Exception:
            pass

    def validate(self, val_loader):
        """éªŒè¯å‡½æ•° - é€‚é…512x512"""
        self.controlnet.eval()
        total_loss = 0.0
        num_batches = 0
        
        print(f"ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ {len(val_loader)} ä¸ªæ‰¹æ¬¡")
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                if batch is None:
                    continue
                
                try:
                    with torch.amp.autocast('cuda'):
                        loss = self.compute_loss(batch, training=False)
                    
                    loss_value = loss.item()
                    total_loss += loss_value
                    num_batches += 1
                    
                    if batch_idx % 3 == 0:  # æ›´é¢‘ç¹çš„éªŒè¯æ—¥å¿—
                        print(f"éªŒè¯æ‰¹æ¬¡ {batch_idx}/{len(val_loader)} | Loss: {loss_value:.6f}")
                        
                except Exception as e:
                    print(f"âŒ éªŒè¯æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    continue
        
        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')
        print(f"âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
        return avg_loss

    def save_checkpoint(self, epoch, task_name, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(exist_ok=True, parents=True)
        
        if is_best:
            save_path = output_dir / f"controlnet_{task_name}_best.pth"
        else:
            save_path = output_dir / f"controlnet_{task_name}_epoch_{epoch}.pth"
            
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.controlnet.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'lr_scheduler_state_dict': self.lr_scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'config': self.config
        }
        
        torch.save(checkpoint, save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}")

    def plot_and_save_losses(self, train_losses, val_losses=None):
        """ç»˜åˆ¶è®­ç»ƒ/éªŒè¯æŸå¤±"""
        try:
            output_dir = Path(self.config['output_dir'])
            output_dir.mkdir(parents=True, exist_ok=True)

            plt.figure(figsize=(10, 6))
            epochs = list(range(1, len(train_losses) + 1))
            
            plt.plot(epochs, train_losses, marker='o', color='tab:blue', label='Train Loss', linewidth=2)
            if val_losses is not None and len(val_losses) == len(train_losses):
                plt.plot(epochs, val_losses, marker='s', color='tab:orange', label='Val Loss', linewidth=2)
                
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title(f'Training / Validation Loss - {self.task_name} (512x512)')
            plt.grid(alpha=0.3)
            plt.legend()
            
            save_path = output_dir / f'training_val_loss_{self.task_name}_512.png'
            plt.savefig(save_path, dpi=200, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“ˆ Loss å›¾å·²ä¿å­˜: {save_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ Loss å›¾å¤±è´¥: {e}")

    def train(self, train_loader, val_loader):
        """è®­ç»ƒå¾ªç¯ - é€‚é…512x512"""
        print("ğŸš€ å¼€å§‹512x512è®­ç»ƒ...")
        print(f"ğŸ“ è¾“å…¥åˆ†è¾¨ç‡: 512x512")
        print(f"ğŸ¯ ä»»åŠ¡: {self.task_name}")
        
        train_losses = []
        val_losses = []
        
        # åˆå§‹éªŒè¯
        print("\nğŸ” è¿›è¡Œåˆå§‹éªŒè¯...")
        initial_val_loss = self.validate(val_loader)
        print(f"åˆå§‹éªŒè¯æŸå¤±: {initial_val_loss:.6f}")
        
        for epoch in range(1, self.config['num_epochs'] + 1):
            epoch_start_time = time.time()
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(train_loader, epoch)
            train_losses.append(train_loss)
            
            # éªŒè¯
            val_loss = self.validate(val_loader)
            val_losses.append(val_loss)

            # ç”Ÿæˆå›¾ç‰‡
            if epoch % self.config['save_interval'] == 0:
                self.log_validation(val_loader, epoch, self.config['output_dir'])

            epoch_time = time.time() - epoch_start_time
            current_lr = self.optimizer.param_groups[0]['lr']
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š Epoch {epoch}/{self.config['num_epochs']} å®Œæˆ")
            print(f"   Train Loss: {train_loss:.6f}")
            print(f"   Val Loss: {val_loss:.6f}")
            print(f"   LR: {current_lr:.2e} | Time: {epoch_time:.1f}s")
            print(f"{'='*60}")
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.lr_scheduler.step()
            
            # æœ€ä½³æ¨¡å‹ä¿å­˜ï¼ˆå»æ‰æ—©åœæœºåˆ¶ï¼Œåªä¿å­˜æœ€ä½³æ¨¡å‹ï¼‰
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.save_checkpoint(epoch, self.config['task_name'], is_best=True)
                print(f"ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: {val_loss:.6f}")
            
            # å®šæœŸä¿å­˜
            if epoch % self.config['save_interval'] == 0:
                self.save_checkpoint(epoch, self.config['task_name'])
            
            # æ¸…ç†æ˜¾å­˜
            if self.device.type == 'cuda':
                torch.cuda.empty_cache()
                self._log_gpu_memory(f"End of Epoch {epoch}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹å’ŒæŸå¤±æ›²çº¿
        self.save_checkpoint(self.config['num_epochs'], self.config['task_name'])
        self.plot_and_save_losses(train_losses, val_losses)
        
        print(f"\nğŸ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.6f}")

def main():
    # 512x512é…ç½® - æ›´ä¿å®ˆçš„å‚æ•°
    config = {
        'learning_rate': 1e-5,      # é™ä½å­¦ä¹ ç‡
        'num_epochs': 500,           # å‡å°‘è®­ç»ƒè½®æ•°
        'batch_size': 2,            # å‡å°æ‰¹æ¬¡å¤§å°
        'save_interval': 5,
        'accumulation_steps': 2,
        'weight_decay': 1e-2,       # é€šè¿‡ä¼˜åŒ–å™¨çš„weight_decayå®ç°æ­£åˆ™åŒ–
    }

    tasks = [
        {'name': 'move_object', 'display': 'ç§»åŠ¨ç‰©ä½“'},
        {'name': 'drop_object', 'display': 'æ‰è½ç‰©ä½“'},
        {'name': 'cover_object', 'display': 'è¦†ç›–ç‰©ä½“'}
    ]

    for task in tasks:
        task_name = task['name']
        print(f"\n{'='*60}")
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: {task['display']}")
        print(f"ğŸ“ åˆ†è¾¨ç‡: 512x512")
        print(f"{'='*60}")
        
        task_config = config.copy()
        task_config['task_name'] = task_name
        task_config['output_dir'] = f'training_results_{task_name}_512'
        
        # åŠ è½½æ•°æ® - ä½¿ç”¨512æ•°æ®é›†
        try:
            train_loader, val_loader, test_loader = create_task_specific_loaders(
                task_name=task_name,
                batch_size=task_config['batch_size'],
                data_path="processed_data_512"  # ä¿®æ”¹ä¸º512æ•°æ®é›†è·¯å¾„
            )
        except Exception as e:
            print(f"âŒ è·³è¿‡ä»»åŠ¡ {task_name}: {e}")
            continue

        # ä½¿ç”¨1000ä¸ªæ ·æœ¬
        max_samples = 1000
        if max_samples is not None:
            orig_train_ds = train_loader.dataset
            orig_val_ds = val_loader.dataset
            orig_test_ds = test_loader.dataset
            combined = ConcatDataset([orig_train_ds, orig_val_ds, orig_test_ds])
            total = len(combined)
            
            if max_samples > total:
                print(f"âš ï¸ è¯·æ±‚çš„æ ·æœ¬æ•° {max_samples} è¶…è¿‡å¯ç”¨æ ·æœ¬ {total}ï¼Œä½¿ç”¨å…¨éƒ¨æ ·æœ¬")
                max_samples = total

            print(f"ğŸ“Š ä»æ€»æ ·æœ¬ {total} ä¸­éšæœºæŠ½å– {max_samples} ä¸ªï¼ˆæŒ‰ 8:1:1 åˆ’åˆ†ï¼‰")

            generator = torch.Generator()
            generator.manual_seed(42)
            perm = torch.randperm(total, generator=generator)[:max_samples].tolist()

            n_train = int(max_samples * 0.8)
            n_val = int(max_samples * 0.1)
            n_test = max_samples - n_train - n_val

            train_idx = perm[:n_train]
            val_idx = perm[n_train:n_train + n_val]
            test_idx = perm[n_train + n_val:]

            small_train_ds = Subset(combined, train_idx)
            small_val_ds = Subset(combined, val_idx)
            small_test_ds = Subset(combined, test_idx)

            train_loader = DataLoader(small_train_ds, batch_size=task_config['batch_size'], 
                                    shuffle=True, num_workers=2, pin_memory=True)
            val_loader = DataLoader(small_val_ds, batch_size=task_config['batch_size'], 
                                  shuffle=False, num_workers=2, pin_memory=True)

            print(f"âœ… æ•°æ®é›†åˆ†é…: train={len(small_train_ds)} val={len(small_val_ds)}")

        if len(train_loader) == 0:
            print(f"âš ï¸ ä»»åŠ¡ {task_name} æ— è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡")
            continue

        # åˆå§‹åŒ–å¹¶è®­ç»ƒ
        try:
            trainer = ControlNet512Trainer(task_config)
            trainer.train(train_loader, val_loader)
        except Exception as e:
            print(f"âŒ è®­ç»ƒä»»åŠ¡ {task_name} å¤±è´¥: {e}")
            continue

if __name__ == "__main__":
    main()