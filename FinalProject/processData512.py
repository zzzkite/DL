#!/usr/bin/env python3
"""
Something-Something V2 æ•°æ®é›†å¤„ç†è„šæœ¬ - 512x512ç‰ˆæœ¬
è¾“å…¥å‰20å¸§ï¼Œé¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡ä¸­é—´4å¸§ï¼‰
"""

import os
import json
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
import random

class VideoProcessor:
    def __init__(self, video_dir="extracted_videos/20bn-something-something-v2", 
                 label_dir="labels",
                 output_dir="processed_data_512"):
        self.video_dir = Path(video_dir)
        self.label_dir = Path(label_dir)
        self.output_dir = Path(output_dir)
        self.target_size = (512, 512)  # ä¿®æ”¹ä¸º512x512
        self.setup_directories()
        
    def setup_directories(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„"""
        directories = [
            "frames/move_object",
            "frames/drop_object", 
            "frames/cover_object",
            "metadata",
            "samples"
        ]
        
        for dir_name in directories:
            (self.output_dir / dir_name).mkdir(parents=True, exist_ok=True)
        print(f"âœ… ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ - åˆ†è¾¨ç‡: {self.target_size[0]}x{self.target_size[1]}")
    
    def load_dataset_labels(self, split='train'):
        """åŠ è½½æ•°æ®é›†æ ‡ç­¾"""
        label_file = self.label_dir / f"{split}.json"
        
        # è¯»å–å¹¶ä¿®å¤JSONæ ¼å¼
        samples = []
        with open(label_file, 'r') as f:
            content = f.read().strip()
            # ä¿®å¤JSONæ ¼å¼
            if not content.startswith('['):
                content = '[' + content + ']'
            content = content.replace('},]', '}]')
            
            try:
                samples = json.loads(content)
            except json.JSONDecodeError as e:
                print(f"JSONè§£æé”™è¯¯: {e}")
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•é€è¡Œè¯»å–
                samples = []
                with open(label_file, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line and line != '[' and line != ']':
                            if line.endswith(','):
                                line = line[:-1]
                            try:
                                sample = json.loads(line)
                                samples.append(sample)
                            except json.JSONDecodeError:
                                continue
        
        print(f"âœ… åŠ è½½äº† {split} é›†çš„ {len(samples)} ä¸ªæ ·æœ¬")
        return samples
    
    def categorize_by_template_pattern(self, samples):
        """ä½¿ç”¨æ¨¡æ¿æ¨¡å¼åŒ¹é…æ¥åˆ†ç±»æ ·æœ¬"""
        categories = {
            'move_object': {
                'patterns': [
                    "Moving [something]",
                    "Pushing [something]",
                    "Pulling [something]",
                    "Moving [something] from left to right",
                    "Moving [something] from right to left",
                    "Pushing [something] from left to right",
                    "Pushing [something] from right to left",
                    "Pulling [something] from left to right", 
                    "Pulling [something] from right to left",
                    "Moving [something] up",
                    "Moving [something] down"
                ],
                'samples': []
            },
            'drop_object': {
                'patterns': [
                    "Dropping [something]",
                    "Letting [something] fall",
                    "Lifting [something] up completely, then letting it drop down",
                    "Dropping [something] onto [something]",
                    "Dropping [something] behind [something]",
                    "Dropping [something] in front of [something]",
                    "Dropping [something] into [something]",
                    "Dropping [something] next to [something]"
                ],
                'samples': []
            },
            'cover_object': {
                'patterns': [
                    "Covering [something] with [something]",
                    "Putting [something] on [something]",
                    "Putting [something] onto [something]",
                    "Putting [something] on top of [something]",
                    "Placing [something] on [something]"
                ],
                'samples': []
            }
        }
        
        # åˆ†ç±»æ ·æœ¬
        for sample in samples:
            template = sample.get('template', '')
            label = sample.get('label', '').lower()
            
            matched = False
            for category, info in categories.items():
                for pattern in info['patterns']:
                    # æ£€æŸ¥æ¨¡æ¿æ˜¯å¦åŒ…å«æ¨¡å¼ï¼Œæˆ–è€…æ ‡ç­¾æ˜¯å¦åŒ…å«å…³é”®è¯
                    if pattern.lower() in template.lower() or self.contains_keywords(label, category):
                        info['samples'].append(sample)
                        matched = True
                        break
                if matched:
                    break
        
        # æ‰“å°åˆ†ç±»ç»“æœ
        print("\n=== æ ·æœ¬åˆ†ç±»ç»“æœ ===")
        for category, info in categories.items():
            print(f"{category}: {len(info['samples'])} ä¸ªæ ·æœ¬")
            # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬çš„æ¨¡æ¿
            for sample in info['samples'][:3]:
                print(f"  - {sample['template']}")
        
        return categories
    
    def contains_keywords(self, label, category):
        """æ£€æŸ¥æ ‡ç­¾æ˜¯å¦åŒ…å«ç±»åˆ«çš„å…³é”®è¯"""
        keywords = {
            'move_object': ['moving', 'pushing', 'pulling', 'sliding'],
            'drop_object': ['dropping', 'falling', 'letting fall'],
            'cover_object': ['covering', 'putting on', 'placing on', 'on top of']
        }
        
        return any(keyword in label for keyword in keywords.get(category, []))
    
    def select_samples(self, categorized_samples, samples_per_category=100):
        """é€‰æ‹©æ ·æœ¬"""
        selected_samples = {}
        
        for category, info in categorized_samples.items():
            available_samples = info['samples']
            if len(available_samples) >= samples_per_category:
                selected = random.sample(available_samples, samples_per_category)
            else:
                selected = available_samples
                print(f"âš ï¸  {category} åªæœ‰ {len(available_samples)} ä¸ªæ ·æœ¬ï¼Œå°‘äºè¦æ±‚çš„ {samples_per_category}")
            
            selected_samples[category] = selected
            print(f"âœ… {category}: é€‰æ‹©äº† {len(selected)} ä¸ªæ ·æœ¬")
        
        return selected_samples
    
    def extract_frames(self, video_path, num_frames=25):
        """æå–è§†é¢‘å¸§ - æå–25å¸§ï¼Œä½¿ç”¨å‰20å¸§ä½œä¸ºè¾“å…¥ï¼Œç¬¬25å¸§ä½œä¸ºç›®æ ‡"""
        try:
            cap = cv2.VideoCapture(str(video_path))
            if not cap.isOpened():
                return None
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            if total_frames < num_frames:
                return None
            
            # å‡åŒ€æå–25å¸§
            frame_indices = np.linspace(0, total_frames-1, num_frames, dtype=int)
            
            frames = []
            for idx in frame_indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
                ret, frame = cap.read()
                if ret:
                    # ä½¿ç”¨é«˜è´¨é‡æ’å€¼æ–¹æ³•ä¸Šé‡‡æ ·åˆ°512x512
                    frame_resized = cv2.resize(frame, self.target_size, interpolation=cv2.INTER_LANCZOS4)
                    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
                    frames.append(frame_rgb)
                else:
                    return None
            
            cap.release()
            return frames
            
        except Exception as e:
            print(f"å¤„ç†è§†é¢‘å¤±è´¥ {video_path.name}: {e}")
            return None
    
    def process_samples_with_retry(self, categorized_samples, target_per_category=200):
        """å¤„ç†æ ·æœ¬ï¼Œå¦‚æœå¤±è´¥åˆ™è‡ªåŠ¨è¡¥è¶³"""
        all_samples = []
        processed_videos = set()  # è®°å½•å·²å¤„ç†çš„è§†é¢‘ID
        
        # é¦–å…ˆæ£€æŸ¥å·²å­˜åœ¨çš„æ ·æœ¬
        existing_samples = self.load_existing_samples()
        for sample in existing_samples:
            all_samples.append(sample)
            processed_videos.add(sample['video_id'])
        
        print(f"å·²åŠ è½½ {len(existing_samples)} ä¸ªç°æœ‰æ ·æœ¬")
        
        # å¤„ç†æ¯ä¸ªç±»åˆ«ç›´åˆ°è¾¾åˆ°ç›®æ ‡æ•°é‡
        for category, info in categorized_samples.items():
            print(f"\nå¤„ç†ç±»åˆ«: {category}")
            
            # è®¡ç®—å½“å‰å·²æœ‰çš„æ ·æœ¬æ•°é‡
            current_count = len([s for s in all_samples if s['category'] == category])
            print(f"å½“å‰å·²æœ‰ {current_count} ä¸ªæ ·æœ¬ï¼Œç›®æ ‡ {target_per_category} ä¸ª")
            
            if current_count >= target_per_category:
                print(f"âœ… {category} å·²è¾¾åˆ°ç›®æ ‡æ•°é‡")
                continue
            
            # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰æ ·æœ¬ï¼Œæ’é™¤å·²å¤„ç†çš„
            available_samples = [s for s in info['samples'] if s['id'] not in processed_videos]
            
            if len(available_samples) == 0:
                print(f"âŒ {category} æ²¡æœ‰æ›´å¤šå¯ç”¨æ ·æœ¬")
                continue
            
            # éšæœºæ‰“ä¹±å¯ç”¨æ ·æœ¬
            random.shuffle(available_samples)
            
            processed_count = current_count
            batch_size = min(50, len(available_samples))  # æ¯æ¬¡å¤„ç†ä¸€æ‰¹
            
            for batch_start in range(0, len(available_samples), batch_size):
                if processed_count >= target_per_category:
                    break
                    
                batch = available_samples[batch_start:batch_start + batch_size]
                print(f"  å¤„ç†æ‰¹æ¬¡ {batch_start//batch_size + 1}, æ ·æœ¬ {len(batch)} ä¸ª")
                
                for i, sample in enumerate(batch):
                    if processed_count >= target_per_category:
                        break
                        
                    video_id = sample['id']
                    video_path = self.video_dir / f"{video_id}.webm"
                    
                    if not video_path.exists():
                        print(f"    âš ï¸  è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                        processed_videos.add(video_id)
                        continue
                    
                    print(f"    [{processed_count+1}/{target_per_category}] å¤„ç†: {video_id}")
                    
                    # æå–25å¸§ï¼šå‰20å¸§ä½œä¸ºè¾“å…¥ï¼Œç¬¬25å¸§ä½œä¸ºç›®æ ‡ï¼ˆè·³è¿‡21-24å¸§ï¼‰
                    frames = self.extract_frames(video_path, num_frames=25)
                    
                    if frames and len(frames) >= 25:
                        # ä¿å­˜å¸§æ•°æ® - å‰20å¸§ä½œä¸ºè¾“å…¥ï¼Œç¬¬25å¸§ä½œä¸ºç›®æ ‡
                        input_frames = np.array(frames[:20])  # å‰20å¸§ä½œä¸ºè¾“å…¥
                        target_frame = np.array(frames[24])   # ç¬¬25å¸§ä½œä¸ºç›®æ ‡ï¼ˆè·³è¿‡ä¸­é—´4å¸§ï¼‰
                        
                        input_path = self.output_dir / "frames" / category / f"{video_id}_input.npy"
                        target_path = self.output_dir / "frames" / category / f"{video_id}_target.npy"
                        
                        np.save(input_path, input_frames)
                        np.save(target_path, target_frame)
                        
                        # ä¿å­˜ç¤ºä¾‹å›¾åƒï¼ˆå¦‚æœæ˜¯è¯¥ç±»åˆ«ç¬¬ä¸€ä¸ªæˆåŠŸæ ·æœ¬ï¼‰
                        if processed_count == 0 and len([s for s in all_samples if s['category'] == category]) == 0:
                            sample_dir = self.output_dir / "samples" / category
                            sample_dir.mkdir(parents=True, exist_ok=True)
                            
                            cv2.imwrite(str(sample_dir / "input_frame_0.jpg"), 
                                       cv2.cvtColor(frames[0], cv2.COLOR_RGB2BGR))
                            cv2.imwrite(str(sample_dir / "target_frame.jpg"), 
                                       cv2.cvtColor(frames[24], cv2.COLOR_RGB2BGR))  # ç¬¬25å¸§ä½œä¸ºç›®æ ‡
                        
                        processed_sample = {
                            'category': category,
                            'video_id': video_id,
                            'video_path': str(video_path),
                            'input_frames_path': str(input_path),
                            'target_frame_path': str(target_path),
                            'template': sample['template'],
                            'label': sample['label'],
                            'placeholders': sample.get('placeholders', []),
                            'resolution': f"{self.target_size[0]}x{self.target_size[1]}"  # æ·»åŠ åˆ†è¾¨ç‡ä¿¡æ¯
                        }
                        
                        all_samples.append(processed_sample)
                        processed_videos.add(video_id)
                        processed_count += 1
                    else:
                        print(f"    âš ï¸  æ— æ³•æå–å¸§: {video_id}")
                        processed_videos.add(video_id)
                
                # æ¯å¤„ç†å®Œä¸€ä¸ªæ‰¹æ¬¡å°±ä¿å­˜ä¸€æ¬¡å…ƒæ•°æ®
                self.save_metadata(all_samples)
            
            print(f"âœ… {category}: æˆåŠŸå¤„ç† {processed_count} ä¸ªè§†é¢‘")
        
        return all_samples
    
    def load_existing_samples(self):
        """åŠ è½½å·²å­˜åœ¨çš„æ ·æœ¬"""
        existing_samples = []
        metadata_file = self.output_dir / "metadata" / "all_samples.csv"
        
        if metadata_file.exists():
            try:
                df = pd.read_csv(metadata_file)
                for _, row in df.iterrows():
                    sample = {
                        'category': row['category'],
                        'video_id': row['video_id'],
                        'video_path': row['video_path'],
                        'input_frames_path': row['input_frames_path'],
                        'target_frame_path': row['target_frame_path'],
                        'template': row.get('template', ''),
                        'label': row.get('label', ''),
                        'placeholders': eval(row.get('placeholders', '[]')) if isinstance(row.get('placeholders', ''), str) else [],
                        'resolution': row.get('resolution', '512x512')
                    }
                    existing_samples.append(sample)
                print(f"âœ… åŠ è½½äº† {len(existing_samples)} ä¸ªç°æœ‰æ ·æœ¬")
            except Exception as e:
                print(f"âš ï¸  åŠ è½½ç°æœ‰æ ·æœ¬å¤±è´¥: {e}")
        
        return existing_samples
    
    def save_metadata(self, all_samples):
        """ä¿å­˜å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼ˆ8:1:1æ¯”ä¾‹ï¼‰"""
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ ·æœ¬è¿›è¡Œåˆ’åˆ†
        if len(all_samples) < 10:
            print(f"âš ï¸  æ ·æœ¬æ•°é‡ä¸è¶³ {len(all_samples)}ï¼Œæ— æ³•åˆ’åˆ†æ•°æ®é›†")
            return
        
        # éšæœºæ‰“ä¹±æ‰€æœ‰æ ·æœ¬
        random.shuffle(all_samples)
        
        # æŒ‰8:1:1æ¯”ä¾‹åˆ’åˆ†æ•°æ®é›†
        total_samples = len(all_samples)
        train_count = int(0.8 * total_samples)  # 80% è®­ç»ƒé›†
        val_count = int(0.1 * total_samples)    # 10% éªŒè¯é›†
        test_count = total_samples - train_count - val_count  # 10% æµ‹è¯•é›†
        
        train_samples = all_samples[:train_count]
        val_samples = all_samples[train_count:train_count + val_count]
        test_samples = all_samples[train_count + val_count:]
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        dataset_info = {
            "name": "Something-Something V2 Processed Dataset",
            "total_samples": total_samples,
            "train_samples": len(train_samples),
            "val_samples": len(val_samples),
            "test_samples": len(test_samples),
            "split_ratio": "train:val:test = {}:{}:{}".format(len(train_samples), len(val_samples), len(test_samples)),
            "frame_info": {
                "input_frames": 20,    # å‰20å¸§ä½œä¸ºè¾“å…¥
                "target_frame": 1,     # ç¬¬25å¸§ä½œä¸ºç›®æ ‡ï¼ˆè·³è¿‡ä¸­é—´4å¸§ï¼‰
                "skip_frames": 4,      # è·³è¿‡çš„å¸§æ•°
                "resolution": f"{self.target_size[0]}x{self.target_size[1]}"  # æ›´æ–°åˆ†è¾¨ç‡
            }
        }
        
        with open(self.output_dir / "metadata" / "dataset_info.json", 'w') as f:
            json.dump(dataset_info, f, indent=2)
        
        # ä¿å­˜æ ·æœ¬æ•°æ®
        all_df = pd.DataFrame(all_samples)
        train_df = pd.DataFrame(train_samples)
        val_df = pd.DataFrame(val_samples)
        test_df = pd.DataFrame(test_samples)
        
        all_df.to_csv(self.output_dir / "metadata" / "all_samples.csv", index=False)
        train_df.to_csv(self.output_dir / "metadata" / "train_samples.csv", index=False)
        val_df.to_csv(self.output_dir / "metadata" / "val_samples.csv", index=False)
        test_df.to_csv(self.output_dir / "metadata" / "test_samples.csv", index=False)
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"\nâœ… å…ƒæ•°æ®å·²ä¿å­˜")
        print(f"   æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"   è®­ç»ƒé›†: {len(train_samples)} (80%)")
        print(f"   éªŒè¯é›†: {len(val_samples)} (10%)")
        print(f"   æµ‹è¯•é›†: {len(test_samples)} (10%)")
        print(f"   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰")
        print(f"   åˆ†è¾¨ç‡: {self.target_size[0]}x{self.target_size[1]}")
        
        # ç±»åˆ«ç»Ÿè®¡ï¼ˆæŒ‰æ•°æ®é›†åˆ’åˆ†ï¼‰
        print("\n=== æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒ ===")
        for dataset_name, dataset in [("è®­ç»ƒé›†", train_samples), ("éªŒè¯é›†", val_samples), ("æµ‹è¯•é›†", test_samples)]:
            category_counts = {}
            for sample in dataset:
                cat = sample['category']
                category_counts[cat] = category_counts.get(cat, 0) + 1
            
            print(f"\n{dataset_name} ({len(dataset)} ä¸ªæ ·æœ¬):")
            for cat, count in category_counts.items():
                print(f"  {cat}: {count} ä¸ªæ ·æœ¬")
    
    def process(self):
        """ä¸»å¤„ç†æµç¨‹"""
        print("å¼€å§‹æ•°æ®å¤„ç†...")
        print(f"ğŸ“¹ å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡ä¸­é—´4å¸§ï¼‰")
        print(f"ğŸ“ åˆ†è¾¨ç‡: {self.target_size[0]}x{self.target_size[1]}")
        
        # åŠ è½½è®­ç»ƒé›†æ ‡ç­¾
        train_samples = self.load_dataset_labels('train')
        
        # åˆ†ç±»æ ·æœ¬
        categorized_samples = self.categorize_by_template_pattern(train_samples)
        
        # å¤„ç†æ ·æœ¬å¹¶è‡ªåŠ¨è¡¥è¶³åˆ°æ¯ä¸ªç±»åˆ«2500ä¸ª
        all_samples = self.process_samples_with_retry(categorized_samples, 2500)
        
        if not all_samples:
            print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ ·æœ¬")
            return
        
        # æœ€ç»ˆä¿å­˜å…ƒæ•°æ®
        self.save_metadata(all_samples)
        
        # æœ€ç»ˆç»Ÿè®¡
        category_counts = {}
        for sample in all_samples:
            cat = sample['category']
            category_counts[cat] = category_counts.get(cat, 0) + 1
        
        print(f"\nğŸ‰ æ•°æ®å¤„ç†å®Œæˆ!")
        print(f"   æ€»å…±å¤„ç†äº† {len(all_samples)} ä¸ªæ ·æœ¬")
        print(f"   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰")
        print(f"   åˆ†è¾¨ç‡: {self.target_size[0]}x{self.target_size[1]}")
        print(f"   å„ç±»åˆ«æ•°é‡:")
        for cat, count in category_counts.items():
            print(f"     {cat}: {count} ä¸ªæ ·æœ¬")

def main():
    processor = VideoProcessor()
    processor.process()

if __name__ == "__main__":
    main()