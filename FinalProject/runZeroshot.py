#!/usr/bin/env python3
"""
ControlNet Zero-Shot Baseline é¢„æµ‹è„šæœ¬ (æœ¬åœ°æ¨¡å‹é€‚é…ç‰ˆ)
ç”¨é€”ï¼šä½¿ç”¨å®˜æ–¹æƒé‡ï¼ˆä¸å¾®è°ƒï¼‰ç›´æ¥é¢„æµ‹ï¼Œç”¨äºç”Ÿæˆå¯¹æ¯”å›¾ã€‚
"""

import torch
import cv2
import numpy as np
from pathlib import Path
from PIL import Image
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

try:
    # åªä¾èµ– diffusers + æœ¬åœ° loaderï¼›ä¸ä¾èµ– cldmï¼ˆå¦‚æ—  cldm åˆ™ç›´æ¥ä½¿ç”¨ hub æˆ– diffusers æœ¬åœ°ç›®å½•ï¼‰
    from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
    from loaderData512 import create_task_specific_loaders  # âœ… ç¡®ä¿ä½¿ç”¨ 512 æ•°æ®åŠ è½½å™¨
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


class ZeroShotPredictor:
    def __init__(self, output_dir="results_zeroshot"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        print(f"ğŸš€ Zero-Shot é¢„æµ‹æ¨¡å¼ | Device: {self.device}")

        # ================= é…ç½®è·¯å¾„ (è¯·æ ¸å¯¹è¿™é‡Œ) =================
        # 1. SD v1.5 çš„æœ¬åœ°è·¯å¾„ (å’Œè®­ç»ƒè„šæœ¬ä¿æŒä¸€è‡´)
        self.sd_model_path = str(project_root / "stable-diffusion-v1-5")
        if not os.path.exists(self.sd_model_path):
            # å…¼å®¹æ—§çš„è·¯å¾„å†™æ³•
            alt = str(project_root / "stable-diffusion-v1_5")
            if os.path.exists(alt):
                self.sd_model_path = alt
            else:
                # å°è¯•é»˜è®¤ hub åç§°ä½œä¸ºå›é€€
                self.sd_model_path = "runwayml/stable-diffusion-v1-5"

        # 2. ControlNet æœ¬åœ°ç›®å½•/æ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨é¡¹ç›®ä¸­çš„ ControlNet æ¨¡å‹ï¼‰
        # æˆ‘ä»¬ä¼šå°è¯•å‡ ç§æœ¬åœ°ä½ç½®ï¼š
        # - FinalProject/ControlNet/models/control_sd15_canny.pth
        # - FinalProject/ControlNet-v1-1/control_v11p_sd15_canny.pth (+ yaml)
        self.cn_model_dir = str(project_root / "ControlNet")
        self.cn_v11_dir = str(project_root / "ControlNet-v1-1")
        # =======================================================

        # åŠ è½½ ControlNet
        self.controlnet = self._load_controlnet()

        # åŠ è½½ SD Pipe
        print(f"ğŸ“¦ åŠ è½½ Stable Diffusion åº•åº§: {self.sd_model_path}")
        self.pipe = StableDiffusionControlNetPipeline.from_pretrained(
            self.sd_model_path,
            controlnet=self.controlnet,
            torch_dtype=torch.float16,
            safety_checker=None,
            local_files_only=True if os.path.exists(self.sd_model_path) else False
        ).to(self.device)

        # ä¼˜åŒ–è®¾ç½®
        self.pipe.scheduler = UniPCMultistepScheduler.from_config(self.pipe.scheduler.config)
        self.pipe.enable_model_cpu_offload()
        self.pipe.enable_xformers_memory_efficient_attention()

    def _load_controlnet(self):
        """åŠ è½½ ControlNetï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°è½¬æ¢å¥½çš„ diffusers æ ¼å¼ï¼Œæˆ–è€…è½¬æ¢ .pth"""
        print("ğŸ“¦ æ­£åœ¨åŠ è½½å®˜æ–¹ ControlNet Canny æƒé‡...")
        # å¦‚æœä»“åº“é‡Œåªæœ‰ cldm/.pth æ–‡ä»¶ä½†æ²¡æœ‰ cldm ç¯å¢ƒï¼Œæ— æ³•ç›´æ¥åŠ è½½ï¼›å…ˆæ£€æµ‹å¹¶æç¤º
        try:
            alt_pth = os.path.join(self.cn_model_dir, 'models', 'control_sd15_canny.pth')
            v11_pth = os.path.join(self.cn_v11_dir, 'control_v11p_sd15_canny.pth')
            if os.path.exists(alt_pth) or os.path.exists(v11_pth):
                print(f"âš ï¸ å‘ç°æœ¬åœ° .pth æ–‡ä»¶ï¼Œä½†å½“å‰ç¯å¢ƒæ²¡æœ‰ cldmï¼Œæ— æ³•ç›´æ¥ç”¨ .pth åŠ è½½: {alt_pth if os.path.exists(alt_pth) else v11_pth}")
                print("   å»ºè®®ï¼šè¦ä¹ˆå®‰è£… cldmï¼ˆå¯ç”¨ create_model/load_state_dict è½¬æ¢ï¼‰ï¼Œè¦ä¹ˆæŠŠæ¨¡å‹è½¬æ¢ä¸º diffusers æ ¼å¼åæ”¾åœ¨æœ¬åœ°ç›®å½•ã€‚è„šæœ¬å°†ç»§ç»­å°è¯•ä»æœ¬åœ° diffusers ç›®å½•æˆ– hub åŠ è½½ã€‚")
        except Exception:
            pass

        # å¦‚æœæœ¬åœ°æ²¡æœ‰å¯ç›´æ¥åŠ è½½çš„ cldm æ–‡ä»¶ï¼Œå°è¯•ç”¨ diffusers ä»æœ¬åœ°ç›®å½•ï¼ˆè‹¥å­˜åœ¨ï¼‰æˆ– hub åŠ è½½
        try:
            if os.path.exists(self.cn_v11_dir):
                # å¦‚æœå­˜åœ¨ä¸€ä¸ªå·²è½¬æ¢çš„ diffusers é£æ ¼ç›®å½•åˆ™ç›´æ¥åŠ è½½
                try:
                    print(f"ğŸ” å°è¯•ä»æœ¬åœ° diffusers é£æ ¼ç›®å½•åŠ è½½ ControlNet: {self.cn_v11_dir}")
                    return ControlNetModel.from_pretrained(self.cn_v11_dir, torch_dtype=torch.float16).to(self.device)
                except Exception:
                    pass

            if os.path.exists(self.cn_model_dir):
                try:
                    print(f"ğŸ” å°è¯•ä»æœ¬åœ° diffusers é£æ ¼ç›®å½•åŠ è½½ ControlNet: {self.cn_model_dir}")
                    return ControlNetModel.from_pretrained(self.cn_model_dir, torch_dtype=torch.float16).to(self.device)
                except Exception:
                    pass

            # æœ€åå›é€€ï¼šåœ¨çº¿åŠ è½½å®˜æ–¹é¢„è®­ç»ƒçš„ sd-controlnet-canny
            print("ğŸŒ å›é€€åˆ°åœ¨çº¿åŠ è½½ lllyasviel/sd-controlnet-canny")
            return ControlNetModel.from_pretrained(
                "lllyasviel/sd-controlnet-canny",
                torch_dtype=torch.float16,
                local_files_only=False
            ).to(self.device)
        except Exception as e:
            print(f"âŒ ä¸¥é‡é”™è¯¯: æ— æ³•åŠ è½½ Canny ControlNet æ¨¡å‹: {e}")
            raise

    def get_canny_image(self, tensor_img):
        # è½¬æ¢é€»è¾‘ä¿æŒä¸å˜ï¼Œç¡®ä¿å¤„ç†çš„æ˜¯ 512 å›¾
        img = tensor_img.squeeze(0).permute(1, 2, 0).cpu().numpy()
        if img.min() < 0:
            img = (img + 1) / 2
        img = (img * 255).astype(np.uint8)
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        edge = cv2.Canny(gray, 100, 200)
        edge = np.stack([edge] * 3, axis=-1)
        return Image.fromarray(edge), Image.fromarray(img)

    def run_prediction(self, dataloader, task_name, num_samples=20):
        # ... (å’Œä¹‹å‰çš„é€»è¾‘å®Œå…¨ä¸€è‡´ï¼Œä»£ç çœç•¥ä»¥èŠ‚çœç¯‡å¹…ï¼Œç›´æ¥ç”¨ä¸Šé¢çš„ run_prediction å³å¯) ...
        # è¿™é‡ŒæŠŠ run_prediction çš„ä»£ç å®Œæ•´ç²˜è´´è¿‡æ¥
        print(f"\nğŸ¨ å¼€å§‹ä»»åŠ¡ {task_name} çš„ Zero-Shot é¢„æµ‹...")
        save_path = self.output_dir / task_name
        save_path.mkdir(exist_ok=True)

        count = 0
        for batch in dataloader:
            if count >= num_samples: break

            # ç¡®ä¿åªå– Frame 20
            frame_20_batch = batch['input_frames'][:, -1]
            target_batch = batch['target_frame']
            prompts = batch.get('label_text', ['moving object'] * len(frame_20_batch))

            for i in range(len(frame_20_batch)):
                if count >= num_samples: break

                canny_pil, frame_20_pil = self.get_canny_image(frame_20_batch[i:i + 1])

                gt_np = target_batch[i].permute(1, 2, 0).cpu().numpy()
                if gt_np.min() < 0: gt_np = (gt_np + 1) / 2
                gt_pil = Image.fromarray((gt_np * 255).astype(np.uint8))

                seed = torch.Generator(device="cpu").manual_seed(42)

                with torch.inference_mode():
                    output_image = self.pipe(
                        prompt=prompts[i],
                        image=canny_pil,
                        num_inference_steps=20,
                        guidance_scale=7.5,
                        generator=seed
                    ).images[0]

                w, h = 512, 512
                grid = Image.new('RGB', (w * 4, h))
                grid.paste(frame_20_pil, (0, 0))
                grid.paste(canny_pil, (w, 0))
                grid.paste(output_image, (w * 2, 0))
                grid.paste(gt_pil, (w * 3, 0))

                file_name = f"sample_{count:03d}.jpg"
                grid.save(save_path / file_name)
                count += 1
                print(f"âœ… å·²ä¿å­˜: {task_name}/{file_name}")


def main():
    batch_size = 4
    num_samples_to_visualize = 20  # è·‘ 20 å¼ æ¥çœ‹çœ‹å°±è¡Œ
    tasks = ['move_object', 'drop_object', 'cover_object']

    predictor = ZeroShotPredictor()

    for task in tasks:
        try:
            # âœ… è¿™é‡Œè°ƒç”¨çš„æ˜¯ loaderData512ï¼Œä¿è¯åŠ è½½çš„æ˜¯ 512 æ•°æ®
            # ä¸”åŠ è½½çš„æ˜¯ test_loader (æµ‹è¯•é›†)
            _, _, test_loader = create_task_specific_loaders(
                task_name=task,
                batch_size=batch_size,
                data_path="processed_data_512"
            )

            if len(test_loader) == 0: continue
            predictor.run_prediction(test_loader, task, num_samples_to_visualize)

        except Exception as e:
            print(f"âŒ ä»»åŠ¡ {task} å‡ºé”™: {e}")


if __name__ == "__main__":
    main()