#!/usr/bin/env python3
"""
PyTorchæ•°æ®åŠ è½½å™¨ - ç”¨äºå¸§é¢„æµ‹ä»»åŠ¡
"""

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd
from pathlib import Path
import torchvision.transforms as transforms

class FramePredictionDataset(Dataset):
    def __init__(self, metadata_file, transform=None):
        """
        å¸§é¢„æµ‹æ•°æ®é›†ç±»
        
        Args:
            metadata_file: å…ƒæ•°æ®CSVæ–‡ä»¶è·¯å¾„
            transform: æ•°æ®å˜æ¢
        """
        self.metadata = pd.read_csv(metadata_file)
        self.transform = transform
        
        # æ‰“å°æ•°æ®é›†ä¿¡æ¯
        print(f"âœ… åŠ è½½æ•°æ®é›†: {len(self.metadata)} ä¸ªæ ·æœ¬")
        category_counts = self.metadata['category'].value_counts()
        for category, count in category_counts.items():
            print(f"   {category}: {count} ä¸ªæ ·æœ¬")
    
    def __len__(self):
        return len(self.metadata)
    
    def __getitem__(self, idx):
        sample = self.metadata.iloc[idx]
        
        try:
            # åŠ è½½è¾“å…¥å¸§ï¼ˆå‰20å¸§ï¼‰
            input_frames = np.load(sample['input_frames_path'])  # (20, 96, 96, 3)
            # åŠ è½½ç›®æ ‡å¸§ï¼ˆç¬¬21å¸§ï¼‰
            target_frame = np.load(sample['target_frame_path'])  # (96, 96, 3)
            
            # è½¬æ¢ä¸ºPyTorchå¼ é‡
            input_frames = torch.from_numpy(input_frames).float()
            target_frame = torch.from_numpy(target_frame).float()
            
            # è°ƒæ•´ç»´åº¦é¡ºåº: (T, H, W, C) -> (T, C, H, W)
            input_frames = input_frames.permute(0, 3, 1, 2)  # (20, 3, 96, 96)
            target_frame = target_frame.permute(2, 0, 1)     # (3, 96, 96)
            
            # å½’ä¸€åŒ–åˆ° [0, 1] (å¦‚æœæ•°æ®åœ¨0-255èŒƒå›´å†…)
            input_frames = input_frames / 255.0
            target_frame = target_frame / 255.0
            
            # åº”ç”¨æ•°æ®å˜æ¢ï¼ˆå¦‚æœæœ‰ï¼‰
            if self.transform:
                input_frames = self.transform(input_frames)
                target_frame = self.transform(target_frame)
            
            return {
                'input_frames': input_frames,
                'target_frame': target_frame,
                'category': sample['category'],
                'video_id': sample['video_id'],
                'template': sample['template'],
                'label_text': sample['label']
            }
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ ·æœ¬å¤±è´¥ {sample['video_id']}: {e}")
            # è¿”å›ä¸€ä¸ªç©ºæ ·æœ¬æˆ–è·³è¿‡
            return None
    
    def get_category_indices(self, category):
        """è·å–ç‰¹å®šç±»åˆ«çš„æ‰€æœ‰ç´¢å¼•"""
        return self.metadata[self.metadata['category'] == category].index.tolist()

def create_data_loaders(batch_size=8, data_path="processed_data", num_workers=4):
    """
    åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨
    
    Args:
        batch_size: æ‰¹æ¬¡å¤§å°
        data_path: å¤„ç†æ•°æ®çš„è·¯å¾„
        num_workers: æ•°æ®åŠ è½½çš„è¿›ç¨‹æ•°
    """
    
    # æ•°æ®å˜æ¢ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ•°æ®å¢å¼ºï¼‰
    transform = transforms.Compose([
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ•°æ®å¢å¼ºï¼Œå¦‚éšæœºç¿»è½¬ç­‰
        # transforms.RandomHorizontalFlip(p=0.5),
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = FramePredictionDataset(
        f"{data_path}/metadata/train_samples.csv", 
        transform=transform
    )
    val_dataset = FramePredictionDataset(
        f"{data_path}/metadata/val_samples.csv"
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=True  # åŠ é€ŸGPUæ•°æ®ä¼ è¾“
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=True
    )
    
    print(f"âœ… åˆ›å»ºæ•°æ®åŠ è½½å™¨å®Œæˆ")
    print(f"   è®­ç»ƒé›†: {len(train_dataset)} ä¸ªæ ·æœ¬, {len(train_loader)} ä¸ªæ‰¹æ¬¡")
    print(f"   éªŒè¯é›†: {len(val_dataset)} ä¸ªæ ·æœ¬, {len(val_loader)} ä¸ªæ‰¹æ¬¡")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    return train_loader, val_loader

def test_data_loader():
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    print("æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
    
    train_loader, val_loader = create_data_loaders(batch_size=4)
    
    # æµ‹è¯•ä¸€ä¸ªè®­ç»ƒæ‰¹æ¬¡
    for batch_idx, batch in enumerate(train_loader):
        if batch_idx >= 1:  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
            break
            
        print(f"\n=== æ‰¹æ¬¡ {batch_idx} ===")
        print(f"è¾“å…¥å¸§å½¢çŠ¶: {batch['input_frames'].shape}")  # (4, 20, 3, 96, 96)
        print(f"ç›®æ ‡å¸§å½¢çŠ¶: {batch['target_frame'].shape}")  # (4, 3, 96, 96)
        print(f"æ•°æ®èŒƒå›´: [{batch['input_frames'].min():.3f}, {batch['input_frames'].max():.3f}]")
        print(f"ç±»åˆ«: {batch['category'][:2]}")  # æ˜¾ç¤ºå‰2ä¸ªç±»åˆ«
        print(f"è§†é¢‘ID: {batch['video_id'][:2]}")  # æ˜¾ç¤ºå‰2ä¸ªID
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
        assert 0.0 <= batch['input_frames'].min() <= batch['input_frames'].max() <= 1.0
        assert 0.0 <= batch['target_frame'].min() <= batch['target_frame'].max() <= 1.0
    
    print("\nğŸ‰ æ•°æ®åŠ è½½å™¨æµ‹è¯•é€šè¿‡!")

if __name__ == "__main__":
    test_data_loader()