#!/usr/bin/env python3
"""
ControlNet 1.1 ä¿®å¤ç‰ˆè®­ç»ƒè„šæœ¬
è§£å†³è®­ç»ƒlosså¼‚å¸¸é«˜çš„é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset, ConcatDataset
import torch.optim as optim
import cv2
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import sys
import os
import gc
import time
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

try:
    from diffusers import DDPMScheduler, AutoencoderKL, UNet2DConditionModel
    from transformers import CLIPTokenizer, CLIPTextModel
    from loaderData import create_task_specific_loaders
    
    try:
        from cldm.model import create_model, load_state_dict
        CONTROLNET_AVAILABLE = True
        print("âœ… æˆåŠŸå¯¼å…¥ControlNetæ¨¡å—")
    except ImportError as e:
        print(f"âš ï¸  æ— æ³•å¯¼å…¥cldm: {e}")
        CONTROLNET_AVAILABLE = False
        
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

class FixedControlNetTrainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.task_name = config.get('task_name', 'unknown_task')
        
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ¯ ä»»åŠ¡: {self.task_name}")
        
        # è®­ç»ƒçŠ¶æ€
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        self.max_patience = config.get('patience', 10)
        
        # æ¢¯åº¦ç¼©æ”¾å™¨
        self.scaler = torch.amp.GradScaler('cuda')
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.setup_models()
        self.setup_optimizers()
        
    def setup_models(self):
        """æ¨¡å‹åˆå§‹åŒ–"""
        print("ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...")
        
        # 1. åŠ è½½ç»„ä»¶
        self.tokenizer = CLIPTokenizer.from_pretrained("stable-diffusion-v1-5/tokenizer", local_files_only=True)
        self.text_encoder = CLIPTextModel.from_pretrained("stable-diffusion-v1-5/text_encoder", local_files_only=True).to(self.device)
        self.vae = AutoencoderKL.from_pretrained("stable-diffusion-v1-5/vae", local_files_only=True).to(self.device)
        self.unet = UNet2DConditionModel.from_pretrained("stable-diffusion-v1-5/unet", local_files_only=True).to(self.device)
        self.noise_scheduler = DDPMScheduler.from_pretrained("stable-diffusion-v1-5/scheduler", local_files_only=True)
        
        # 2. åŠ è½½ ControlNet
        self.controlnet = self.load_controlnet().to(self.device)
        
        # 3. å†»ç»“å‚æ•°
        self.text_encoder.requires_grad_(False)
        self.vae.requires_grad_(False)
        self.unet.requires_grad_(False)
        self.controlnet.requires_grad_(True)
        
        # æ‰“å°å‚æ•°é‡
        trainable_params = sum(p.numel() for p in self.controlnet.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in self.controlnet.parameters())
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå¯è®­ç»ƒå‚æ•°: {trainable_params:,} / æ€»å‚æ•°: {total_params:,}")

    def load_controlnet(self):
        """åŠ è½½ControlNetæ¨¡å‹"""
        try:
            if CONTROLNET_AVAILABLE:
                controlnet_dir = Path("ControlNet-v1-1")
                model_path = controlnet_dir / "control_sd15_canny.pth"
                config_path = controlnet_dir / "cldm_v15.yaml"
                
                if model_path.exists():
                    print(f"ğŸ“‚ åŠ è½½é¢„è®­ç»ƒæƒé‡: {model_path}")
                    model = create_model(str(config_path)).to(self.device)
                    model.load_state_dict(load_state_dict(str(model_path), location='cpu'))
                    return model.control_model
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œå°†å°è¯•ä»UNetåˆå§‹åŒ–")
            
            # å¤‡é€‰æ–¹æ¡ˆï¼šä» UNet åˆå§‹åŒ–
            from diffusers import ControlNetModel
            print("ğŸ†• ä» UNet å¤åˆ¶æƒé‡åˆå§‹åŒ– ControlNet")
            controlnet = ControlNetModel.from_unet(self.unet, conditioning_channels=3)
            return controlnet
                
        except Exception as e:
            print(f"âŒ åŠ è½½ControlNetå¤±è´¥: {e}")
            raise

    def setup_optimizers(self):
        """ä¼˜åŒ–å™¨é…ç½®"""
        # ä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡
        no_decay = ["bias", "LayerNorm.weight"]
        optimizer_grouped_parameters = [
            {
                "params": [p for n, p in self.controlnet.named_parameters() 
                          if not any(nd in n for nd in no_decay) and p.requires_grad],
                "weight_decay": self.config.get('weight_decay', 1e-2),
                "lr": self.config.get('learning_rate', 1e-5),
            },
            {
                "params": [p for n, p in self.controlnet.named_parameters() 
                          if any(nd in n for nd in no_decay) and p.requires_grad],
                "weight_decay": 0.0,
                "lr": self.config.get('learning_rate', 1e-5),
            },
        ]
        
        self.optimizer = optim.AdamW(
            optimizer_grouped_parameters,
            betas=(0.9, 0.999),
            eps=1e-8
        )
        
        # ä½¿ç”¨ç®€å•çš„ä½™å¼¦é€€ç«
        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, 
            T_max=self.config.get('num_epochs', 50),
            eta_min=1e-6
        )

    def get_canny_edges(self, image_tensor, training=False):
        """
        Cannyè¾¹ç¼˜æ£€æµ‹
        """
        images_np = image_tensor.permute(0, 2, 3, 1).cpu().numpy()
        
        # ç¡®ä¿è¾“å…¥åœ¨ [0, 1] èŒƒå›´å†…
        if torch.max(image_tensor) > 1.0:
            images_np = ((images_np + 1.0) * 127.5).astype(np.uint8)
        else:
            images_np = (images_np * 255).astype(np.uint8)
        
        edges_list = []
        for i in range(images_np.shape[0]):
            img_gray = cv2.cvtColor(images_np[i], cv2.COLOR_RGB2GRAY)
            
            # ä½¿ç”¨å›ºå®šçš„Cannyé˜ˆå€¼ä»¥ç¡®ä¿ä¸€è‡´æ€§
            v = np.median(img_gray)
            lower = int(max(50, 0.5 * v))
            upper = int(min(200, 1.5 * v))
            edge = cv2.Canny(img_gray, lower, upper)
            
            # æ‰©å±•å›3é€šé“
            edge = np.stack([edge] * 3, axis=-1)
            edges_list.append(edge)
            
        edges_np = np.stack(edges_list)
        edges_tensor = torch.from_numpy(edges_np).float() / 255.0
        return edges_tensor.permute(0, 3, 1, 2).to(self.device)

    def compute_loss(self, batch, training=True):
        """ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° - ç¡®ä¿è®­ç»ƒå’ŒéªŒè¯ä½¿ç”¨ç›¸åŒçš„è®¡ç®—æ–¹å¼"""
        # 1. å‡†å¤‡æ•°æ®
        current_frame_20 = batch['input_frames'][:, -1].to(self.device) 
        target_frame_25 = batch['target_frame'].to(self.device)
        text_descriptions = batch.get('label_text', ['interaction'] * len(current_frame_20))
        
        # 2. VAEç¼–ç ç›®æ ‡å›¾
        target_latents = self.vae.encode(target_frame_25 * 2.0 - 1.0).latent_dist.sample()
        target_latents = target_latents * self.vae.config.scaling_factor
        
        # 3. CLIPç¼–ç æ–‡æœ¬
        inputs = self.tokenizer(
            text_descriptions, 
            max_length=77, 
            padding="max_length", 
            truncation=True, 
            return_tensors="pt"
        ).to(self.device)
        encoder_hidden_states = self.text_encoder(inputs.input_ids)[0]
        
        # 4. å‡†å¤‡ControlNetæ¡ä»¶
        control_cond = self.get_canny_edges(current_frame_20, training=training)
        
        # 5. é‡‡æ ·timestepå’Œå™ªå£° - ä½¿ç”¨å›ºå®šçš„å…¨èŒƒå›´
        timesteps = torch.randint(
            0, 
            self.noise_scheduler.config.num_train_timesteps, 
            (target_latents.shape[0],), 
            device=self.device
        ).long()
        
        noise = torch.randn_like(target_latents)
        noisy_latents = self.noise_scheduler.add_noise(target_latents, noise, timesteps)
        
        # 6. ControlNetå‰å‘
        down_block_res_samples, mid_block_res_sample = self.controlnet(
            noisy_latents,
            timesteps,
            encoder_hidden_states=encoder_hidden_states,
            controlnet_cond=control_cond,
            return_dict=False,
        )
        
        # 7. UNeté¢„æµ‹
        noise_pred = self.unet(
            noisy_latents,
            timesteps,
            encoder_hidden_states=encoder_hidden_states,
            down_block_additional_residuals=down_block_res_samples,
            mid_block_additional_residual=mid_block_res_sample,
        ).sample
        
        # 8. è®¡ç®—æŸå¤± - ç§»é™¤äº†L2æ­£åˆ™åŒ–ï¼Œä¸éªŒè¯ä¿æŒä¸€è‡´
        loss = F.mse_loss(noise_pred, noise)
        
        return loss

    def train_epoch(self, train_loader, epoch):
        """ä¿®å¤çš„è®­ç»ƒepoch"""
        self.controlnet.train()
        total_loss = 0
        num_batches = 0
        
        accumulation_steps = self.config.get('accumulation_steps', 2)
        
        for batch_idx, batch in enumerate(train_loader):
            if batch is None: 
                continue
                
            # é‡ç½®æ¢¯åº¦
            self.optimizer.zero_grad()
            
            try:
                # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦
                with torch.amp.autocast('cuda'):
                    loss = self.compute_loss(batch, training=True)
                
                # æ¢¯åº¦ç´¯ç§¯
                loss = loss / accumulation_steps
                
                # åå‘ä¼ æ’­
                self.scaler.scale(loss).backward()
                
                if (batch_idx + 1) % accumulation_steps == 0:
                    # æ¢¯åº¦è£å‰ª
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.controlnet.parameters(), max_norm=1.0)
                    
                    # ä¼˜åŒ–å™¨æ­¥è¿›
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()
                
                # è®°å½•æŸå¤±
                loss_value = loss.item() * accumulation_steps
                total_loss += loss_value
                num_batches += 1
                
                # æ‰“å°è¿›åº¦
                if batch_idx % 10 == 0:
                    current_lr = self.optimizer.param_groups[0]['lr']
                    print(f"Epoch {epoch} | Batch {batch_idx}/{len(train_loader)} | "
                          f"Loss: {loss_value:.6f} | LR: {current_lr:.2e}")
                
                # æ¸…ç†æ˜¾å­˜
                if batch_idx % 20 == 0 and self.device.type == 'cuda':
                    torch.cuda.empty_cache()
                    
            except Exception as e:
                print(f"âŒ è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                continue
        
        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')
        print(f"âœ… ç¬¬ {epoch} è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
        return avg_loss

    def validate(self, val_loader):
        """ä¿®å¤çš„éªŒè¯å‡½æ•° - ä¸è®­ç»ƒä½¿ç”¨ç›¸åŒçš„æŸå¤±è®¡ç®—æ–¹å¼"""
        self.controlnet.eval()
        total_loss = 0.0
        num_batches = 0
        
        print(f"ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ {len(val_loader)} ä¸ªæ‰¹æ¬¡")
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                if batch is None:
                    continue
                
                try:
                    with torch.amp.autocast('cuda'):
                        loss = self.compute_loss(batch, training=False)
                    
                    loss_value = loss.item()
                    total_loss += loss_value
                    num_batches += 1
                    
                    if batch_idx % 5 == 0:
                        print(f"éªŒè¯æ‰¹æ¬¡ {batch_idx}/{len(val_loader)} | Loss: {loss_value:.6f}")
                        
                except Exception as e:
                    print(f"âŒ éªŒè¯æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    continue
        
        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')
        print(f"âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
        return avg_loss

    def save_checkpoint(self, epoch, task_name, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(exist_ok=True, parents=True)
        
        if is_best:
            save_path = output_dir / f"controlnet_{task_name}_best.pth"
        else:
            save_path = output_dir / f"controlnet_{task_name}_epoch_{epoch}.pth"
            
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.controlnet.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'lr_scheduler_state_dict': self.lr_scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'config': self.config
        }
        
        torch.save(checkpoint, save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}")

    def plot_and_save_losses(self, train_losses, val_losses=None):
        """ç»˜åˆ¶è®­ç»ƒ/éªŒè¯æŸå¤±"""
        try:
            output_dir = Path(self.config['output_dir'])
            output_dir.mkdir(parents=True, exist_ok=True)

            plt.figure(figsize=(10, 6))
            epochs = list(range(1, len(train_losses) + 1))
            
            plt.plot(epochs, train_losses, marker='o', color='tab:blue', label='Train Loss', linewidth=2)
            if val_losses is not None and len(val_losses) == len(train_losses):
                plt.plot(epochs, val_losses, marker='s', color='tab:orange', label='Val Loss', linewidth=2)
                
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title(f'Training / Validation Loss - {self.task_name}')
            plt.grid(alpha=0.3)
            plt.legend()
            
            save_path = output_dir / f'training_val_loss_{self.task_name}.png'
            plt.savefig(save_path, dpi=200, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“ˆ Loss å›¾å·²ä¿å­˜: {save_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ Loss å›¾å¤±è´¥: {e}")

    def train(self, train_loader, val_loader):
        """ä¿®å¤çš„è®­ç»ƒå¾ªç¯"""
        print("ğŸš€ å¼€å§‹ä¿®å¤ç‰ˆè®­ç»ƒ...")
        
        train_losses = []
        val_losses = []
        
        # åˆå§‹éªŒè¯
        print("\nğŸ” è¿›è¡Œåˆå§‹éªŒè¯...")
        initial_val_loss = self.validate(val_loader)
        print(f"åˆå§‹éªŒè¯æŸå¤±: {initial_val_loss:.6f}")
        
        for epoch in range(1, self.config['num_epochs'] + 1):
            epoch_start_time = time.time()
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(train_loader, epoch)
            train_losses.append(train_loss)
            
            # éªŒè¯
            val_loss = self.validate(val_loader)
            val_losses.append(val_loss)
            
            epoch_time = time.time() - epoch_start_time
            current_lr = self.optimizer.param_groups[0]['lr']
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š Epoch {epoch}/{self.config['num_epochs']} å®Œæˆ")
            print(f"   Train Loss: {train_loss:.6f}")
            print(f"   Val Loss: {val_loss:.6f}")
            print(f"   LR: {current_lr:.2e} | Time: {epoch_time:.1f}s")
            print(f"{'='*60}")
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.lr_scheduler.step()
            
            # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
                self.save_checkpoint(epoch, self.config['task_name'], is_best=True)
                print(f"ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: {val_loss:.6f}")
            else:
                self.patience_counter += 1
                print(f"â³ æ—©åœè®¡æ•°: {self.patience_counter}/{self.max_patience}")
            
            # å®šæœŸä¿å­˜
            if epoch % self.config['save_interval'] == 0:
                self.save_checkpoint(epoch, self.config['task_name'])
            
            # æ—©åœæ£€æŸ¥
            if self.patience_counter >= self.max_patience:
                print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨ epoch {epoch} åœæ­¢è®­ç»ƒ")
                break
            
            # æ¸…ç†æ˜¾å­˜
            if self.device.type == 'cuda':
                torch.cuda.empty_cache()
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹å’ŒæŸå¤±æ›²çº¿
        self.save_checkpoint(self.config['num_epochs'], self.config['task_name'])
        self.plot_and_save_losses(train_losses, val_losses)
        
        print(f"\nğŸ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.6f}")

def main():
    # ä¿®å¤çš„é…ç½® - ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°
    config = {
        'learning_rate': 1e-5,      # é™ä½å­¦ä¹ ç‡
        'num_epochs': 50,           # å‡å°‘è®­ç»ƒè½®æ•°
        'batch_size': 2,            # å‡å°æ‰¹æ¬¡å¤§å°
        'save_interval': 5,
        'accumulation_steps': 2,
        'weight_decay': 1e-2,       # é€šè¿‡ä¼˜åŒ–å™¨çš„weight_decayå®ç°æ­£åˆ™åŒ–
        'patience': 10,
    }

    tasks = [
        {'name': 'move_object', 'display': 'ç§»åŠ¨ç‰©ä½“'},
        {'name': 'drop_object', 'display': 'æ‰è½ç‰©ä½“'},
        {'name': 'cover_object', 'display': 'è¦†ç›–ç‰©ä½“'}
    ]

    for task in tasks:
        task_name = task['name']
        print(f"\n{'='*60}")
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: {task['display']}")
        print(f"{'='*60}")
        
        task_config = config.copy()
        task_config['task_name'] = task_name
        task_config['output_dir'] = f'training_results_{task_name}_fixed'
        
        # åŠ è½½æ•°æ®
        try:
            train_loader, val_loader, test_loader = create_task_specific_loaders(
                task_name=task_name,
                batch_size=task_config['batch_size'],
                data_path="processed_data"
            )
        except Exception as e:
            print(f"âŒ è·³è¿‡ä»»åŠ¡ {task_name}: {e}")
            continue

        # ä½¿ç”¨1000ä¸ªæ ·æœ¬
        max_samples = 1000
        if max_samples is not None:
            orig_train_ds = train_loader.dataset
            orig_val_ds = val_loader.dataset
            orig_test_ds = test_loader.dataset
            combined = ConcatDataset([orig_train_ds, orig_val_ds, orig_test_ds])
            total = len(combined)
            
            if max_samples > total:
                print(f"âš ï¸ è¯·æ±‚çš„æ ·æœ¬æ•° {max_samples} è¶…è¿‡å¯ç”¨æ ·æœ¬ {total}ï¼Œä½¿ç”¨å…¨éƒ¨æ ·æœ¬")
                max_samples = total

            print(f"ğŸ“Š ä»æ€»æ ·æœ¬ {total} ä¸­éšæœºæŠ½å– {max_samples} ä¸ªï¼ˆæŒ‰ 8:1:1 åˆ’åˆ†ï¼‰")

            generator = torch.Generator()
            generator.manual_seed(42)
            perm = torch.randperm(total, generator=generator)[:max_samples].tolist()

            n_train = int(max_samples * 0.8)
            n_val = int(max_samples * 0.1)
            n_test = max_samples - n_train - n_val

            train_idx = perm[:n_train]
            val_idx = perm[n_train:n_train + n_val]
            test_idx = perm[n_train + n_val:]

            small_train_ds = Subset(combined, train_idx)
            small_val_ds = Subset(combined, val_idx)
            small_test_ds = Subset(combined, test_idx)

            train_loader = DataLoader(small_train_ds, batch_size=task_config['batch_size'], 
                                    shuffle=True, num_workers=2, pin_memory=True)
            val_loader = DataLoader(small_val_ds, batch_size=task_config['batch_size'], 
                                  shuffle=False, num_workers=2, pin_memory=True)
            test_loader = DataLoader(small_test_ds, batch_size=task_config['batch_size'], 
                                   shuffle=False, num_workers=2, pin_memory=True)

            print(f"âœ… æ•°æ®é›†åˆ†é…: train={len(small_train_ds)} val={len(small_val_ds)} test={len(small_test_ds)}")

        if len(train_loader) == 0:
            print(f"âš ï¸ ä»»åŠ¡ {task_name} æ— è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡")
            continue

        # åˆå§‹åŒ–å¹¶è®­ç»ƒ
        try:
            trainer = FixedControlNetTrainer(task_config)
            trainer.train(train_loader, val_loader)
        except Exception as e:
            print(f"âŒ è®­ç»ƒä»»åŠ¡ {task_name} å¤±è´¥: {e}")
            continue

if __name__ == "__main__":
    main()