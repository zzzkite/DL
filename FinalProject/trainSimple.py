#!/usr/bin/env python3
"""
ControlNet 1.1 ç®€æ˜“ç‰ˆè®­ç»ƒè„šæœ¬ - Baseline
é€»è¾‘ï¼šè¾“å…¥ç¬¬20å¸§çš„Cannyè¾¹ç¼˜ -> é¢„æµ‹ç¬¬25å¸§
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset, ConcatDataset
import torch.optim as optim
import cv2
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import sys
import os
import gc
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

try:
    from diffusers import DDPMScheduler, AutoencoderKL, UNet2DConditionModel
    from transformers import CLIPTokenizer, CLIPTextModel
    from loaderData import create_task_specific_loaders
    
    try:
        from cldm.model import create_model, load_state_dict
        CONTROLNET_AVAILABLE = True
        print("âœ… æˆåŠŸå¯¼å…¥ControlNetæ¨¡å—")
    except ImportError as e:
        print(f"âš ï¸  æ— æ³•å¯¼å…¥cldm: {e}")
        CONTROLNET_AVAILABLE = False
        
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# âŒ åˆ é™¤äº†å¤æ‚çš„ EnhancedTemporalFeatureExtractor ç±»ï¼Œç›´æ¥ç”¨ OpenCV å¤„ç†

class SimpleControlNetTrainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.task_name = config.get('task_name', 'unknown_task')
        
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device} (RTX 3090 Mode)")
        print(f"ğŸ¯ ä»»åŠ¡: {self.task_name} - ç®€åŒ–ç‰ˆ: ç¬¬20å¸§(Canny) â†’ é¢„æµ‹ç¬¬25å¸§")
        
        # æ¢¯åº¦ç¼©æ”¾å™¨
        self.scaler = torch.amp.GradScaler('cuda')
        # æ˜¾å­˜ç›‘æ§ä¸æ¸…ç†è®¾ç½®
        self.cleanup_steps = config.get('cleanup_steps', 20)  # æ¯å¤šå°‘ä¸ª batch æ¸…ç†ä¸€æ¬¡æ˜¾å­˜
        self.mem_log_steps = config.get('mem_log_steps', 10)  # æ¯å¤šå°‘ä¸ª batch æ‰“å°æ˜¾å­˜ä¿¡æ¯
        self.enable_mem_logging = config.get('enable_mem_logging', True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.setup_models()
        self.setup_optimizers()
        
    def setup_models(self):
        """æ¨¡å‹åˆå§‹åŒ–"""
        print("ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...")
        
        # 1. åŠ è½½ç»„ä»¶
        self.tokenizer = CLIPTokenizer.from_pretrained("stable-diffusion-v1-5/tokenizer", local_files_only=True)
        self.text_encoder = CLIPTextModel.from_pretrained("stable-diffusion-v1-5/text_encoder", local_files_only=True).to(self.device)
        self.vae = AutoencoderKL.from_pretrained("stable-diffusion-v1-5/vae", local_files_only=True).to(self.device)
        self.unet = UNet2DConditionModel.from_pretrained("stable-diffusion-v1-5/unet", local_files_only=True).to(self.device)
        self.noise_scheduler = DDPMScheduler.from_pretrained("stable-diffusion-v1-5/scheduler", local_files_only=True)
        
        # 2. åŠ è½½ ControlNet
        self.controlnet = self.load_controlnet().to(self.device)
        
        # 3. å†»ç»“å‚æ•° (å¾®è°ƒçš„æ ¸å¿ƒ)
        self.text_encoder.requires_grad_(False)
        self.vae.requires_grad_(False)
        self.unet.requires_grad_(False)
        self.controlnet.requires_grad_(True) # åªè®­ç»ƒ ControlNet
        
        # æ‰“å°å‚æ•°é‡
        trainable_params = sum(p.numel() for p in self.controlnet.parameters() if p.requires_grad)
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

    def load_controlnet(self):
        """åŠ è½½ControlNetæ¨¡å‹"""
        try:
            if CONTROLNET_AVAILABLE:
                # ä¼˜å…ˆåŠ è½½ Canny é¢„è®­ç»ƒæƒé‡ (è¿™éå¸¸é€‚åˆåªæœ‰250ä¸ªæ•°æ®çš„æƒ…å†µ)
                controlnet_dir = Path("ControlNet-v1-1")
                model_path = controlnet_dir / "control_sd15_canny.pth"
                config_path = controlnet_dir / "cldm_v15.yaml"
                
                if model_path.exists():
                    print(f"ğŸ“‚ åŠ è½½é¢„è®­ç»ƒæƒé‡: {model_path}")
                    model = create_model(str(config_path)).to(self.device)
                    model.load_state_dict(load_state_dict(str(model_path), location='cpu'))
                    return model.control_model
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œå°†å°è¯•ä»UNetåˆå§‹åŒ– (Scratch)")
            
            # å¤‡é€‰æ–¹æ¡ˆï¼šä» UNet åˆå§‹åŒ– (å¦‚æœæ²¡æœ‰ä¸‹è½½æƒé‡)
            from diffusers import ControlNetModel
            print("ğŸ†• ä» UNet å¤åˆ¶æƒé‡åˆå§‹åŒ– ControlNet")
            controlnet = ControlNetModel.from_unet(self.unet, conditioning_channels=3)
            return controlnet
                
        except Exception as e:
            print(f"âŒ åŠ è½½ControlNetå¤±è´¥: {e}")
            raise

    # ----- GPU å†…å­˜ç›‘æ§/æ¸…ç†åŠ©æ‰‹ -----
    def _log_gpu_memory(self, label: str = ""):
        if self.device.type != 'cuda' or not self.enable_mem_logging:
            return
        try:
            allocated = torch.cuda.memory_allocated() / 1024**2
            reserved = torch.cuda.memory_reserved() / 1024**2
            max_alloc = torch.cuda.max_memory_allocated() / 1024**2
            print(f"[GPU MEM] {label} allocated={allocated:.1f}MB reserved={reserved:.1f}MB max_alloc={max_alloc:.1f}MB")
        except Exception:
            pass

    def _cleanup_and_gc(self):
        try:
            torch.cuda.synchronize()
        except Exception:
            pass
        try:
            torch.cuda.empty_cache()
        except Exception:
            pass
        gc.collect()
    
    def setup_optimizers(self):
        """ä¼˜åŒ–å™¨é…ç½®"""
        self.optimizer = optim.AdamW(
            self.controlnet.parameters(),
            lr=self.config.get('learning_rate', 1e-5),
            weight_decay=1e-2
        )
        # ç®€å•çš„ä½™å¼¦é€€ç«
        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=self.config['num_epochs']
        )

    def get_canny_edges(self, image_tensor):
        """
        å°† Tensor å›¾åƒè½¬æ¢ä¸º Canny è¾¹ç¼˜å›¾
        è¾“å…¥: (B, 3, H, W) èŒƒå›´ [-1, 1] æˆ– [0, 1]
        è¾“å‡º: (B, 3, H, W) èŒƒå›´ [0, 1]
        """
        # 1. è½¬æ¢ä¸º numpy (B, H, W, 3) èŒƒå›´ [0, 255]
        # å‡è®¾è¾“å…¥å·²ç»æ˜¯ [0, 1]
        images_np = image_tensor.permute(0, 2, 3, 1).cpu().numpy()
        images_np = (images_np * 255).astype(np.uint8)
        
        edges_list = []
        for i in range(images_np.shape[0]):
            img_gray = cv2.cvtColor(images_np[i], cv2.COLOR_RGB2GRAY)
            # è‡ªé€‚åº”é˜ˆå€¼ Canny
            v = np.median(img_gray)
            lower = int(max(0, 0.66 * v))
            upper = int(min(255, 1.33 * v))
            edge = cv2.Canny(img_gray, lower, upper)
            
            # æ‰©å±•å› 3 é€šé“å¹¶å½’ä¸€åŒ–åˆ° [0, 1]
            edge = np.stack([edge]*3, axis=-1)
            edges_list.append(edge)
            
        edges_np = np.stack(edges_list)
        edges_tensor = torch.from_numpy(edges_np).float() / 255.0
        return edges_tensor.permute(0, 3, 1, 2).to(self.device)
    
    def train_epoch(self, train_loader, epoch):
        self.controlnet.train()
        total_loss = 0
        num_batches = 0
        
        for batch in train_loader:
            if batch is None: continue
            
            # 1. å‡†å¤‡æ•°æ®
            # input_frames: (B, 20, 3, H, W)
            # æˆ‘ä»¬åªå–ç¬¬ 20 å¸§ (Index -1) ä½œä¸ºè¾“å…¥æ¡ä»¶
            current_frame_20 = batch['input_frames'][:, -1].to(self.device) 
            target_frame_25 = batch['target_frame'].to(self.device)
            text_descriptions = batch.get('label_text', ['interaction'] * len(current_frame_20))
            
            with torch.amp.autocast('cuda'):
                # 2. VAE ç¼–ç ç›®æ ‡å›¾ (Frame 25) -> Latents
                # å›¾åƒéœ€è¦å½’ä¸€åŒ–åˆ° [-1, 1]
                target_latents = self.vae.encode(target_frame_25 * 2.0 - 1.0).latent_dist.sample()
                target_latents = target_latents * self.vae.config.scaling_factor
                
                # 3. CLIP ç¼–ç æ–‡æœ¬
                inputs = self.tokenizer(text_descriptions, max_length=77, padding="max_length", truncation=True, return_tensors="pt").to(self.device)
                encoder_hidden_states = self.text_encoder(inputs.input_ids)[0]
                
                # 4. å‡†å¤‡ ControlNet æ¡ä»¶ (Frame 20 -> Canny)
                # å‡è®¾ data loader å‡ºæ¥çš„å›¾åƒæ˜¯ [0, 1]ï¼Œå¦‚æœä¸æ˜¯è¯·è°ƒæ•´
                control_cond = self.get_canny_edges(current_frame_20)
                
                # 5. åŠ å™ª
                noise = torch.randn_like(target_latents)
                timesteps = torch.randint(0, self.noise_scheduler.config.num_train_timesteps, (target_latents.shape[0],), device=self.device).long()
                noisy_latents = self.noise_scheduler.add_noise(target_latents, noise, timesteps)
                
                # 6. å‰å‘ä¼ æ’­
                down_block_res_samples, mid_block_res_sample = self.controlnet(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=encoder_hidden_states,
                    controlnet_cond=control_cond,
                    return_dict=False,
                )
                
                # 7. UNet é¢„æµ‹
                noise_pred = self.unet(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states=encoder_hidden_states,
                    down_block_additional_residuals=down_block_res_samples,
                    mid_block_additional_residual=mid_block_res_sample,
                ).sample
                
                loss = F.mse_loss(noise_pred, noise)

            # 8. åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            self.scaler.scale(loss).backward()
            self.scaler.step(self.optimizer)
            self.scaler.update()
            
            total_loss += loss.item()
            num_batches += 1
            
            # æ‰“å° loss
            if num_batches % 10 == 0:
                print(f"Epoch {epoch} | Batch {num_batches} | Loss: {loss.item():.4f}")

            # å®šæœŸæ‰“å°æ˜¾å­˜å¹¶æ¸…ç†ä¸´æ—¶å¼ é‡ä»¥é¿å…çˆ†æ˜¾å­˜
            if self.device.type == 'cuda' and self.enable_mem_logging and (num_batches % self.mem_log_steps == 0):
                self._log_gpu_memory(f"Epoch{epoch} Batch{num_batches} mid-step")

            # åˆ é™¤å¤§å¼ é‡å¼•ç”¨ï¼Œé‡Šæ”¾ Python å±‚æŒæœ‰çš„å¼•ç”¨
            try:
                del target_latents, encoder_hidden_states, control_cond, noise, timesteps, noisy_latents
                del down_block_res_samples, mid_block_res_sample, noise_pred
            except Exception:
                pass

            # æ¯éš” cleanup_steps è§¦å‘ empty_cache + gc
            if self.device.type == 'cuda' and ((num_batches) % self.cleanup_steps == 0):
                self._cleanup_and_gc()
                if self.enable_mem_logging:
                    self._log_gpu_memory(f"After cleanup Epoch{epoch} Batch{num_batches}")

        return total_loss / num_batches if num_batches > 0 else 0

    def save_checkpoint(self, epoch, task_name):
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(exist_ok=True)
        save_path = output_dir / f"controlnet_{task_name}_epoch_{epoch}.pth"
        torch.save(self.controlnet.state_dict(), save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}")

    def plot_and_save_losses(self, train_losses, val_losses=None):
        """ç»˜åˆ¶è®­ç»ƒ/éªŒè¯æŸå¤±å¹¶ä¿å­˜åˆ°è¾“å‡ºç›®å½•ï¼ˆåŒä¸€å›¾ï¼‰"""
        try:
            output_dir = Path(self.config['output_dir'])
            output_dir.mkdir(parents=True, exist_ok=True)

            plt.figure(figsize=(8, 6))
            epochs = list(range(1, len(train_losses) + 1))
            plt.plot(epochs, train_losses, marker='o', color='tab:blue', label='Train Loss')
            if val_losses is not None and len(val_losses) == len(train_losses):
                plt.plot(epochs, val_losses, marker='o', color='tab:orange', label='Val Loss')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title(f'Training / Validation Loss - {self.task_name}')
            plt.grid(alpha=0.3)
            plt.legend()
            save_path = output_dir / f'training_val_loss_{self.task_name}.png'
            plt.savefig(save_path, dpi=200, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“ˆ Loss å›¾å·²ä¿å­˜: {save_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ Loss å›¾å¤±è´¥: {e}")

    def validate(self, val_loader):
        """éªŒè¯æ¨¡å‹å¹¶è¿”å›å¹³å‡éªŒè¯æŸå¤±"""
        self.controlnet.eval()
        total_loss = 0.0
        num_batches = 0
        with torch.no_grad():
            for batch in val_loader:
                if batch is None:
                    continue

                # å‡†å¤‡æ•°æ®
                current_frame_20 = batch['input_frames'][:, -1].to(self.device)
                target_frame_25 = batch['target_frame'].to(self.device)
                text_descriptions = batch.get('label_text', ['interaction'] * len(current_frame_20))

                with torch.amp.autocast('cuda'):
                    target_latents = self.vae.encode(target_frame_25 * 2.0 - 1.0).latent_dist.sample()
                    target_latents = target_latents * self.vae.config.scaling_factor

                    inputs = self.tokenizer(text_descriptions, max_length=77, padding="max_length", truncation=True, return_tensors="pt").to(self.device)
                    encoder_hidden_states = self.text_encoder(inputs.input_ids)[0]

                    control_cond = self.get_canny_edges(current_frame_20)

                    noise = torch.randn_like(target_latents)
                    timesteps = torch.randint(0, self.noise_scheduler.config.num_train_timesteps, (target_latents.shape[0],), device=self.device).long()
                    noisy_latents = self.noise_scheduler.add_noise(target_latents, noise, timesteps)

                    down_block_res_samples, mid_block_res_sample = self.controlnet(
                        noisy_latents,
                        timesteps,
                        encoder_hidden_states=encoder_hidden_states,
                        controlnet_cond=control_cond,
                        return_dict=False,
                    )

                    noise_pred = self.unet(
                        noisy_latents,
                        timesteps,
                        encoder_hidden_states=encoder_hidden_states,
                        down_block_additional_residuals=down_block_res_samples,
                        mid_block_additional_residual=mid_block_res_sample,
                    ).sample

                    loss = F.mse_loss(noise_pred, noise)

                total_loss += loss.item()
                num_batches += 1

                # å®šæœŸæ¸…ç†ä»¥é¿å…æŒæœ‰è¿‡å¤šæ˜¾å­˜
                if self.device.type == 'cuda' and (num_batches % self.mem_log_steps == 0):
                    self._log_gpu_memory(f"Validate Batch {num_batches}")
                    self._cleanup_and_gc()

        avg = total_loss / num_batches if num_batches > 0 else 0.0
        return avg

    def train(self, train_loader, val_loader):
        print("ğŸš€ å¼€å§‹ Simple Version è®­ç»ƒ...")
        
        train_losses = []
        val_losses = []
        for epoch in range(1, self.config['num_epochs'] + 1):
            loss = self.train_epoch(train_loader, epoch)
            train_losses.append(loss)

            # éªŒè¯
            try:
                val_loss = self.validate(val_loader)
            except Exception as e:
                print(f"âš ï¸ éªŒè¯é˜¶æ®µå‡ºé”™: {e}")
                val_loss = 0.0
            val_losses.append(val_loss)

            self.lr_scheduler.step()
            print(f"=== Epoch {epoch} å®Œæˆ | Train Loss: {loss:.4f} | Val Loss: {val_loss:.4f} ===")

            if epoch % self.config['save_interval'] == 0:
                self.save_checkpoint(epoch, self.config['task_name'])

            # æ¯ä¸ª epoch ç»“æŸæ—¶å†åšä¸€æ¬¡å…¨é¢çš„æ¸…ç†å’Œæ˜¾å­˜è®°å½•
            if self.device.type == 'cuda':
                self._cleanup_and_gc()
                if self.enable_mem_logging:
                    self._log_gpu_memory(f"End of Epoch {epoch}")

        # ä»»åŠ¡å®Œæˆåä¿å­˜è®­ç»ƒ/éªŒè¯ Loss æ›²çº¿åˆ°è¾“å‡ºç›®å½•
        try:
            self.plot_and_save_losses(train_losses, val_losses)
        except Exception as e:
            print(f"âš ï¸ ç»˜åˆ¶/ä¿å­˜ Loss æ›²çº¿å¤±è´¥: {e}")

def main():
    # åŸºç¡€é…ç½®
    config = {
        'learning_rate': 2e-5, # ControlNet å¾®è°ƒå¸¸ç”¨ LR
        'num_epochs': 50,      # æ•°æ®å°‘ï¼Œä¸éœ€è¦å¤ªå¤šepochï¼Œæˆ–è€…æ ¹æ®lossæƒ…å†µæ—©åœ
        'batch_size': 4,       # 3090 å¯ä»¥é€‚å½“å¤§ä¸€ç‚¹
        'save_interval': 10,
    }

    # ä»»åŠ¡åˆ—è¡¨ (ä¿æŒåŸä»£ç ç»“æ„)
    tasks = [
        {'name': 'move_object', 'display': 'ç§»åŠ¨ç‰©ä½“'},
        {'name': 'drop_object', 'display': 'æ‰è½ç‰©ä½“'},
        {'name': 'cover_object', 'display': 'è¦†ç›–ç‰©ä½“'}
    ]

    for task in tasks:
        task_name = task['name']
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: {task['display']}")
        
        task_config = config.copy()
        task_config['task_name'] = task_name
        task_config['output_dir'] = f'training_results_{task_name}_simple'
        
        # åŠ è½½æ•°æ®
        try:
            # å¤ç”¨ä½ ä»¬åŸæ¥çš„ loader æ¥å£
            train_loader, val_loader, test_loader = create_task_specific_loaders(
                task_name=task_name,
                batch_size=task_config['batch_size'],
                data_path="processed_data"
            )
        except Exception as e:
            print(f"è·³è¿‡ä»»åŠ¡ {task_name}: {e}")
            continue

        # å¦‚æœç”¨æˆ·å¸Œæœ›åªç”¨éƒ¨åˆ†æ ·æœ¬è¿›è¡Œå¿«é€ŸéªŒè¯ï¼Œå¯ä»¥é€šè¿‡ config['max_samples'] æ§åˆ¶
        # å®ƒä¼šä» train/val/test ä¸‰ä¸ªåŸå§‹åˆ†åŒºçš„è”åˆé›†åˆä¸­éšæœºæŠ½å–æ€»è®¡ max_samples ä¸ªæ ·æœ¬ï¼Œ
        # å¹¶æŒ‰ç…§ 8:1:1 çš„æ¯”ä¾‹é‡æ–°åˆ’åˆ†ä¸ºæ–°è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ã€‚
        max_samples = task_config.get('max_samples', 1000)  # e.g., 1000
        if max_samples is not None:
            # åˆå¹¶åŸå§‹ä¸‰ä¸ª dataset
            orig_train_ds = train_loader.dataset
            orig_val_ds = val_loader.dataset
            orig_test_ds = test_loader.dataset
            combined = ConcatDataset([orig_train_ds, orig_val_ds, orig_test_ds])
            total = len(combined)
            if max_samples > total:
                print(f"è¯·æ±‚çš„æ ·æœ¬æ•° {max_samples} è¶…è¿‡å¯ç”¨æ ·æœ¬ {total}ï¼Œå°†ä½¿ç”¨å…¨éƒ¨æ ·æœ¬")
                max_samples = total

            print(f"ä»æ€»æ ·æœ¬ {total} ä¸­éšæœºæŠ½å– {max_samples} ä¸ªç”¨äºå¿«é€ŸéªŒè¯ï¼ˆæŒ‰ 8:1:1 åˆ’åˆ†ï¼‰")

            # éšæœºé€‰æ‹©ç´¢å¼•
            generator = torch.Generator()
            generator.manual_seed(task_config.get('random_seed', 42))
            perm = torch.randperm(total, generator=generator)[:max_samples].tolist()

            # æŒ‰ 8:1:1 åˆ’åˆ†
            n_train = int(max_samples * 0.8)
            n_val = int(max_samples * 0.1)
            n_test = max_samples - n_train - n_val

            train_idx = perm[:n_train]
            val_idx = perm[n_train:n_train + n_val]
            test_idx = perm[n_train + n_val:]

            # åˆ›å»º Subset dataset å¹¶ DataLoader
            small_train_ds = Subset(combined, train_idx)
            small_val_ds = Subset(combined, val_idx)
            small_test_ds = Subset(combined, test_idx)

            train_loader = DataLoader(small_train_ds, batch_size=task_config['batch_size'], shuffle=True, num_workers=4, pin_memory=True)
            val_loader = DataLoader(small_val_ds, batch_size=task_config['batch_size'], shuffle=False, num_workers=4, pin_memory=True)
            test_loader = DataLoader(small_test_ds, batch_size=task_config['batch_size'], shuffle=False, num_workers=4, pin_memory=True)

            print(f"=> å¿«é€ŸéªŒè¯é›†æ ·æœ¬åˆ†é…: train={len(small_train_ds)} val={len(small_val_ds)} test={len(small_test_ds)}")

        if len(train_loader) == 0:
            continue

        # åˆå§‹åŒ–å¹¶è®­ç»ƒ
        trainer = SimpleControlNetTrainer(task_config)
        trainer.train(train_loader, val_loader)

if __name__ == "__main__":
    main()