nohup: ignoring input
/home/zhangzhikui/enter/envs/dl/lib/python3.10/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
`torch_dtype` is deprecated! Use `dtype` instead!
‚ö†Ô∏è  Êó†Ê≥ïÂØºÂÖ•cldm: No module named 'cldm'
============================================================
üéØ ControlNet 1.1 Â§ö‰ªªÂä°ÂàÜÂà´ËÆ≠ÁªÉÔºàÂä®ÊÄÅÊù°‰ª∂Áº©ÊîæÔºâ
üìä ‰ªªÂä°: Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ß
============================================================

==================================================
üöÄ ÂºÄÂßãËÆ≠ÁªÉ‰ªªÂä°: ÁßªÂä®Áâ©‰Ωì (move_object)
==================================================
‰ªªÂä°ÈÖçÁΩÆ:
  learning_rate: 0.0001 üéØ
  min_learning_rate: 1e-06
  weight_decay: 0.01 üéØ
  num_epochs: 50 üéØ
  batch_size: 2
  save_interval: 10
  gradient_accumulation_steps: 4
  lr_scheduler: cosine
  lr_step_size: 20
  lr_gamma: 0.5
  warmup_steps: 500
  grad_clip: 1.0
  conditioning_strategy: adaptive üéØ
  initial_conditioning_scale: 0.2 üéØ
  final_conditioning_scale: 1.0 üéØ
  adaptive_threshold: 0.15
  scale_step: 0.05
  gtad_clip: 0.5 üéØ
  output_dir: training_results_move_object
  task_name: move_object

üìä Âä†ËΩΩ ÁßªÂä®Áâ©‰Ωì Êï∞ÊçÆ...
   Á≠õÈÄâ‰ªªÂä° 'move_object': 2014/6000 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (move_object): 2014 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   move_object: 2014 ‰∏™Ê†∑Êú¨
   Á≠õÈÄâ‰ªªÂä° 'move_object': 236/750 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (move_object): 236 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   move_object: 236 ‰∏™Ê†∑Êú¨
   Á≠õÈÄâ‰ªªÂä° 'move_object': 250/750 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (move_object): 250 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   move_object: 250 ‰∏™Ê†∑Êú¨
‚úÖ ÂàõÂª∫‰ªªÂä° 'move_object' Êï∞ÊçÆÂä†ËΩΩÂô®ÂÆåÊàê
   ËÆ≠ÁªÉÈõÜ: 2014 ‰∏™Ê†∑Êú¨, 1007 ‰∏™ÊâπÊ¨°
   È™åËØÅÈõÜ: 236 ‰∏™Ê†∑Êú¨, 118 ‰∏™ÊâπÊ¨°
   ÊµãËØïÈõÜ: 250 ‰∏™Ê†∑Êú¨, 125 ‰∏™ÊâπÊ¨°
   ÊâπÊ¨°Â§ßÂ∞è: 2
‚úÖ Êï∞ÊçÆÂä†ËΩΩÊàêÂäü
   ËÆ≠ÁªÉÈõÜ: 2014 Ê†∑Êú¨
   È™åËØÅÈõÜ: 236 Ê†∑Êú¨
   ÊµãËØïÈõÜ: 250 Ê†∑Êú¨ - ‰øùÁïôÁî®‰∫éÊúÄÁªàËØÑ‰º∞
üöÄ ‰ΩøÁî®ËÆæÂ§á: cuda
üéØ ‰ªªÂä°: move_object - Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ß
üéØ Âä®ÊÄÅÊù°‰ª∂Áº©ÊîæÁ≠ñÁï•: adaptive
   ÂàùÂßãÁº©Êîæ: 0.2 ‚Üí ÊúÄÁªàÁº©Êîæ: 1.0
üì¶ ÂàùÂßãÂåñÊ®°ÂûãÔºàÂÜÖÂ≠ò‰ºòÂåñÁâàÔºâ...
‚úÖ ‰ΩøÁî®diffusers ControlNet
ÂàùÂßãÂåñÂ¢ûÂº∫Êó∂Â∫èÁâπÂæÅÊèêÂèñÂô®...
‚úÖ Ê®°ÂûãÂàùÂßãÂåñÂÆåÊàê
   ControlNetÂèÇÊï∞: 361,279,120 ÂèØËÆ≠ÁªÉ / 361,279,120 ÊÄªËÆ°
‚úÖ ‰ºòÂåñÂô®ËÆæÁΩÆÂÆåÊàê
üöÄ ÂºÄÂßãËÆ≠ÁªÉÂæ™ÁéØ...
üìä ‰ªÖ‰ΩøÁî®ËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜÔºåÊµãËØïÈõÜ‰øùÁïôÁî®‰∫éÊúÄÁªàËØÑ‰º∞

=== Epoch 1/50 ===
/data/zhangzhikui/githubbase/DL/FinalProject/train.py:420: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  Epoch 1, Batch 0, Loss: 0.4343, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 10, Loss: 0.0267, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 20, Loss: 0.3350, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 30, Loss: 0.0971, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 40, Loss: 0.1710, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 50, Loss: 0.0860, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 60, Loss: 0.0247, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 70, Loss: 0.3723, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 80, Loss: 0.0755, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 90, Loss: 0.3950, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 100, Loss: 0.0082, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 110, Loss: 0.0349, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 120, Loss: 0.0823, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 130, Loss: 0.2329, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 140, Loss: 0.1677, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 150, Loss: 0.8050, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 160, Loss: 0.2100, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 170, Loss: 0.0887, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 180, Loss: 0.2273, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 190, Loss: 0.0678, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 200, Loss: 0.0259, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 210, Loss: 0.2934, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 220, Loss: 0.1773, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 230, Loss: 0.0950, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 240, Loss: 0.4087, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 250, Loss: 0.5549, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 260, Loss: 0.0917, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 270, Loss: 0.1030, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 280, Loss: 0.0746, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 290, Loss: 0.3260, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 300, Loss: 0.1339, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 310, Loss: 0.2264, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 320, Loss: 0.1392, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 330, Loss: 0.0115, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 340, Loss: 0.1648, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 350, Loss: 0.2174, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 360, Loss: 0.0670, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 370, Loss: 0.0265, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 380, Loss: 0.0540, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 390, Loss: 0.0198, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 400, Loss: 0.2058, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 410, Loss: 0.0110, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 420, Loss: 0.1519, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 430, Loss: 0.0621, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 440, Loss: 0.1761, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 450, Loss: 0.1630, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 460, Loss: 0.1118, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 470, Loss: 0.0544, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 480, Loss: 0.3266, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 490, Loss: 0.3563, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 500, Loss: 0.0392, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 510, Loss: 0.3121, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 520, Loss: 0.1478, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 530, Loss: 0.1090, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 540, Loss: 0.0114, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 550, Loss: 0.1828, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 560, Loss: 0.0373, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 570, Loss: 0.0203, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 580, Loss: 0.3622, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 590, Loss: 0.3848, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 600, Loss: 0.3609, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 610, Loss: 0.2405, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 620, Loss: 0.2373, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 630, Loss: 0.1322, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 640, Loss: 0.1224, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 650, Loss: 0.0927, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 660, Loss: 0.1820, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 670, Loss: 0.0079, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 680, Loss: 0.4532, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 690, Loss: 0.3369, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 700, Loss: 0.1638, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 710, Loss: 0.0351, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 720, Loss: 0.0313, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 730, Loss: 0.5128, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 740, Loss: 0.1601, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 750, Loss: 0.2427, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 760, Loss: 0.2112, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 770, Loss: 0.0365, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 780, Loss: 0.0250, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 790, Loss: 0.2184, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 800, Loss: 0.0111, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 810, Loss: 0.1587, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 820, Loss: 0.0561, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 830, Loss: 0.0349, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 840, Loss: 0.0786, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 850, Loss: 0.5263, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 860, Loss: 0.3037, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 870, Loss: 0.1122, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 880, Loss: 0.1430, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 890, Loss: 0.0586, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 900, Loss: 0.0083, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 910, Loss: 0.0610, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 920, Loss: 0.0250, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 930, Loss: 0.2246, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 940, Loss: 0.3221, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 950, Loss: 0.1579, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 960, Loss: 0.1145, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 970, Loss: 0.1459, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 980, Loss: 0.1772, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 990, Loss: 0.1937, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 1000, Loss: 0.4574, LR: 1.00e-04, Scale: 0.200
/data/zhangzhikui/githubbase/DL/FinalProject/train.py:574: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=self.device.type == 'cuda'):
‚úÖ Epoch 1 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1915
   È™åËØÅÊçüÂ§±: 0.2052
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_best.pth
üíæ ‰øùÂ≠òÊúÄ‰Ω≥Ê®°ÂûãÔºåÈ™åËØÅÊçüÂ§±: 0.2052

=== Epoch 2/50 ===
  Epoch 2, Batch 0, Loss: 0.0678, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 10, Loss: 0.4052, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 20, Loss: 0.2277, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 30, Loss: 0.1567, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 40, Loss: 0.3493, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 50, Loss: 0.0488, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 60, Loss: 0.2774, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 70, Loss: 0.2259, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 80, Loss: 0.2841, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 90, Loss: 0.2283, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 100, Loss: 0.4479, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 110, Loss: 0.1296, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 120, Loss: 0.1381, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 130, Loss: 0.2155, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 140, Loss: 0.0383, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 150, Loss: 0.2438, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 160, Loss: 0.3751, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 170, Loss: 0.3894, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 180, Loss: 0.0191, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 190, Loss: 0.0699, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 200, Loss: 0.0426, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 210, Loss: 0.0096, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 220, Loss: 0.0239, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 230, Loss: 0.1310, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 240, Loss: 0.1757, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 250, Loss: 0.0269, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 260, Loss: 0.0842, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 270, Loss: 0.5714, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 280, Loss: 0.0446, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 290, Loss: 0.3505, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 300, Loss: 0.1633, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 310, Loss: 0.1119, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 320, Loss: 0.4933, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 330, Loss: 0.1223, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 340, Loss: 0.2322, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 350, Loss: 0.6788, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 360, Loss: 0.1573, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 370, Loss: 0.0266, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 380, Loss: 0.0479, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 390, Loss: 0.3132, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 400, Loss: 0.5331, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 410, Loss: 0.1876, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 420, Loss: 0.2113, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 430, Loss: 0.1866, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 440, Loss: 0.4764, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 450, Loss: 0.3601, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 460, Loss: 0.0806, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 470, Loss: 0.2739, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 480, Loss: 0.2078, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 490, Loss: 0.0325, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 500, Loss: 0.0409, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 510, Loss: 0.0272, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 520, Loss: 0.1040, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 530, Loss: 0.3522, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 540, Loss: 0.0081, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 550, Loss: 0.6966, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 560, Loss: 0.1829, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 570, Loss: 0.1287, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 580, Loss: 0.2120, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 590, Loss: 0.1496, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 600, Loss: 0.1586, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 610, Loss: 0.0273, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 620, Loss: 0.0443, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 630, Loss: 0.1253, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 640, Loss: 0.3639, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 650, Loss: 0.0138, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 660, Loss: 0.0206, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 670, Loss: 0.1727, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 680, Loss: 0.4844, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 690, Loss: 0.2881, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 700, Loss: 0.1376, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 710, Loss: 0.0355, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 720, Loss: 0.1451, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 730, Loss: 0.0618, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 740, Loss: 0.1538, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 750, Loss: 0.3332, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 760, Loss: 0.3393, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 770, Loss: 0.0850, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 780, Loss: 0.3935, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 790, Loss: 0.1385, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 800, Loss: 0.0731, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 810, Loss: 0.1701, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 820, Loss: 0.0220, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 830, Loss: 0.4536, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 840, Loss: 0.1140, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 850, Loss: 0.1812, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 860, Loss: 0.0251, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 870, Loss: 0.0830, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 880, Loss: 0.4594, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 890, Loss: 0.1971, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 900, Loss: 0.1966, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 910, Loss: 0.1977, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 920, Loss: 0.1469, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 930, Loss: 0.1963, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 940, Loss: 0.1643, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 950, Loss: 0.1268, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 960, Loss: 0.0631, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 970, Loss: 0.2929, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 980, Loss: 0.0223, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 990, Loss: 0.0346, LR: 9.99e-05, Scale: 0.200
  Epoch 2, Batch 1000, Loss: 0.0718, LR: 9.99e-05, Scale: 0.200
‚úÖ Epoch 2 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1925
   È™åËØÅÊçüÂ§±: 0.1858
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_best.pth
üíæ ‰øùÂ≠òÊúÄ‰Ω≥Ê®°ÂûãÔºåÈ™åËØÅÊçüÂ§±: 0.1858

=== Epoch 3/50 ===
  Epoch 3, Batch 0, Loss: 0.3492, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 10, Loss: 0.0091, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 20, Loss: 0.2155, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 30, Loss: 0.4218, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 40, Loss: 0.3674, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 50, Loss: 0.4454, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 60, Loss: 0.1324, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 70, Loss: 0.0438, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 80, Loss: 0.1218, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 90, Loss: 0.0058, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 100, Loss: 0.0540, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 110, Loss: 0.2960, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 120, Loss: 0.1303, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 130, Loss: 0.0495, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 140, Loss: 0.2164, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 150, Loss: 0.1526, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 160, Loss: 0.3262, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 170, Loss: 0.2775, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 180, Loss: 0.2656, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 190, Loss: 0.2650, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 200, Loss: 0.2362, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 210, Loss: 0.0128, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 220, Loss: 0.2315, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 230, Loss: 0.1502, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 240, Loss: 0.3480, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 250, Loss: 0.0051, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 260, Loss: 0.6594, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 270, Loss: 0.4660, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 280, Loss: 0.2324, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 290, Loss: 0.3914, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 300, Loss: 0.0448, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 310, Loss: 0.2684, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 320, Loss: 0.2626, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 330, Loss: 0.0752, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 340, Loss: 0.0617, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 350, Loss: 0.2135, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 360, Loss: 0.4002, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 370, Loss: 0.2376, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 380, Loss: 0.0479, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 390, Loss: 0.2563, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 400, Loss: 0.2219, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 410, Loss: 0.1808, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 420, Loss: 0.1592, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 430, Loss: 0.1045, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 440, Loss: 0.1692, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 450, Loss: 0.1618, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 460, Loss: 0.1450, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 470, Loss: 0.1728, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 480, Loss: 0.0163, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 490, Loss: 0.0433, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 500, Loss: 0.0140, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 510, Loss: 0.3042, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 520, Loss: 0.2543, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 530, Loss: 0.5112, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 540, Loss: 0.0252, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 550, Loss: 0.1964, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 560, Loss: 0.1272, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 570, Loss: 0.0417, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 580, Loss: 0.3371, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 590, Loss: 0.0659, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 600, Loss: 0.1212, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 610, Loss: 0.2164, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 620, Loss: 0.0575, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 630, Loss: 0.2307, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 640, Loss: 0.1334, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 650, Loss: 0.1601, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 660, Loss: 0.2133, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 670, Loss: 0.3912, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 680, Loss: 0.2429, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 690, Loss: 0.0943, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 700, Loss: 0.0780, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 710, Loss: 0.1036, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 720, Loss: 0.0087, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 730, Loss: 0.1818, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 740, Loss: 0.0116, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 750, Loss: 0.1849, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 760, Loss: 0.3837, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 770, Loss: 0.1758, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 780, Loss: 0.0871, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 790, Loss: 0.2141, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 800, Loss: 0.2177, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 810, Loss: 0.0349, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 820, Loss: 0.0294, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 830, Loss: 0.2786, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 840, Loss: 0.5592, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 850, Loss: 0.0947, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 860, Loss: 0.0996, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 870, Loss: 0.0949, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 880, Loss: 0.0523, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 890, Loss: 0.0676, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 900, Loss: 0.1791, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 910, Loss: 0.0813, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 920, Loss: 0.4084, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 930, Loss: 0.0277, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 940, Loss: 0.3539, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 950, Loss: 0.0448, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 960, Loss: 0.0130, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 970, Loss: 0.0272, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 980, Loss: 0.0884, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 990, Loss: 0.1193, LR: 9.96e-05, Scale: 0.200
  Epoch 3, Batch 1000, Loss: 0.0109, LR: 9.96e-05, Scale: 0.200
‚úÖ Epoch 3 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1924
   È™åËØÅÊçüÂ§±: 0.1899
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 4/50 ===
  Epoch 4, Batch 0, Loss: 0.0597, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 10, Loss: 0.1259, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 20, Loss: 0.0085, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 30, Loss: 0.2021, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 40, Loss: 0.0211, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 50, Loss: 0.1364, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 60, Loss: 0.4950, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 70, Loss: 0.2691, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 80, Loss: 0.0963, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 90, Loss: 0.0330, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 100, Loss: 0.0093, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 110, Loss: 0.2931, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 120, Loss: 0.1504, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 130, Loss: 0.4611, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 140, Loss: 0.0860, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 150, Loss: 0.0226, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 160, Loss: 0.3525, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 170, Loss: 0.1747, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 180, Loss: 0.0830, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 190, Loss: 0.0454, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 200, Loss: 0.2327, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 210, Loss: 0.5675, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 220, Loss: 0.0756, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 230, Loss: 0.1921, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 240, Loss: 0.0639, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 250, Loss: 0.2738, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 260, Loss: 0.1265, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 270, Loss: 0.2832, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 280, Loss: 0.0337, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 290, Loss: 0.3200, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 300, Loss: 0.1274, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 310, Loss: 0.0140, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 320, Loss: 0.1917, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 330, Loss: 0.2925, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 340, Loss: 0.2451, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 350, Loss: 0.3877, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 360, Loss: 0.1279, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 370, Loss: 0.1143, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 380, Loss: 0.2969, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 390, Loss: 0.1438, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 400, Loss: 0.0983, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 410, Loss: 0.1734, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 420, Loss: 0.0070, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 430, Loss: 0.0162, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 440, Loss: 0.1916, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 450, Loss: 0.1733, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 460, Loss: 0.1606, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 470, Loss: 0.1430, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 480, Loss: 0.3392, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 490, Loss: 0.0559, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 500, Loss: 0.5280, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 510, Loss: 0.0529, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 520, Loss: 0.1631, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 530, Loss: 0.0102, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 540, Loss: 0.0238, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 550, Loss: 0.5121, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 560, Loss: 0.0697, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 570, Loss: 0.1072, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 580, Loss: 0.0400, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 590, Loss: 0.1567, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 600, Loss: 0.1269, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 610, Loss: 0.1952, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 620, Loss: 0.1267, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 630, Loss: 0.0064, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 640, Loss: 0.1496, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 650, Loss: 0.2377, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 660, Loss: 0.1268, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 670, Loss: 0.0498, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 680, Loss: 0.2617, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 690, Loss: 0.2636, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 700, Loss: 0.2826, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 710, Loss: 0.0049, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 720, Loss: 0.1236, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 730, Loss: 0.1375, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 740, Loss: 0.0749, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 750, Loss: 0.4346, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 760, Loss: 0.0993, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 770, Loss: 0.1240, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 780, Loss: 0.1988, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 790, Loss: 0.2286, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 800, Loss: 0.0206, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 810, Loss: 0.0098, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 820, Loss: 0.3448, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 830, Loss: 0.0424, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 840, Loss: 0.0979, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 850, Loss: 0.0775, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 860, Loss: 0.1955, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 870, Loss: 0.0649, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 880, Loss: 0.2321, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 890, Loss: 0.1720, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 900, Loss: 0.1417, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 910, Loss: 0.0167, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 920, Loss: 0.2026, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 930, Loss: 0.0929, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 940, Loss: 0.0642, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 950, Loss: 0.0404, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 960, Loss: 0.4140, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 970, Loss: 0.1645, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 980, Loss: 0.2162, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 990, Loss: 0.2367, LR: 9.91e-05, Scale: 0.200
  Epoch 4, Batch 1000, Loss: 0.1428, LR: 9.91e-05, Scale: 0.200
‚úÖ Epoch 4 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1933
   È™åËØÅÊçüÂ§±: 0.1940
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 5/50 ===
  Epoch 5, Batch 0, Loss: 0.1872, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 10, Loss: 0.5430, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 20, Loss: 0.0850, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 30, Loss: 0.0579, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 40, Loss: 0.3514, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 50, Loss: 0.0412, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 60, Loss: 0.0055, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 70, Loss: 0.0257, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 80, Loss: 0.1690, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 90, Loss: 0.0143, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 100, Loss: 0.1553, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 110, Loss: 0.0371, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 120, Loss: 0.2328, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 130, Loss: 0.3740, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 140, Loss: 0.4524, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 150, Loss: 0.3378, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 160, Loss: 0.2625, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 170, Loss: 0.1572, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 180, Loss: 0.0117, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 190, Loss: 0.1977, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 200, Loss: 0.0736, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 210, Loss: 0.2102, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 220, Loss: 0.1574, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 230, Loss: 0.3782, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 240, Loss: 0.0185, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 250, Loss: 0.1236, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 260, Loss: 0.1239, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 270, Loss: 0.1899, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 280, Loss: 0.0485, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 290, Loss: 0.2787, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 300, Loss: 0.3243, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 310, Loss: 0.0463, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 320, Loss: 0.0783, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 330, Loss: 0.2221, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 340, Loss: 0.0355, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 350, Loss: 0.1010, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 360, Loss: 0.0626, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 370, Loss: 0.2313, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 380, Loss: 0.1527, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 390, Loss: 0.2261, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 400, Loss: 0.1632, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 410, Loss: 0.1845, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 420, Loss: 0.2072, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 430, Loss: 0.0036, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 440, Loss: 0.1012, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 450, Loss: 0.3825, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 460, Loss: 0.2356, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 470, Loss: 0.3302, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 480, Loss: 0.0575, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 490, Loss: 0.4753, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 500, Loss: 0.1297, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 510, Loss: 0.0170, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 520, Loss: 0.1519, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 530, Loss: 0.1473, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 540, Loss: 0.3197, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 550, Loss: 0.2192, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 560, Loss: 0.1605, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 570, Loss: 0.0383, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 580, Loss: 0.0272, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 590, Loss: 0.6201, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 600, Loss: 0.1121, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 610, Loss: 0.0255, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 620, Loss: 0.2163, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 630, Loss: 0.3088, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 640, Loss: 0.2156, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 650, Loss: 0.3854, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 660, Loss: 0.3909, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 670, Loss: 0.2439, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 680, Loss: 0.1105, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 690, Loss: 0.0472, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 700, Loss: 0.6584, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 710, Loss: 0.0225, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 720, Loss: 0.1559, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 730, Loss: 0.0904, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 740, Loss: 0.1597, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 750, Loss: 0.3236, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 760, Loss: 0.1378, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 770, Loss: 0.3629, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 780, Loss: 0.3596, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 790, Loss: 0.0631, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 800, Loss: 0.0691, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 810, Loss: 0.2720, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 820, Loss: 0.5214, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 830, Loss: 0.1465, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 840, Loss: 0.0159, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 850, Loss: 0.4524, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 860, Loss: 0.0251, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 870, Loss: 0.2792, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 880, Loss: 0.1179, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 890, Loss: 0.1718, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 900, Loss: 0.4917, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 910, Loss: 0.1974, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 920, Loss: 0.0798, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 930, Loss: 0.0043, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 940, Loss: 0.0164, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 950, Loss: 0.3256, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 960, Loss: 0.2022, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 970, Loss: 0.2774, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 980, Loss: 0.0819, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 990, Loss: 0.2016, LR: 9.84e-05, Scale: 0.200
  Epoch 5, Batch 1000, Loss: 0.0055, LR: 9.84e-05, Scale: 0.200
‚úÖ Epoch 5 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1911
   È™åËØÅÊçüÂ§±: 0.1779
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_best.pth
üíæ ‰øùÂ≠òÊúÄ‰Ω≥Ê®°ÂûãÔºåÈ™åËØÅÊçüÂ§±: 0.1779

=== Epoch 6/50 ===
  Epoch 6, Batch 0, Loss: 0.0780, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 10, Loss: 0.4219, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 20, Loss: 0.3885, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 30, Loss: 0.0865, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 40, Loss: 0.0126, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 50, Loss: 0.0344, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 60, Loss: 0.4334, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 70, Loss: 0.1697, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 80, Loss: 0.1826, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 90, Loss: 0.1409, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 100, Loss: 0.3105, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 110, Loss: 0.0801, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 120, Loss: 0.0605, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 130, Loss: 0.1562, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 140, Loss: 0.0119, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 150, Loss: 0.0190, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 160, Loss: 0.3819, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 170, Loss: 0.0357, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 180, Loss: 0.1542, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 190, Loss: 0.0547, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 200, Loss: 0.3088, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 210, Loss: 0.0431, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 220, Loss: 0.3676, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 230, Loss: 0.1324, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 240, Loss: 0.1093, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 250, Loss: 0.1019, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 260, Loss: 0.3831, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 270, Loss: 0.1279, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 280, Loss: 0.2279, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 290, Loss: 0.8354, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 300, Loss: 0.0310, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 310, Loss: 0.1127, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 320, Loss: 0.0068, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 330, Loss: 0.2143, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 340, Loss: 0.0203, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 350, Loss: 0.2695, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 360, Loss: 0.1991, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 370, Loss: 0.2550, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 380, Loss: 0.1643, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 390, Loss: 0.2138, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 400, Loss: 0.1213, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 410, Loss: 0.1104, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 420, Loss: 0.3946, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 430, Loss: 0.1212, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 440, Loss: 0.0232, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 450, Loss: 0.2741, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 460, Loss: 0.0451, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 470, Loss: 0.1946, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 480, Loss: 0.0094, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 490, Loss: 0.1206, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 500, Loss: 0.1066, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 510, Loss: 0.0247, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 520, Loss: 0.3873, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 530, Loss: 0.3215, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 540, Loss: 0.3496, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 550, Loss: 0.0364, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 560, Loss: 0.4059, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 570, Loss: 0.0928, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 580, Loss: 0.0694, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 590, Loss: 0.1890, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 600, Loss: 0.1051, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 610, Loss: 0.3531, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 620, Loss: 0.1338, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 630, Loss: 0.0186, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 640, Loss: 0.0105, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 650, Loss: 0.2380, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 660, Loss: 0.1284, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 670, Loss: 0.4021, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 680, Loss: 0.0486, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 690, Loss: 0.1844, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 700, Loss: 0.4357, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 710, Loss: 0.1089, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 720, Loss: 0.1727, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 730, Loss: 0.4373, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 740, Loss: 0.1970, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 750, Loss: 0.3901, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 760, Loss: 0.3272, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 770, Loss: 0.1473, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 780, Loss: 0.1933, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 790, Loss: 0.0502, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 800, Loss: 0.1377, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 810, Loss: 0.1155, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 820, Loss: 0.0433, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 830, Loss: 0.1390, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 840, Loss: 0.0650, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 850, Loss: 0.1803, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 860, Loss: 0.2995, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 870, Loss: 0.5145, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 880, Loss: 0.1659, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 890, Loss: 0.2286, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 900, Loss: 0.0375, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 910, Loss: 0.4612, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 920, Loss: 0.3023, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 930, Loss: 0.0496, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 940, Loss: 0.4056, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 950, Loss: 0.3682, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 960, Loss: 0.0173, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 970, Loss: 0.3170, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 980, Loss: 0.1224, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 990, Loss: 0.0261, LR: 9.76e-05, Scale: 0.200
  Epoch 6, Batch 1000, Loss: 0.0748, LR: 9.76e-05, Scale: 0.200
‚úÖ Epoch 6 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1910
   È™åËØÅÊçüÂ§±: 0.1939
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 7/50 ===
  Epoch 7, Batch 0, Loss: 0.1660, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 10, Loss: 0.0191, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 20, Loss: 0.0903, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 30, Loss: 0.1041, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 40, Loss: 0.0781, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 50, Loss: 0.0922, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 60, Loss: 0.2623, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 70, Loss: 0.0100, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 80, Loss: 0.1104, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 90, Loss: 0.1723, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 100, Loss: 0.0417, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 110, Loss: 0.1567, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 120, Loss: 0.1385, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 130, Loss: 0.0533, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 140, Loss: 0.0117, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 150, Loss: 0.3099, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 160, Loss: 0.0415, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 170, Loss: 0.2381, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 180, Loss: 0.4884, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 190, Loss: 0.1504, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 200, Loss: 0.1676, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 210, Loss: 0.2810, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 220, Loss: 0.1989, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 230, Loss: 0.2207, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 240, Loss: 0.5468, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 250, Loss: 0.1532, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 260, Loss: 0.0228, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 270, Loss: 0.4525, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 280, Loss: 0.4773, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 290, Loss: 0.3674, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 300, Loss: 0.1894, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 310, Loss: 0.4080, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 320, Loss: 0.1371, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 330, Loss: 0.0831, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 340, Loss: 0.1435, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 350, Loss: 0.1095, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 360, Loss: 0.2055, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 370, Loss: 0.3932, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 380, Loss: 0.1565, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 390, Loss: 0.1961, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 400, Loss: 0.4163, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 410, Loss: 0.0736, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 420, Loss: 0.0563, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 430, Loss: 0.0759, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 440, Loss: 0.1926, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 450, Loss: 0.2222, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 460, Loss: 0.3304, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 470, Loss: 0.1317, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 480, Loss: 0.0737, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 490, Loss: 0.1461, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 500, Loss: 0.2358, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 510, Loss: 0.1307, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 520, Loss: 0.3648, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 530, Loss: 0.1164, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 540, Loss: 0.1067, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 550, Loss: 0.4682, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 560, Loss: 0.0282, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 570, Loss: 0.0948, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 580, Loss: 0.1523, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 590, Loss: 0.0132, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 600, Loss: 0.2824, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 610, Loss: 0.3956, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 620, Loss: 0.2524, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 630, Loss: 0.3986, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 640, Loss: 0.1007, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 650, Loss: 0.1460, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 660, Loss: 0.4236, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 670, Loss: 0.0523, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 680, Loss: 0.1696, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 690, Loss: 0.0837, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 700, Loss: 0.4229, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 710, Loss: 0.1969, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 720, Loss: 0.0202, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 730, Loss: 0.4283, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 740, Loss: 0.3872, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 750, Loss: 0.3172, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 760, Loss: 0.3133, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 770, Loss: 0.4384, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 780, Loss: 0.5249, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 790, Loss: 0.0199, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 800, Loss: 0.0270, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 810, Loss: 0.3862, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 820, Loss: 0.4553, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 830, Loss: 0.2819, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 840, Loss: 0.0098, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 850, Loss: 0.0086, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 860, Loss: 0.1304, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 870, Loss: 0.4040, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 880, Loss: 0.0824, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 890, Loss: 0.4205, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 900, Loss: 0.0454, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 910, Loss: 0.0890, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 920, Loss: 0.1570, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 930, Loss: 0.1439, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 940, Loss: 0.1129, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 950, Loss: 0.3083, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 960, Loss: 0.0930, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 970, Loss: 0.1579, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 980, Loss: 0.1761, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 990, Loss: 0.0608, LR: 9.65e-05, Scale: 0.200
  Epoch 7, Batch 1000, Loss: 0.2831, LR: 9.65e-05, Scale: 0.200
‚úÖ Epoch 7 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1868
   È™åËØÅÊçüÂ§±: 0.1991
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 8/50 ===
  Epoch 8, Batch 0, Loss: 0.2142, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 10, Loss: 0.0251, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 20, Loss: 0.0427, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 30, Loss: 0.3321, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 40, Loss: 0.1270, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 50, Loss: 0.4193, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 60, Loss: 0.0284, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 70, Loss: 0.1978, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 80, Loss: 0.1844, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 90, Loss: 0.1671, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 100, Loss: 0.1221, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 110, Loss: 0.2654, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 120, Loss: 0.0855, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 130, Loss: 0.2543, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 140, Loss: 0.4364, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 150, Loss: 0.3017, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 160, Loss: 0.5194, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 170, Loss: 0.1322, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 180, Loss: 0.2022, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 190, Loss: 0.1681, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 200, Loss: 0.0765, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 210, Loss: 0.0266, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 220, Loss: 0.1558, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 230, Loss: 0.2160, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 240, Loss: 0.0573, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 250, Loss: 0.1157, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 260, Loss: 0.0585, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 270, Loss: 0.0776, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 280, Loss: 0.1219, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 290, Loss: 0.4182, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 300, Loss: 0.1289, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 310, Loss: 0.0591, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 320, Loss: 0.3906, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 330, Loss: 0.2924, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 340, Loss: 0.0260, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 350, Loss: 0.0416, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 360, Loss: 0.0882, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 370, Loss: 0.1094, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 380, Loss: 0.1275, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 390, Loss: 0.0417, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 400, Loss: 0.5627, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 410, Loss: 0.3273, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 420, Loss: 0.0633, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 430, Loss: 0.0118, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 440, Loss: 0.3599, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 450, Loss: 0.0682, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 460, Loss: 0.0881, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 470, Loss: 0.0776, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 480, Loss: 0.1793, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 490, Loss: 0.1171, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 500, Loss: 0.0950, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 510, Loss: 0.1668, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 520, Loss: 0.4574, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 530, Loss: 0.2323, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 540, Loss: 0.0687, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 550, Loss: 0.2291, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 560, Loss: 0.0758, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 570, Loss: 0.1267, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 580, Loss: 0.1905, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 590, Loss: 0.1273, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 600, Loss: 0.2192, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 610, Loss: 0.2994, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 620, Loss: 0.2490, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 630, Loss: 0.1244, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 640, Loss: 0.3012, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 650, Loss: 0.2310, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 660, Loss: 0.0230, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 670, Loss: 0.1570, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 680, Loss: 0.3765, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 690, Loss: 0.1494, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 700, Loss: 0.0799, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 710, Loss: 0.1020, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 720, Loss: 0.1471, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 730, Loss: 0.0610, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 740, Loss: 0.1952, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 750, Loss: 0.1272, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 760, Loss: 0.0639, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 770, Loss: 0.1930, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 780, Loss: 0.0753, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 790, Loss: 0.1496, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 800, Loss: 0.3525, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 810, Loss: 0.4963, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 820, Loss: 0.1489, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 830, Loss: 0.0855, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 840, Loss: 0.3602, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 850, Loss: 0.0692, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 860, Loss: 0.0329, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 870, Loss: 0.1644, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 880, Loss: 0.3155, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 890, Loss: 0.2808, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 900, Loss: 0.1980, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 910, Loss: 0.6372, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 920, Loss: 0.5357, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 930, Loss: 0.3978, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 940, Loss: 0.2546, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 950, Loss: 0.3001, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 960, Loss: 0.2045, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 970, Loss: 0.1455, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 980, Loss: 0.1359, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 990, Loss: 0.1110, LR: 9.53e-05, Scale: 0.200
  Epoch 8, Batch 1000, Loss: 0.0195, LR: 9.53e-05, Scale: 0.200
‚úÖ Epoch 8 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1852
   È™åËØÅÊçüÂ§±: 0.1923
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 9/50 ===
  Epoch 9, Batch 0, Loss: 0.0655, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 10, Loss: 0.6656, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 20, Loss: 0.2442, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 30, Loss: 0.2435, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 40, Loss: 0.1008, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 50, Loss: 0.0194, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 60, Loss: 0.2294, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 70, Loss: 0.1513, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 80, Loss: 0.0440, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 90, Loss: 0.1053, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 100, Loss: 0.2576, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 110, Loss: 0.1793, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 120, Loss: 0.0457, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 130, Loss: 0.1035, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 140, Loss: 0.1842, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 150, Loss: 0.5623, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 160, Loss: 0.0557, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 170, Loss: 0.0371, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 180, Loss: 0.2369, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 190, Loss: 0.0955, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 200, Loss: 0.0083, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 210, Loss: 0.1954, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 220, Loss: 0.0900, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 230, Loss: 0.0285, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 240, Loss: 0.1796, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 250, Loss: 0.1042, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 260, Loss: 0.0305, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 270, Loss: 0.1171, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 280, Loss: 0.2309, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 290, Loss: 0.1387, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 300, Loss: 0.1186, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 310, Loss: 0.1767, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 320, Loss: 0.0057, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 330, Loss: 0.0129, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 340, Loss: 0.2388, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 350, Loss: 0.1500, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 360, Loss: 0.1316, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 370, Loss: 0.3935, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 380, Loss: 0.0457, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 390, Loss: 0.0661, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 400, Loss: 0.0541, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 410, Loss: 0.0635, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 420, Loss: 0.0082, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 430, Loss: 0.0499, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 440, Loss: 0.3290, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 450, Loss: 0.1027, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 460, Loss: 0.0581, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 470, Loss: 0.0317, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 480, Loss: 0.1225, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 490, Loss: 0.1310, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 500, Loss: 0.0706, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 510, Loss: 0.2340, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 520, Loss: 0.2098, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 530, Loss: 0.0803, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 540, Loss: 0.1506, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 550, Loss: 0.3704, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 560, Loss: 0.1661, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 570, Loss: 0.1206, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 580, Loss: 0.3818, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 590, Loss: 0.1204, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 600, Loss: 0.2973, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 610, Loss: 0.0342, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 620, Loss: 0.1491, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 630, Loss: 0.2890, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 640, Loss: 0.2172, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 650, Loss: 0.3767, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 660, Loss: 0.2438, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 670, Loss: 0.3076, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 680, Loss: 0.2030, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 690, Loss: 0.1182, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 700, Loss: 0.0499, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 710, Loss: 0.1578, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 720, Loss: 0.0845, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 730, Loss: 0.3274, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 740, Loss: 0.2101, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 750, Loss: 0.2547, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 760, Loss: 0.1029, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 770, Loss: 0.2849, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 780, Loss: 0.0311, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 790, Loss: 0.1359, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 800, Loss: 0.1041, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 810, Loss: 0.4819, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 820, Loss: 0.2236, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 830, Loss: 0.1081, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 840, Loss: 0.1300, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 850, Loss: 0.5231, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 860, Loss: 0.0330, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 870, Loss: 0.2402, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 880, Loss: 0.2013, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 890, Loss: 0.2185, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 900, Loss: 0.1795, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 910, Loss: 0.1629, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 920, Loss: 0.0578, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 930, Loss: 0.1897, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 940, Loss: 0.0665, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 950, Loss: 0.0312, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 960, Loss: 0.3135, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 970, Loss: 0.3681, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 980, Loss: 0.0475, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 990, Loss: 0.1922, LR: 9.39e-05, Scale: 0.200
  Epoch 9, Batch 1000, Loss: 0.1027, LR: 9.39e-05, Scale: 0.200
‚úÖ Epoch 9 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1913
   È™åËØÅÊçüÂ§±: 0.1791
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 10/50 ===
  Epoch 10, Batch 0, Loss: 0.2964, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 10, Loss: 0.1451, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 20, Loss: 0.2093, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 30, Loss: 0.0529, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 40, Loss: 0.1711, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 50, Loss: 0.1162, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 60, Loss: 0.1107, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 70, Loss: 0.2872, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 80, Loss: 0.2246, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 90, Loss: 0.1414, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 100, Loss: 0.0611, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 110, Loss: 0.3544, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 120, Loss: 0.2607, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 130, Loss: 0.3479, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 140, Loss: 0.0872, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 150, Loss: 0.3801, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 160, Loss: 0.6665, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 170, Loss: 0.2605, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 180, Loss: 0.0132, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 190, Loss: 0.1421, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 200, Loss: 0.1797, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 210, Loss: 0.3937, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 220, Loss: 0.1071, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 230, Loss: 0.4843, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 240, Loss: 0.0882, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 250, Loss: 0.3966, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 260, Loss: 0.0871, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 270, Loss: 0.4035, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 280, Loss: 0.5013, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 290, Loss: 0.0522, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 300, Loss: 0.2821, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 310, Loss: 0.2180, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 320, Loss: 0.1898, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 330, Loss: 0.1490, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 340, Loss: 0.2965, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 350, Loss: 0.2357, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 360, Loss: 0.1980, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 370, Loss: 0.0273, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 380, Loss: 0.4095, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 390, Loss: 0.2696, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 400, Loss: 0.4170, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 410, Loss: 0.2042, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 420, Loss: 0.1013, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 430, Loss: 0.2405, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 440, Loss: 0.2538, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 450, Loss: 0.1640, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 460, Loss: 0.0862, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 470, Loss: 0.1848, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 480, Loss: 0.5587, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 490, Loss: 0.0607, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 500, Loss: 0.3331, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 510, Loss: 0.1600, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 520, Loss: 0.1739, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 530, Loss: 0.1175, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 540, Loss: 0.2059, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 550, Loss: 0.0784, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 560, Loss: 0.1655, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 570, Loss: 0.2059, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 580, Loss: 0.0275, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 590, Loss: 0.0572, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 600, Loss: 0.0049, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 610, Loss: 0.4027, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 620, Loss: 0.2273, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 630, Loss: 0.1113, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 640, Loss: 0.1827, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 650, Loss: 0.3614, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 660, Loss: 0.1468, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 670, Loss: 0.2475, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 680, Loss: 0.1600, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 690, Loss: 0.0891, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 700, Loss: 0.7999, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 710, Loss: 0.0105, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 720, Loss: 0.1010, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 730, Loss: 0.5729, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 740, Loss: 0.0316, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 750, Loss: 0.1987, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 760, Loss: 0.0683, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 770, Loss: 0.0066, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 780, Loss: 0.4295, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 790, Loss: 0.2082, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 800, Loss: 0.0672, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 810, Loss: 0.0264, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 820, Loss: 0.3265, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 830, Loss: 0.5757, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 840, Loss: 0.0849, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 850, Loss: 0.1805, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 860, Loss: 0.1813, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 870, Loss: 0.4039, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 880, Loss: 0.0057, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 890, Loss: 0.0157, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 900, Loss: 0.1333, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 910, Loss: 0.1918, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 920, Loss: 0.2723, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 930, Loss: 0.3227, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 940, Loss: 0.0963, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 950, Loss: 0.2079, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 960, Loss: 0.0561, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 970, Loss: 0.1858, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 980, Loss: 0.2567, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 990, Loss: 0.1819, LR: 9.23e-05, Scale: 0.200
  Epoch 10, Batch 1000, Loss: 0.0811, LR: 9.23e-05, Scale: 0.200
‚úÖ Epoch 10 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1932
   È™åËØÅÊçüÂ§±: 0.1795
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_10.pth

=== Epoch 11/50 ===
  Epoch 11, Batch 0, Loss: 0.5416, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 10, Loss: 0.4686, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 20, Loss: 0.0481, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 30, Loss: 0.0137, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 40, Loss: 0.1102, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 50, Loss: 0.1240, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 60, Loss: 0.2123, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 70, Loss: 0.3733, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 80, Loss: 0.1178, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 90, Loss: 0.0691, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 100, Loss: 0.2437, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 110, Loss: 0.0960, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 120, Loss: 0.1867, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 130, Loss: 0.0452, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 140, Loss: 0.1945, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 150, Loss: 0.6051, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 160, Loss: 0.0087, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 170, Loss: 0.0933, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 180, Loss: 0.0468, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 190, Loss: 0.0846, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 200, Loss: 0.2194, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 210, Loss: 0.4681, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 220, Loss: 0.0794, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 230, Loss: 0.1590, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 240, Loss: 0.2102, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 250, Loss: 0.2546, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 260, Loss: 0.5300, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 270, Loss: 0.2299, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 280, Loss: 0.1447, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 290, Loss: 0.0171, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 300, Loss: 0.3228, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 310, Loss: 0.0931, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 320, Loss: 0.1951, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 330, Loss: 0.5023, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 340, Loss: 0.2350, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 350, Loss: 0.0820, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 360, Loss: 0.1078, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 370, Loss: 0.0713, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 380, Loss: 0.2311, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 390, Loss: 0.1037, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 400, Loss: 0.1606, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 410, Loss: 0.0251, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 420, Loss: 0.3450, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 430, Loss: 0.1929, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 440, Loss: 0.2075, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 450, Loss: 0.2196, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 460, Loss: 0.0967, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 470, Loss: 0.0549, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 480, Loss: 0.1611, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 490, Loss: 0.0431, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 500, Loss: 0.2198, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 510, Loss: 0.2872, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 520, Loss: 0.1005, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 530, Loss: 0.0382, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 540, Loss: 0.0739, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 550, Loss: 0.2513, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 560, Loss: 0.1114, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 570, Loss: 0.1676, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 580, Loss: 0.2672, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 590, Loss: 0.1480, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 600, Loss: 0.0428, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 610, Loss: 0.2627, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 620, Loss: 0.0590, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 630, Loss: 0.1588, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 640, Loss: 0.1024, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 650, Loss: 0.0740, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 660, Loss: 0.3923, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 670, Loss: 0.1146, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 680, Loss: 0.2021, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 690, Loss: 0.2621, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 700, Loss: 0.0076, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 710, Loss: 0.0675, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 720, Loss: 0.1290, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 730, Loss: 0.0141, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 740, Loss: 0.1712, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 750, Loss: 0.5171, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 760, Loss: 0.0651, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 770, Loss: 0.4338, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 780, Loss: 0.2357, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 790, Loss: 0.0762, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 800, Loss: 0.2353, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 810, Loss: 0.4769, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 820, Loss: 0.2435, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 830, Loss: 0.0085, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 840, Loss: 0.0454, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 850, Loss: 0.1466, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 860, Loss: 0.6195, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 870, Loss: 0.2079, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 880, Loss: 0.0742, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 890, Loss: 0.0515, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 900, Loss: 0.2318, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 910, Loss: 0.2477, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 920, Loss: 0.4764, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 930, Loss: 0.2032, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 940, Loss: 0.0768, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 950, Loss: 0.2643, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 960, Loss: 0.4889, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 970, Loss: 0.1105, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 980, Loss: 0.0301, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 990, Loss: 0.3788, LR: 9.05e-05, Scale: 0.200
  Epoch 11, Batch 1000, Loss: 0.0404, LR: 9.05e-05, Scale: 0.200
‚úÖ Epoch 11 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1920
   È™åËØÅÊçüÂ§±: 0.2009
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 12/50 ===
  Epoch 12, Batch 0, Loss: 0.1732, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 10, Loss: 0.2141, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 20, Loss: 0.3909, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 30, Loss: 0.0388, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 40, Loss: 0.1075, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 50, Loss: 0.2275, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 60, Loss: 0.4601, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 70, Loss: 0.2407, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 80, Loss: 0.2381, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 90, Loss: 0.1308, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 100, Loss: 0.0042, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 110, Loss: 0.0991, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 120, Loss: 0.0441, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 130, Loss: 0.0299, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 140, Loss: 0.3186, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 150, Loss: 0.1724, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 160, Loss: 0.3699, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 170, Loss: 0.2628, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 180, Loss: 0.0911, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 190, Loss: 0.4792, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 200, Loss: 0.2164, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 210, Loss: 0.0525, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 220, Loss: 0.0873, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 230, Loss: 0.1861, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 240, Loss: 0.1402, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 250, Loss: 0.1144, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 260, Loss: 0.0307, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 270, Loss: 0.4453, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 280, Loss: 0.3404, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 290, Loss: 0.0351, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 300, Loss: 0.2673, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 310, Loss: 0.0089, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 320, Loss: 0.3235, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 330, Loss: 0.1611, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 340, Loss: 0.2449, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 350, Loss: 0.0111, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 360, Loss: 0.2495, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 370, Loss: 0.1258, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 380, Loss: 0.3391, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 390, Loss: 0.2512, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 400, Loss: 0.5067, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 410, Loss: 0.1566, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 420, Loss: 0.3250, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 430, Loss: 0.1881, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 440, Loss: 0.2801, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 450, Loss: 0.2640, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 460, Loss: 0.0905, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 470, Loss: 0.1101, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 480, Loss: 0.0801, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 490, Loss: 0.3650, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 500, Loss: 0.2074, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 510, Loss: 0.0710, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 520, Loss: 0.2067, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 530, Loss: 0.4504, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 540, Loss: 0.0755, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 550, Loss: 0.0785, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 560, Loss: 0.3663, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 570, Loss: 0.2171, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 580, Loss: 0.0464, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 590, Loss: 0.3103, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 600, Loss: 0.1870, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 610, Loss: 0.0376, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 620, Loss: 0.1747, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 630, Loss: 0.1911, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 640, Loss: 0.1148, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 650, Loss: 0.3595, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 660, Loss: 0.1548, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 670, Loss: 0.0838, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 680, Loss: 0.1695, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 690, Loss: 0.0636, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 700, Loss: 0.3563, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 710, Loss: 0.0622, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 720, Loss: 0.0193, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 730, Loss: 0.4974, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 740, Loss: 0.0149, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 750, Loss: 0.0175, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 760, Loss: 0.3182, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 770, Loss: 0.3477, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 780, Loss: 0.1699, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 790, Loss: 0.0319, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 800, Loss: 0.0053, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 810, Loss: 0.0344, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 820, Loss: 0.0313, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 830, Loss: 0.1356, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 840, Loss: 0.0143, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 850, Loss: 0.2802, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 860, Loss: 0.0354, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 870, Loss: 0.2682, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 880, Loss: 0.0530, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 890, Loss: 0.0828, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 900, Loss: 0.0372, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 910, Loss: 0.0261, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 920, Loss: 0.3286, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 930, Loss: 0.0247, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 940, Loss: 0.4913, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 950, Loss: 0.3557, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 960, Loss: 0.4784, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 970, Loss: 0.2066, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 980, Loss: 0.1076, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 990, Loss: 0.2546, LR: 8.86e-05, Scale: 0.200
  Epoch 12, Batch 1000, Loss: 0.0698, LR: 8.86e-05, Scale: 0.200
‚úÖ Epoch 12 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1888
   È™åËØÅÊçüÂ§±: 0.1850
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 13/50 ===
  Epoch 13, Batch 0, Loss: 0.1272, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 10, Loss: 0.0667, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 20, Loss: 0.5078, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 30, Loss: 0.2421, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 40, Loss: 0.1934, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 50, Loss: 0.0328, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 60, Loss: 0.4847, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 70, Loss: 0.5573, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 80, Loss: 0.0117, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 90, Loss: 0.1743, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 100, Loss: 0.0929, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 110, Loss: 0.0146, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 120, Loss: 0.0755, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 130, Loss: 0.0074, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 140, Loss: 0.2648, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 150, Loss: 0.0160, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 160, Loss: 0.0075, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 170, Loss: 0.0324, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 180, Loss: 0.0649, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 190, Loss: 0.1357, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 200, Loss: 0.2388, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 210, Loss: 0.0089, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 220, Loss: 0.0516, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 230, Loss: 0.2998, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 240, Loss: 0.0192, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 250, Loss: 0.1413, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 260, Loss: 0.1095, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 270, Loss: 0.2198, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 280, Loss: 0.2525, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 290, Loss: 0.1179, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 300, Loss: 0.0756, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 310, Loss: 0.1315, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 320, Loss: 0.4400, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 330, Loss: 0.1972, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 340, Loss: 0.1451, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 350, Loss: 0.2263, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 360, Loss: 0.0380, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 370, Loss: 0.0501, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 380, Loss: 0.0558, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 390, Loss: 0.0597, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 400, Loss: 0.3249, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 410, Loss: 0.1714, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 420, Loss: 0.0688, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 430, Loss: 0.1798, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 440, Loss: 0.0843, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 450, Loss: 0.2342, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 460, Loss: 0.0551, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 470, Loss: 0.1752, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 480, Loss: 0.1865, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 490, Loss: 0.1699, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 500, Loss: 0.0775, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 510, Loss: 0.0288, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 520, Loss: 0.2948, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 530, Loss: 0.2108, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 540, Loss: 0.1172, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 550, Loss: 0.0509, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 560, Loss: 0.2824, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 570, Loss: 0.3715, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 580, Loss: 0.2969, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 590, Loss: 0.1728, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 600, Loss: 0.0532, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 610, Loss: 0.2647, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 620, Loss: 0.3054, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 630, Loss: 0.0584, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 640, Loss: 0.1147, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 650, Loss: 0.1818, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 660, Loss: 0.0342, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 670, Loss: 0.1582, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 680, Loss: 0.1373, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 690, Loss: 0.0994, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 700, Loss: 0.1015, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 710, Loss: 0.0088, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 720, Loss: 0.2450, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 730, Loss: 0.4487, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 740, Loss: 0.1677, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 750, Loss: 0.0398, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 760, Loss: 0.1194, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 770, Loss: 0.0217, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 780, Loss: 0.1712, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 790, Loss: 0.0718, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 800, Loss: 0.2007, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 810, Loss: 0.0276, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 820, Loss: 0.1050, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 830, Loss: 0.1493, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 840, Loss: 0.6187, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 850, Loss: 0.2091, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 860, Loss: 0.1756, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 870, Loss: 0.4931, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 880, Loss: 0.3779, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 890, Loss: 0.2099, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 900, Loss: 0.1605, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 910, Loss: 0.1121, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 920, Loss: 0.2419, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 930, Loss: 0.0603, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 940, Loss: 0.2155, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 950, Loss: 0.0720, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 960, Loss: 0.1391, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 970, Loss: 0.1404, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 980, Loss: 0.0074, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 990, Loss: 0.1404, LR: 8.66e-05, Scale: 0.200
  Epoch 13, Batch 1000, Loss: 0.0515, LR: 8.66e-05, Scale: 0.200
‚úÖ Epoch 13 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1858
   È™åËØÅÊçüÂ§±: 0.1951
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 14/50 ===
  Epoch 14, Batch 0, Loss: 0.1130, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 10, Loss: 0.1157, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 20, Loss: 0.1245, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 30, Loss: 0.1234, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 40, Loss: 0.2856, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 50, Loss: 0.3343, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 60, Loss: 0.1353, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 70, Loss: 0.0137, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 80, Loss: 0.0940, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 90, Loss: 0.0099, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 100, Loss: 0.0980, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 110, Loss: 0.3459, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 120, Loss: 0.3229, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 130, Loss: 0.0614, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 140, Loss: 0.2830, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 150, Loss: 0.0135, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 160, Loss: 0.1852, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 170, Loss: 0.4109, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 180, Loss: 0.0806, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 190, Loss: 0.1270, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 200, Loss: 0.0604, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 210, Loss: 0.0403, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 220, Loss: 0.0809, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 230, Loss: 0.2837, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 240, Loss: 0.0389, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 250, Loss: 0.1247, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 260, Loss: 0.2222, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 270, Loss: 0.0970, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 280, Loss: 0.2189, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 290, Loss: 0.1208, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 300, Loss: 0.1969, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 310, Loss: 0.0576, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 320, Loss: 0.0308, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 330, Loss: 0.2465, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 340, Loss: 0.0647, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 350, Loss: 0.2408, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 360, Loss: 0.2535, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 370, Loss: 0.1486, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 380, Loss: 0.0248, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 390, Loss: 0.3009, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 400, Loss: 0.1139, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 410, Loss: 0.1507, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 420, Loss: 0.1186, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 430, Loss: 0.2382, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 440, Loss: 0.2889, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 450, Loss: 0.4694, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 460, Loss: 0.2207, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 470, Loss: 0.4582, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 480, Loss: 0.1480, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 490, Loss: 0.4222, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 500, Loss: 0.1465, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 510, Loss: 0.0132, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 520, Loss: 0.3141, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 530, Loss: 0.0151, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 540, Loss: 0.1027, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 550, Loss: 0.3042, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 560, Loss: 0.5029, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 570, Loss: 0.2306, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 580, Loss: 0.3415, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 590, Loss: 0.0754, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 600, Loss: 0.0484, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 610, Loss: 0.0388, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 620, Loss: 0.0864, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 630, Loss: 0.0295, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 640, Loss: 0.3101, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 650, Loss: 0.2563, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 660, Loss: 0.1856, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 670, Loss: 0.1775, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 680, Loss: 0.0452, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 690, Loss: 0.0742, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 700, Loss: 0.5862, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 710, Loss: 0.2716, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 720, Loss: 0.0255, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 730, Loss: 0.0359, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 740, Loss: 0.0835, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 750, Loss: 0.2758, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 760, Loss: 0.0237, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 770, Loss: 0.0634, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 780, Loss: 0.1111, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 790, Loss: 0.0756, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 800, Loss: 0.0913, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 810, Loss: 0.0800, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 820, Loss: 0.1179, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 830, Loss: 0.2286, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 840, Loss: 0.2858, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 850, Loss: 0.1597, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 860, Loss: 0.4820, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 870, Loss: 0.0546, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 880, Loss: 0.2509, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 890, Loss: 0.0476, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 900, Loss: 0.1626, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 910, Loss: 0.0129, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 920, Loss: 0.2968, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 930, Loss: 0.0446, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 940, Loss: 0.4872, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 950, Loss: 0.1548, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 960, Loss: 0.0991, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 970, Loss: 0.0794, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 980, Loss: 0.1286, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 990, Loss: 0.2874, LR: 8.44e-05, Scale: 0.200
  Epoch 14, Batch 1000, Loss: 0.1744, LR: 8.44e-05, Scale: 0.200
‚úÖ Epoch 14 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1902
   È™åËØÅÊçüÂ§±: 0.2018
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 15/50 ===
  Epoch 15, Batch 0, Loss: 0.1878, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 10, Loss: 0.0345, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 20, Loss: 0.0165, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 30, Loss: 0.1168, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 40, Loss: 0.0495, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 50, Loss: 0.2000, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 60, Loss: 0.3912, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 70, Loss: 0.2149, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 80, Loss: 0.2117, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 90, Loss: 0.2947, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 100, Loss: 0.1184, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 110, Loss: 0.1937, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 120, Loss: 0.0709, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 130, Loss: 0.3948, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 140, Loss: 0.3144, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 150, Loss: 0.0049, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 160, Loss: 0.0485, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 170, Loss: 0.4436, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 180, Loss: 0.1973, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 190, Loss: 0.3397, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 200, Loss: 0.3847, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 210, Loss: 0.2506, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 220, Loss: 0.4314, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 230, Loss: 0.2069, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 240, Loss: 0.3069, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 250, Loss: 0.0592, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 260, Loss: 0.0923, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 270, Loss: 0.0994, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 280, Loss: 0.5940, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 290, Loss: 0.1944, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 300, Loss: 0.1607, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 310, Loss: 0.0981, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 320, Loss: 0.1357, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 330, Loss: 0.0057, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 340, Loss: 0.0052, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 350, Loss: 0.3729, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 360, Loss: 0.0816, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 370, Loss: 0.0246, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 380, Loss: 0.0728, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 390, Loss: 0.1831, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 400, Loss: 0.2929, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 410, Loss: 0.0224, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 420, Loss: 0.1294, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 430, Loss: 0.2992, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 440, Loss: 0.0380, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 450, Loss: 0.0777, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 460, Loss: 0.1425, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 470, Loss: 0.4006, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 480, Loss: 0.0051, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 490, Loss: 0.0576, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 500, Loss: 0.2016, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 510, Loss: 0.3965, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 520, Loss: 0.0198, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 530, Loss: 0.0055, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 540, Loss: 0.0630, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 550, Loss: 0.1646, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 560, Loss: 0.0156, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 570, Loss: 0.0766, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 580, Loss: 0.1146, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 590, Loss: 0.0509, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 600, Loss: 0.0552, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 610, Loss: 0.4301, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 620, Loss: 0.0681, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 630, Loss: 0.2277, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 640, Loss: 0.1248, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 650, Loss: 0.1057, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 660, Loss: 0.3100, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 670, Loss: 0.0497, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 680, Loss: 0.2174, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 690, Loss: 0.2241, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 700, Loss: 0.1267, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 710, Loss: 0.0404, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 720, Loss: 0.0657, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 730, Loss: 0.1328, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 740, Loss: 0.2969, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 750, Loss: 0.1399, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 760, Loss: 0.1690, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 770, Loss: 0.0139, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 780, Loss: 0.1228, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 790, Loss: 0.1875, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 800, Loss: 0.0032, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 810, Loss: 0.0247, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 820, Loss: 0.0726, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 830, Loss: 0.1258, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 840, Loss: 0.2340, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 850, Loss: 0.4036, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 860, Loss: 0.0428, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 870, Loss: 0.1330, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 880, Loss: 0.5659, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 890, Loss: 0.0180, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 900, Loss: 0.4402, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 910, Loss: 0.2734, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 920, Loss: 0.3503, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 930, Loss: 0.1770, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 940, Loss: 0.4684, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 950, Loss: 0.0746, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 960, Loss: 0.2827, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 970, Loss: 0.2089, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 980, Loss: 0.2060, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 990, Loss: 0.4456, LR: 8.21e-05, Scale: 0.200
  Epoch 15, Batch 1000, Loss: 0.0154, LR: 8.21e-05, Scale: 0.200
‚úÖ Epoch 15 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1921
   È™åËØÅÊçüÂ§±: 0.1698
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_best.pth
üíæ ‰øùÂ≠òÊúÄ‰Ω≥Ê®°ÂûãÔºåÈ™åËØÅÊçüÂ§±: 0.1698

=== Epoch 16/50 ===
  Epoch 16, Batch 0, Loss: 0.0518, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 10, Loss: 0.0478, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 20, Loss: 0.1704, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 30, Loss: 0.1953, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 40, Loss: 0.1414, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 50, Loss: 0.0315, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 60, Loss: 0.4306, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 70, Loss: 0.0428, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 80, Loss: 0.1790, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 90, Loss: 0.2220, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 100, Loss: 0.1043, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 110, Loss: 0.2053, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 120, Loss: 0.0470, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 130, Loss: 0.1537, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 140, Loss: 0.1956, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 150, Loss: 0.3754, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 160, Loss: 0.0972, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 170, Loss: 0.2217, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 180, Loss: 0.0838, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 190, Loss: 0.1464, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 200, Loss: 0.0024, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 210, Loss: 0.1327, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 220, Loss: 0.2568, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 230, Loss: 0.1437, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 240, Loss: 0.0390, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 250, Loss: 0.1238, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 260, Loss: 0.3543, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 270, Loss: 0.1527, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 280, Loss: 0.2042, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 290, Loss: 0.0768, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 300, Loss: 0.0894, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 310, Loss: 0.1890, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 320, Loss: 0.4183, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 330, Loss: 0.0440, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 340, Loss: 0.0570, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 350, Loss: 0.2447, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 360, Loss: 0.1094, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 370, Loss: 0.3752, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 380, Loss: 0.2064, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 390, Loss: 0.1365, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 400, Loss: 0.1770, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 410, Loss: 0.0622, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 420, Loss: 0.2776, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 430, Loss: 0.2936, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 440, Loss: 0.1588, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 450, Loss: 0.2178, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 460, Loss: 0.2577, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 470, Loss: 0.1493, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 480, Loss: 0.1077, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 490, Loss: 0.0779, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 500, Loss: 0.4928, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 510, Loss: 0.2115, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 520, Loss: 0.3213, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 530, Loss: 0.0093, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 540, Loss: 0.4118, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 550, Loss: 0.2844, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 560, Loss: 0.0509, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 570, Loss: 0.0792, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 580, Loss: 0.0489, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 590, Loss: 0.0147, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 600, Loss: 0.1265, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 610, Loss: 0.1161, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 620, Loss: 0.1942, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 630, Loss: 0.0099, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 640, Loss: 0.0090, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 650, Loss: 0.2183, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 660, Loss: 0.1979, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 670, Loss: 0.3241, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 680, Loss: 0.3978, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 690, Loss: 0.0158, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 700, Loss: 0.2461, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 710, Loss: 0.2646, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 720, Loss: 0.2753, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 730, Loss: 0.4221, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 740, Loss: 0.1407, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 750, Loss: 0.1076, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 760, Loss: 0.2853, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 770, Loss: 0.0162, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 780, Loss: 0.0492, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 790, Loss: 0.2040, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 800, Loss: 0.4398, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 810, Loss: 0.1959, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 820, Loss: 0.1641, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 830, Loss: 0.1035, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 840, Loss: 0.3462, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 850, Loss: 0.0429, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 860, Loss: 0.4803, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 870, Loss: 0.0389, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 880, Loss: 0.3601, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 890, Loss: 0.2680, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 900, Loss: 0.1232, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 910, Loss: 0.4082, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 920, Loss: 0.4630, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 930, Loss: 0.3228, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 940, Loss: 0.2433, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 950, Loss: 0.0794, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 960, Loss: 0.5232, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 970, Loss: 0.2451, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 980, Loss: 0.1622, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 990, Loss: 0.1628, LR: 7.96e-05, Scale: 0.200
  Epoch 16, Batch 1000, Loss: 0.0358, LR: 7.96e-05, Scale: 0.200
‚úÖ Epoch 16 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1894
   È™åËØÅÊçüÂ§±: 0.1713
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 17/50 ===
  Epoch 17, Batch 0, Loss: 0.1128, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 10, Loss: 0.0858, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 20, Loss: 0.1847, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 30, Loss: 0.2466, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 40, Loss: 0.0483, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 50, Loss: 0.0343, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 60, Loss: 0.0704, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 70, Loss: 0.2962, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 80, Loss: 0.3698, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 90, Loss: 0.1705, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 100, Loss: 0.1464, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 110, Loss: 0.1188, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 120, Loss: 0.1961, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 130, Loss: 0.0242, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 140, Loss: 0.1241, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 150, Loss: 0.2203, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 160, Loss: 0.1198, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 170, Loss: 0.4082, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 180, Loss: 0.1795, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 190, Loss: 0.3402, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 200, Loss: 0.7372, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 210, Loss: 0.0178, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 220, Loss: 0.3185, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 230, Loss: 0.2802, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 240, Loss: 0.0486, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 250, Loss: 0.0462, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 260, Loss: 0.0032, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 270, Loss: 0.4339, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 280, Loss: 0.0584, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 290, Loss: 0.2730, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 300, Loss: 0.0329, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 310, Loss: 0.1385, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 320, Loss: 0.3388, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 330, Loss: 0.4335, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 340, Loss: 0.1448, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 350, Loss: 0.5934, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 360, Loss: 0.2680, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 370, Loss: 0.2665, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 380, Loss: 0.0479, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 390, Loss: 0.2803, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 400, Loss: 0.1668, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 410, Loss: 0.2181, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 420, Loss: 0.2093, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 430, Loss: 0.0818, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 440, Loss: 0.0119, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 450, Loss: 0.0336, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 460, Loss: 0.3531, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 470, Loss: 0.0250, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 480, Loss: 0.2690, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 490, Loss: 0.0500, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 500, Loss: 0.0778, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 510, Loss: 0.1097, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 520, Loss: 0.4630, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 530, Loss: 0.0938, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 540, Loss: 0.2201, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 550, Loss: 0.4055, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 560, Loss: 0.0641, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 570, Loss: 0.3659, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 580, Loss: 0.0984, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 590, Loss: 0.1109, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 600, Loss: 0.0820, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 610, Loss: 0.1146, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 620, Loss: 0.3503, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 630, Loss: 0.1182, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 640, Loss: 0.1648, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 650, Loss: 0.0690, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 660, Loss: 0.0479, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 670, Loss: 0.0373, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 680, Loss: 0.2024, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 690, Loss: 0.1741, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 700, Loss: 0.0359, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 710, Loss: 0.0527, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 720, Loss: 0.3597, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 730, Loss: 0.3924, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 740, Loss: 0.4749, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 750, Loss: 0.0347, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 760, Loss: 0.0173, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 770, Loss: 0.1711, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 780, Loss: 0.5116, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 790, Loss: 0.0050, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 800, Loss: 0.1298, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 810, Loss: 0.1417, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 820, Loss: 0.0062, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 830, Loss: 0.0815, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 840, Loss: 0.1102, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 850, Loss: 0.3066, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 860, Loss: 0.5498, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 870, Loss: 0.0621, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 880, Loss: 0.0067, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 890, Loss: 0.3563, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 900, Loss: 0.1170, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 910, Loss: 0.4149, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 920, Loss: 0.0448, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 930, Loss: 0.0720, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 940, Loss: 0.1587, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 950, Loss: 0.0520, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 960, Loss: 0.3062, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 970, Loss: 0.2252, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 980, Loss: 0.0044, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 990, Loss: 0.1744, LR: 7.70e-05, Scale: 0.200
  Epoch 17, Batch 1000, Loss: 0.1133, LR: 7.70e-05, Scale: 0.200
‚úÖ Epoch 17 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1939
   È™åËØÅÊçüÂ§±: 0.1804
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 18/50 ===
  Epoch 18, Batch 0, Loss: 0.0111, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 10, Loss: 0.4157, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 20, Loss: 0.1480, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 30, Loss: 0.0382, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 40, Loss: 0.1479, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 50, Loss: 0.1127, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 60, Loss: 0.1641, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 70, Loss: 0.6531, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 80, Loss: 0.6274, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 90, Loss: 0.4342, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 100, Loss: 0.0809, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 110, Loss: 0.1758, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 120, Loss: 0.2641, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 130, Loss: 0.1746, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 140, Loss: 0.1287, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 150, Loss: 0.0201, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 160, Loss: 0.2969, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 170, Loss: 0.2730, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 180, Loss: 0.2656, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 190, Loss: 0.3036, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 200, Loss: 0.2066, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 210, Loss: 0.0247, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 220, Loss: 0.1708, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 230, Loss: 0.0692, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 240, Loss: 0.0073, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 250, Loss: 0.1885, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 260, Loss: 0.0782, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 270, Loss: 0.2996, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 280, Loss: 0.1138, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 290, Loss: 0.5027, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 300, Loss: 0.0103, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 310, Loss: 0.2193, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 320, Loss: 0.0881, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 330, Loss: 0.5046, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 340, Loss: 0.0480, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 350, Loss: 0.1717, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 360, Loss: 0.0518, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 370, Loss: 0.2845, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 380, Loss: 0.0518, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 390, Loss: 0.3273, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 400, Loss: 0.1772, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 410, Loss: 0.0084, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 420, Loss: 0.1156, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 430, Loss: 0.1735, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 440, Loss: 0.1265, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 450, Loss: 0.0141, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 460, Loss: 0.2710, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 470, Loss: 0.3698, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 480, Loss: 0.4587, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 490, Loss: 0.0356, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 500, Loss: 0.0146, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 510, Loss: 0.2712, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 520, Loss: 0.0350, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 530, Loss: 0.0684, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 540, Loss: 0.1340, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 550, Loss: 0.2472, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 560, Loss: 0.1541, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 570, Loss: 0.0739, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 580, Loss: 0.3332, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 590, Loss: 0.2507, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 600, Loss: 0.0149, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 610, Loss: 0.1180, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 620, Loss: 0.1410, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 630, Loss: 0.1922, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 640, Loss: 0.2737, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 650, Loss: 0.3497, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 660, Loss: 0.2326, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 670, Loss: 0.1382, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 680, Loss: 0.3776, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 690, Loss: 0.2011, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 700, Loss: 0.3361, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 710, Loss: 0.2927, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 720, Loss: 0.0473, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 730, Loss: 0.1462, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 740, Loss: 0.1413, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 750, Loss: 0.1841, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 760, Loss: 0.3224, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 770, Loss: 0.1288, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 780, Loss: 0.2254, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 790, Loss: 0.1775, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 800, Loss: 0.3905, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 810, Loss: 0.2359, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 820, Loss: 0.1244, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 830, Loss: 0.1525, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 840, Loss: 0.2814, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 850, Loss: 0.3856, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 860, Loss: 0.2704, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 870, Loss: 0.1488, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 880, Loss: 0.2590, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 890, Loss: 0.0928, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 900, Loss: 0.0677, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 910, Loss: 0.0920, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 920, Loss: 0.5943, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 930, Loss: 0.1512, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 940, Loss: 0.0729, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 950, Loss: 0.0886, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 960, Loss: 0.0085, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 970, Loss: 0.1875, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 980, Loss: 0.4315, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 990, Loss: 0.1341, LR: 7.43e-05, Scale: 0.200
  Epoch 18, Batch 1000, Loss: 0.0107, LR: 7.43e-05, Scale: 0.200
‚úÖ Epoch 18 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1854
   È™åËØÅÊçüÂ§±: 0.1741
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 19/50 ===
  Epoch 19, Batch 0, Loss: 0.0312, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 10, Loss: 0.1093, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 20, Loss: 0.0442, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 30, Loss: 0.3655, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 40, Loss: 0.0605, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 50, Loss: 0.0207, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 60, Loss: 0.1181, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 70, Loss: 0.0083, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 80, Loss: 0.1504, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 90, Loss: 0.2136, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 100, Loss: 0.0399, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 110, Loss: 0.0131, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 120, Loss: 0.0346, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 130, Loss: 0.3014, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 140, Loss: 0.3341, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 150, Loss: 0.2964, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 160, Loss: 0.2491, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 170, Loss: 0.2047, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 180, Loss: 0.0135, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 190, Loss: 0.2335, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 200, Loss: 0.2270, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 210, Loss: 0.4040, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 220, Loss: 0.1036, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 230, Loss: 0.1457, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 240, Loss: 0.0242, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 250, Loss: 0.4016, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 260, Loss: 0.0415, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 270, Loss: 0.0140, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 280, Loss: 0.1290, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 290, Loss: 0.0207, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 300, Loss: 0.0408, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 310, Loss: 0.1048, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 320, Loss: 0.4129, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 330, Loss: 0.1406, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 340, Loss: 0.2221, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 350, Loss: 0.2722, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 360, Loss: 0.1787, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 370, Loss: 0.0432, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 380, Loss: 0.1140, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 390, Loss: 0.3637, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 400, Loss: 0.2613, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 410, Loss: 0.2783, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 420, Loss: 0.2112, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 430, Loss: 0.1818, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 440, Loss: 0.4230, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 450, Loss: 0.0070, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 460, Loss: 0.1456, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 470, Loss: 0.1262, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 480, Loss: 0.4538, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 490, Loss: 0.1907, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 500, Loss: 0.2991, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 510, Loss: 0.2650, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 520, Loss: 0.3060, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 530, Loss: 0.0748, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 540, Loss: 0.3936, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 550, Loss: 0.1993, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 560, Loss: 0.2744, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 570, Loss: 0.0722, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 580, Loss: 0.2761, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 590, Loss: 0.0245, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 600, Loss: 0.2349, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 610, Loss: 0.1756, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 620, Loss: 0.1225, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 630, Loss: 0.0860, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 640, Loss: 0.1630, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 650, Loss: 0.2516, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 660, Loss: 0.1562, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 670, Loss: 0.1144, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 680, Loss: 0.1659, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 690, Loss: 0.3446, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 700, Loss: 0.1318, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 710, Loss: 0.1697, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 720, Loss: 0.0657, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 730, Loss: 0.0307, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 740, Loss: 0.2783, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 750, Loss: 0.2832, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 760, Loss: 0.0515, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 770, Loss: 0.1678, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 780, Loss: 0.1048, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 790, Loss: 0.5733, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 800, Loss: 0.4166, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 810, Loss: 0.1271, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 820, Loss: 0.2346, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 830, Loss: 0.4707, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 840, Loss: 0.4758, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 850, Loss: 0.1366, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 860, Loss: 0.1301, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 870, Loss: 0.2148, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 880, Loss: 0.1338, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 890, Loss: 0.3040, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 900, Loss: 0.4593, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 910, Loss: 0.2915, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 920, Loss: 0.2660, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 930, Loss: 0.1692, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 940, Loss: 0.3342, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 950, Loss: 0.0126, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 960, Loss: 0.3772, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 970, Loss: 0.3927, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 980, Loss: 0.2664, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 990, Loss: 0.1384, LR: 7.16e-05, Scale: 0.200
  Epoch 19, Batch 1000, Loss: 0.5393, LR: 7.16e-05, Scale: 0.200
‚úÖ Epoch 19 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1908
   È™åËØÅÊçüÂ§±: 0.1823
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 20/50 ===
  Epoch 20, Batch 0, Loss: 0.1449, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 10, Loss: 0.1214, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 20, Loss: 0.3186, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 30, Loss: 0.1543, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 40, Loss: 0.2336, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 50, Loss: 0.0997, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 60, Loss: 0.3810, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 70, Loss: 0.0283, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 80, Loss: 0.1640, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 90, Loss: 0.0279, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 100, Loss: 0.1400, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 110, Loss: 0.3049, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 120, Loss: 0.5062, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 130, Loss: 0.0101, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 140, Loss: 0.1462, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 150, Loss: 0.2277, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 160, Loss: 0.0037, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 170, Loss: 0.2463, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 180, Loss: 0.0230, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 190, Loss: 0.0301, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 200, Loss: 0.2447, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 210, Loss: 0.0513, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 220, Loss: 0.0856, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 230, Loss: 0.2547, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 240, Loss: 0.0322, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 250, Loss: 0.4957, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 260, Loss: 0.0205, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 270, Loss: 0.1682, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 280, Loss: 0.0263, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 290, Loss: 0.3649, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 300, Loss: 0.0400, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 310, Loss: 0.0776, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 320, Loss: 0.1252, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 330, Loss: 0.4307, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 340, Loss: 0.0537, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 350, Loss: 0.0137, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 360, Loss: 0.1859, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 370, Loss: 0.1737, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 380, Loss: 0.2416, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 390, Loss: 0.1202, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 400, Loss: 0.0160, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 410, Loss: 0.1106, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 420, Loss: 0.3102, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 430, Loss: 0.1172, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 440, Loss: 0.0215, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 450, Loss: 0.2654, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 460, Loss: 0.0164, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 470, Loss: 0.0315, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 480, Loss: 0.5275, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 490, Loss: 0.3438, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 500, Loss: 0.1560, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 510, Loss: 0.0261, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 520, Loss: 0.4139, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 530, Loss: 0.1650, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 540, Loss: 0.1341, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 550, Loss: 0.1947, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 560, Loss: 0.1130, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 570, Loss: 0.2020, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 580, Loss: 0.0864, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 590, Loss: 0.0365, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 600, Loss: 0.0701, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 610, Loss: 0.2943, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 620, Loss: 0.2761, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 630, Loss: 0.0276, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 640, Loss: 0.1078, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 650, Loss: 0.4889, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 660, Loss: 0.1646, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 670, Loss: 0.1404, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 680, Loss: 0.3752, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 690, Loss: 0.0199, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 700, Loss: 0.0067, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 710, Loss: 0.1704, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 720, Loss: 0.1668, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 730, Loss: 0.0871, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 740, Loss: 0.3636, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 750, Loss: 0.5283, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 760, Loss: 0.3328, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 770, Loss: 0.5602, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 780, Loss: 0.1626, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 790, Loss: 0.1519, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 800, Loss: 0.3031, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 810, Loss: 0.2801, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 820, Loss: 0.1224, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 830, Loss: 0.0077, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 840, Loss: 0.1670, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 850, Loss: 0.0350, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 860, Loss: 0.0263, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 870, Loss: 0.3228, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 880, Loss: 0.2058, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 890, Loss: 0.2952, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 900, Loss: 0.0306, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 910, Loss: 0.0347, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 920, Loss: 0.1192, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 930, Loss: 0.4711, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 940, Loss: 0.0402, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 950, Loss: 0.1514, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 960, Loss: 0.3792, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 970, Loss: 0.0170, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 980, Loss: 0.2532, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 990, Loss: 0.2309, LR: 6.87e-05, Scale: 0.200
  Epoch 20, Batch 1000, Loss: 0.2134, LR: 6.87e-05, Scale: 0.200
‚úÖ Epoch 20 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1900
   È™åËØÅÊçüÂ§±: 0.1864
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_20.pth

=== Epoch 21/50 ===
  Epoch 21, Batch 0, Loss: 0.1255, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 10, Loss: 0.1528, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 20, Loss: 0.0054, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 30, Loss: 0.0475, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 40, Loss: 0.2090, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 50, Loss: 0.5392, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 60, Loss: 0.1293, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 70, Loss: 0.1121, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 80, Loss: 0.0401, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 90, Loss: 0.1413, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 100, Loss: 0.2306, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 110, Loss: 0.1760, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 120, Loss: 0.3650, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 130, Loss: 0.0993, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 140, Loss: 0.1936, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 150, Loss: 0.0639, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 160, Loss: 0.1958, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 170, Loss: 0.0935, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 180, Loss: 0.2136, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 190, Loss: 0.0129, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 200, Loss: 0.0306, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 210, Loss: 0.2783, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 220, Loss: 0.0269, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 230, Loss: 0.3715, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 240, Loss: 0.1272, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 250, Loss: 0.1598, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 260, Loss: 0.1670, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 270, Loss: 0.4302, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 280, Loss: 0.0693, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 290, Loss: 0.1742, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 300, Loss: 0.1206, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 310, Loss: 0.0202, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 320, Loss: 0.4957, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 330, Loss: 0.0703, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 340, Loss: 0.0715, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 350, Loss: 0.0580, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 360, Loss: 0.1211, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 370, Loss: 0.0595, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 380, Loss: 0.1751, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 390, Loss: 0.0825, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 400, Loss: 0.4240, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 410, Loss: 0.0479, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 420, Loss: 0.0559, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 430, Loss: 0.0325, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 440, Loss: 0.0813, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 450, Loss: 0.1937, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 460, Loss: 0.1873, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 470, Loss: 0.5184, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 480, Loss: 0.5024, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 490, Loss: 0.3511, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 500, Loss: 0.1080, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 510, Loss: 0.0996, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 520, Loss: 0.1606, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 530, Loss: 0.0853, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 540, Loss: 0.1873, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 550, Loss: 0.3830, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 560, Loss: 0.1547, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 570, Loss: 0.1362, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 580, Loss: 0.2579, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 590, Loss: 0.0097, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 600, Loss: 0.2172, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 610, Loss: 0.4052, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 620, Loss: 0.1629, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 630, Loss: 0.2096, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 640, Loss: 0.5422, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 650, Loss: 0.1335, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 660, Loss: 0.3948, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 670, Loss: 0.1144, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 680, Loss: 0.0368, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 690, Loss: 0.0933, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 700, Loss: 0.0453, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 710, Loss: 0.2182, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 720, Loss: 0.1570, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 730, Loss: 0.1407, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 740, Loss: 0.0854, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 750, Loss: 0.6172, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 760, Loss: 0.0268, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 770, Loss: 0.0505, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 780, Loss: 0.2040, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 790, Loss: 0.0590, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 800, Loss: 0.0629, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 810, Loss: 0.0723, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 820, Loss: 0.2528, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 830, Loss: 0.3338, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 840, Loss: 0.1213, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 850, Loss: 0.0239, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 860, Loss: 0.2444, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 870, Loss: 0.2199, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 880, Loss: 0.1219, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 890, Loss: 0.2134, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 900, Loss: 0.0533, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 910, Loss: 0.0564, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 920, Loss: 0.2259, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 930, Loss: 0.7675, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 940, Loss: 0.3679, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 950, Loss: 0.3422, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 960, Loss: 0.2456, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 970, Loss: 0.2104, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 980, Loss: 0.2855, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 990, Loss: 0.4765, LR: 6.58e-05, Scale: 0.200
  Epoch 21, Batch 1000, Loss: 0.0899, LR: 6.58e-05, Scale: 0.200
‚úÖ Epoch 21 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1905
   È™åËØÅÊçüÂ§±: 0.2097
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 22/50 ===
  Epoch 22, Batch 0, Loss: 0.3146, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 10, Loss: 0.3774, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 20, Loss: 0.0100, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 30, Loss: 0.2739, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 40, Loss: 0.0832, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 50, Loss: 0.0900, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 60, Loss: 0.0515, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 70, Loss: 0.3896, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 80, Loss: 0.5381, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 90, Loss: 0.0280, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 100, Loss: 0.1420, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 110, Loss: 0.0121, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 120, Loss: 0.2454, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 130, Loss: 0.0868, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 140, Loss: 0.0366, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 150, Loss: 0.1833, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 160, Loss: 0.2802, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 170, Loss: 0.1483, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 180, Loss: 0.1414, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 190, Loss: 0.0800, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 200, Loss: 0.2694, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 210, Loss: 0.1045, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 220, Loss: 0.0436, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 230, Loss: 0.3499, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 240, Loss: 0.0765, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 250, Loss: 0.2899, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 260, Loss: 0.3432, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 270, Loss: 0.1779, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 280, Loss: 0.2393, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 290, Loss: 0.1469, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 300, Loss: 0.3277, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 310, Loss: 0.1353, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 320, Loss: 0.0172, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 330, Loss: 0.4679, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 340, Loss: 0.2718, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 350, Loss: 0.0277, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 360, Loss: 0.1492, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 370, Loss: 0.2171, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 380, Loss: 0.0927, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 390, Loss: 0.0664, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 400, Loss: 0.0066, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 410, Loss: 0.0523, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 420, Loss: 0.0083, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 430, Loss: 0.1928, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 440, Loss: 0.2395, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 450, Loss: 0.2861, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 460, Loss: 0.2761, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 470, Loss: 0.1265, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 480, Loss: 0.5007, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 490, Loss: 0.0065, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 500, Loss: 0.0249, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 510, Loss: 0.1159, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 520, Loss: 0.0593, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 530, Loss: 0.0519, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 540, Loss: 0.4453, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 550, Loss: 0.0824, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 560, Loss: 0.1967, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 570, Loss: 0.1977, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 580, Loss: 0.0760, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 590, Loss: 0.1015, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 600, Loss: 0.4020, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 610, Loss: 0.4391, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 620, Loss: 0.1381, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 630, Loss: 0.3129, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 640, Loss: 0.0810, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 650, Loss: 0.1053, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 660, Loss: 0.5433, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 670, Loss: 0.3529, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 680, Loss: 0.2303, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 690, Loss: 0.4980, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 700, Loss: 0.3387, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 710, Loss: 0.0241, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 720, Loss: 0.1209, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 730, Loss: 0.2774, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 740, Loss: 0.1715, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 750, Loss: 0.5564, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 760, Loss: 0.0588, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 770, Loss: 0.1973, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 780, Loss: 0.1628, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 790, Loss: 0.2900, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 800, Loss: 0.3647, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 810, Loss: 0.3685, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 820, Loss: 0.0950, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 830, Loss: 0.1374, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 840, Loss: 0.1792, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 850, Loss: 0.3322, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 860, Loss: 0.1860, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 870, Loss: 0.0489, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 880, Loss: 0.3714, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 890, Loss: 0.3771, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 900, Loss: 0.1347, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 910, Loss: 0.4443, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 920, Loss: 0.0903, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 930, Loss: 0.2142, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 940, Loss: 0.0963, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 950, Loss: 0.3060, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 960, Loss: 0.1054, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 970, Loss: 0.4414, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 980, Loss: 0.2988, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 990, Loss: 0.1127, LR: 6.28e-05, Scale: 0.200
  Epoch 22, Batch 1000, Loss: 0.0117, LR: 6.28e-05, Scale: 0.200
‚úÖ Epoch 22 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1891
   È™åËØÅÊçüÂ§±: 0.1824
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 23/50 ===
  Epoch 23, Batch 0, Loss: 0.3327, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 10, Loss: 0.0371, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 20, Loss: 0.0259, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 30, Loss: 0.3767, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 40, Loss: 0.2933, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 50, Loss: 0.0898, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 60, Loss: 0.0238, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 70, Loss: 0.1821, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 80, Loss: 0.0812, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 90, Loss: 0.2904, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 100, Loss: 0.1542, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 110, Loss: 0.2101, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 120, Loss: 0.2913, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 130, Loss: 0.2376, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 140, Loss: 0.1496, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 150, Loss: 0.4062, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 160, Loss: 0.0456, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 170, Loss: 0.0939, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 180, Loss: 0.3473, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 190, Loss: 0.0229, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 200, Loss: 0.3201, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 210, Loss: 0.1266, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 220, Loss: 0.1901, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 230, Loss: 0.3667, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 240, Loss: 0.0630, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 250, Loss: 0.1968, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 260, Loss: 0.1546, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 270, Loss: 0.3716, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 280, Loss: 0.0931, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 290, Loss: 0.2340, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 300, Loss: 0.1859, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 310, Loss: 0.0520, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 320, Loss: 0.1573, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 330, Loss: 0.0821, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 340, Loss: 0.0891, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 350, Loss: 0.1074, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 360, Loss: 0.1852, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 370, Loss: 0.1976, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 380, Loss: 0.0615, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 390, Loss: 0.2643, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 400, Loss: 0.2868, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 410, Loss: 0.0923, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 420, Loss: 0.0686, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 430, Loss: 0.1584, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 440, Loss: 0.0809, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 450, Loss: 0.1674, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 460, Loss: 0.1120, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 470, Loss: 0.4345, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 480, Loss: 0.5781, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 490, Loss: 0.4158, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 500, Loss: 0.0385, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 510, Loss: 0.0110, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 520, Loss: 0.0748, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 530, Loss: 0.3339, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 540, Loss: 0.6461, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 550, Loss: 0.4714, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 560, Loss: 0.3318, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 570, Loss: 0.3194, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 580, Loss: 0.0121, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 590, Loss: 0.1301, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 600, Loss: 0.2064, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 610, Loss: 0.1707, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 620, Loss: 0.0643, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 630, Loss: 0.0305, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 640, Loss: 0.2673, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 650, Loss: 0.1553, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 660, Loss: 0.0689, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 670, Loss: 0.0606, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 680, Loss: 0.0668, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 690, Loss: 0.0841, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 700, Loss: 0.0651, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 710, Loss: 0.3656, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 720, Loss: 0.0777, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 730, Loss: 0.4070, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 740, Loss: 0.0280, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 750, Loss: 0.0873, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 760, Loss: 0.2554, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 770, Loss: 0.0493, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 780, Loss: 0.0689, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 790, Loss: 0.3986, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 800, Loss: 0.2192, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 810, Loss: 0.1348, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 820, Loss: 0.0680, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 830, Loss: 0.2838, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 840, Loss: 0.0533, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 850, Loss: 0.0776, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 860, Loss: 0.2258, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 870, Loss: 0.1350, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 880, Loss: 0.3027, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 890, Loss: 0.0189, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 900, Loss: 0.0543, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 910, Loss: 0.0271, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 920, Loss: 0.0247, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 930, Loss: 0.1516, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 940, Loss: 0.1941, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 950, Loss: 0.0509, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 960, Loss: 0.0470, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 970, Loss: 0.1261, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 980, Loss: 0.1733, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 990, Loss: 0.2081, LR: 5.98e-05, Scale: 0.200
  Epoch 23, Batch 1000, Loss: 0.0191, LR: 5.98e-05, Scale: 0.200
‚úÖ Epoch 23 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1900
   È™åËØÅÊçüÂ§±: 0.1907
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 24/50 ===
  Epoch 24, Batch 0, Loss: 0.0536, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 10, Loss: 0.1664, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 20, Loss: 0.3031, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 30, Loss: 0.2222, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 40, Loss: 0.0075, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 50, Loss: 0.2963, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 60, Loss: 0.0099, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 70, Loss: 0.0154, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 80, Loss: 0.0146, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 90, Loss: 0.2428, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 100, Loss: 0.0453, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 110, Loss: 0.0670, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 120, Loss: 0.4406, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 130, Loss: 0.0372, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 140, Loss: 0.0178, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 150, Loss: 0.1368, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 160, Loss: 0.3087, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 170, Loss: 0.2148, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 180, Loss: 0.3540, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 190, Loss: 0.2643, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 200, Loss: 0.1079, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 210, Loss: 0.1844, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 220, Loss: 0.2592, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 230, Loss: 0.2765, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 240, Loss: 0.0211, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 250, Loss: 0.0082, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 260, Loss: 0.0716, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 270, Loss: 0.1136, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 280, Loss: 0.1813, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 290, Loss: 0.0122, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 300, Loss: 0.2021, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 310, Loss: 0.0084, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 320, Loss: 0.0187, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 330, Loss: 0.3689, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 340, Loss: 0.2183, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 350, Loss: 0.2527, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 360, Loss: 0.1883, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 370, Loss: 0.3727, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 380, Loss: 0.2674, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 390, Loss: 0.1329, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 400, Loss: 0.0108, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 410, Loss: 0.0348, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 420, Loss: 0.0113, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 430, Loss: 0.0726, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 440, Loss: 0.1232, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 450, Loss: 0.2384, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 460, Loss: 0.3116, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 470, Loss: 0.1750, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 480, Loss: 0.0491, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 490, Loss: 0.0127, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 500, Loss: 0.0942, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 510, Loss: 0.4687, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 520, Loss: 0.1556, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 530, Loss: 0.0770, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 540, Loss: 0.0852, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 550, Loss: 0.2306, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 560, Loss: 0.3468, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 570, Loss: 0.1565, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 580, Loss: 0.3047, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 590, Loss: 0.1755, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 600, Loss: 0.3289, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 610, Loss: 0.0151, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 620, Loss: 0.0401, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 630, Loss: 0.1148, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 640, Loss: 0.4332, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 650, Loss: 0.0508, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 660, Loss: 0.1035, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 670, Loss: 0.2767, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 680, Loss: 0.1061, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 690, Loss: 0.3970, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 700, Loss: 0.0525, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 710, Loss: 0.0682, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 720, Loss: 0.0385, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 730, Loss: 0.2451, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 740, Loss: 0.3182, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 750, Loss: 0.4090, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 760, Loss: 0.0658, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 770, Loss: 0.2148, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 780, Loss: 0.2353, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 790, Loss: 0.4016, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 800, Loss: 0.3586, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 810, Loss: 0.4077, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 820, Loss: 0.3286, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 830, Loss: 0.1110, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 840, Loss: 0.0459, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 850, Loss: 0.0321, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 860, Loss: 0.3037, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 870, Loss: 0.1162, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 880, Loss: 0.2257, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 890, Loss: 0.2075, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 900, Loss: 0.0778, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 910, Loss: 0.2534, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 920, Loss: 0.5132, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 930, Loss: 0.0474, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 940, Loss: 0.1388, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 950, Loss: 0.2812, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 960, Loss: 0.0248, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 970, Loss: 0.3520, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 980, Loss: 0.3482, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 990, Loss: 0.3520, LR: 5.67e-05, Scale: 0.200
  Epoch 24, Batch 1000, Loss: 0.2563, LR: 5.67e-05, Scale: 0.200
‚úÖ Epoch 24 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1893
   È™åËØÅÊçüÂ§±: 0.2028
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 25/50 ===
  Epoch 25, Batch 0, Loss: 0.3681, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 10, Loss: 0.1828, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 20, Loss: 0.1239, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 30, Loss: 0.3406, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 40, Loss: 0.2240, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 50, Loss: 0.1264, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 60, Loss: 0.0181, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 70, Loss: 0.2673, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 80, Loss: 0.5122, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 90, Loss: 0.4612, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 100, Loss: 0.3516, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 110, Loss: 0.1410, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 120, Loss: 0.1448, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 130, Loss: 0.0472, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 140, Loss: 0.1320, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 150, Loss: 0.2104, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 160, Loss: 0.3153, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 170, Loss: 0.0112, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 180, Loss: 0.2203, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 190, Loss: 0.0777, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 200, Loss: 0.3878, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 210, Loss: 0.2910, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 220, Loss: 0.1148, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 230, Loss: 0.0268, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 240, Loss: 0.0071, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 250, Loss: 0.0776, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 260, Loss: 0.1542, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 270, Loss: 0.0799, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 280, Loss: 0.3363, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 290, Loss: 0.1847, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 300, Loss: 0.1004, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 310, Loss: 0.4849, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 320, Loss: 0.0156, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 330, Loss: 0.0200, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 340, Loss: 0.1651, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 350, Loss: 0.1374, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 360, Loss: 0.1202, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 370, Loss: 0.0408, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 380, Loss: 0.2967, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 390, Loss: 0.2078, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 400, Loss: 0.0189, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 410, Loss: 0.1283, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 420, Loss: 0.2911, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 430, Loss: 0.0219, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 440, Loss: 0.1373, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 450, Loss: 0.0459, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 460, Loss: 0.0202, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 470, Loss: 0.0898, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 480, Loss: 0.0631, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 490, Loss: 0.2056, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 500, Loss: 0.5553, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 510, Loss: 0.1269, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 520, Loss: 0.1592, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 530, Loss: 0.1534, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 540, Loss: 0.0804, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 550, Loss: 0.3293, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 560, Loss: 0.2267, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 570, Loss: 0.1095, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 580, Loss: 0.0401, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 590, Loss: 0.0074, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 600, Loss: 0.2738, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 610, Loss: 0.1362, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 620, Loss: 0.1087, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 630, Loss: 0.3530, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 640, Loss: 0.2120, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 650, Loss: 0.0682, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 660, Loss: 0.1393, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 670, Loss: 0.2518, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 680, Loss: 0.2040, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 690, Loss: 0.0126, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 700, Loss: 0.1650, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 710, Loss: 0.2253, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 720, Loss: 0.3437, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 730, Loss: 0.4259, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 740, Loss: 0.2674, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 750, Loss: 0.1399, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 760, Loss: 0.1712, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 770, Loss: 0.1752, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 780, Loss: 0.0911, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 790, Loss: 0.2719, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 800, Loss: 0.3545, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 810, Loss: 0.0375, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 820, Loss: 0.0764, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 830, Loss: 0.0759, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 840, Loss: 0.2375, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 850, Loss: 0.2790, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 860, Loss: 0.1384, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 870, Loss: 0.4373, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 880, Loss: 0.0300, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 890, Loss: 0.3098, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 900, Loss: 0.1065, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 910, Loss: 0.2460, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 920, Loss: 0.2243, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 930, Loss: 0.2885, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 940, Loss: 0.0388, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 950, Loss: 0.0947, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 960, Loss: 0.4873, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 970, Loss: 0.1116, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 980, Loss: 0.1888, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 990, Loss: 0.2953, LR: 5.36e-05, Scale: 0.200
  Epoch 25, Batch 1000, Loss: 0.1880, LR: 5.36e-05, Scale: 0.200
‚úÖ Epoch 25 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1898
   È™åËØÅÊçüÂ§±: 0.1860
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 26/50 ===
  Epoch 26, Batch 0, Loss: 0.1605, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 10, Loss: 0.1144, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 20, Loss: 0.3527, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 30, Loss: 0.4687, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 40, Loss: 0.2496, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 50, Loss: 0.3526, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 60, Loss: 0.1217, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 70, Loss: 0.3486, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 80, Loss: 0.0149, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 90, Loss: 0.0753, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 100, Loss: 0.0082, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 110, Loss: 0.0959, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 120, Loss: 0.6040, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 130, Loss: 0.0941, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 140, Loss: 0.4687, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 150, Loss: 0.1409, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 160, Loss: 0.2430, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 170, Loss: 0.0452, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 180, Loss: 0.0571, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 190, Loss: 0.1165, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 200, Loss: 0.0880, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 210, Loss: 0.1686, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 220, Loss: 0.0770, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 230, Loss: 0.0922, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 240, Loss: 0.1146, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 250, Loss: 0.2142, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 260, Loss: 0.2507, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 270, Loss: 0.4488, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 280, Loss: 0.3608, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 290, Loss: 0.0841, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 300, Loss: 0.0505, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 310, Loss: 0.1208, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 320, Loss: 0.1812, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 330, Loss: 0.3271, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 340, Loss: 0.2944, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 350, Loss: 0.0251, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 360, Loss: 0.2380, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 370, Loss: 0.0358, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 380, Loss: 0.0617, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 390, Loss: 0.0460, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 400, Loss: 0.1823, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 410, Loss: 0.1070, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 420, Loss: 0.1735, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 430, Loss: 0.1398, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 440, Loss: 0.0596, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 450, Loss: 0.1275, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 460, Loss: 0.5730, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 470, Loss: 0.2815, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 480, Loss: 0.1439, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 490, Loss: 0.0747, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 500, Loss: 0.2126, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 510, Loss: 0.3822, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 520, Loss: 0.3394, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 530, Loss: 0.1648, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 540, Loss: 0.2257, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 550, Loss: 0.0043, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 560, Loss: 0.0823, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 570, Loss: 0.2112, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 580, Loss: 0.6913, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 590, Loss: 0.0590, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 600, Loss: 0.2054, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 610, Loss: 0.0903, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 620, Loss: 0.1063, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 630, Loss: 0.2007, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 640, Loss: 0.6099, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 650, Loss: 0.0372, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 660, Loss: 0.2316, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 670, Loss: 0.0632, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 680, Loss: 0.3990, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 690, Loss: 0.0199, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 700, Loss: 0.2466, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 710, Loss: 0.4707, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 720, Loss: 0.2692, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 730, Loss: 0.4055, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 740, Loss: 0.4410, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 750, Loss: 0.1997, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 760, Loss: 0.2374, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 770, Loss: 0.4732, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 780, Loss: 0.2028, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 790, Loss: 0.5126, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 800, Loss: 0.4193, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 810, Loss: 0.0732, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 820, Loss: 0.0820, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 830, Loss: 0.1021, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 840, Loss: 0.5190, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 850, Loss: 0.1760, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 860, Loss: 0.0335, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 870, Loss: 0.0493, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 880, Loss: 0.0195, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 890, Loss: 0.2709, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 900, Loss: 0.3865, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 910, Loss: 0.0035, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 920, Loss: 0.1365, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 930, Loss: 0.0235, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 940, Loss: 0.2888, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 950, Loss: 0.0756, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 960, Loss: 0.2755, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 970, Loss: 0.0616, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 980, Loss: 0.1261, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 990, Loss: 0.0443, LR: 5.05e-05, Scale: 0.200
  Epoch 26, Batch 1000, Loss: 0.1061, LR: 5.05e-05, Scale: 0.200
‚úÖ Epoch 26 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1767
   È™åËØÅÊçüÂ§±: 0.2049
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 27/50 ===
  Epoch 27, Batch 0, Loss: 0.0516, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 10, Loss: 0.0489, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 20, Loss: 0.1164, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 30, Loss: 0.2327, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 40, Loss: 0.2406, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 50, Loss: 0.1640, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 60, Loss: 0.0600, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 70, Loss: 0.4552, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 80, Loss: 0.4456, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 90, Loss: 0.3692, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 100, Loss: 0.3401, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 110, Loss: 0.1733, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 120, Loss: 0.1375, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 130, Loss: 0.2008, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 140, Loss: 0.3573, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 150, Loss: 0.3073, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 160, Loss: 0.2926, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 170, Loss: 0.1582, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 180, Loss: 0.3498, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 190, Loss: 0.1944, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 200, Loss: 0.0685, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 210, Loss: 0.0321, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 220, Loss: 0.0170, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 230, Loss: 0.2319, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 240, Loss: 0.0214, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 250, Loss: 0.1289, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 260, Loss: 0.0391, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 270, Loss: 0.0354, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 280, Loss: 0.0656, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 290, Loss: 0.3404, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 300, Loss: 0.3438, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 310, Loss: 0.0314, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 320, Loss: 0.1815, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 330, Loss: 0.2017, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 340, Loss: 0.3584, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 350, Loss: 0.1357, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 360, Loss: 0.1592, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 370, Loss: 0.1941, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 380, Loss: 0.2535, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 390, Loss: 0.0965, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 400, Loss: 0.0490, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 410, Loss: 0.0243, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 420, Loss: 0.1337, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 430, Loss: 0.0191, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 440, Loss: 0.4484, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 450, Loss: 0.0733, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 460, Loss: 0.2998, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 470, Loss: 0.4296, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 480, Loss: 0.0869, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 490, Loss: 0.3101, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 500, Loss: 0.0755, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 510, Loss: 0.4097, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 520, Loss: 0.1703, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 530, Loss: 0.0465, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 540, Loss: 0.3882, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 550, Loss: 0.0275, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 560, Loss: 0.2033, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 570, Loss: 0.3277, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 580, Loss: 0.0132, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 590, Loss: 0.1037, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 600, Loss: 0.2841, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 610, Loss: 0.2166, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 620, Loss: 0.2531, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 630, Loss: 0.2678, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 640, Loss: 0.3105, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 650, Loss: 0.0571, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 660, Loss: 0.0848, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 670, Loss: 0.0435, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 680, Loss: 0.1364, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 690, Loss: 0.0452, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 700, Loss: 0.2425, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 710, Loss: 0.3666, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 720, Loss: 0.1868, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 730, Loss: 0.1964, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 740, Loss: 0.0718, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 750, Loss: 0.1489, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 760, Loss: 0.2456, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 770, Loss: 0.0773, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 780, Loss: 0.0359, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 790, Loss: 0.0327, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 800, Loss: 0.1669, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 810, Loss: 0.1242, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 820, Loss: 0.3428, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 830, Loss: 0.2668, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 840, Loss: 0.3797, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 850, Loss: 0.1496, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 860, Loss: 0.2371, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 870, Loss: 0.2255, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 880, Loss: 0.1028, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 890, Loss: 0.2842, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 900, Loss: 0.1520, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 910, Loss: 0.0634, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 920, Loss: 0.4572, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 930, Loss: 0.0213, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 940, Loss: 0.2469, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 950, Loss: 0.1472, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 960, Loss: 0.8142, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 970, Loss: 0.0886, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 980, Loss: 0.2771, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 990, Loss: 0.2773, LR: 4.74e-05, Scale: 0.200
  Epoch 27, Batch 1000, Loss: 0.0178, LR: 4.74e-05, Scale: 0.200
‚úÖ Epoch 27 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1928
   È™åËØÅÊçüÂ§±: 0.1604
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_best.pth
üíæ ‰øùÂ≠òÊúÄ‰Ω≥Ê®°ÂûãÔºåÈ™åËØÅÊçüÂ§±: 0.1604

=== Epoch 28/50 ===
  Epoch 28, Batch 0, Loss: 0.1469, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 10, Loss: 0.2817, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 20, Loss: 0.0401, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 30, Loss: 0.2684, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 40, Loss: 0.2543, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 50, Loss: 0.0590, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 60, Loss: 0.5422, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 70, Loss: 0.1782, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 80, Loss: 0.2729, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 90, Loss: 0.2565, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 100, Loss: 0.0126, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 110, Loss: 0.0438, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 120, Loss: 0.2724, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 130, Loss: 0.1511, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 140, Loss: 0.2381, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 150, Loss: 0.1088, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 160, Loss: 0.0369, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 170, Loss: 0.4849, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 180, Loss: 0.3474, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 190, Loss: 0.1647, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 200, Loss: 0.2548, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 210, Loss: 0.0828, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 220, Loss: 0.1411, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 230, Loss: 0.2529, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 240, Loss: 0.1526, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 250, Loss: 0.2288, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 260, Loss: 0.0389, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 270, Loss: 0.0862, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 280, Loss: 0.4153, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 290, Loss: 0.5062, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 300, Loss: 0.1528, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 310, Loss: 0.3469, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 320, Loss: 0.0826, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 330, Loss: 0.0402, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 340, Loss: 0.0345, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 350, Loss: 0.2172, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 360, Loss: 0.2741, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 370, Loss: 0.6382, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 380, Loss: 0.1105, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 390, Loss: 0.1630, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 400, Loss: 0.2817, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 410, Loss: 0.0395, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 420, Loss: 0.2568, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 430, Loss: 0.2212, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 440, Loss: 0.5861, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 450, Loss: 0.0382, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 460, Loss: 0.0239, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 470, Loss: 0.4265, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 480, Loss: 0.1749, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 490, Loss: 0.0381, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 500, Loss: 0.0720, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 510, Loss: 0.0564, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 520, Loss: 0.0994, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 530, Loss: 0.2125, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 540, Loss: 0.0921, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 550, Loss: 0.0182, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 560, Loss: 0.2351, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 570, Loss: 0.1822, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 580, Loss: 0.1503, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 590, Loss: 0.5920, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 600, Loss: 0.5053, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 610, Loss: 0.0061, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 620, Loss: 0.1991, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 630, Loss: 0.1559, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 640, Loss: 0.0859, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 650, Loss: 0.0446, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 660, Loss: 0.1144, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 670, Loss: 0.3838, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 680, Loss: 0.0564, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 690, Loss: 0.2240, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 700, Loss: 0.1557, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 710, Loss: 0.2515, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 720, Loss: 0.2248, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 730, Loss: 0.0528, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 740, Loss: 0.1204, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 750, Loss: 0.2077, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 760, Loss: 0.0340, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 770, Loss: 0.0787, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 780, Loss: 0.1655, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 790, Loss: 0.0192, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 800, Loss: 0.2524, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 810, Loss: 0.0142, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 820, Loss: 0.2534, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 830, Loss: 0.3174, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 840, Loss: 0.3231, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 850, Loss: 0.1588, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 860, Loss: 0.2866, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 870, Loss: 0.3005, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 880, Loss: 0.2050, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 890, Loss: 0.0568, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 900, Loss: 0.0448, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 910, Loss: 0.2544, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 920, Loss: 0.1185, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 930, Loss: 0.1338, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 940, Loss: 0.1022, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 950, Loss: 0.1225, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 960, Loss: 0.3632, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 970, Loss: 0.1521, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 980, Loss: 0.2465, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 990, Loss: 0.0315, LR: 4.43e-05, Scale: 0.200
  Epoch 28, Batch 1000, Loss: 0.1531, LR: 4.43e-05, Scale: 0.200
‚úÖ Epoch 28 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1879
   È™åËØÅÊçüÂ§±: 0.1773
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 29/50 ===
  Epoch 29, Batch 0, Loss: 0.2774, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 10, Loss: 0.0356, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 20, Loss: 0.2896, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 30, Loss: 0.2390, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 40, Loss: 0.3116, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 50, Loss: 0.3638, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 60, Loss: 0.1905, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 70, Loss: 0.2215, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 80, Loss: 0.0587, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 90, Loss: 0.0333, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 100, Loss: 0.1292, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 110, Loss: 0.0699, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 120, Loss: 0.2289, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 130, Loss: 0.3840, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 140, Loss: 0.4012, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 150, Loss: 0.4124, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 160, Loss: 0.2639, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 170, Loss: 0.2346, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 180, Loss: 0.2496, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 190, Loss: 0.3115, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 200, Loss: 0.1338, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 210, Loss: 0.2250, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 220, Loss: 0.3203, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 230, Loss: 0.2518, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 240, Loss: 0.1421, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 250, Loss: 0.1231, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 260, Loss: 0.0071, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 270, Loss: 0.1843, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 280, Loss: 0.3316, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 290, Loss: 0.0069, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 300, Loss: 0.2739, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 310, Loss: 0.2490, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 320, Loss: 0.2203, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 330, Loss: 0.5301, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 340, Loss: 0.1848, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 350, Loss: 0.2219, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 360, Loss: 0.4303, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 370, Loss: 0.0486, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 380, Loss: 0.1086, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 390, Loss: 0.2142, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 400, Loss: 0.2531, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 410, Loss: 0.0820, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 420, Loss: 0.1151, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 430, Loss: 0.0082, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 440, Loss: 0.1640, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 450, Loss: 0.1634, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 460, Loss: 0.3407, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 470, Loss: 0.0149, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 480, Loss: 0.0173, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 490, Loss: 0.1025, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 500, Loss: 0.1662, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 510, Loss: 0.0269, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 520, Loss: 0.4321, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 530, Loss: 0.2471, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 540, Loss: 0.3086, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 550, Loss: 0.3332, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 560, Loss: 0.2143, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 570, Loss: 0.3040, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 580, Loss: 0.1219, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 590, Loss: 0.0595, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 600, Loss: 0.2789, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 610, Loss: 0.0191, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 620, Loss: 0.4753, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 630, Loss: 0.1557, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 640, Loss: 0.1152, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 650, Loss: 0.1455, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 660, Loss: 0.0136, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 670, Loss: 0.1529, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 680, Loss: 0.0065, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 690, Loss: 0.1573, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 700, Loss: 0.0180, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 710, Loss: 0.2522, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 720, Loss: 0.0754, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 730, Loss: 0.5222, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 740, Loss: 0.6022, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 750, Loss: 0.0505, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 760, Loss: 0.1111, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 770, Loss: 0.0374, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 780, Loss: 0.2213, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 790, Loss: 0.2333, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 800, Loss: 0.4384, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 810, Loss: 0.5113, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 820, Loss: 0.0205, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 830, Loss: 0.0267, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 840, Loss: 0.2248, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 850, Loss: 0.0980, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 860, Loss: 0.2612, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 870, Loss: 0.0787, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 880, Loss: 0.0139, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 890, Loss: 0.0060, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 900, Loss: 0.1457, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 910, Loss: 0.1240, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 920, Loss: 0.2060, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 930, Loss: 0.1044, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 940, Loss: 0.0386, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 950, Loss: 0.0146, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 960, Loss: 0.1312, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 970, Loss: 0.0255, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 980, Loss: 0.1605, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 990, Loss: 0.4789, LR: 4.12e-05, Scale: 0.200
  Epoch 29, Batch 1000, Loss: 0.3618, LR: 4.12e-05, Scale: 0.200
‚úÖ Epoch 29 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1889
   È™åËØÅÊçüÂ§±: 0.1744
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 30/50 ===
  Epoch 30, Batch 0, Loss: 0.1124, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 10, Loss: 0.2172, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 20, Loss: 0.0918, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 30, Loss: 0.0644, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 40, Loss: 0.1201, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 50, Loss: 0.0310, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 60, Loss: 0.1467, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 70, Loss: 0.3473, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 80, Loss: 0.0940, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 90, Loss: 0.4070, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 100, Loss: 0.0523, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 110, Loss: 0.0619, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 120, Loss: 0.2406, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 130, Loss: 0.1576, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 140, Loss: 0.0506, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 150, Loss: 0.0911, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 160, Loss: 0.3547, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 170, Loss: 0.0108, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 180, Loss: 0.3020, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 190, Loss: 0.2079, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 200, Loss: 0.1933, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 210, Loss: 0.1696, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 220, Loss: 0.0555, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 230, Loss: 0.4699, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 240, Loss: 0.2142, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 250, Loss: 0.2413, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 260, Loss: 0.0417, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 270, Loss: 0.1646, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 280, Loss: 0.0217, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 290, Loss: 0.0623, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 300, Loss: 0.1376, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 310, Loss: 0.2661, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 320, Loss: 0.0099, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 330, Loss: 0.1575, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 340, Loss: 0.0179, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 350, Loss: 0.1949, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 360, Loss: 0.0974, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 370, Loss: 0.2259, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 380, Loss: 0.0278, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 390, Loss: 0.1451, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 400, Loss: 0.0089, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 410, Loss: 0.2637, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 420, Loss: 0.1359, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 430, Loss: 0.2922, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 440, Loss: 0.0696, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 450, Loss: 0.0191, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 460, Loss: 0.0715, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 470, Loss: 0.3862, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 480, Loss: 0.0182, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 490, Loss: 0.1216, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 500, Loss: 0.0120, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 510, Loss: 0.1246, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 520, Loss: 0.3766, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 530, Loss: 0.2343, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 540, Loss: 0.3372, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 550, Loss: 0.1663, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 560, Loss: 0.1294, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 570, Loss: 0.3615, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 580, Loss: 0.2849, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 590, Loss: 0.1104, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 600, Loss: 0.0144, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 610, Loss: 0.2723, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 620, Loss: 0.0486, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 630, Loss: 0.0953, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 640, Loss: 0.0595, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 650, Loss: 0.0879, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 660, Loss: 0.0133, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 670, Loss: 0.1491, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 680, Loss: 0.3068, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 690, Loss: 0.2307, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 700, Loss: 0.1598, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 710, Loss: 0.0033, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 720, Loss: 0.0098, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 730, Loss: 0.2026, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 740, Loss: 0.2457, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 750, Loss: 0.1081, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 760, Loss: 0.4576, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 770, Loss: 0.1684, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 780, Loss: 0.1318, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 790, Loss: 0.0847, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 800, Loss: 0.0276, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 810, Loss: 0.1301, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 820, Loss: 0.1314, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 830, Loss: 0.5097, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 840, Loss: 0.0148, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 850, Loss: 0.1201, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 860, Loss: 0.3080, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 870, Loss: 0.1218, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 880, Loss: 0.0722, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 890, Loss: 0.1313, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 900, Loss: 0.1477, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 910, Loss: 0.1220, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 920, Loss: 0.1303, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 930, Loss: 0.1582, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 940, Loss: 0.1722, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 950, Loss: 0.0299, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 960, Loss: 0.2453, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 970, Loss: 0.0041, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 980, Loss: 0.3041, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 990, Loss: 0.0954, LR: 3.82e-05, Scale: 0.200
  Epoch 30, Batch 1000, Loss: 0.0678, LR: 3.82e-05, Scale: 0.200
‚úÖ Epoch 30 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1913
   È™åËØÅÊçüÂ§±: 0.1943
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_30.pth

=== Epoch 31/50 ===
  Epoch 31, Batch 0, Loss: 0.2359, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 10, Loss: 0.0553, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 20, Loss: 0.0259, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 30, Loss: 0.1965, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 40, Loss: 0.1498, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 50, Loss: 0.0375, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 60, Loss: 0.0920, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 70, Loss: 0.1596, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 80, Loss: 0.0294, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 90, Loss: 0.3284, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 100, Loss: 0.2396, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 110, Loss: 0.2168, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 120, Loss: 0.2047, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 130, Loss: 0.0712, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 140, Loss: 0.2244, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 150, Loss: 0.0136, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 160, Loss: 0.0301, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 170, Loss: 0.0710, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 180, Loss: 0.4692, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 190, Loss: 0.2452, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 200, Loss: 0.0409, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 210, Loss: 0.1687, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 220, Loss: 0.0900, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 230, Loss: 0.1364, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 240, Loss: 0.0321, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 250, Loss: 0.1232, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 260, Loss: 0.0536, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 270, Loss: 0.1413, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 280, Loss: 0.1933, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 290, Loss: 0.0876, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 300, Loss: 0.2134, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 310, Loss: 0.0825, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 320, Loss: 0.0165, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 330, Loss: 0.2915, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 340, Loss: 0.2719, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 350, Loss: 0.0447, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 360, Loss: 0.2242, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 370, Loss: 0.2944, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 380, Loss: 0.2285, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 390, Loss: 0.1513, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 400, Loss: 0.2016, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 410, Loss: 0.0779, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 420, Loss: 0.4106, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 430, Loss: 0.3874, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 440, Loss: 0.0501, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 450, Loss: 0.1663, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 460, Loss: 0.0840, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 470, Loss: 0.1183, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 480, Loss: 0.3428, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 490, Loss: 0.1197, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 500, Loss: 0.0861, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 510, Loss: 0.0091, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 520, Loss: 0.1241, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 530, Loss: 0.3099, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 540, Loss: 0.4480, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 550, Loss: 0.1792, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 560, Loss: 0.0418, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 570, Loss: 0.0080, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 580, Loss: 0.4165, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 590, Loss: 0.1635, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 600, Loss: 0.3622, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 610, Loss: 0.5298, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 620, Loss: 0.3460, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 630, Loss: 0.2750, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 640, Loss: 0.1585, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 650, Loss: 0.1260, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 660, Loss: 0.3292, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 670, Loss: 0.2846, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 680, Loss: 0.1077, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 690, Loss: 0.0781, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 700, Loss: 0.4654, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 710, Loss: 0.1636, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 720, Loss: 0.2485, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 730, Loss: 0.1545, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 740, Loss: 0.1156, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 750, Loss: 0.0930, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 760, Loss: 0.1997, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 770, Loss: 0.0362, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 780, Loss: 0.2384, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 790, Loss: 0.0452, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 800, Loss: 0.0235, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 810, Loss: 0.0583, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 820, Loss: 0.0948, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 830, Loss: 0.2020, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 840, Loss: 0.2518, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 850, Loss: 0.1624, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 860, Loss: 0.0676, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 870, Loss: 0.0066, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 880, Loss: 0.0378, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 890, Loss: 0.0592, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 900, Loss: 0.1798, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 910, Loss: 0.0261, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 920, Loss: 0.1631, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 930, Loss: 0.1764, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 940, Loss: 0.2053, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 950, Loss: 0.0496, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 960, Loss: 0.0066, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 970, Loss: 0.0561, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 980, Loss: 0.4407, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 990, Loss: 0.3938, LR: 3.52e-05, Scale: 0.200
  Epoch 31, Batch 1000, Loss: 0.0993, LR: 3.52e-05, Scale: 0.200
‚úÖ Epoch 31 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1799
   È™åËØÅÊçüÂ§±: 0.1819
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 32/50 ===
  Epoch 32, Batch 0, Loss: 0.0304, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 10, Loss: 0.3767, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 20, Loss: 0.0099, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 30, Loss: 0.2517, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 40, Loss: 0.0824, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 50, Loss: 0.0559, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 60, Loss: 0.1861, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 70, Loss: 0.2545, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 80, Loss: 0.1193, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 90, Loss: 0.2639, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 100, Loss: 0.3270, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 110, Loss: 0.1562, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 120, Loss: 0.0755, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 130, Loss: 0.1451, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 140, Loss: 0.2717, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 150, Loss: 0.0675, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 160, Loss: 0.3677, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 170, Loss: 0.0509, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 180, Loss: 0.2851, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 190, Loss: 0.0790, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 200, Loss: 0.1337, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 210, Loss: 0.0410, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 220, Loss: 0.1252, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 230, Loss: 0.0693, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 240, Loss: 0.3241, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 250, Loss: 0.0422, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 260, Loss: 0.2216, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 270, Loss: 0.2501, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 280, Loss: 0.4214, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 290, Loss: 0.6438, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 300, Loss: 0.1024, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 310, Loss: 0.0076, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 320, Loss: 0.2933, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 330, Loss: 0.3126, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 340, Loss: 0.3284, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 350, Loss: 0.1258, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 360, Loss: 0.0043, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 370, Loss: 0.1403, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 380, Loss: 0.2962, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 390, Loss: 0.2591, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 400, Loss: 0.2274, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 410, Loss: 0.1785, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 420, Loss: 0.0404, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 430, Loss: 0.4046, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 440, Loss: 0.0914, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 450, Loss: 0.1343, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 460, Loss: 0.0043, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 470, Loss: 0.1855, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 480, Loss: 0.2283, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 490, Loss: 0.4149, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 500, Loss: 0.0507, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 510, Loss: 0.1078, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 520, Loss: 0.0551, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 530, Loss: 0.0512, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 540, Loss: 0.1333, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 550, Loss: 0.2244, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 560, Loss: 0.4027, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 570, Loss: 0.2733, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 580, Loss: 0.1980, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 590, Loss: 0.2910, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 600, Loss: 0.0602, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 610, Loss: 0.2177, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 620, Loss: 0.1717, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 630, Loss: 0.4067, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 640, Loss: 0.0356, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 650, Loss: 0.3057, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 660, Loss: 0.5554, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 670, Loss: 0.1681, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 680, Loss: 0.4734, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 690, Loss: 0.0487, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 700, Loss: 0.0091, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 710, Loss: 0.2688, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 720, Loss: 0.2002, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 730, Loss: 0.0686, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 740, Loss: 0.0538, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 750, Loss: 0.2201, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 760, Loss: 0.0553, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 770, Loss: 0.3610, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 780, Loss: 0.1440, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 790, Loss: 0.1530, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 800, Loss: 0.2927, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 810, Loss: 0.3256, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 820, Loss: 0.4813, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 830, Loss: 0.4483, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 840, Loss: 0.1128, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 850, Loss: 0.2313, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 860, Loss: 0.1474, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 870, Loss: 0.2531, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 880, Loss: 0.2770, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 890, Loss: 0.1865, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 900, Loss: 0.2694, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 910, Loss: 0.0050, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 920, Loss: 0.0728, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 930, Loss: 0.4561, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 940, Loss: 0.0273, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 950, Loss: 0.2519, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 960, Loss: 0.3680, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 970, Loss: 0.0767, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 980, Loss: 0.4405, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 990, Loss: 0.0876, LR: 3.23e-05, Scale: 0.200
  Epoch 32, Batch 1000, Loss: 0.0289, LR: 3.23e-05, Scale: 0.200
‚úÖ Epoch 32 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1904
   È™åËØÅÊçüÂ§±: 0.1674
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 33/50 ===
  Epoch 33, Batch 0, Loss: 0.2024, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 10, Loss: 0.1247, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 20, Loss: 0.0458, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 30, Loss: 0.0047, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 40, Loss: 0.0120, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 50, Loss: 0.0456, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 60, Loss: 0.3163, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 70, Loss: 0.0955, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 80, Loss: 0.4779, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 90, Loss: 0.3551, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 100, Loss: 0.0368, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 110, Loss: 0.0732, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 120, Loss: 0.4781, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 130, Loss: 0.0219, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 140, Loss: 0.3126, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 150, Loss: 0.0223, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 160, Loss: 0.2252, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 170, Loss: 0.1259, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 180, Loss: 0.0496, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 190, Loss: 0.2374, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 200, Loss: 0.1164, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 210, Loss: 0.0888, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 220, Loss: 0.1983, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 230, Loss: 0.3678, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 240, Loss: 0.0456, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 250, Loss: 0.0236, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 260, Loss: 0.1174, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 270, Loss: 0.3720, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 280, Loss: 0.1473, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 290, Loss: 0.1976, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 300, Loss: 0.2056, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 310, Loss: 0.1873, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 320, Loss: 0.3731, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 330, Loss: 0.0611, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 340, Loss: 0.1856, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 350, Loss: 0.1547, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 360, Loss: 0.0087, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 370, Loss: 0.1062, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 380, Loss: 0.0753, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 390, Loss: 0.2044, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 400, Loss: 0.2355, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 410, Loss: 0.3422, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 420, Loss: 0.2450, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 430, Loss: 0.2013, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 440, Loss: 0.1380, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 450, Loss: 0.1155, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 460, Loss: 0.0339, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 470, Loss: 0.3793, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 480, Loss: 0.0371, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 490, Loss: 0.1455, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 500, Loss: 0.4731, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 510, Loss: 0.0330, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 520, Loss: 0.3091, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 530, Loss: 0.0601, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 540, Loss: 0.0215, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 550, Loss: 0.4834, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 560, Loss: 0.1401, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 570, Loss: 0.2237, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 580, Loss: 0.2672, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 590, Loss: 0.1226, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 600, Loss: 0.1440, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 610, Loss: 0.0116, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 620, Loss: 0.4645, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 630, Loss: 0.1989, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 640, Loss: 0.3357, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 650, Loss: 0.1064, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 660, Loss: 0.0214, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 670, Loss: 0.0404, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 680, Loss: 0.5560, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 690, Loss: 0.0202, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 700, Loss: 0.3877, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 710, Loss: 0.4034, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 720, Loss: 0.3614, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 730, Loss: 0.3890, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 740, Loss: 0.1404, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 750, Loss: 0.0495, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 760, Loss: 0.0761, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 770, Loss: 0.3430, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 780, Loss: 0.2525, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 790, Loss: 0.2033, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 800, Loss: 0.1484, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 810, Loss: 0.0108, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 820, Loss: 0.1480, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 830, Loss: 0.0743, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 840, Loss: 0.2335, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 850, Loss: 0.2439, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 860, Loss: 0.0318, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 870, Loss: 0.1333, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 880, Loss: 0.3033, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 890, Loss: 0.2241, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 900, Loss: 0.1053, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 910, Loss: 0.2131, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 920, Loss: 0.4638, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 930, Loss: 0.1600, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 940, Loss: 0.6070, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 950, Loss: 0.0345, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 960, Loss: 0.4152, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 970, Loss: 0.3524, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 980, Loss: 0.0968, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 990, Loss: 0.1404, LR: 2.94e-05, Scale: 0.200
  Epoch 33, Batch 1000, Loss: 0.4818, LR: 2.94e-05, Scale: 0.200
‚úÖ Epoch 33 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1897
   È™åËØÅÊçüÂ§±: 0.1801
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 34/50 ===
  Epoch 34, Batch 0, Loss: 0.2151, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 10, Loss: 0.3848, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 20, Loss: 0.0875, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 30, Loss: 0.2174, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 40, Loss: 0.2106, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 50, Loss: 0.2654, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 60, Loss: 0.0713, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 70, Loss: 0.0231, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 80, Loss: 0.2404, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 90, Loss: 0.3246, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 100, Loss: 0.0457, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 110, Loss: 0.0051, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 120, Loss: 0.5416, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 130, Loss: 0.0290, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 140, Loss: 0.1436, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 150, Loss: 0.2711, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 160, Loss: 0.0915, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 170, Loss: 0.0105, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 180, Loss: 0.1101, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 190, Loss: 0.0405, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 200, Loss: 0.1943, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 210, Loss: 0.2488, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 220, Loss: 0.0695, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 230, Loss: 0.0753, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 240, Loss: 0.4225, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 250, Loss: 0.1758, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 260, Loss: 0.0774, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 270, Loss: 0.1610, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 280, Loss: 0.2918, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 290, Loss: 0.0290, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 300, Loss: 0.0156, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 310, Loss: 0.3250, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 320, Loss: 0.3627, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 330, Loss: 0.0819, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 340, Loss: 0.2010, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 350, Loss: 0.4430, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 360, Loss: 0.1183, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 370, Loss: 0.1349, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 380, Loss: 0.0771, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 390, Loss: 0.2427, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 400, Loss: 0.1786, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 410, Loss: 0.1818, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 420, Loss: 0.1844, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 430, Loss: 0.2146, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 440, Loss: 0.3784, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 450, Loss: 0.0806, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 460, Loss: 0.1929, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 470, Loss: 0.2842, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 480, Loss: 0.0045, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 490, Loss: 0.2350, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 500, Loss: 0.1434, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 510, Loss: 0.3501, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 520, Loss: 0.1762, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 530, Loss: 0.2656, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 540, Loss: 0.2947, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 550, Loss: 0.3270, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 560, Loss: 0.5846, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 570, Loss: 0.2260, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 580, Loss: 0.1821, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 590, Loss: 0.0087, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 600, Loss: 0.0547, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 610, Loss: 0.3395, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 620, Loss: 0.1509, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 630, Loss: 0.1059, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 640, Loss: 0.2046, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 650, Loss: 0.1578, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 660, Loss: 0.2195, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 670, Loss: 0.0836, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 680, Loss: 0.1300, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 690, Loss: 0.0869, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 700, Loss: 0.4230, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 710, Loss: 0.0094, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 720, Loss: 0.1446, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 730, Loss: 0.3860, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 740, Loss: 0.1116, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 750, Loss: 0.1971, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 760, Loss: 0.3601, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 770, Loss: 0.1779, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 780, Loss: 0.0055, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 790, Loss: 0.0376, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 800, Loss: 0.3961, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 810, Loss: 0.2246, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 820, Loss: 0.1832, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 830, Loss: 0.1330, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 840, Loss: 0.0822, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 850, Loss: 0.2019, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 860, Loss: 0.2558, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 870, Loss: 0.0954, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 880, Loss: 0.3888, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 890, Loss: 0.2983, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 900, Loss: 0.0740, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 910, Loss: 0.0128, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 920, Loss: 0.0449, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 930, Loss: 0.4253, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 940, Loss: 0.3267, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 950, Loss: 0.3800, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 960, Loss: 0.0282, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 970, Loss: 0.5185, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 980, Loss: 0.0262, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 990, Loss: 0.1521, LR: 2.67e-05, Scale: 0.200
  Epoch 34, Batch 1000, Loss: 0.3052, LR: 2.67e-05, Scale: 0.200
‚úÖ Epoch 34 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1830
   È™åËØÅÊçüÂ§±: 0.1839
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 35/50 ===
  Epoch 35, Batch 0, Loss: 0.1561, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 10, Loss: 0.1450, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 20, Loss: 0.1563, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 30, Loss: 0.1973, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 40, Loss: 0.3277, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 50, Loss: 0.2570, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 60, Loss: 0.3904, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 70, Loss: 0.1272, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 80, Loss: 0.1762, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 90, Loss: 0.2362, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 100, Loss: 0.3976, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 110, Loss: 0.4033, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 120, Loss: 0.1057, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 130, Loss: 0.1122, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 140, Loss: 0.2200, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 150, Loss: 0.1872, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 160, Loss: 0.5927, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 170, Loss: 0.0718, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 180, Loss: 0.0170, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 190, Loss: 0.0331, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 200, Loss: 0.0887, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 210, Loss: 0.0038, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 220, Loss: 0.0229, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 230, Loss: 0.0278, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 240, Loss: 0.3082, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 250, Loss: 0.2597, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 260, Loss: 0.0050, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 270, Loss: 0.1568, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 280, Loss: 0.4043, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 290, Loss: 0.3364, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 300, Loss: 0.3494, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 310, Loss: 0.1758, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 320, Loss: 0.0720, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 330, Loss: 0.2837, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 340, Loss: 0.2513, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 350, Loss: 0.0269, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 360, Loss: 0.0628, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 370, Loss: 0.0482, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 380, Loss: 0.0149, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 390, Loss: 0.1150, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 400, Loss: 0.1853, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 410, Loss: 0.0084, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 420, Loss: 0.0352, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 430, Loss: 0.0709, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 440, Loss: 0.4393, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 450, Loss: 0.2374, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 460, Loss: 0.2666, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 470, Loss: 0.0866, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 480, Loss: 0.0267, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 490, Loss: 0.1050, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 500, Loss: 0.4805, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 510, Loss: 0.1915, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 520, Loss: 0.1038, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 530, Loss: 0.2221, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 540, Loss: 0.1278, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 550, Loss: 0.2569, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 560, Loss: 0.5478, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 570, Loss: 0.0617, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 580, Loss: 0.1083, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 590, Loss: 0.0571, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 600, Loss: 0.3318, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 610, Loss: 0.0434, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 620, Loss: 0.2555, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 630, Loss: 0.0386, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 640, Loss: 0.0341, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 650, Loss: 0.3665, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 660, Loss: 0.0100, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 670, Loss: 0.1118, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 680, Loss: 0.2669, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 690, Loss: 0.0942, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 700, Loss: 0.0253, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 710, Loss: 0.0291, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 720, Loss: 0.4169, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 730, Loss: 0.1318, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 740, Loss: 0.2477, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 750, Loss: 0.2396, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 760, Loss: 0.0927, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 770, Loss: 0.1966, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 780, Loss: 0.0322, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 790, Loss: 0.1722, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 800, Loss: 0.1436, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 810, Loss: 0.1807, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 820, Loss: 0.5729, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 830, Loss: 0.0593, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 840, Loss: 0.0377, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 850, Loss: 0.1950, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 860, Loss: 0.4448, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 870, Loss: 0.4419, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 880, Loss: 0.0189, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 890, Loss: 0.3008, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 900, Loss: 0.1795, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 910, Loss: 0.1568, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 920, Loss: 0.0187, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 930, Loss: 0.0262, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 940, Loss: 0.0878, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 950, Loss: 0.3175, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 960, Loss: 0.0096, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 970, Loss: 0.1806, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 980, Loss: 0.2480, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 990, Loss: 0.3880, LR: 2.40e-05, Scale: 0.200
  Epoch 35, Batch 1000, Loss: 0.1614, LR: 2.40e-05, Scale: 0.200
‚úÖ Epoch 35 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1826
   È™åËØÅÊçüÂ§±: 0.1913
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 36/50 ===
  Epoch 36, Batch 0, Loss: 0.3922, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 10, Loss: 0.0240, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 20, Loss: 0.1049, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 30, Loss: 0.0509, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 40, Loss: 0.0822, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 50, Loss: 0.1898, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 60, Loss: 0.1107, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 70, Loss: 0.0996, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 80, Loss: 0.0885, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 90, Loss: 0.1180, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 100, Loss: 0.2885, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 110, Loss: 0.4759, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 120, Loss: 0.1639, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 130, Loss: 0.0342, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 140, Loss: 0.2420, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 150, Loss: 0.3651, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 160, Loss: 0.3437, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 170, Loss: 0.0363, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 180, Loss: 0.4049, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 190, Loss: 0.4638, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 200, Loss: 0.3074, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 210, Loss: 0.2368, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 220, Loss: 0.2809, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 230, Loss: 0.2323, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 240, Loss: 0.3169, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 250, Loss: 0.1382, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 260, Loss: 0.0576, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 270, Loss: 0.5257, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 280, Loss: 0.3068, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 290, Loss: 0.2243, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 300, Loss: 0.1981, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 310, Loss: 0.2936, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 320, Loss: 0.1791, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 330, Loss: 0.2996, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 340, Loss: 0.3158, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 350, Loss: 0.1486, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 360, Loss: 0.0160, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 370, Loss: 0.2133, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 380, Loss: 0.1301, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 390, Loss: 0.1807, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 400, Loss: 0.1126, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 410, Loss: 0.1401, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 420, Loss: 0.1610, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 430, Loss: 0.0524, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 440, Loss: 0.0742, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 450, Loss: 0.2497, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 460, Loss: 0.3476, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 470, Loss: 0.2281, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 480, Loss: 0.2298, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 490, Loss: 0.3772, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 500, Loss: 0.0045, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 510, Loss: 0.1182, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 520, Loss: 0.0685, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 530, Loss: 0.1679, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 540, Loss: 0.2431, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 550, Loss: 0.0756, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 560, Loss: 0.2263, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 570, Loss: 0.2561, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 580, Loss: 0.0078, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 590, Loss: 0.0900, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 600, Loss: 0.1496, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 610, Loss: 0.2425, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 620, Loss: 0.4992, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 630, Loss: 0.1266, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 640, Loss: 0.0998, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 650, Loss: 0.0237, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 660, Loss: 0.0312, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 670, Loss: 0.0921, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 680, Loss: 0.2546, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 690, Loss: 0.1360, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 700, Loss: 0.0423, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 710, Loss: 0.1088, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 720, Loss: 0.2359, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 730, Loss: 0.0827, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 740, Loss: 0.1034, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 750, Loss: 0.2643, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 760, Loss: 0.0455, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 770, Loss: 0.3710, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 780, Loss: 0.4932, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 790, Loss: 0.4363, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 800, Loss: 0.2252, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 810, Loss: 0.2003, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 820, Loss: 0.1669, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 830, Loss: 0.1768, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 840, Loss: 0.0768, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 850, Loss: 0.2674, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 860, Loss: 0.0463, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 870, Loss: 0.2040, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 880, Loss: 0.1926, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 890, Loss: 0.1194, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 900, Loss: 0.0480, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 910, Loss: 0.4326, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 920, Loss: 0.0709, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 930, Loss: 0.0190, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 940, Loss: 0.0628, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 950, Loss: 0.2037, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 960, Loss: 0.4950, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 970, Loss: 0.1335, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 980, Loss: 0.1998, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 990, Loss: 0.1712, LR: 2.14e-05, Scale: 0.200
  Epoch 36, Batch 1000, Loss: 0.0738, LR: 2.14e-05, Scale: 0.200
‚úÖ Epoch 36 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1786
   È™åËØÅÊçüÂ§±: 0.1868
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 37/50 ===
  Epoch 37, Batch 0, Loss: 0.0099, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 10, Loss: 0.0911, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 20, Loss: 0.4076, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 30, Loss: 0.0182, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 40, Loss: 0.0266, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 50, Loss: 0.1612, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 60, Loss: 0.2531, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 70, Loss: 0.1058, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 80, Loss: 0.2812, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 90, Loss: 0.0178, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 100, Loss: 0.1014, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 110, Loss: 0.1415, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 120, Loss: 0.4517, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 130, Loss: 0.1502, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 140, Loss: 0.0045, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 150, Loss: 0.3386, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 160, Loss: 0.0114, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 170, Loss: 0.1079, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 180, Loss: 0.2279, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 190, Loss: 0.1585, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 200, Loss: 0.1177, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 210, Loss: 0.0618, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 220, Loss: 0.0425, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 230, Loss: 0.0418, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 240, Loss: 0.0336, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 250, Loss: 0.1638, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 260, Loss: 0.2412, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 270, Loss: 0.1198, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 280, Loss: 0.1517, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 290, Loss: 0.1263, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 300, Loss: 0.0180, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 310, Loss: 0.2489, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 320, Loss: 0.4611, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 330, Loss: 0.1888, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 340, Loss: 0.1698, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 350, Loss: 0.0759, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 360, Loss: 0.3351, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 370, Loss: 0.2902, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 380, Loss: 0.2307, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 390, Loss: 0.0521, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 400, Loss: 0.1289, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 410, Loss: 0.0177, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 420, Loss: 0.0538, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 430, Loss: 0.0209, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 440, Loss: 0.1041, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 450, Loss: 0.4003, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 460, Loss: 0.0747, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 470, Loss: 0.2962, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 480, Loss: 0.5311, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 490, Loss: 0.0129, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 500, Loss: 0.0948, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 510, Loss: 0.1032, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 520, Loss: 0.2500, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 530, Loss: 0.2045, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 540, Loss: 0.0051, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 550, Loss: 0.2347, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 560, Loss: 0.1715, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 570, Loss: 0.1189, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 580, Loss: 0.0618, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 590, Loss: 0.3136, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 600, Loss: 0.0873, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 610, Loss: 0.3758, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 620, Loss: 0.0832, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 630, Loss: 0.4445, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 640, Loss: 0.1576, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 650, Loss: 0.1824, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 660, Loss: 0.1159, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 670, Loss: 0.0981, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 680, Loss: 0.0105, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 690, Loss: 0.0553, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 700, Loss: 0.3270, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 710, Loss: 0.0575, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 720, Loss: 0.0257, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 730, Loss: 0.2366, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 740, Loss: 0.0337, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 750, Loss: 0.0505, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 760, Loss: 0.2307, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 770, Loss: 0.3172, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 780, Loss: 0.3393, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 790, Loss: 0.3748, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 800, Loss: 0.5172, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 810, Loss: 0.2311, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 820, Loss: 0.2966, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 830, Loss: 0.1761, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 840, Loss: 0.6424, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 850, Loss: 0.1810, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 860, Loss: 0.0509, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 870, Loss: 0.4455, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 880, Loss: 0.1311, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 890, Loss: 0.0210, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 900, Loss: 0.4048, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 910, Loss: 0.0455, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 920, Loss: 0.4078, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 930, Loss: 0.0049, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 940, Loss: 0.1564, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 950, Loss: 0.0407, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 960, Loss: 0.2302, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 970, Loss: 0.1669, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 980, Loss: 0.1290, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 990, Loss: 0.1055, LR: 1.89e-05, Scale: 0.200
  Epoch 37, Batch 1000, Loss: 0.0629, LR: 1.89e-05, Scale: 0.200
‚úÖ Epoch 37 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1760
   È™åËØÅÊçüÂ§±: 0.2062
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 38/50 ===
  Epoch 38, Batch 0, Loss: 0.2295, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 10, Loss: 0.0274, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 20, Loss: 0.1971, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 30, Loss: 0.0573, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 40, Loss: 0.1181, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 50, Loss: 0.1071, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 60, Loss: 0.0430, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 70, Loss: 0.1211, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 80, Loss: 0.1358, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 90, Loss: 0.1414, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 100, Loss: 0.2169, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 110, Loss: 0.2420, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 120, Loss: 0.0953, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 130, Loss: 0.1179, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 140, Loss: 0.0299, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 150, Loss: 0.0598, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 160, Loss: 0.1068, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 170, Loss: 0.1737, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 180, Loss: 0.2323, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 190, Loss: 0.0790, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 200, Loss: 0.3983, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 210, Loss: 0.4034, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 220, Loss: 0.2620, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 230, Loss: 0.0921, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 240, Loss: 0.1296, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 250, Loss: 0.1562, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 260, Loss: 0.0106, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 270, Loss: 0.2801, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 280, Loss: 0.0503, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 290, Loss: 0.0389, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 300, Loss: 0.1490, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 310, Loss: 0.2890, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 320, Loss: 0.1296, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 330, Loss: 0.0871, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 340, Loss: 0.4463, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 350, Loss: 0.2354, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 360, Loss: 0.0374, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 370, Loss: 0.0841, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 380, Loss: 0.1809, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 390, Loss: 0.3877, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 400, Loss: 0.1724, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 410, Loss: 0.1800, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 420, Loss: 0.2607, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 430, Loss: 0.2140, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 440, Loss: 0.0343, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 450, Loss: 0.2883, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 460, Loss: 0.4148, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 470, Loss: 0.3451, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 480, Loss: 0.4006, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 490, Loss: 0.0142, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 500, Loss: 0.1337, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 510, Loss: 0.5960, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 520, Loss: 0.2453, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 530, Loss: 0.0949, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 540, Loss: 0.1674, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 550, Loss: 0.3125, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 560, Loss: 0.0569, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 570, Loss: 0.0470, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 580, Loss: 0.0086, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 590, Loss: 0.5780, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 600, Loss: 0.1859, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 610, Loss: 0.4401, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 620, Loss: 0.0737, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 630, Loss: 0.0619, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 640, Loss: 0.0047, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 650, Loss: 0.1901, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 660, Loss: 0.0149, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 670, Loss: 0.0139, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 680, Loss: 0.2970, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 690, Loss: 0.0625, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 700, Loss: 0.0584, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 710, Loss: 0.0167, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 720, Loss: 0.3538, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 730, Loss: 0.0134, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 740, Loss: 0.0836, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 750, Loss: 0.0572, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 760, Loss: 0.3890, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 770, Loss: 0.0218, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 780, Loss: 0.0084, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 790, Loss: 0.4544, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 800, Loss: 0.3466, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 810, Loss: 0.2079, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 820, Loss: 0.1145, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 830, Loss: 0.4275, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 840, Loss: 0.3425, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 850, Loss: 0.2313, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 860, Loss: 0.1911, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 870, Loss: 0.1112, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 880, Loss: 0.1822, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 890, Loss: 0.0340, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 900, Loss: 0.0241, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 910, Loss: 0.3056, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 920, Loss: 0.0327, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 930, Loss: 0.0038, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 940, Loss: 0.0820, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 950, Loss: 0.2312, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 960, Loss: 0.3700, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 970, Loss: 0.1943, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 980, Loss: 0.0800, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 990, Loss: 0.0204, LR: 1.66e-05, Scale: 0.200
  Epoch 38, Batch 1000, Loss: 0.1402, LR: 1.66e-05, Scale: 0.200
‚úÖ Epoch 38 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1841
   È™åËØÅÊçüÂ§±: 0.1873
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 39/50 ===
  Epoch 39, Batch 0, Loss: 0.4772, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 10, Loss: 0.2315, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 20, Loss: 0.0076, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 30, Loss: 0.0300, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 40, Loss: 0.3767, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 50, Loss: 0.3343, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 60, Loss: 0.1183, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 70, Loss: 0.1749, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 80, Loss: 0.0277, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 90, Loss: 0.1097, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 100, Loss: 0.0643, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 110, Loss: 0.1261, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 120, Loss: 0.1463, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 130, Loss: 0.3532, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 140, Loss: 0.0229, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 150, Loss: 0.4630, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 160, Loss: 0.0304, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 170, Loss: 0.1679, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 180, Loss: 0.2289, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 190, Loss: 0.6139, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 200, Loss: 0.2912, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 210, Loss: 0.1086, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 220, Loss: 0.2358, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 230, Loss: 0.3197, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 240, Loss: 0.1390, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 250, Loss: 0.2258, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 260, Loss: 0.1201, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 270, Loss: 0.1339, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 280, Loss: 0.0998, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 290, Loss: 0.1180, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 300, Loss: 0.2957, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 310, Loss: 0.4299, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 320, Loss: 0.5570, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 330, Loss: 0.0512, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 340, Loss: 0.0376, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 350, Loss: 0.1369, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 360, Loss: 0.1162, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 370, Loss: 0.1018, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 380, Loss: 0.0955, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 390, Loss: 0.3082, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 400, Loss: 0.1760, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 410, Loss: 0.2410, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 420, Loss: 0.2835, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 430, Loss: 0.1863, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 440, Loss: 0.2061, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 450, Loss: 0.2376, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 460, Loss: 0.0180, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 470, Loss: 0.1869, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 480, Loss: 0.0763, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 490, Loss: 0.0556, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 500, Loss: 0.4042, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 510, Loss: 0.2641, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 520, Loss: 0.2370, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 530, Loss: 0.3827, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 540, Loss: 0.0132, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 550, Loss: 0.0079, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 560, Loss: 0.3289, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 570, Loss: 0.4426, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 580, Loss: 0.1028, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 590, Loss: 0.3284, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 600, Loss: 0.0427, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 610, Loss: 0.4746, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 620, Loss: 0.0206, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 630, Loss: 0.2637, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 640, Loss: 0.0402, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 650, Loss: 0.0446, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 660, Loss: 0.0753, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 670, Loss: 0.3294, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 680, Loss: 0.2042, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 690, Loss: 0.0750, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 700, Loss: 0.1947, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 710, Loss: 0.2267, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 720, Loss: 0.3698, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 730, Loss: 0.3947, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 740, Loss: 0.0576, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 750, Loss: 0.0389, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 760, Loss: 0.1705, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 770, Loss: 0.0537, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 780, Loss: 0.4275, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 790, Loss: 0.1208, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 800, Loss: 0.0931, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 810, Loss: 0.0083, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 820, Loss: 0.1972, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 830, Loss: 0.2199, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 840, Loss: 0.1191, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 850, Loss: 0.1944, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 860, Loss: 0.1378, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 870, Loss: 0.0156, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 880, Loss: 0.3187, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 890, Loss: 0.1008, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 900, Loss: 0.1297, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 910, Loss: 0.1380, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 920, Loss: 0.0218, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 930, Loss: 0.1981, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 940, Loss: 0.3901, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 950, Loss: 0.1533, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 960, Loss: 0.2171, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 970, Loss: 0.0941, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 980, Loss: 0.2282, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 990, Loss: 0.0536, LR: 1.44e-05, Scale: 0.200
  Epoch 39, Batch 1000, Loss: 0.1966, LR: 1.44e-05, Scale: 0.200
‚úÖ Epoch 39 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1775
   È™åËØÅÊçüÂ§±: 0.1686
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 40/50 ===
  Epoch 40, Batch 0, Loss: 0.0177, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 10, Loss: 0.1473, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 20, Loss: 0.1316, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 30, Loss: 0.1260, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 40, Loss: 0.0720, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 50, Loss: 0.0176, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 60, Loss: 0.0675, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 70, Loss: 0.0583, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 80, Loss: 0.3330, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 90, Loss: 0.2446, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 100, Loss: 0.0182, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 110, Loss: 0.1028, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 120, Loss: 0.1158, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 130, Loss: 0.0554, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 140, Loss: 0.1316, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 150, Loss: 0.0934, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 160, Loss: 0.2240, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 170, Loss: 0.3963, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 180, Loss: 0.1045, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 190, Loss: 0.4525, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 200, Loss: 0.0668, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 210, Loss: 0.2084, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 220, Loss: 0.1787, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 230, Loss: 0.1014, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 240, Loss: 0.0276, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 250, Loss: 0.3834, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 260, Loss: 0.4189, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 270, Loss: 0.6523, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 280, Loss: 0.0375, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 290, Loss: 0.1414, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 300, Loss: 0.0566, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 310, Loss: 0.0105, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 320, Loss: 0.3188, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 330, Loss: 0.2007, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 340, Loss: 0.1595, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 350, Loss: 0.0870, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 360, Loss: 0.2680, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 370, Loss: 0.1844, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 380, Loss: 0.0960, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 390, Loss: 0.0344, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 400, Loss: 0.4283, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 410, Loss: 0.1729, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 420, Loss: 0.1733, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 430, Loss: 0.2053, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 440, Loss: 0.2815, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 450, Loss: 0.0889, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 460, Loss: 0.3226, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 470, Loss: 0.1854, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 480, Loss: 0.0162, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 490, Loss: 0.0046, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 500, Loss: 0.1292, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 510, Loss: 0.0514, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 520, Loss: 0.0910, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 530, Loss: 0.0843, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 540, Loss: 0.1361, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 550, Loss: 0.0781, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 560, Loss: 0.1912, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 570, Loss: 0.0473, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 580, Loss: 0.2127, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 590, Loss: 0.0577, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 600, Loss: 0.0562, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 610, Loss: 0.1867, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 620, Loss: 0.0585, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 630, Loss: 0.1299, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 640, Loss: 0.0938, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 650, Loss: 0.0765, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 660, Loss: 0.2792, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 670, Loss: 0.0366, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 680, Loss: 0.0329, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 690, Loss: 0.0165, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 700, Loss: 0.0919, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 710, Loss: 0.3313, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 720, Loss: 0.3157, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 730, Loss: 0.3738, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 740, Loss: 0.0113, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 750, Loss: 0.1792, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 760, Loss: 0.1567, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 770, Loss: 0.0226, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 780, Loss: 0.1129, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 790, Loss: 0.1479, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 800, Loss: 0.4585, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 810, Loss: 0.2248, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 820, Loss: 0.0060, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 830, Loss: 0.0529, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 840, Loss: 0.1101, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 850, Loss: 0.1035, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 860, Loss: 0.1735, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 870, Loss: 0.2291, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 880, Loss: 0.2303, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 890, Loss: 0.1341, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 900, Loss: 0.2288, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 910, Loss: 0.0612, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 920, Loss: 0.3418, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 930, Loss: 0.5132, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 940, Loss: 0.2908, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 950, Loss: 0.0807, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 960, Loss: 0.1728, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 970, Loss: 0.1782, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 980, Loss: 0.2294, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 990, Loss: 0.1536, LR: 1.24e-05, Scale: 0.200
  Epoch 40, Batch 1000, Loss: 0.1185, LR: 1.24e-05, Scale: 0.200
‚úÖ Epoch 40 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1766
   È™åËØÅÊçüÂ§±: 0.1888
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_40.pth

=== Epoch 41/50 ===
  Epoch 41, Batch 0, Loss: 0.3799, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 10, Loss: 0.0640, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 20, Loss: 0.1043, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 30, Loss: 0.2792, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 40, Loss: 0.0240, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 50, Loss: 0.0995, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 60, Loss: 0.4262, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 70, Loss: 0.3378, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 80, Loss: 0.5772, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 90, Loss: 0.0201, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 100, Loss: 0.3712, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 110, Loss: 0.2444, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 120, Loss: 0.5162, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 130, Loss: 0.0377, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 140, Loss: 0.2555, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 150, Loss: 0.0428, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 160, Loss: 0.0196, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 170, Loss: 0.1864, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 180, Loss: 0.5213, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 190, Loss: 0.2682, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 200, Loss: 0.1774, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 210, Loss: 0.0591, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 220, Loss: 0.0695, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 230, Loss: 0.0964, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 240, Loss: 0.1595, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 250, Loss: 0.0442, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 260, Loss: 0.1114, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 270, Loss: 0.3302, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 280, Loss: 0.2313, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 290, Loss: 0.0787, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 300, Loss: 0.1721, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 310, Loss: 0.0110, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 320, Loss: 0.1247, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 330, Loss: 0.0602, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 340, Loss: 0.0667, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 350, Loss: 0.2223, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 360, Loss: 0.0947, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 370, Loss: 0.3580, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 380, Loss: 0.2001, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 390, Loss: 0.4328, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 400, Loss: 0.0694, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 410, Loss: 0.1646, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 420, Loss: 0.3976, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 430, Loss: 0.0974, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 440, Loss: 0.2737, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 450, Loss: 0.3140, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 460, Loss: 0.4840, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 470, Loss: 0.0249, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 480, Loss: 0.2413, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 490, Loss: 0.1163, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 500, Loss: 0.0959, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 510, Loss: 0.1257, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 520, Loss: 0.1493, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 530, Loss: 0.0792, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 540, Loss: 0.1044, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 550, Loss: 0.0764, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 560, Loss: 0.2866, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 570, Loss: 0.6324, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 580, Loss: 0.0909, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 590, Loss: 0.0610, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 600, Loss: 0.0079, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 610, Loss: 0.0582, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 620, Loss: 0.4150, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 630, Loss: 0.0805, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 640, Loss: 0.0469, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 650, Loss: 0.1449, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 660, Loss: 0.4577, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 670, Loss: 0.0191, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 680, Loss: 0.1307, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 690, Loss: 0.0136, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 700, Loss: 0.1159, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 710, Loss: 0.3165, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 720, Loss: 0.2245, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 730, Loss: 0.0440, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 740, Loss: 0.0678, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 750, Loss: 0.2024, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 760, Loss: 0.2644, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 770, Loss: 0.1228, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 780, Loss: 0.3536, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 790, Loss: 0.5035, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 800, Loss: 0.0482, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 810, Loss: 0.3476, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 820, Loss: 0.0228, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 830, Loss: 0.1446, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 840, Loss: 0.1381, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 850, Loss: 0.2210, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 860, Loss: 0.0172, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 870, Loss: 0.2313, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 880, Loss: 0.1608, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 890, Loss: 0.4945, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 900, Loss: 0.0074, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 910, Loss: 0.1661, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 920, Loss: 0.1170, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 930, Loss: 0.0235, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 940, Loss: 0.0774, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 950, Loss: 0.1926, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 960, Loss: 0.1194, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 970, Loss: 0.5324, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 980, Loss: 0.1708, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 990, Loss: 0.0773, LR: 1.05e-05, Scale: 0.200
  Epoch 41, Batch 1000, Loss: 0.1025, LR: 1.05e-05, Scale: 0.200
‚úÖ Epoch 41 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1719
   È™åËØÅÊçüÂ§±: 0.1973
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 42/50 ===
  Epoch 42, Batch 0, Loss: 0.0123, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 10, Loss: 0.5966, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 20, Loss: 0.4159, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 30, Loss: 0.1226, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 40, Loss: 0.3358, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 50, Loss: 0.4823, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 60, Loss: 0.3570, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 70, Loss: 0.0535, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 80, Loss: 0.4339, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 90, Loss: 0.1904, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 100, Loss: 0.0889, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 110, Loss: 0.5551, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 120, Loss: 0.1701, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 130, Loss: 0.3415, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 140, Loss: 0.4010, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 150, Loss: 0.0724, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 160, Loss: 0.0389, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 170, Loss: 0.2277, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 180, Loss: 0.1970, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 190, Loss: 0.0569, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 200, Loss: 0.5754, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 210, Loss: 0.2178, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 220, Loss: 0.0633, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 230, Loss: 0.0061, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 240, Loss: 0.1093, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 250, Loss: 0.3870, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 260, Loss: 0.1211, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 270, Loss: 0.4167, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 280, Loss: 0.1360, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 290, Loss: 0.2431, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 300, Loss: 0.0967, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 310, Loss: 0.5903, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 320, Loss: 0.2848, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 330, Loss: 0.0625, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 340, Loss: 0.3033, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 350, Loss: 0.1189, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 360, Loss: 0.0800, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 370, Loss: 0.0450, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 380, Loss: 0.2022, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 390, Loss: 0.0474, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 400, Loss: 0.3278, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 410, Loss: 0.1416, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 420, Loss: 0.2271, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 430, Loss: 0.0296, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 440, Loss: 0.1600, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 450, Loss: 0.0152, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 460, Loss: 0.1819, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 470, Loss: 0.5196, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 480, Loss: 0.1222, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 490, Loss: 0.0362, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 500, Loss: 0.0478, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 510, Loss: 0.3542, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 520, Loss: 0.4301, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 530, Loss: 0.1382, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 540, Loss: 0.2870, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 550, Loss: 0.0893, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 560, Loss: 0.4014, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 570, Loss: 0.0880, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 580, Loss: 0.0992, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 590, Loss: 0.0498, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 600, Loss: 0.0822, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 610, Loss: 0.0794, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 620, Loss: 0.1995, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 630, Loss: 0.3227, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 640, Loss: 0.1233, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 650, Loss: 0.1519, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 660, Loss: 0.2800, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 670, Loss: 0.5624, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 680, Loss: 0.3109, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 690, Loss: 0.1604, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 700, Loss: 0.0051, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 710, Loss: 0.0955, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 720, Loss: 0.1067, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 730, Loss: 0.1643, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 740, Loss: 0.3316, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 750, Loss: 0.2193, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 760, Loss: 0.1145, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 770, Loss: 0.0782, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 780, Loss: 0.2300, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 790, Loss: 0.2188, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 800, Loss: 0.2072, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 810, Loss: 0.2451, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 820, Loss: 0.0892, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 830, Loss: 0.0106, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 840, Loss: 0.0403, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 850, Loss: 0.0260, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 860, Loss: 0.1863, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 870, Loss: 0.1896, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 880, Loss: 0.1549, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 890, Loss: 0.1026, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 900, Loss: 0.4039, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 910, Loss: 0.0630, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 920, Loss: 0.6039, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 930, Loss: 0.2035, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 940, Loss: 0.0196, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 950, Loss: 0.0527, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 960, Loss: 0.1698, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 970, Loss: 0.0650, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 980, Loss: 0.0050, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 990, Loss: 0.1143, LR: 8.71e-06, Scale: 0.200
  Epoch 42, Batch 1000, Loss: 0.2260, LR: 8.71e-06, Scale: 0.200
‚úÖ Epoch 42 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1787
   È™åËØÅÊçüÂ§±: 0.1996
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 43/50 ===
  Epoch 43, Batch 0, Loss: 0.3787, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 10, Loss: 0.2966, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 20, Loss: 0.2584, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 30, Loss: 0.1034, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 40, Loss: 0.3127, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 50, Loss: 0.1554, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 60, Loss: 0.0654, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 70, Loss: 0.3295, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 80, Loss: 0.2332, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 90, Loss: 0.4276, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 100, Loss: 0.3353, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 110, Loss: 0.0724, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 120, Loss: 0.2414, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 130, Loss: 0.0525, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 140, Loss: 0.1685, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 150, Loss: 0.4262, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 160, Loss: 0.5352, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 170, Loss: 0.1074, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 180, Loss: 0.0666, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 190, Loss: 0.0499, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 200, Loss: 0.1541, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 210, Loss: 0.2070, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 220, Loss: 0.2460, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 230, Loss: 0.2651, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 240, Loss: 0.2324, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 250, Loss: 0.0415, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 260, Loss: 0.3910, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 270, Loss: 0.0383, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 280, Loss: 0.0694, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 290, Loss: 0.2676, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 300, Loss: 0.6660, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 310, Loss: 0.0074, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 320, Loss: 0.0543, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 330, Loss: 0.1379, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 340, Loss: 0.0258, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 350, Loss: 0.3828, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 360, Loss: 0.0384, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 370, Loss: 0.1086, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 380, Loss: 0.0141, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 390, Loss: 0.1086, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 400, Loss: 0.1995, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 410, Loss: 0.3254, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 420, Loss: 0.1224, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 430, Loss: 0.2647, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 440, Loss: 0.0205, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 450, Loss: 0.3820, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 460, Loss: 0.4136, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 470, Loss: 0.0313, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 480, Loss: 0.2010, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 490, Loss: 0.2681, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 500, Loss: 0.0188, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 510, Loss: 0.0954, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 520, Loss: 0.6285, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 530, Loss: 0.3053, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 540, Loss: 0.4300, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 550, Loss: 0.3792, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 560, Loss: 0.2416, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 570, Loss: 0.0785, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 580, Loss: 0.1943, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 590, Loss: 0.0531, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 600, Loss: 0.4544, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 610, Loss: 0.1097, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 620, Loss: 0.0893, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 630, Loss: 0.1407, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 640, Loss: 0.3421, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 650, Loss: 0.2894, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 660, Loss: 0.3390, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 670, Loss: 0.0161, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 680, Loss: 0.2922, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 690, Loss: 0.2278, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 700, Loss: 0.1386, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 710, Loss: 0.0397, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 720, Loss: 0.0861, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 730, Loss: 0.0532, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 740, Loss: 0.1290, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 750, Loss: 0.0882, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 760, Loss: 0.2407, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 770, Loss: 0.2151, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 780, Loss: 0.1834, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 790, Loss: 0.2835, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 800, Loss: 0.2586, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 810, Loss: 0.1588, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 820, Loss: 0.0958, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 830, Loss: 0.0659, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 840, Loss: 0.2426, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 850, Loss: 0.0328, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 860, Loss: 0.2734, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 870, Loss: 0.0147, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 880, Loss: 0.0693, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 890, Loss: 0.1583, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 900, Loss: 0.0629, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 910, Loss: 0.1746, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 920, Loss: 0.2304, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 930, Loss: 0.3293, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 940, Loss: 0.0487, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 950, Loss: 0.6657, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 960, Loss: 0.0362, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 970, Loss: 0.4365, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 980, Loss: 0.4430, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 990, Loss: 0.0458, LR: 7.12e-06, Scale: 0.200
  Epoch 43, Batch 1000, Loss: 0.0930, LR: 7.12e-06, Scale: 0.200
‚úÖ Epoch 43 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1869
   È™åËØÅÊçüÂ§±: 0.1743
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 44/50 ===
  Epoch 44, Batch 0, Loss: 0.2205, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 10, Loss: 0.2286, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 20, Loss: 0.1523, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 30, Loss: 0.1771, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 40, Loss: 0.1591, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 50, Loss: 0.3714, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 60, Loss: 0.1186, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 70, Loss: 0.0135, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 80, Loss: 0.3104, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 90, Loss: 0.1229, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 100, Loss: 0.5607, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 110, Loss: 0.2124, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 120, Loss: 0.1596, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 130, Loss: 0.2191, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 140, Loss: 0.2374, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 150, Loss: 0.1629, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 160, Loss: 0.2548, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 170, Loss: 0.0123, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 180, Loss: 0.2295, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 190, Loss: 0.1217, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 200, Loss: 0.1825, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 210, Loss: 0.1114, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 220, Loss: 0.3858, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 230, Loss: 0.1406, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 240, Loss: 0.2000, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 250, Loss: 0.1334, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 260, Loss: 0.1023, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 270, Loss: 0.0239, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 280, Loss: 0.0411, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 290, Loss: 0.0511, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 300, Loss: 0.3247, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 310, Loss: 0.0059, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 320, Loss: 0.2108, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 330, Loss: 0.0597, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 340, Loss: 0.3188, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 350, Loss: 0.0894, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 360, Loss: 0.1711, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 370, Loss: 0.2173, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 380, Loss: 0.1494, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 390, Loss: 0.0879, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 400, Loss: 0.0060, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 410, Loss: 0.0827, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 420, Loss: 0.4399, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 430, Loss: 0.1176, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 440, Loss: 0.1151, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 450, Loss: 0.0458, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 460, Loss: 0.1367, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 470, Loss: 0.0097, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 480, Loss: 0.3057, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 490, Loss: 0.1648, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 500, Loss: 0.0239, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 510, Loss: 0.1755, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 520, Loss: 0.0514, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 530, Loss: 0.0238, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 540, Loss: 0.6119, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 550, Loss: 0.1719, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 560, Loss: 0.2630, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 570, Loss: 0.2734, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 580, Loss: 0.1174, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 590, Loss: 0.0457, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 600, Loss: 0.0956, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 610, Loss: 0.0696, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 620, Loss: 0.3145, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 630, Loss: 0.2005, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 640, Loss: 0.0407, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 650, Loss: 0.0760, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 660, Loss: 0.0356, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 670, Loss: 0.0943, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 680, Loss: 0.1723, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 690, Loss: 0.2051, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 700, Loss: 0.5045, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 710, Loss: 0.0978, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 720, Loss: 0.0785, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 730, Loss: 0.4428, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 740, Loss: 0.4172, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 750, Loss: 0.2124, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 760, Loss: 0.3116, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 770, Loss: 0.0394, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 780, Loss: 0.1203, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 790, Loss: 0.1467, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 800, Loss: 0.2867, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 810, Loss: 0.2303, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 820, Loss: 0.2035, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 830, Loss: 0.0382, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 840, Loss: 0.0552, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 850, Loss: 0.0595, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 860, Loss: 0.0152, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 870, Loss: 0.2394, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 880, Loss: 0.0212, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 890, Loss: 0.1462, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 900, Loss: 0.1156, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 910, Loss: 0.2972, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 920, Loss: 0.0207, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 930, Loss: 0.0922, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 940, Loss: 0.1578, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 950, Loss: 0.3286, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 960, Loss: 0.0749, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 970, Loss: 0.0912, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 980, Loss: 0.5730, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 990, Loss: 0.0598, LR: 5.71e-06, Scale: 0.200
  Epoch 44, Batch 1000, Loss: 0.0078, LR: 5.71e-06, Scale: 0.200
‚úÖ Epoch 44 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1794
   È™åËØÅÊçüÂ§±: 0.1954
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 45/50 ===
  Epoch 45, Batch 0, Loss: 0.0913, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 10, Loss: 0.0652, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 20, Loss: 0.0263, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 30, Loss: 0.2742, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 40, Loss: 0.0485, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 50, Loss: 0.1029, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 60, Loss: 0.2285, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 70, Loss: 0.0987, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 80, Loss: 0.1825, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 90, Loss: 0.0097, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 100, Loss: 0.2887, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 110, Loss: 0.2727, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 120, Loss: 0.1484, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 130, Loss: 0.0267, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 140, Loss: 0.1416, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 150, Loss: 0.2227, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 160, Loss: 0.3577, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 170, Loss: 0.1868, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 180, Loss: 0.0387, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 190, Loss: 0.3539, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 200, Loss: 0.2744, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 210, Loss: 0.3531, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 220, Loss: 0.0177, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 230, Loss: 0.2171, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 240, Loss: 0.0774, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 250, Loss: 0.4070, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 260, Loss: 0.3966, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 270, Loss: 0.1374, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 280, Loss: 0.0375, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 290, Loss: 0.4250, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 300, Loss: 0.1384, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 310, Loss: 0.3699, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 320, Loss: 0.2120, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 330, Loss: 0.3033, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 340, Loss: 0.2512, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 350, Loss: 0.2246, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 360, Loss: 0.0773, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 370, Loss: 0.0666, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 380, Loss: 0.0403, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 390, Loss: 0.4013, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 400, Loss: 0.2306, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 410, Loss: 0.3232, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 420, Loss: 0.0326, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 430, Loss: 0.0569, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 440, Loss: 0.2673, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 450, Loss: 0.2280, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 460, Loss: 0.2006, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 470, Loss: 0.1425, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 480, Loss: 0.1692, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 490, Loss: 0.1793, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 500, Loss: 0.0757, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 510, Loss: 0.1206, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 520, Loss: 0.1458, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 530, Loss: 0.3056, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 540, Loss: 0.0493, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 550, Loss: 0.3544, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 560, Loss: 0.0088, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 570, Loss: 0.2280, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 580, Loss: 0.0068, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 590, Loss: 0.0542, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 600, Loss: 0.2666, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 610, Loss: 0.0692, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 620, Loss: 0.0518, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 630, Loss: 0.0279, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 640, Loss: 0.2172, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 650, Loss: 0.1553, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 660, Loss: 0.1829, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 670, Loss: 0.0739, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 680, Loss: 0.0846, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 690, Loss: 0.0353, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 700, Loss: 0.0153, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 710, Loss: 0.2110, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 720, Loss: 0.2854, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 730, Loss: 0.4601, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 740, Loss: 0.4103, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 750, Loss: 0.2874, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 760, Loss: 0.1620, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 770, Loss: 0.1234, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 780, Loss: 0.0292, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 790, Loss: 0.1031, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 800, Loss: 0.2566, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 810, Loss: 0.3769, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 820, Loss: 0.1484, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 830, Loss: 0.2381, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 840, Loss: 0.3565, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 850, Loss: 0.2790, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 860, Loss: 0.0889, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 870, Loss: 0.3875, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 880, Loss: 0.0862, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 890, Loss: 0.1056, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 900, Loss: 0.3753, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 910, Loss: 0.1134, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 920, Loss: 0.0696, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 930, Loss: 0.2004, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 940, Loss: 0.3204, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 950, Loss: 0.4080, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 960, Loss: 0.3571, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 970, Loss: 0.0766, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 980, Loss: 0.0856, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 990, Loss: 0.0874, LR: 4.48e-06, Scale: 0.200
  Epoch 45, Batch 1000, Loss: 0.1515, LR: 4.48e-06, Scale: 0.200
‚úÖ Epoch 45 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1834
   È™åËØÅÊçüÂ§±: 0.1978
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 46/50 ===
  Epoch 46, Batch 0, Loss: 0.1824, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 10, Loss: 0.1450, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 20, Loss: 0.2055, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 30, Loss: 0.2953, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 40, Loss: 0.0931, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 50, Loss: 0.3149, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 60, Loss: 0.0990, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 70, Loss: 0.3100, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 80, Loss: 0.1650, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 90, Loss: 0.2099, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 100, Loss: 0.0803, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 110, Loss: 0.2947, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 120, Loss: 0.0438, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 130, Loss: 0.0432, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 140, Loss: 0.1506, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 150, Loss: 0.2860, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 160, Loss: 0.1127, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 170, Loss: 0.2012, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 180, Loss: 0.2655, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 190, Loss: 0.0461, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 200, Loss: 0.0410, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 210, Loss: 0.0337, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 220, Loss: 0.4706, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 230, Loss: 0.0119, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 240, Loss: 0.1239, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 250, Loss: 0.0680, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 260, Loss: 0.0257, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 270, Loss: 0.1459, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 280, Loss: 0.3382, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 290, Loss: 0.1150, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 300, Loss: 0.1937, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 310, Loss: 0.2241, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 320, Loss: 0.0406, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 330, Loss: 0.1691, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 340, Loss: 0.3966, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 350, Loss: 0.3859, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 360, Loss: 0.1041, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 370, Loss: 0.2072, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 380, Loss: 0.4589, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 390, Loss: 0.4324, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 400, Loss: 0.0932, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 410, Loss: 0.0236, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 420, Loss: 0.3358, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 430, Loss: 0.0337, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 440, Loss: 0.2253, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 450, Loss: 0.0120, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 460, Loss: 0.1204, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 470, Loss: 0.3212, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 480, Loss: 0.0112, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 490, Loss: 0.1544, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 500, Loss: 0.2386, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 510, Loss: 0.2262, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 520, Loss: 0.0827, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 530, Loss: 0.2264, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 540, Loss: 0.2036, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 550, Loss: 0.2004, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 560, Loss: 0.1276, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 570, Loss: 0.2343, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 580, Loss: 0.0100, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 590, Loss: 0.0226, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 600, Loss: 0.2110, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 610, Loss: 0.0743, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 620, Loss: 0.4140, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 630, Loss: 0.3988, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 640, Loss: 0.1312, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 650, Loss: 0.1298, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 660, Loss: 0.2983, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 670, Loss: 0.2877, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 680, Loss: 0.2027, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 690, Loss: 0.4202, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 700, Loss: 0.2994, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 710, Loss: 0.0349, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 720, Loss: 0.0264, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 730, Loss: 0.2210, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 740, Loss: 0.1843, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 750, Loss: 0.1808, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 760, Loss: 0.4069, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 770, Loss: 0.1273, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 780, Loss: 0.0646, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 790, Loss: 0.3540, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 800, Loss: 0.0408, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 810, Loss: 0.0320, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 820, Loss: 0.1686, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 830, Loss: 0.3792, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 840, Loss: 0.0690, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 850, Loss: 0.1374, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 860, Loss: 0.2529, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 870, Loss: 0.1909, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 880, Loss: 0.1398, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 890, Loss: 0.3802, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 900, Loss: 0.0077, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 910, Loss: 0.0697, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 920, Loss: 0.1757, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 930, Loss: 0.1220, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 940, Loss: 0.3079, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 950, Loss: 0.0406, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 960, Loss: 0.1748, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 970, Loss: 0.2591, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 980, Loss: 0.0197, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 990, Loss: 0.0239, LR: 3.42e-06, Scale: 0.200
  Epoch 46, Batch 1000, Loss: 0.1108, LR: 3.42e-06, Scale: 0.200
‚úÖ Epoch 46 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1767
   È™åËØÅÊçüÂ§±: 0.1758
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 47/50 ===
  Epoch 47, Batch 0, Loss: 0.2693, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 10, Loss: 0.1780, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 20, Loss: 0.0226, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 30, Loss: 0.1101, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 40, Loss: 0.1408, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 50, Loss: 0.0697, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 60, Loss: 0.0953, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 70, Loss: 0.0056, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 80, Loss: 0.0541, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 90, Loss: 0.1846, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 100, Loss: 0.0305, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 110, Loss: 0.2032, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 120, Loss: 0.0173, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 130, Loss: 0.0125, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 140, Loss: 0.1599, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 150, Loss: 0.0721, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 160, Loss: 0.3401, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 170, Loss: 0.3506, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 180, Loss: 0.0255, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 190, Loss: 0.0891, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 200, Loss: 0.0709, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 210, Loss: 0.1487, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 220, Loss: 0.0185, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 230, Loss: 0.2305, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 240, Loss: 0.5300, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 250, Loss: 0.0417, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 260, Loss: 0.2276, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 270, Loss: 0.1695, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 280, Loss: 0.0380, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 290, Loss: 0.0603, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 300, Loss: 0.0335, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 310, Loss: 0.0246, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 320, Loss: 0.0198, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 330, Loss: 0.3551, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 340, Loss: 0.3056, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 350, Loss: 0.0683, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 360, Loss: 0.0240, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 370, Loss: 0.3852, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 380, Loss: 0.1001, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 390, Loss: 0.4182, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 400, Loss: 0.0662, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 410, Loss: 0.1817, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 420, Loss: 0.2785, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 430, Loss: 0.2553, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 440, Loss: 0.1111, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 450, Loss: 0.0075, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 460, Loss: 0.3018, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 470, Loss: 0.0665, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 480, Loss: 0.2505, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 490, Loss: 0.4341, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 500, Loss: 0.0105, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 510, Loss: 0.0442, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 520, Loss: 0.3374, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 530, Loss: 0.0274, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 540, Loss: 0.0167, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 550, Loss: 0.2190, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 560, Loss: 0.2805, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 570, Loss: 0.1356, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 580, Loss: 0.3502, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 590, Loss: 0.2884, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 600, Loss: 0.3834, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 610, Loss: 0.5354, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 620, Loss: 0.2457, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 630, Loss: 0.0948, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 640, Loss: 0.1517, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 650, Loss: 0.2214, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 660, Loss: 0.2885, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 670, Loss: 0.1715, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 680, Loss: 0.0050, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 690, Loss: 0.0336, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 700, Loss: 0.2985, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 710, Loss: 0.2294, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 720, Loss: 0.2121, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 730, Loss: 0.1199, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 740, Loss: 0.2647, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 750, Loss: 0.4462, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 760, Loss: 0.3205, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 770, Loss: 0.0933, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 780, Loss: 0.3097, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 790, Loss: 0.0065, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 800, Loss: 0.3097, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 810, Loss: 0.0448, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 820, Loss: 0.0261, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 830, Loss: 0.0323, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 840, Loss: 0.1316, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 850, Loss: 0.2455, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 860, Loss: 0.2143, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 870, Loss: 0.1908, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 880, Loss: 0.1536, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 890, Loss: 0.1873, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 900, Loss: 0.0274, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 910, Loss: 0.2637, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 920, Loss: 0.0225, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 930, Loss: 0.0521, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 940, Loss: 0.0895, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 950, Loss: 0.0099, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 960, Loss: 0.1859, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 970, Loss: 0.0929, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 980, Loss: 0.2867, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 990, Loss: 0.1143, LR: 2.56e-06, Scale: 0.200
  Epoch 47, Batch 1000, Loss: 0.2100, LR: 2.56e-06, Scale: 0.200
‚úÖ Epoch 47 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1885
   È™åËØÅÊçüÂ§±: 0.1731
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 48/50 ===
Traceback (most recent call last):
  File "/data/zhangzhikui/githubbase/DL/FinalProject/train.py", line 854, in main
    trainer.train(train_loader, val_loader)
  File "/data/zhangzhikui/githubbase/DL/FinalProject/train.py", line 637, in train
    train_loss = self.train_epoch(train_loader, epoch)
  File "/data/zhangzhikui/githubbase/DL/FinalProject/train.py", line 520, in train_epoch
    self.scaler.unscale_(self.optimizer)
  File "/home/zhangzhikui/enter/envs/dl/lib/python3.10/site-packages/torch/amp/grad_scaler.py", line 328, in unscale_
    raise RuntimeError(
RuntimeError: unscale_() has already been called on this optimizer since the last update().
  Epoch 48, Batch 0, Loss: 0.2263, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 10, Loss: 0.1618, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 20, Loss: 0.0450, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 30, Loss: 0.1164, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 40, Loss: 0.0803, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 50, Loss: 0.4175, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 60, Loss: 0.4895, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 70, Loss: 0.1096, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 80, Loss: 0.0273, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 90, Loss: 0.0552, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 100, Loss: 0.1081, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 110, Loss: 0.1292, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 120, Loss: 0.1332, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 130, Loss: 0.2015, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 140, Loss: 0.0334, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 150, Loss: 0.2174, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 160, Loss: 0.1233, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 170, Loss: 0.1499, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 180, Loss: 0.1254, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 190, Loss: 0.0627, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 200, Loss: 0.3084, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 210, Loss: 0.0376, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 220, Loss: 0.0035, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 230, Loss: 0.1552, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 240, Loss: 0.1104, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 250, Loss: 0.4619, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 260, Loss: 0.3723, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 270, Loss: 0.6141, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 280, Loss: 0.1751, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 290, Loss: 0.0572, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 300, Loss: 0.2931, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 310, Loss: 0.1014, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 320, Loss: 0.1555, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 330, Loss: 0.0274, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 340, Loss: 0.0308, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 350, Loss: 0.1902, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 360, Loss: 0.3002, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 370, Loss: 0.1685, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 380, Loss: 0.2430, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 390, Loss: 0.0752, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 400, Loss: 0.1399, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 410, Loss: 0.0042, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 420, Loss: 0.1485, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 430, Loss: 0.2068, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 440, Loss: 0.4963, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 450, Loss: 0.1222, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 460, Loss: 0.2198, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 470, Loss: 0.0165, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 480, Loss: 0.2457, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 490, Loss: 0.2335, LR: 1.88e-06, Scale: 0.200
  Epoch 48, Batch 500, Loss: 0.3014, LR: 1.88e-06, Scale: 0.200
‚ö†Ô∏è  ÊâπÊ¨° 504 ÂÜÖÂ≠ò‰∏çË∂≥ÔºåË∑≥Ëøá

‚ùå ‰ªªÂä° ÁßªÂä®Áâ©‰Ωì ËÆ≠ÁªÉÂ§±Ë¥•: unscale_() has already been called on this optimizer since the last update().

==================================================
üöÄ ÂºÄÂßãËÆ≠ÁªÉ‰ªªÂä°: ÊéâËêΩÁâ©‰Ωì (drop_object)
==================================================
‰ªªÂä°ÈÖçÁΩÆ:
  learning_rate: 0.0001 üéØ
  min_learning_rate: 1e-06
  weight_decay: 0.001
  num_epochs: 50 üéØ
  batch_size: 2
  save_interval: 10
  gradient_accumulation_steps: 4
  lr_scheduler: cosine
  lr_step_size: 20
  lr_gamma: 0.5
  warmup_steps: 500
  grad_clip: 1.0
  conditioning_strategy: linear_increase üéØ
  initial_conditioning_scale: 0.8 üéØ
  final_conditioning_scale: 1.3 üéØ
  adaptive_threshold: 0.15
  scale_step: 0.05
  output_dir: training_results_drop_object
  task_name: drop_object

üìä Âä†ËΩΩ ÊéâËêΩÁâ©‰Ωì Êï∞ÊçÆ...
   Á≠õÈÄâ‰ªªÂä° 'drop_object': 1969/6000 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (drop_object): 1969 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   drop_object: 1969 ‰∏™Ê†∑Êú¨
   Á≠õÈÄâ‰ªªÂä° 'drop_object': 271/750 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (drop_object): 271 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   drop_object: 271 ‰∏™Ê†∑Êú¨
   Á≠õÈÄâ‰ªªÂä° 'drop_object': 260/750 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (drop_object): 260 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   drop_object: 260 ‰∏™Ê†∑Êú¨
‚úÖ ÂàõÂª∫‰ªªÂä° 'drop_object' Êï∞ÊçÆÂä†ËΩΩÂô®ÂÆåÊàê
   ËÆ≠ÁªÉÈõÜ: 1969 ‰∏™Ê†∑Êú¨, 985 ‰∏™ÊâπÊ¨°
   È™åËØÅÈõÜ: 271 ‰∏™Ê†∑Êú¨, 136 ‰∏™ÊâπÊ¨°
   ÊµãËØïÈõÜ: 260 ‰∏™Ê†∑Êú¨, 130 ‰∏™ÊâπÊ¨°
   ÊâπÊ¨°Â§ßÂ∞è: 2
‚úÖ Êï∞ÊçÆÂä†ËΩΩÊàêÂäü
   ËÆ≠ÁªÉÈõÜ: 1969 Ê†∑Êú¨
   È™åËØÅÈõÜ: 271 Ê†∑Êú¨
   ÊµãËØïÈõÜ: 260 Ê†∑Êú¨ - ‰øùÁïôÁî®‰∫éÊúÄÁªàËØÑ‰º∞
üöÄ ‰ΩøÁî®ËÆæÂ§á: cuda
üéØ ‰ªªÂä°: drop_object - Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ß
üéØ Âä®ÊÄÅÊù°‰ª∂Áº©ÊîæÁ≠ñÁï•: linear_increase
   ÂàùÂßãÁº©Êîæ: 0.8 ‚Üí ÊúÄÁªàÁº©Êîæ: 1.3
üì¶ ÂàùÂßãÂåñÊ®°ÂûãÔºàÂÜÖÂ≠ò‰ºòÂåñÁâàÔºâ...
‚úÖ ‰ΩøÁî®diffusers ControlNet
ÂàùÂßãÂåñÂ¢ûÂº∫Êó∂Â∫èÁâπÂæÅÊèêÂèñÂô®...
‚ùå Ê®°ÂûãÂàùÂßãÂåñÂ§±Ë¥•: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 22.06 MiB is free. Process 3591458 has 2.57 GiB memory in use. Process 3592301 has 274.00 MiB memory in use. Process 761813 has 9.53 GiB memory in use. Including non-PyTorch memory, this process has 9.36 GiB memory in use. Process 790144 has 264.00 MiB memory in use. Process 790594 has 264.00 MiB memory in use. Process 833665 has 1.37 GiB memory in use. Of the allocated memory 8.91 GiB is allocated by PyTorch, and 130.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
‚ùå ËÆ≠ÁªÉÂô®ÂàùÂßãÂåñÂ§±Ë¥•: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 22.06 MiB is free. Process 3591458 has 2.57 GiB memory in use. Process 3592301 has 274.00 MiB memory in use. Process 761813 has 9.53 GiB memory in use. Including non-PyTorch memory, this process has 9.36 GiB memory in use. Process 790144 has 264.00 MiB memory in use. Process 790594 has 264.00 MiB memory in use. Process 833665 has 1.37 GiB memory in use. Of the allocated memory 8.91 GiB is allocated by PyTorch, and 130.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

==================================================
üöÄ ÂºÄÂßãËÆ≠ÁªÉ‰ªªÂä°: Ë¶ÜÁõñÁâ©‰Ωì (cover_object)
==================================================
‰ªªÂä°ÈÖçÁΩÆ:
  learning_rate: 8e-06 üéØ
  min_learning_rate: 1e-06
  weight_decay: 0.001
  num_epochs: 50 üéØ
  batch_size: 2
  save_interval: 10
  gradient_accumulation_steps: 4
  lr_scheduler: cosine
  lr_step_size: 20
  lr_gamma: 0.5
  warmup_steps: 500
  grad_clip: 1.0
  conditioning_strategy: stepwise üéØ
  initial_conditioning_scale: 0.8 üéØ
  final_conditioning_scale: 1.2 üéØ
  adaptive_threshold: 0.15
  scale_step: 0.05
  output_dir: training_results_cover_object
  task_name: cover_object

üìä Âä†ËΩΩ Ë¶ÜÁõñÁâ©‰Ωì Êï∞ÊçÆ...
   Á≠õÈÄâ‰ªªÂä° 'cover_object': 2017/6000 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (cover_object): 2017 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   cover_object: 2017 ‰∏™Ê†∑Êú¨
   Á≠õÈÄâ‰ªªÂä° 'cover_object': 243/750 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (cover_object): 243 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   cover_object: 243 ‰∏™Ê†∑Êú¨
   Á≠õÈÄâ‰ªªÂä° 'cover_object': 240/750 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (cover_object): 240 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   cover_object: 240 ‰∏™Ê†∑Êú¨
‚úÖ ÂàõÂª∫‰ªªÂä° 'cover_object' Êï∞ÊçÆÂä†ËΩΩÂô®ÂÆåÊàê
   ËÆ≠ÁªÉÈõÜ: 2017 ‰∏™Ê†∑Êú¨, 1009 ‰∏™ÊâπÊ¨°
   È™åËØÅÈõÜ: 243 ‰∏™Ê†∑Êú¨, 122 ‰∏™ÊâπÊ¨°
   ÊµãËØïÈõÜ: 240 ‰∏™Ê†∑Êú¨, 120 ‰∏™ÊâπÊ¨°
   ÊâπÊ¨°Â§ßÂ∞è: 2
‚úÖ Êï∞ÊçÆÂä†ËΩΩÊàêÂäü
   ËÆ≠ÁªÉÈõÜ: 2017 Ê†∑Êú¨
   È™åËØÅÈõÜ: 243 Ê†∑Êú¨
   ÊµãËØïÈõÜ: 240 Ê†∑Êú¨ - ‰øùÁïôÁî®‰∫éÊúÄÁªàËØÑ‰º∞
üöÄ ‰ΩøÁî®ËÆæÂ§á: cuda
üéØ ‰ªªÂä°: cover_object - Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ß
üéØ Âä®ÊÄÅÊù°‰ª∂Áº©ÊîæÁ≠ñÁï•: stepwise
   ÂàùÂßãÁº©Êîæ: 0.8 ‚Üí ÊúÄÁªàÁº©Êîæ: 1.2
üì¶ ÂàùÂßãÂåñÊ®°ÂûãÔºàÂÜÖÂ≠ò‰ºòÂåñÁâàÔºâ...
‚úÖ ‰ΩøÁî®diffusers ControlNet
ÂàùÂßãÂåñÂ¢ûÂº∫Êó∂Â∫èÁâπÂæÅÊèêÂèñÂô®...
‚ùå Ê®°ÂûãÂàùÂßãÂåñÂ§±Ë¥•: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 43.81 MiB is free. Process 3591458 has 2.57 GiB memory in use. Process 3592301 has 274.00 MiB memory in use. Process 761813 has 9.54 GiB memory in use. Including non-PyTorch memory, this process has 10.70 GiB memory in use. Process 790144 has 264.00 MiB memory in use. Process 790594 has 264.00 MiB memory in use. Of the allocated memory 10.29 GiB is allocated by PyTorch, and 90.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
‚ùå ËÆ≠ÁªÉÂô®ÂàùÂßãÂåñÂ§±Ë¥•: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 43.81 MiB is free. Process 3591458 has 2.57 GiB memory in use. Process 3592301 has 274.00 MiB memory in use. Process 761813 has 9.54 GiB memory in use. Including non-PyTorch memory, this process has 10.70 GiB memory in use. Process 790144 has 264.00 MiB memory in use. Process 790594 has 264.00 MiB memory in use. Of the allocated memory 10.29 GiB is allocated by PyTorch, and 90.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

============================================================
üéä ÊâÄÊúâ‰ªªÂä°ËÆ≠ÁªÉÂÆåÊàê!
üìÅ ÊØè‰∏™‰ªªÂä°ÁöÑÊ®°Âûã‰øùÂ≠òÂú®ÂêÑËá™ÁöÑÁõÆÂΩï‰∏≠:
   ÁßªÂä®Áâ©‰Ωì: training_results_move_object/
   ÊéâËêΩÁâ©‰Ωì: training_results_drop_object/
   Ë¶ÜÁõñÁâ©‰Ωì: training_results_cover_object/
============================================================
