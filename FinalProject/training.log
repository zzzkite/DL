nohup: ignoring input
/home/zhangzhikui/enter/envs/dl/lib/python3.10/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
`torch_dtype` is deprecated! Use `dtype` instead!
‚ö†Ô∏è  Êó†Ê≥ïÂØºÂÖ•cldm: No module named 'cldm'
============================================================
üéØ ControlNet 1.1 Â§ö‰ªªÂä°ÂàÜÂà´ËÆ≠ÁªÉÔºàÂä®ÊÄÅÊù°‰ª∂Áº©ÊîæÔºâ
üìä ‰ªªÂä°: Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ß
============================================================

==================================================
üöÄ ÂºÄÂßãËÆ≠ÁªÉ‰ªªÂä°: ÁßªÂä®Áâ©‰Ωì (move_object)
==================================================
‰ªªÂä°ÈÖçÁΩÆ:
  learning_rate: 0.0001 üéØ
  min_learning_rate: 1e-06
  weight_decay: 0.01 üéØ
  num_epochs: 200 üéØ
  batch_size: 2
  save_interval: 10
  gradient_accumulation_steps: 4
  lr_scheduler: cosine
  lr_step_size: 20
  lr_gamma: 0.5
  warmup_steps: 500
  grad_clip: 1.0
  conditioning_strategy: adaptive üéØ
  initial_conditioning_scale: 0.2 üéØ
  final_conditioning_scale: 1.0 üéØ
  adaptive_threshold: 0.15
  scale_step: 0.05
  gtad_clip: 0.5 üéØ
  output_dir: training_results_move_object
  task_name: move_object

üìä Âä†ËΩΩ ÁßªÂä®Áâ©‰Ωì Êï∞ÊçÆ...
   Á≠õÈÄâ‰ªªÂä° 'move_object': 243/720 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (move_object): 243 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   move_object: 243 ‰∏™Ê†∑Êú¨
   Á≠õÈÄâ‰ªªÂä° 'move_object': 28/90 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (move_object): 28 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   move_object: 28 ‰∏™Ê†∑Êú¨
   Á≠õÈÄâ‰ªªÂä° 'move_object': 29/90 ‰∏™Ê†∑Êú¨
‚úÖ Âä†ËΩΩÊï∞ÊçÆÈõÜ (move_object): 29 ‰∏™Ê†∑Êú¨
   Â∏ßËÆæÁΩÆ: ËæìÂÖ•Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ßÔºàË∑≥Ëøá4Â∏ßÔºâ
   move_object: 29 ‰∏™Ê†∑Êú¨
‚úÖ ÂàõÂª∫‰ªªÂä° 'move_object' Êï∞ÊçÆÂä†ËΩΩÂô®ÂÆåÊàê
   ËÆ≠ÁªÉÈõÜ: 243 ‰∏™Ê†∑Êú¨, 122 ‰∏™ÊâπÊ¨°
   È™åËØÅÈõÜ: 28 ‰∏™Ê†∑Êú¨, 14 ‰∏™ÊâπÊ¨°
   ÊµãËØïÈõÜ: 29 ‰∏™Ê†∑Êú¨, 15 ‰∏™ÊâπÊ¨°
   ÊâπÊ¨°Â§ßÂ∞è: 2
‚úÖ Êï∞ÊçÆÂä†ËΩΩÊàêÂäü
   ËÆ≠ÁªÉÈõÜ: 243 Ê†∑Êú¨
   È™åËØÅÈõÜ: 28 Ê†∑Êú¨
   ÊµãËØïÈõÜ: 29 Ê†∑Êú¨ - ‰øùÁïôÁî®‰∫éÊúÄÁªàËØÑ‰º∞
üöÄ ‰ΩøÁî®ËÆæÂ§á: cuda
üéØ ‰ªªÂä°: move_object - Ââç20Â∏ß ‚Üí È¢ÑÊµãÁ¨¨25Â∏ß
üéØ Âä®ÊÄÅÊù°‰ª∂Áº©ÊîæÁ≠ñÁï•: adaptive
   ÂàùÂßãÁº©Êîæ: 0.2 ‚Üí ÊúÄÁªàÁº©Êîæ: 1.0
üì¶ ÂàùÂßãÂåñÊ®°ÂûãÔºàÂÜÖÂ≠ò‰ºòÂåñÁâàÔºâ...
‚úÖ ‰ΩøÁî®diffusers ControlNet
ÂàùÂßãÂåñÂ¢ûÂº∫Êó∂Â∫èÁâπÂæÅÊèêÂèñÂô®...
‚úÖ Ê®°ÂûãÂàùÂßãÂåñÂÆåÊàê
   ControlNetÂèÇÊï∞: 361,279,120 ÂèØËÆ≠ÁªÉ / 361,279,120 ÊÄªËÆ°
‚úÖ ‰ºòÂåñÂô®ËÆæÁΩÆÂÆåÊàê
üöÄ ÂºÄÂßãËÆ≠ÁªÉÂæ™ÁéØ...
üìä ‰ªÖ‰ΩøÁî®ËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜÔºåÊµãËØïÈõÜ‰øùÁïôÁî®‰∫éÊúÄÁªàËØÑ‰º∞

=== Epoch 1/200 ===
/data/zhangzhikui/githubbase/DL/FinalProject/train.py:420: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  Epoch 1, Batch 0, Loss: 0.3559, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 10, Loss: 0.0283, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 20, Loss: 0.2796, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 30, Loss: 0.2618, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 40, Loss: 0.2379, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 50, Loss: 0.2776, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 60, Loss: 0.1457, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 70, Loss: 0.1619, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 80, Loss: 0.1453, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 90, Loss: 0.3836, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 100, Loss: 0.3890, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 110, Loss: 0.0139, LR: 1.00e-04, Scale: 0.200
  Epoch 1, Batch 120, Loss: 0.2175, LR: 1.00e-04, Scale: 0.200
/data/zhangzhikui/githubbase/DL/FinalProject/train.py:574: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=self.device.type == 'cuda'):
‚úÖ Epoch 1 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1916
   È™åËØÅÊçüÂ§±: 0.2327
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_best.pth
üíæ ‰øùÂ≠òÊúÄ‰Ω≥Ê®°ÂûãÔºåÈ™åËØÅÊçüÂ§±: 0.2327

=== Epoch 2/200 ===
  Epoch 2, Batch 0, Loss: 0.1810, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 10, Loss: 0.0956, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 20, Loss: 0.0418, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 30, Loss: 0.0227, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 40, Loss: 0.2929, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 50, Loss: 0.6314, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 60, Loss: 0.1002, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 70, Loss: 0.2543, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 80, Loss: 0.0443, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 90, Loss: 0.2258, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 100, Loss: 0.2818, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 110, Loss: 0.4139, LR: 1.00e-04, Scale: 0.200
  Epoch 2, Batch 120, Loss: 0.0154, LR: 1.00e-04, Scale: 0.200
‚úÖ Epoch 2 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1736
   È™åËØÅÊçüÂ§±: 0.1968
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_best.pth
üíæ ‰øùÂ≠òÊúÄ‰Ω≥Ê®°ÂûãÔºåÈ™åËØÅÊçüÂ§±: 0.1968

=== Epoch 3/200 ===
  Epoch 3, Batch 0, Loss: 0.2286, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 10, Loss: 0.0285, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 20, Loss: 0.1111, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 30, Loss: 0.5185, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 40, Loss: 0.0078, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 50, Loss: 0.2643, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 60, Loss: 0.1092, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 70, Loss: 0.0282, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 80, Loss: 0.1022, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 90, Loss: 0.0138, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 100, Loss: 0.1403, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 110, Loss: 0.1244, LR: 1.00e-04, Scale: 0.200
  Epoch 3, Batch 120, Loss: 0.1077, LR: 1.00e-04, Scale: 0.200
‚úÖ Epoch 3 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1996
   È™åËØÅÊçüÂ§±: 0.2113
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 4/200 ===
  Epoch 4, Batch 0, Loss: 0.0320, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 10, Loss: 0.1348, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 20, Loss: 0.1250, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 30, Loss: 0.1252, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 40, Loss: 0.1045, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 50, Loss: 0.4176, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 60, Loss: 0.0059, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 70, Loss: 0.1466, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 80, Loss: 0.2819, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 90, Loss: 0.2787, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 100, Loss: 0.0061, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 110, Loss: 0.1448, LR: 9.99e-05, Scale: 0.200
  Epoch 4, Batch 120, Loss: 0.2103, LR: 9.99e-05, Scale: 0.200
‚úÖ Epoch 4 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1997
   È™åËØÅÊçüÂ§±: 0.1052
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_best.pth
üíæ ‰øùÂ≠òÊúÄ‰Ω≥Ê®°ÂûãÔºåÈ™åËØÅÊçüÂ§±: 0.1052

=== Epoch 5/200 ===
  Epoch 5, Batch 0, Loss: 0.0197, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 10, Loss: 0.0369, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 20, Loss: 0.4441, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 30, Loss: 0.4778, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 40, Loss: 0.3128, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 50, Loss: 0.2475, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 60, Loss: 0.2477, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 70, Loss: 0.3192, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 80, Loss: 0.4158, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 90, Loss: 0.2490, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 100, Loss: 0.2851, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 110, Loss: 0.0759, LR: 9.99e-05, Scale: 0.200
  Epoch 5, Batch 120, Loss: 0.4640, LR: 9.99e-05, Scale: 0.200
‚úÖ Epoch 5 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1752
   È™åËØÅÊçüÂ§±: 0.2231
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 6/200 ===
  Epoch 6, Batch 0, Loss: 0.2274, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 10, Loss: 0.4718, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 20, Loss: 0.2996, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 30, Loss: 0.2323, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 40, Loss: 0.4778, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 50, Loss: 0.2708, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 60, Loss: 0.2586, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 70, Loss: 0.5835, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 80, Loss: 0.0166, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 90, Loss: 0.2358, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 100, Loss: 0.2110, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 110, Loss: 0.2105, LR: 9.98e-05, Scale: 0.200
  Epoch 6, Batch 120, Loss: 0.1244, LR: 9.98e-05, Scale: 0.200
‚úÖ Epoch 6 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2319
   È™åËØÅÊçüÂ§±: 0.2376
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 7/200 ===
  Epoch 7, Batch 0, Loss: 0.2734, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 10, Loss: 0.2227, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 20, Loss: 0.2420, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 30, Loss: 0.0451, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 40, Loss: 0.2389, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 50, Loss: 0.4611, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 60, Loss: 0.1159, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 70, Loss: 0.4282, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 80, Loss: 0.2260, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 90, Loss: 0.2711, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 100, Loss: 0.3106, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 110, Loss: 0.7966, LR: 9.98e-05, Scale: 0.200
  Epoch 7, Batch 120, Loss: 0.4137, LR: 9.98e-05, Scale: 0.200
‚úÖ Epoch 7 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2022
   È™åËØÅÊçüÂ§±: 0.1771
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 8/200 ===
  Epoch 8, Batch 0, Loss: 0.0765, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 10, Loss: 0.1727, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 20, Loss: 0.3297, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 30, Loss: 0.1338, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 40, Loss: 0.1894, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 50, Loss: 0.1313, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 60, Loss: 0.1112, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 70, Loss: 0.0591, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 80, Loss: 0.5413, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 90, Loss: 0.0485, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 100, Loss: 0.1081, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 110, Loss: 0.1462, LR: 9.97e-05, Scale: 0.200
  Epoch 8, Batch 120, Loss: 0.2369, LR: 9.97e-05, Scale: 0.200
‚úÖ Epoch 8 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1901
   È™åËØÅÊçüÂ§±: 0.2313
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 9/200 ===
  Epoch 9, Batch 0, Loss: 0.0083, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 10, Loss: 0.0507, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 20, Loss: 0.1252, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 30, Loss: 0.1840, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 40, Loss: 0.4085, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 50, Loss: 0.1933, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 60, Loss: 0.0253, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 70, Loss: 0.0578, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 80, Loss: 0.2413, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 90, Loss: 0.2198, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 100, Loss: 0.2614, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 110, Loss: 0.0117, LR: 9.96e-05, Scale: 0.200
  Epoch 9, Batch 120, Loss: 0.0857, LR: 9.96e-05, Scale: 0.200
‚úÖ Epoch 9 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2168
   È™åËØÅÊçüÂ§±: 0.1733
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 10/200 ===
  Epoch 10, Batch 0, Loss: 0.1083, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 10, Loss: 0.2220, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 20, Loss: 0.2208, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 30, Loss: 0.2370, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 40, Loss: 0.6226, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 50, Loss: 0.1106, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 60, Loss: 0.1847, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 70, Loss: 0.0360, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 80, Loss: 0.2416, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 90, Loss: 0.0399, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 100, Loss: 0.2855, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 110, Loss: 0.2091, LR: 9.95e-05, Scale: 0.200
  Epoch 10, Batch 120, Loss: 0.1569, LR: 9.95e-05, Scale: 0.200
‚úÖ Epoch 10 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1766
   È™åËØÅÊçüÂ§±: 0.2222
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_10.pth

=== Epoch 11/200 ===
  Epoch 11, Batch 0, Loss: 0.4610, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 10, Loss: 0.3823, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 20, Loss: 0.1084, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 30, Loss: 0.2521, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 40, Loss: 0.2487, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 50, Loss: 0.2713, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 60, Loss: 0.4497, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 70, Loss: 0.5439, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 80, Loss: 0.0533, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 90, Loss: 0.0560, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 100, Loss: 0.2970, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 110, Loss: 0.1141, LR: 9.94e-05, Scale: 0.200
  Epoch 11, Batch 120, Loss: 0.2739, LR: 9.94e-05, Scale: 0.200
‚úÖ Epoch 11 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2028
   È™åËØÅÊçüÂ§±: 0.1405
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 12/200 ===
  Epoch 12, Batch 0, Loss: 0.0990, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 10, Loss: 0.2503, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 20, Loss: 0.0578, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 30, Loss: 0.4754, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 40, Loss: 0.2248, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 50, Loss: 0.0548, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 60, Loss: 0.3020, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 70, Loss: 0.1997, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 80, Loss: 0.1702, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 90, Loss: 0.0885, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 100, Loss: 0.1302, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 110, Loss: 0.0844, LR: 9.93e-05, Scale: 0.200
  Epoch 12, Batch 120, Loss: 0.1665, LR: 9.93e-05, Scale: 0.200
‚úÖ Epoch 12 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1848
   È™åËØÅÊçüÂ§±: 0.2625
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 13/200 ===
  Epoch 13, Batch 0, Loss: 0.1524, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 10, Loss: 0.0425, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 20, Loss: 0.2006, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 30, Loss: 0.0326, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 40, Loss: 0.1519, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 50, Loss: 0.1008, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 60, Loss: 0.0190, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 70, Loss: 0.0408, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 80, Loss: 0.3800, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 90, Loss: 0.0646, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 100, Loss: 0.2362, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 110, Loss: 0.3209, LR: 9.91e-05, Scale: 0.200
  Epoch 13, Batch 120, Loss: 0.1894, LR: 9.91e-05, Scale: 0.200
‚úÖ Epoch 13 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1858
   È™åËØÅÊçüÂ§±: 0.1797
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 14/200 ===
  Epoch 14, Batch 0, Loss: 0.1482, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 10, Loss: 0.2448, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 20, Loss: 0.1497, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 30, Loss: 0.4050, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 40, Loss: 0.3718, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 50, Loss: 0.0243, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 60, Loss: 0.0364, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 70, Loss: 0.0330, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 80, Loss: 0.0720, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 90, Loss: 0.1908, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 100, Loss: 0.3656, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 110, Loss: 0.0651, LR: 9.90e-05, Scale: 0.200
  Epoch 14, Batch 120, Loss: 0.1974, LR: 9.90e-05, Scale: 0.200
‚úÖ Epoch 14 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1756
   È™åËØÅÊçüÂ§±: 0.2412
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 15/200 ===
  Epoch 15, Batch 0, Loss: 0.0295, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 10, Loss: 0.2096, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 20, Loss: 0.3628, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 30, Loss: 0.1881, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 40, Loss: 0.0576, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 50, Loss: 0.1461, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 60, Loss: 0.0064, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 70, Loss: 0.1948, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 80, Loss: 0.2932, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 90, Loss: 0.0983, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 100, Loss: 0.1404, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 110, Loss: 0.0240, LR: 9.88e-05, Scale: 0.200
  Epoch 15, Batch 120, Loss: 0.0080, LR: 9.88e-05, Scale: 0.200
‚úÖ Epoch 15 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1801
   È™åËØÅÊçüÂ§±: 0.2681
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 16/200 ===
  Epoch 16, Batch 0, Loss: 0.0580, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 10, Loss: 0.2047, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 20, Loss: 0.0479, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 30, Loss: 0.0638, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 40, Loss: 0.2108, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 50, Loss: 0.1259, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 60, Loss: 0.1255, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 70, Loss: 0.0469, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 80, Loss: 0.0432, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 90, Loss: 0.0252, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 100, Loss: 0.1052, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 110, Loss: 0.0605, LR: 9.86e-05, Scale: 0.200
  Epoch 16, Batch 120, Loss: 0.1576, LR: 9.86e-05, Scale: 0.200
‚úÖ Epoch 16 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1929
   È™åËØÅÊçüÂ§±: 0.1588
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 17/200 ===
  Epoch 17, Batch 0, Loss: 0.1302, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 10, Loss: 0.1066, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 20, Loss: 0.3143, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 30, Loss: 0.4582, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 40, Loss: 0.3507, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 50, Loss: 0.1628, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 60, Loss: 0.0352, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 70, Loss: 0.0258, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 80, Loss: 0.1042, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 90, Loss: 0.1274, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 100, Loss: 0.5049, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 110, Loss: 0.1375, LR: 9.84e-05, Scale: 0.200
  Epoch 17, Batch 120, Loss: 0.2348, LR: 9.84e-05, Scale: 0.200
‚úÖ Epoch 17 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1808
   È™åËØÅÊçüÂ§±: 0.1769
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 18/200 ===
  Epoch 18, Batch 0, Loss: 0.1858, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 10, Loss: 0.3771, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 20, Loss: 0.5557, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 30, Loss: 0.1827, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 40, Loss: 0.1525, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 50, Loss: 0.0468, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 60, Loss: 0.1016, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 70, Loss: 0.3339, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 80, Loss: 0.1571, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 90, Loss: 0.4530, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 100, Loss: 0.1352, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 110, Loss: 0.1042, LR: 9.82e-05, Scale: 0.200
  Epoch 18, Batch 120, Loss: 0.7979, LR: 9.82e-05, Scale: 0.200
‚úÖ Epoch 18 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1910
   È™åËØÅÊçüÂ§±: 0.1794
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 19/200 ===
  Epoch 19, Batch 0, Loss: 0.7550, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 10, Loss: 0.1241, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 20, Loss: 0.2093, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 30, Loss: 0.3108, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 40, Loss: 0.0637, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 50, Loss: 0.0093, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 60, Loss: 0.3163, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 70, Loss: 0.3414, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 80, Loss: 0.4939, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 90, Loss: 0.2939, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 100, Loss: 0.1242, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 110, Loss: 0.2698, LR: 9.80e-05, Scale: 0.200
  Epoch 19, Batch 120, Loss: 0.4394, LR: 9.80e-05, Scale: 0.200
‚úÖ Epoch 19 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1852
   È™åËØÅÊçüÂ§±: 0.1285
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 20/200 ===
  Epoch 20, Batch 0, Loss: 0.1586, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 10, Loss: 0.1194, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 20, Loss: 0.1220, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 30, Loss: 0.0291, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 40, Loss: 0.0335, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 50, Loss: 0.0068, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 60, Loss: 0.1192, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 70, Loss: 0.0448, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 80, Loss: 0.6179, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 90, Loss: 0.1323, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 100, Loss: 0.1932, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 110, Loss: 0.0950, LR: 9.78e-05, Scale: 0.200
  Epoch 20, Batch 120, Loss: 0.4511, LR: 9.78e-05, Scale: 0.200
‚úÖ Epoch 20 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1782
   È™åËØÅÊçüÂ§±: 0.2469
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_20.pth

=== Epoch 21/200 ===
  Epoch 21, Batch 0, Loss: 0.1731, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 10, Loss: 0.0578, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 20, Loss: 0.1118, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 30, Loss: 0.1519, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 40, Loss: 0.3515, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 50, Loss: 0.1224, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 60, Loss: 0.1213, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 70, Loss: 0.1066, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 80, Loss: 0.2936, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 90, Loss: 0.0839, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 100, Loss: 0.0128, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 110, Loss: 0.2267, LR: 9.76e-05, Scale: 0.200
  Epoch 21, Batch 120, Loss: 0.1337, LR: 9.76e-05, Scale: 0.200
‚úÖ Epoch 21 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1714
   È™åËØÅÊçüÂ§±: 0.2209
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 22/200 ===
  Epoch 22, Batch 0, Loss: 0.1525, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 10, Loss: 0.0954, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 20, Loss: 0.5560, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 30, Loss: 0.0040, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 40, Loss: 0.1498, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 50, Loss: 0.1037, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 60, Loss: 0.3934, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 70, Loss: 0.2070, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 80, Loss: 0.0553, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 90, Loss: 0.5431, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 100, Loss: 0.2431, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 110, Loss: 0.1877, LR: 9.73e-05, Scale: 0.200
  Epoch 22, Batch 120, Loss: 0.2916, LR: 9.73e-05, Scale: 0.200
‚úÖ Epoch 22 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1991
   È™åËØÅÊçüÂ§±: 0.2385
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 23/200 ===
  Epoch 23, Batch 0, Loss: 0.0259, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 10, Loss: 0.4556, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 20, Loss: 0.0424, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 30, Loss: 0.3399, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 40, Loss: 0.2700, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 50, Loss: 0.2574, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 60, Loss: 0.2458, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 70, Loss: 0.0866, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 80, Loss: 0.2262, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 90, Loss: 0.1896, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 100, Loss: 0.1996, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 110, Loss: 0.2445, LR: 9.71e-05, Scale: 0.200
  Epoch 23, Batch 120, Loss: 0.0676, LR: 9.71e-05, Scale: 0.200
‚úÖ Epoch 23 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1743
   È™åËØÅÊçüÂ§±: 0.1620
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 24/200 ===
  Epoch 24, Batch 0, Loss: 0.2161, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 10, Loss: 0.3440, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 20, Loss: 0.0277, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 30, Loss: 0.6424, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 40, Loss: 0.0679, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 50, Loss: 0.1737, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 60, Loss: 0.0072, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 70, Loss: 0.0592, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 80, Loss: 0.0487, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 90, Loss: 0.2577, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 100, Loss: 0.2319, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 110, Loss: 0.1100, LR: 9.68e-05, Scale: 0.200
  Epoch 24, Batch 120, Loss: 0.1449, LR: 9.68e-05, Scale: 0.200
‚úÖ Epoch 24 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2093
   È™åËØÅÊçüÂ§±: 0.1675
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 25/200 ===
  Epoch 25, Batch 0, Loss: 0.1844, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 10, Loss: 0.0422, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 20, Loss: 0.2991, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 30, Loss: 0.0675, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 40, Loss: 0.1912, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 50, Loss: 0.1999, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 60, Loss: 0.5701, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 70, Loss: 0.0366, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 80, Loss: 0.0088, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 90, Loss: 0.0375, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 100, Loss: 0.0076, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 110, Loss: 0.1344, LR: 9.65e-05, Scale: 0.200
  Epoch 25, Batch 120, Loss: 0.0699, LR: 9.65e-05, Scale: 0.200
‚úÖ Epoch 25 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2061
   È™åËØÅÊçüÂ§±: 0.1736
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 26/200 ===
  Epoch 26, Batch 0, Loss: 0.3009, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 10, Loss: 0.2621, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 20, Loss: 0.2914, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 30, Loss: 0.2734, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 40, Loss: 0.0148, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 50, Loss: 0.1294, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 60, Loss: 0.3080, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 70, Loss: 0.3669, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 80, Loss: 0.2048, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 90, Loss: 0.1946, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 100, Loss: 0.1909, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 110, Loss: 0.0353, LR: 9.62e-05, Scale: 0.200
  Epoch 26, Batch 120, Loss: 0.5143, LR: 9.62e-05, Scale: 0.200
‚úÖ Epoch 26 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2024
   È™åËØÅÊçüÂ§±: 0.1672
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 27/200 ===
  Epoch 27, Batch 0, Loss: 0.4359, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 10, Loss: 0.4579, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 20, Loss: 0.2335, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 30, Loss: 0.2713, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 40, Loss: 0.0217, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 50, Loss: 0.1742, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 60, Loss: 0.1517, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 70, Loss: 0.0197, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 80, Loss: 0.4255, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 90, Loss: 0.2356, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 100, Loss: 0.0825, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 110, Loss: 0.4802, LR: 9.59e-05, Scale: 0.200
  Epoch 27, Batch 120, Loss: 0.2862, LR: 9.59e-05, Scale: 0.200
‚úÖ Epoch 27 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2161
   È™åËØÅÊçüÂ§±: 0.1852
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 28/200 ===
  Epoch 28, Batch 0, Loss: 0.4268, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 10, Loss: 0.0628, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 20, Loss: 0.0601, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 30, Loss: 0.1645, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 40, Loss: 0.0961, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 50, Loss: 0.3018, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 60, Loss: 0.0758, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 70, Loss: 0.0347, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 80, Loss: 0.0660, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 90, Loss: 0.4966, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 100, Loss: 0.0616, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 110, Loss: 0.0513, LR: 9.56e-05, Scale: 0.200
  Epoch 28, Batch 120, Loss: 0.2582, LR: 9.56e-05, Scale: 0.200
‚úÖ Epoch 28 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1671
   È™åËØÅÊçüÂ§±: 0.1924
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 29/200 ===
  Epoch 29, Batch 0, Loss: 0.1269, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 10, Loss: 0.0204, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 20, Loss: 0.2765, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 30, Loss: 0.2593, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 40, Loss: 0.0849, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 50, Loss: 0.1153, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 60, Loss: 0.0684, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 70, Loss: 0.0096, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 80, Loss: 0.2302, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 90, Loss: 0.4899, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 100, Loss: 0.0350, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 110, Loss: 0.1298, LR: 9.53e-05, Scale: 0.200
  Epoch 29, Batch 120, Loss: 0.0334, LR: 9.53e-05, Scale: 0.200
‚úÖ Epoch 29 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1795
   È™åËØÅÊçüÂ§±: 0.2127
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 30/200 ===
  Epoch 30, Batch 0, Loss: 0.1085, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 10, Loss: 0.0236, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 20, Loss: 0.0901, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 30, Loss: 0.2387, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 40, Loss: 0.4580, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 50, Loss: 0.0388, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 60, Loss: 0.1090, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 70, Loss: 0.0482, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 80, Loss: 0.1849, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 90, Loss: 0.2216, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 100, Loss: 0.1240, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 110, Loss: 0.0747, LR: 9.50e-05, Scale: 0.200
  Epoch 30, Batch 120, Loss: 0.4849, LR: 9.50e-05, Scale: 0.200
‚úÖ Epoch 30 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2041
   È™åËØÅÊçüÂ§±: 0.1637
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_30.pth

=== Epoch 31/200 ===
  Epoch 31, Batch 0, Loss: 0.1902, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 10, Loss: 0.0863, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 20, Loss: 0.0771, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 30, Loss: 0.0478, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 40, Loss: 0.0951, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 50, Loss: 0.4392, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 60, Loss: 0.1238, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 70, Loss: 0.0651, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 80, Loss: 0.1404, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 90, Loss: 0.1350, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 100, Loss: 0.1018, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 110, Loss: 0.4455, LR: 9.46e-05, Scale: 0.200
  Epoch 31, Batch 120, Loss: 0.0094, LR: 9.46e-05, Scale: 0.200
‚úÖ Epoch 31 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1915
   È™åËØÅÊçüÂ§±: 0.2299
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 32/200 ===
  Epoch 32, Batch 0, Loss: 0.0183, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 10, Loss: 0.0965, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 20, Loss: 0.2602, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 30, Loss: 0.2937, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 40, Loss: 0.1291, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 50, Loss: 0.2218, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 60, Loss: 0.5491, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 70, Loss: 0.4640, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 80, Loss: 0.3977, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 90, Loss: 0.2301, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 100, Loss: 0.2115, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 110, Loss: 0.0439, LR: 9.42e-05, Scale: 0.200
  Epoch 32, Batch 120, Loss: 0.3198, LR: 9.42e-05, Scale: 0.200
‚úÖ Epoch 32 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1954
   È™åËØÅÊçüÂ§±: 0.1891
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 33/200 ===
  Epoch 33, Batch 0, Loss: 0.0337, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 10, Loss: 0.1410, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 20, Loss: 0.2261, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 30, Loss: 0.2450, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 40, Loss: 0.3685, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 50, Loss: 0.1254, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 60, Loss: 0.4371, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 70, Loss: 0.4310, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 80, Loss: 0.0999, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 90, Loss: 0.1525, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 100, Loss: 0.0138, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 110, Loss: 0.4144, LR: 9.39e-05, Scale: 0.200
  Epoch 33, Batch 120, Loss: 0.2003, LR: 9.39e-05, Scale: 0.200
‚úÖ Epoch 33 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1793
   È™åËØÅÊçüÂ§±: 0.2177
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 34/200 ===
  Epoch 34, Batch 0, Loss: 0.0482, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 10, Loss: 0.0659, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 20, Loss: 0.1868, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 30, Loss: 0.2532, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 40, Loss: 0.1361, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 50, Loss: 0.1275, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 60, Loss: 0.1095, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 70, Loss: 0.0105, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 80, Loss: 0.4774, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 90, Loss: 0.0086, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 100, Loss: 0.1077, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 110, Loss: 0.1015, LR: 9.35e-05, Scale: 0.200
  Epoch 34, Batch 120, Loss: 0.1496, LR: 9.35e-05, Scale: 0.200
‚úÖ Epoch 34 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1830
   È™åËØÅÊçüÂ§±: 0.1739
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 35/200 ===
  Epoch 35, Batch 0, Loss: 0.1573, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 10, Loss: 0.1807, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 20, Loss: 0.2296, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 30, Loss: 0.0415, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 40, Loss: 0.1866, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 50, Loss: 0.3485, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 60, Loss: 0.1041, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 70, Loss: 0.0190, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 80, Loss: 0.1075, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 90, Loss: 0.4297, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 100, Loss: 0.0260, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 110, Loss: 0.5389, LR: 9.31e-05, Scale: 0.200
  Epoch 35, Batch 120, Loss: 0.1264, LR: 9.31e-05, Scale: 0.200
‚úÖ Epoch 35 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1988
   È™åËØÅÊçüÂ§±: 0.1978
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 36/200 ===
  Epoch 36, Batch 0, Loss: 0.4345, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 10, Loss: 0.0126, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 20, Loss: 0.0251, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 30, Loss: 0.2857, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 40, Loss: 0.3129, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 50, Loss: 0.0182, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 60, Loss: 0.1572, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 70, Loss: 0.2291, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 80, Loss: 0.1484, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 90, Loss: 0.0811, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 100, Loss: 0.1746, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 110, Loss: 0.0541, LR: 9.27e-05, Scale: 0.200
  Epoch 36, Batch 120, Loss: 0.2496, LR: 9.27e-05, Scale: 0.200
‚úÖ Epoch 36 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1840
   È™åËØÅÊçüÂ§±: 0.2385
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 37/200 ===
  Epoch 37, Batch 0, Loss: 0.3591, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 10, Loss: 0.3269, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 20, Loss: 0.1033, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 30, Loss: 0.1177, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 40, Loss: 0.0202, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 50, Loss: 0.0331, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 60, Loss: 0.3863, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 70, Loss: 0.2438, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 80, Loss: 0.0150, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 90, Loss: 0.2331, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 100, Loss: 0.2598, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 110, Loss: 0.2459, LR: 9.23e-05, Scale: 0.200
  Epoch 37, Batch 120, Loss: 0.3841, LR: 9.23e-05, Scale: 0.200
‚úÖ Epoch 37 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1975
   È™åËØÅÊçüÂ§±: 0.2711
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 38/200 ===
  Epoch 38, Batch 0, Loss: 0.3833, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 10, Loss: 0.0326, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 20, Loss: 0.2156, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 30, Loss: 0.5308, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 40, Loss: 0.0379, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 50, Loss: 0.0530, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 60, Loss: 0.2426, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 70, Loss: 0.1077, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 80, Loss: 0.1174, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 90, Loss: 0.1941, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 100, Loss: 0.2929, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 110, Loss: 0.1073, LR: 9.19e-05, Scale: 0.200
  Epoch 38, Batch 120, Loss: 0.2365, LR: 9.19e-05, Scale: 0.200
‚úÖ Epoch 38 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1885
   È™åËØÅÊçüÂ§±: 0.1611
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 39/200 ===
  Epoch 39, Batch 0, Loss: 0.2403, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 10, Loss: 0.1973, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 20, Loss: 0.4147, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 30, Loss: 0.0580, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 40, Loss: 0.0891, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 50, Loss: 0.0836, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 60, Loss: 0.1811, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 70, Loss: 0.0311, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 80, Loss: 0.1768, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 90, Loss: 0.4859, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 100, Loss: 0.0376, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 110, Loss: 0.1877, LR: 9.14e-05, Scale: 0.200
  Epoch 39, Batch 120, Loss: 0.0253, LR: 9.14e-05, Scale: 0.200
‚úÖ Epoch 39 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1907
   È™åËØÅÊçüÂ§±: 0.1069
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 40/200 ===
  Epoch 40, Batch 0, Loss: 0.2193, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 10, Loss: 0.2525, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 20, Loss: 0.0387, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 30, Loss: 0.0515, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 40, Loss: 0.1279, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 50, Loss: 0.1598, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 60, Loss: 0.0073, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 70, Loss: 0.1498, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 80, Loss: 0.3337, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 90, Loss: 0.4775, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 100, Loss: 0.0135, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 110, Loss: 0.0434, LR: 9.10e-05, Scale: 0.200
  Epoch 40, Batch 120, Loss: 0.1229, LR: 9.10e-05, Scale: 0.200
‚úÖ Epoch 40 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1740
   È™åËØÅÊçüÂ§±: 0.1348
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_40.pth

=== Epoch 41/200 ===
  Epoch 41, Batch 0, Loss: 0.0106, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 10, Loss: 0.0597, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 20, Loss: 0.4741, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 30, Loss: 0.0121, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 40, Loss: 0.0196, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 50, Loss: 0.0386, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 60, Loss: 0.1975, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 70, Loss: 0.1598, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 80, Loss: 0.0305, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 90, Loss: 0.0318, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 100, Loss: 0.1263, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 110, Loss: 0.6638, LR: 9.05e-05, Scale: 0.200
  Epoch 41, Batch 120, Loss: 0.1074, LR: 9.05e-05, Scale: 0.200
‚úÖ Epoch 41 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1951
   È™åËØÅÊçüÂ§±: 0.2211
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 42/200 ===
  Epoch 42, Batch 0, Loss: 0.0603, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 10, Loss: 0.3801, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 20, Loss: 0.3358, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 30, Loss: 0.0721, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 40, Loss: 0.1260, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 50, Loss: 0.3336, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 60, Loss: 0.0907, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 70, Loss: 0.1404, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 80, Loss: 0.1994, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 90, Loss: 0.2743, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 100, Loss: 0.2807, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 110, Loss: 0.0888, LR: 9.01e-05, Scale: 0.200
  Epoch 42, Batch 120, Loss: 0.3387, LR: 9.01e-05, Scale: 0.200
‚úÖ Epoch 42 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1871
   È™åËØÅÊçüÂ§±: 0.1786
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 43/200 ===
  Epoch 43, Batch 0, Loss: 0.0623, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 10, Loss: 0.0962, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 20, Loss: 0.0617, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 30, Loss: 0.1942, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 40, Loss: 0.3628, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 50, Loss: 0.0843, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 60, Loss: 0.0608, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 70, Loss: 0.3064, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 80, Loss: 0.0973, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 90, Loss: 0.0552, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 100, Loss: 0.0651, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 110, Loss: 0.0216, LR: 8.96e-05, Scale: 0.200
  Epoch 43, Batch 120, Loss: 0.1917, LR: 8.96e-05, Scale: 0.200
‚úÖ Epoch 43 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1653
   È™åËØÅÊçüÂ§±: 0.1495
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 44/200 ===
  Epoch 44, Batch 0, Loss: 0.0533, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 10, Loss: 0.1941, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 20, Loss: 0.0516, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 30, Loss: 0.1458, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 40, Loss: 0.0679, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 50, Loss: 0.1726, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 60, Loss: 0.2119, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 70, Loss: 0.2861, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 80, Loss: 0.0417, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 90, Loss: 0.4510, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 100, Loss: 0.4211, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 110, Loss: 0.2624, LR: 8.91e-05, Scale: 0.200
  Epoch 44, Batch 120, Loss: 0.2874, LR: 8.91e-05, Scale: 0.200
‚úÖ Epoch 44 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1843
   È™åËØÅÊçüÂ§±: 0.1777
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 45/200 ===
  Epoch 45, Batch 0, Loss: 0.1638, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 10, Loss: 0.1024, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 20, Loss: 0.1286, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 30, Loss: 0.2456, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 40, Loss: 0.1205, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 50, Loss: 0.0051, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 60, Loss: 0.0494, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 70, Loss: 0.1435, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 80, Loss: 0.0827, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 90, Loss: 0.1622, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 100, Loss: 0.1102, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 110, Loss: 0.2030, LR: 8.86e-05, Scale: 0.200
  Epoch 45, Batch 120, Loss: 0.0064, LR: 8.86e-05, Scale: 0.200
‚úÖ Epoch 45 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1656
   È™åËØÅÊçüÂ§±: 0.2036
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 46/200 ===
  Epoch 46, Batch 0, Loss: 0.2265, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 10, Loss: 0.3887, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 20, Loss: 0.1295, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 30, Loss: 0.1988, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 40, Loss: 0.1349, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 50, Loss: 0.1031, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 60, Loss: 0.0577, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 70, Loss: 0.1859, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 80, Loss: 0.1526, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 90, Loss: 0.0495, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 100, Loss: 0.0557, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 110, Loss: 0.0952, LR: 8.81e-05, Scale: 0.200
  Epoch 46, Batch 120, Loss: 0.0163, LR: 8.81e-05, Scale: 0.200
‚úÖ Epoch 46 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1921
   È™åËØÅÊçüÂ§±: 0.1415
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 47/200 ===
  Epoch 47, Batch 0, Loss: 0.1278, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 10, Loss: 0.0171, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 20, Loss: 0.4080, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 30, Loss: 0.0832, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 40, Loss: 0.1785, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 50, Loss: 0.0867, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 60, Loss: 0.1690, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 70, Loss: 0.0301, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 80, Loss: 0.3320, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 90, Loss: 0.2269, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 100, Loss: 0.1864, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 110, Loss: 0.0721, LR: 8.76e-05, Scale: 0.200
  Epoch 47, Batch 120, Loss: 0.1115, LR: 8.76e-05, Scale: 0.200
‚úÖ Epoch 47 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1854
   È™åËØÅÊçüÂ§±: 0.1810
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 48/200 ===
  Epoch 48, Batch 0, Loss: 0.3331, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 10, Loss: 0.0373, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 20, Loss: 0.2069, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 30, Loss: 0.0334, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 40, Loss: 0.2404, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 50, Loss: 0.0194, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 60, Loss: 0.3153, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 70, Loss: 0.0902, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 80, Loss: 0.2524, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 90, Loss: 0.6566, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 100, Loss: 0.1655, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 110, Loss: 0.0390, LR: 8.71e-05, Scale: 0.200
  Epoch 48, Batch 120, Loss: 0.1646, LR: 8.71e-05, Scale: 0.200
‚úÖ Epoch 48 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1704
   È™åËØÅÊçüÂ§±: 0.2379
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 49/200 ===
  Epoch 49, Batch 0, Loss: 0.0970, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 10, Loss: 0.1377, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 20, Loss: 0.0487, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 30, Loss: 0.0363, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 40, Loss: 0.3776, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 50, Loss: 0.0191, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 60, Loss: 0.0920, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 70, Loss: 0.1384, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 80, Loss: 0.1250, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 90, Loss: 0.0624, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 100, Loss: 0.0637, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 110, Loss: 0.3243, LR: 8.66e-05, Scale: 0.200
  Epoch 49, Batch 120, Loss: 0.1454, LR: 8.66e-05, Scale: 0.200
‚úÖ Epoch 49 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1613
   È™åËØÅÊçüÂ§±: 0.1161
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 50/200 ===
  Epoch 50, Batch 0, Loss: 0.3916, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 10, Loss: 0.0112, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 20, Loss: 0.1319, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 30, Loss: 0.0126, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 40, Loss: 0.3760, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 50, Loss: 0.1980, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 60, Loss: 0.3718, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 70, Loss: 0.3849, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 80, Loss: 0.0314, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 90, Loss: 0.4312, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 100, Loss: 0.1310, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 110, Loss: 0.1736, LR: 8.60e-05, Scale: 0.200
  Epoch 50, Batch 120, Loss: 0.1063, LR: 8.60e-05, Scale: 0.200
‚úÖ Epoch 50 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1719
   È™åËØÅÊçüÂ§±: 0.1664
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_50.pth

=== Epoch 51/200 ===
  Epoch 51, Batch 0, Loss: 0.0070, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 10, Loss: 0.1194, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 20, Loss: 0.4633, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 30, Loss: 0.0893, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 40, Loss: 0.5427, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 50, Loss: 0.0313, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 60, Loss: 0.4539, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 70, Loss: 0.0785, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 80, Loss: 0.1570, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 90, Loss: 0.3049, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 100, Loss: 0.0425, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 110, Loss: 0.2301, LR: 8.55e-05, Scale: 0.200
  Epoch 51, Batch 120, Loss: 0.4148, LR: 8.55e-05, Scale: 0.200
‚úÖ Epoch 51 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1878
   È™åËØÅÊçüÂ§±: 0.1813
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 52/200 ===
  Epoch 52, Batch 0, Loss: 0.0468, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 10, Loss: 0.1204, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 20, Loss: 0.4645, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 30, Loss: 0.0633, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 40, Loss: 0.0176, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 50, Loss: 0.0612, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 60, Loss: 0.1990, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 70, Loss: 0.2545, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 80, Loss: 0.0986, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 90, Loss: 0.0168, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 100, Loss: 0.0602, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 110, Loss: 0.0670, LR: 8.49e-05, Scale: 0.200
  Epoch 52, Batch 120, Loss: 0.1621, LR: 8.49e-05, Scale: 0.200
‚úÖ Epoch 52 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1731
   È™åËØÅÊçüÂ§±: 0.2342
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 53/200 ===
  Epoch 53, Batch 0, Loss: 0.1588, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 10, Loss: 0.3681, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 20, Loss: 0.1180, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 30, Loss: 0.1960, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 40, Loss: 0.0348, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 50, Loss: 0.1376, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 60, Loss: 0.0680, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 70, Loss: 0.2391, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 80, Loss: 0.1057, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 90, Loss: 0.2740, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 100, Loss: 0.0498, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 110, Loss: 0.3534, LR: 8.44e-05, Scale: 0.200
  Epoch 53, Batch 120, Loss: 0.0194, LR: 8.44e-05, Scale: 0.200
‚úÖ Epoch 53 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1752
   È™åËØÅÊçüÂ§±: 0.1399
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 54/200 ===
  Epoch 54, Batch 0, Loss: 0.1673, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 10, Loss: 0.3434, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 20, Loss: 0.0489, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 30, Loss: 0.2579, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 40, Loss: 0.2739, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 50, Loss: 0.2092, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 60, Loss: 0.2594, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 70, Loss: 0.1178, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 80, Loss: 0.2712, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 90, Loss: 0.0755, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 100, Loss: 0.2055, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 110, Loss: 0.1151, LR: 8.38e-05, Scale: 0.200
  Epoch 54, Batch 120, Loss: 0.3082, LR: 8.38e-05, Scale: 0.200
‚úÖ Epoch 54 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1788
   È™åËØÅÊçüÂ§±: 0.1838
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 55/200 ===
  Epoch 55, Batch 0, Loss: 0.6040, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 10, Loss: 0.2265, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 20, Loss: 0.0277, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 30, Loss: 0.2578, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 40, Loss: 0.1265, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 50, Loss: 0.5367, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 60, Loss: 0.0528, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 70, Loss: 0.0716, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 80, Loss: 0.0741, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 90, Loss: 0.1899, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 100, Loss: 0.1554, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 110, Loss: 0.1159, LR: 8.32e-05, Scale: 0.200
  Epoch 55, Batch 120, Loss: 0.2015, LR: 8.32e-05, Scale: 0.200
‚úÖ Epoch 55 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1723
   È™åËØÅÊçüÂ§±: 0.2048
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 56/200 ===
  Epoch 56, Batch 0, Loss: 0.5132, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 10, Loss: 0.0116, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 20, Loss: 0.5084, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 30, Loss: 0.2610, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 40, Loss: 0.1967, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 50, Loss: 0.1584, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 60, Loss: 0.0739, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 70, Loss: 0.3034, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 80, Loss: 0.1052, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 90, Loss: 0.1834, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 100, Loss: 0.2070, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 110, Loss: 0.3988, LR: 8.26e-05, Scale: 0.200
  Epoch 56, Batch 120, Loss: 0.1306, LR: 8.26e-05, Scale: 0.200
‚úÖ Epoch 56 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1680
   È™åËØÅÊçüÂ§±: 0.1914
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 57/200 ===
  Epoch 57, Batch 0, Loss: 0.2274, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 10, Loss: 0.2878, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 20, Loss: 0.0951, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 30, Loss: 0.0971, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 40, Loss: 0.2196, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 50, Loss: 0.0406, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 60, Loss: 0.0147, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 70, Loss: 0.0586, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 80, Loss: 0.2680, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 90, Loss: 0.2398, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 100, Loss: 0.1259, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 110, Loss: 0.3111, LR: 8.21e-05, Scale: 0.200
  Epoch 57, Batch 120, Loss: 0.2369, LR: 8.21e-05, Scale: 0.200
‚úÖ Epoch 57 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1857
   È™åËØÅÊçüÂ§±: 0.2078
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 58/200 ===
  Epoch 58, Batch 0, Loss: 0.2168, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 10, Loss: 0.0149, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 20, Loss: 0.5452, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 30, Loss: 0.1451, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 40, Loss: 0.0902, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 50, Loss: 0.2100, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 60, Loss: 0.0938, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 70, Loss: 0.3497, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 80, Loss: 0.1366, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 90, Loss: 0.0488, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 100, Loss: 0.1159, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 110, Loss: 0.0547, LR: 8.14e-05, Scale: 0.200
  Epoch 58, Batch 120, Loss: 0.0910, LR: 8.14e-05, Scale: 0.200
‚úÖ Epoch 58 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1858
   È™åËØÅÊçüÂ§±: 0.1544
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 59/200 ===
  Epoch 59, Batch 0, Loss: 0.0364, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 10, Loss: 0.0404, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 20, Loss: 0.1042, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 30, Loss: 0.2250, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 40, Loss: 0.3836, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 50, Loss: 0.0926, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 60, Loss: 0.2823, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 70, Loss: 0.1502, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 80, Loss: 0.2037, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 90, Loss: 0.2663, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 100, Loss: 0.2393, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 110, Loss: 0.3346, LR: 8.08e-05, Scale: 0.200
  Epoch 59, Batch 120, Loss: 0.0588, LR: 8.08e-05, Scale: 0.200
‚úÖ Epoch 59 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1745
   È™åËØÅÊçüÂ§±: 0.1584
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 60/200 ===
  Epoch 60, Batch 0, Loss: 0.0551, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 10, Loss: 0.0531, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 20, Loss: 0.0260, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 30, Loss: 0.0260, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 40, Loss: 0.1418, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 50, Loss: 0.0724, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 60, Loss: 0.0665, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 70, Loss: 0.0678, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 80, Loss: 0.1564, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 90, Loss: 0.5258, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 100, Loss: 0.0958, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 110, Loss: 0.0315, LR: 8.02e-05, Scale: 0.200
  Epoch 60, Batch 120, Loss: 0.4119, LR: 8.02e-05, Scale: 0.200
‚úÖ Epoch 60 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1755
   È™åËØÅÊçüÂ§±: 0.2178
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_60.pth

=== Epoch 61/200 ===
  Epoch 61, Batch 0, Loss: 0.3083, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 10, Loss: 0.1674, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 20, Loss: 0.2144, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 30, Loss: 0.0972, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 40, Loss: 0.0966, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 50, Loss: 0.3506, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 60, Loss: 0.3863, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 70, Loss: 0.4218, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 80, Loss: 0.1494, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 90, Loss: 0.1239, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 100, Loss: 0.1525, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 110, Loss: 0.0763, LR: 7.96e-05, Scale: 0.200
  Epoch 61, Batch 120, Loss: 0.3086, LR: 7.96e-05, Scale: 0.200
‚úÖ Epoch 61 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1813
   È™åËØÅÊçüÂ§±: 0.2371
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 62/200 ===
  Epoch 62, Batch 0, Loss: 0.0952, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 10, Loss: 0.1689, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 20, Loss: 0.0210, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 30, Loss: 0.1405, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 40, Loss: 0.2548, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 50, Loss: 0.2931, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 60, Loss: 0.3844, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 70, Loss: 0.2247, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 80, Loss: 0.0595, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 90, Loss: 0.0677, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 100, Loss: 0.2043, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 110, Loss: 0.1757, LR: 7.90e-05, Scale: 0.200
  Epoch 62, Batch 120, Loss: 0.5602, LR: 7.90e-05, Scale: 0.200
‚úÖ Epoch 62 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1587
   È™åËØÅÊçüÂ§±: 0.1889
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 63/200 ===
  Epoch 63, Batch 0, Loss: 0.3123, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 10, Loss: 0.3567, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 20, Loss: 0.1652, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 30, Loss: 0.1277, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 40, Loss: 0.4886, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 50, Loss: 0.5445, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 60, Loss: 0.1499, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 70, Loss: 0.0634, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 80, Loss: 0.0473, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 90, Loss: 0.2193, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 100, Loss: 0.1650, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 110, Loss: 0.2815, LR: 7.83e-05, Scale: 0.200
  Epoch 63, Batch 120, Loss: 0.2774, LR: 7.83e-05, Scale: 0.200
‚úÖ Epoch 63 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1877
   È™åËØÅÊçüÂ§±: 0.1627
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 64/200 ===
  Epoch 64, Batch 0, Loss: 0.0871, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 10, Loss: 0.0597, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 20, Loss: 0.4543, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 30, Loss: 0.0211, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 40, Loss: 0.1758, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 50, Loss: 0.2258, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 60, Loss: 0.2239, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 70, Loss: 0.0615, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 80, Loss: 0.1216, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 90, Loss: 0.1796, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 100, Loss: 0.0943, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 110, Loss: 0.4127, LR: 7.77e-05, Scale: 0.200
  Epoch 64, Batch 120, Loss: 0.2640, LR: 7.77e-05, Scale: 0.200
‚úÖ Epoch 64 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1734
   È™åËØÅÊçüÂ§±: 0.2096
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 65/200 ===
  Epoch 65, Batch 0, Loss: 0.1061, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 10, Loss: 0.0304, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 20, Loss: 0.3537, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 30, Loss: 0.0551, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 40, Loss: 0.4237, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 50, Loss: 0.0062, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 60, Loss: 0.3834, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 70, Loss: 0.4922, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 80, Loss: 0.1835, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 90, Loss: 0.0344, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 100, Loss: 0.2305, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 110, Loss: 0.0589, LR: 7.70e-05, Scale: 0.200
  Epoch 65, Batch 120, Loss: 0.2115, LR: 7.70e-05, Scale: 0.200
‚úÖ Epoch 65 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1847
   È™åËØÅÊçüÂ§±: 0.1350
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 66/200 ===
  Epoch 66, Batch 0, Loss: 0.6325, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 10, Loss: 0.4381, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 20, Loss: 0.0054, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 30, Loss: 0.1148, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 40, Loss: 0.1353, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 50, Loss: 0.3959, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 60, Loss: 0.0544, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 70, Loss: 0.1943, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 80, Loss: 0.3841, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 90, Loss: 0.3349, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 100, Loss: 0.0982, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 110, Loss: 0.1995, LR: 7.64e-05, Scale: 0.200
  Epoch 66, Batch 120, Loss: 0.4600, LR: 7.64e-05, Scale: 0.200
‚úÖ Epoch 66 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1763
   È™åËØÅÊçüÂ§±: 0.2051
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 67/200 ===
  Epoch 67, Batch 0, Loss: 0.0880, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 10, Loss: 0.0312, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 20, Loss: 0.0341, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 30, Loss: 0.0137, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 40, Loss: 0.4296, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 50, Loss: 0.1632, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 60, Loss: 0.0625, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 70, Loss: 0.1062, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 80, Loss: 0.1640, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 90, Loss: 0.1175, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 100, Loss: 0.0311, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 110, Loss: 0.0375, LR: 7.57e-05, Scale: 0.200
  Epoch 67, Batch 120, Loss: 0.4929, LR: 7.57e-05, Scale: 0.200
‚úÖ Epoch 67 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1545
   È™åËØÅÊçüÂ§±: 0.2487
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 68/200 ===
  Epoch 68, Batch 0, Loss: 0.2021, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 10, Loss: 0.1112, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 20, Loss: 0.0162, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 30, Loss: 0.2462, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 40, Loss: 0.1018, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 50, Loss: 0.0437, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 60, Loss: 0.1892, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 70, Loss: 0.3069, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 80, Loss: 0.0322, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 90, Loss: 0.1780, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 100, Loss: 0.1050, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 110, Loss: 0.2558, LR: 7.50e-05, Scale: 0.200
  Epoch 68, Batch 120, Loss: 0.1654, LR: 7.50e-05, Scale: 0.200
‚úÖ Epoch 68 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1778
   È™åËØÅÊçüÂ§±: 0.2231
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 69/200 ===
  Epoch 69, Batch 0, Loss: 0.0983, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 10, Loss: 0.1645, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 20, Loss: 0.4100, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 30, Loss: 0.1063, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 40, Loss: 0.3291, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 50, Loss: 0.3132, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 60, Loss: 0.4487, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 70, Loss: 0.0586, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 80, Loss: 0.0084, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 90, Loss: 0.5382, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 100, Loss: 0.0217, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 110, Loss: 0.1319, LR: 7.43e-05, Scale: 0.200
  Epoch 69, Batch 120, Loss: 0.4361, LR: 7.43e-05, Scale: 0.200
‚úÖ Epoch 69 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1797
   È™åËØÅÊçüÂ§±: 0.2103
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 70/200 ===
  Epoch 70, Batch 0, Loss: 0.3382, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 10, Loss: 0.2821, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 20, Loss: 0.0097, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 30, Loss: 0.3479, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 40, Loss: 0.1126, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 50, Loss: 0.2532, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 60, Loss: 0.0389, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 70, Loss: 0.0660, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 80, Loss: 0.0221, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 90, Loss: 0.1360, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 100, Loss: 0.2748, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 110, Loss: 0.0972, LR: 7.37e-05, Scale: 0.200
  Epoch 70, Batch 120, Loss: 0.0916, LR: 7.37e-05, Scale: 0.200
‚úÖ Epoch 70 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1910
   È™åËØÅÊçüÂ§±: 0.1807
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_70.pth

=== Epoch 71/200 ===
  Epoch 71, Batch 0, Loss: 0.0100, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 10, Loss: 0.0594, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 20, Loss: 0.0925, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 30, Loss: 0.1677, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 40, Loss: 0.2558, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 50, Loss: 0.1404, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 60, Loss: 0.1123, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 70, Loss: 0.2847, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 80, Loss: 0.1254, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 90, Loss: 0.0384, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 100, Loss: 0.1720, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 110, Loss: 0.0913, LR: 7.30e-05, Scale: 0.200
  Epoch 71, Batch 120, Loss: 0.1437, LR: 7.30e-05, Scale: 0.200
‚úÖ Epoch 71 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1429
   È™åËØÅÊçüÂ§±: 0.1819
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 72/200 ===
  Epoch 72, Batch 0, Loss: 0.1691, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 10, Loss: 0.1364, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 20, Loss: 0.3994, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 30, Loss: 0.3755, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 40, Loss: 0.2545, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 50, Loss: 0.0890, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 60, Loss: 0.1695, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 70, Loss: 0.2295, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 80, Loss: 0.2195, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 90, Loss: 0.2055, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 100, Loss: 0.0990, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 110, Loss: 0.0562, LR: 7.23e-05, Scale: 0.200
  Epoch 72, Batch 120, Loss: 0.3439, LR: 7.23e-05, Scale: 0.200
‚úÖ Epoch 72 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1759
   È™åËØÅÊçüÂ§±: 0.1875
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 73/200 ===
  Epoch 73, Batch 0, Loss: 0.0373, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 10, Loss: 0.1469, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 20, Loss: 0.1579, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 30, Loss: 0.1903, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 40, Loss: 0.0232, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 50, Loss: 0.1517, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 60, Loss: 0.0261, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 70, Loss: 0.3960, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 80, Loss: 0.2024, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 90, Loss: 0.1764, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 100, Loss: 0.1603, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 110, Loss: 0.1029, LR: 7.16e-05, Scale: 0.200
  Epoch 73, Batch 120, Loss: 0.0154, LR: 7.16e-05, Scale: 0.200
‚úÖ Epoch 73 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1790
   È™åËØÅÊçüÂ§±: 0.1521
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 74/200 ===
  Epoch 74, Batch 0, Loss: 0.3978, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 10, Loss: 0.0679, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 20, Loss: 0.1165, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 30, Loss: 0.0198, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 40, Loss: 0.1662, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 50, Loss: 0.0532, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 60, Loss: 0.4744, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 70, Loss: 0.1557, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 80, Loss: 0.0567, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 90, Loss: 0.3637, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 100, Loss: 0.1745, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 110, Loss: 0.0796, LR: 7.09e-05, Scale: 0.200
  Epoch 74, Batch 120, Loss: 0.1656, LR: 7.09e-05, Scale: 0.200
‚úÖ Epoch 74 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1820
   È™åËØÅÊçüÂ§±: 0.1950
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 75/200 ===
  Epoch 75, Batch 0, Loss: 0.0267, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 10, Loss: 0.0519, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 20, Loss: 0.1545, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 30, Loss: 0.2379, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 40, Loss: 0.0225, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 50, Loss: 0.2893, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 60, Loss: 0.0210, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 70, Loss: 0.0385, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 80, Loss: 0.0522, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 90, Loss: 0.1200, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 100, Loss: 0.0830, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 110, Loss: 0.0642, LR: 7.02e-05, Scale: 0.200
  Epoch 75, Batch 120, Loss: 0.1410, LR: 7.02e-05, Scale: 0.200
‚úÖ Epoch 75 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1617
   È™åËØÅÊçüÂ§±: 0.2201
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 76/200 ===
  Epoch 76, Batch 0, Loss: 0.1826, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 10, Loss: 0.3655, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 20, Loss: 0.2480, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 30, Loss: 0.5044, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 40, Loss: 0.2058, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 50, Loss: 0.0990, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 60, Loss: 0.0058, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 70, Loss: 0.0459, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 80, Loss: 0.2972, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 90, Loss: 0.2012, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 100, Loss: 0.1543, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 110, Loss: 0.0582, LR: 6.94e-05, Scale: 0.200
  Epoch 76, Batch 120, Loss: 0.2458, LR: 6.94e-05, Scale: 0.200
‚úÖ Epoch 76 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1764
   È™åËØÅÊçüÂ§±: 0.1973
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 77/200 ===
  Epoch 77, Batch 0, Loss: 0.3171, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 10, Loss: 0.0546, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 20, Loss: 0.1467, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 30, Loss: 0.2104, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 40, Loss: 0.3041, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 50, Loss: 0.0350, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 60, Loss: 0.0271, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 70, Loss: 0.0751, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 80, Loss: 0.0915, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 90, Loss: 0.0251, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 100, Loss: 0.3084, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 110, Loss: 0.2058, LR: 6.87e-05, Scale: 0.200
  Epoch 77, Batch 120, Loss: 0.1406, LR: 6.87e-05, Scale: 0.200
‚úÖ Epoch 77 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1580
   È™åËØÅÊçüÂ§±: 0.2210
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 78/200 ===
  Epoch 78, Batch 0, Loss: 0.1324, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 10, Loss: 0.0872, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 20, Loss: 0.0953, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 30, Loss: 0.2666, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 40, Loss: 0.1174, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 50, Loss: 0.2355, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 60, Loss: 0.1115, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 70, Loss: 0.1724, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 80, Loss: 0.5304, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 90, Loss: 0.2328, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 100, Loss: 0.0367, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 110, Loss: 0.0611, LR: 6.80e-05, Scale: 0.200
  Epoch 78, Batch 120, Loss: 0.1699, LR: 6.80e-05, Scale: 0.200
‚úÖ Epoch 78 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1677
   È™åËØÅÊçüÂ§±: 0.2100
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 79/200 ===
  Epoch 79, Batch 0, Loss: 0.1178, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 10, Loss: 0.0105, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 20, Loss: 0.4453, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 30, Loss: 0.4913, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 40, Loss: 0.0213, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 50, Loss: 0.3845, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 60, Loss: 0.0677, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 70, Loss: 0.2884, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 80, Loss: 0.1024, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 90, Loss: 0.3135, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 100, Loss: 0.2943, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 110, Loss: 0.4075, LR: 6.73e-05, Scale: 0.200
  Epoch 79, Batch 120, Loss: 0.0048, LR: 6.73e-05, Scale: 0.200
‚úÖ Epoch 79 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1811
   È™åËØÅÊçüÂ§±: 0.1974
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 80/200 ===
  Epoch 80, Batch 0, Loss: 0.1614, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 10, Loss: 0.0474, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 20, Loss: 0.2391, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 30, Loss: 0.0475, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 40, Loss: 0.0092, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 50, Loss: 0.0927, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 60, Loss: 0.0347, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 70, Loss: 0.0215, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 80, Loss: 0.5443, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 90, Loss: 0.2687, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 100, Loss: 0.2145, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 110, Loss: 0.0184, LR: 6.65e-05, Scale: 0.200
  Epoch 80, Batch 120, Loss: 0.1735, LR: 6.65e-05, Scale: 0.200
‚úÖ Epoch 80 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1598
   È™åËØÅÊçüÂ§±: 0.2034
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_80.pth

=== Epoch 81/200 ===
  Epoch 81, Batch 0, Loss: 0.1438, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 10, Loss: 0.1755, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 20, Loss: 0.0326, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 30, Loss: 0.3563, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 40, Loss: 0.2186, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 50, Loss: 0.0789, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 60, Loss: 0.0511, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 70, Loss: 0.2272, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 80, Loss: 0.0294, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 90, Loss: 0.0317, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 100, Loss: 0.2239, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 110, Loss: 0.0285, LR: 6.58e-05, Scale: 0.200
  Epoch 81, Batch 120, Loss: 0.3599, LR: 6.58e-05, Scale: 0.200
‚úÖ Epoch 81 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1847
   È™åËØÅÊçüÂ§±: 0.2517
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 82/200 ===
  Epoch 82, Batch 0, Loss: 0.0845, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 10, Loss: 0.3711, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 20, Loss: 0.0122, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 30, Loss: 0.0802, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 40, Loss: 0.1116, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 50, Loss: 0.0415, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 60, Loss: 0.1872, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 70, Loss: 0.0277, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 80, Loss: 0.1649, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 90, Loss: 0.1514, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 100, Loss: 0.1322, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 110, Loss: 0.0625, LR: 6.51e-05, Scale: 0.200
  Epoch 82, Batch 120, Loss: 0.2226, LR: 6.51e-05, Scale: 0.200
‚úÖ Epoch 82 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1666
   È™åËØÅÊçüÂ§±: 0.3143
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 83/200 ===
  Epoch 83, Batch 0, Loss: 0.0217, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 10, Loss: 0.3093, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 20, Loss: 0.0672, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 30, Loss: 0.0336, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 40, Loss: 0.0920, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 50, Loss: 0.1624, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 60, Loss: 0.1010, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 70, Loss: 0.1384, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 80, Loss: 0.1125, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 90, Loss: 0.2291, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 100, Loss: 0.2225, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 110, Loss: 0.0345, LR: 6.43e-05, Scale: 0.200
  Epoch 83, Batch 120, Loss: 0.0432, LR: 6.43e-05, Scale: 0.200
‚úÖ Epoch 83 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1676
   È™åËØÅÊçüÂ§±: 0.2441
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 84/200 ===
  Epoch 84, Batch 0, Loss: 0.0667, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 10, Loss: 0.4045, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 20, Loss: 0.0059, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 30, Loss: 0.0782, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 40, Loss: 0.0728, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 50, Loss: 0.2248, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 60, Loss: 0.3836, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 70, Loss: 0.0700, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 80, Loss: 0.1130, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 90, Loss: 0.0938, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 100, Loss: 0.2125, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 110, Loss: 0.2471, LR: 6.36e-05, Scale: 0.200
  Epoch 84, Batch 120, Loss: 0.1178, LR: 6.36e-05, Scale: 0.200
‚úÖ Epoch 84 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1661
   È™åËØÅÊçüÂ§±: 0.1671
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 85/200 ===
  Epoch 85, Batch 0, Loss: 0.0517, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 10, Loss: 0.0156, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 20, Loss: 0.0413, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 30, Loss: 0.1204, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 40, Loss: 0.2007, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 50, Loss: 0.2518, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 60, Loss: 0.2158, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 70, Loss: 0.0258, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 80, Loss: 0.1943, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 90, Loss: 0.1951, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 100, Loss: 0.2223, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 110, Loss: 0.1717, LR: 6.28e-05, Scale: 0.200
  Epoch 85, Batch 120, Loss: 0.1549, LR: 6.28e-05, Scale: 0.200
‚úÖ Epoch 85 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1744
   È™åËØÅÊçüÂ§±: 0.2015
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 86/200 ===
  Epoch 86, Batch 0, Loss: 0.1092, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 10, Loss: 0.0819, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 20, Loss: 0.0573, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 30, Loss: 0.3573, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 40, Loss: 0.3756, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 50, Loss: 0.0158, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 60, Loss: 0.3556, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 70, Loss: 0.1150, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 80, Loss: 0.1890, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 90, Loss: 0.4025, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 100, Loss: 0.3013, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 110, Loss: 0.2679, LR: 6.21e-05, Scale: 0.200
  Epoch 86, Batch 120, Loss: 0.1675, LR: 6.21e-05, Scale: 0.200
‚úÖ Epoch 86 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.2095
   È™åËØÅÊçüÂ§±: 0.2104
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 87/200 ===
  Epoch 87, Batch 0, Loss: 0.0939, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 10, Loss: 0.0161, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 20, Loss: 0.1847, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 30, Loss: 0.0062, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 40, Loss: 0.2148, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 50, Loss: 0.1785, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 60, Loss: 0.0762, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 70, Loss: 0.2840, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 80, Loss: 0.0291, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 90, Loss: 0.1065, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 100, Loss: 0.2455, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 110, Loss: 0.0383, LR: 6.13e-05, Scale: 0.200
  Epoch 87, Batch 120, Loss: 0.2786, LR: 6.13e-05, Scale: 0.200
‚úÖ Epoch 87 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1608
   È™åËØÅÊçüÂ§±: 0.1059
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 88/200 ===
  Epoch 88, Batch 0, Loss: 0.2106, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 10, Loss: 0.2025, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 20, Loss: 0.1107, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 30, Loss: 0.2800, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 40, Loss: 0.3059, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 50, Loss: 0.1661, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 60, Loss: 0.4930, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 70, Loss: 0.4707, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 80, Loss: 0.1925, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 90, Loss: 0.2325, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 100, Loss: 0.3294, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 110, Loss: 0.1007, LR: 6.05e-05, Scale: 0.200
  Epoch 88, Batch 120, Loss: 0.1953, LR: 6.05e-05, Scale: 0.200
‚úÖ Epoch 88 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1638
   È™åËØÅÊçüÂ§±: 0.1202
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 89/200 ===
  Epoch 89, Batch 0, Loss: 0.0819, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 10, Loss: 0.1632, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 20, Loss: 0.2522, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 30, Loss: 0.1473, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 40, Loss: 0.2758, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 50, Loss: 0.2538, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 60, Loss: 0.1450, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 70, Loss: 0.1213, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 80, Loss: 0.0056, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 90, Loss: 0.3142, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 100, Loss: 0.1396, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 110, Loss: 0.1269, LR: 5.98e-05, Scale: 0.200
  Epoch 89, Batch 120, Loss: 0.1239, LR: 5.98e-05, Scale: 0.200
‚úÖ Epoch 89 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1523
   È™åËØÅÊçüÂ§±: 0.1754
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 90/200 ===
  Epoch 90, Batch 0, Loss: 0.1751, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 10, Loss: 0.1305, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 20, Loss: 0.0806, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 30, Loss: 0.0996, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 40, Loss: 0.2610, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 50, Loss: 0.1665, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 60, Loss: 0.1447, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 70, Loss: 0.1834, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 80, Loss: 0.0663, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 90, Loss: 0.0275, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 100, Loss: 0.2381, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 110, Loss: 0.1770, LR: 5.90e-05, Scale: 0.200
  Epoch 90, Batch 120, Loss: 0.0043, LR: 5.90e-05, Scale: 0.200
‚úÖ Epoch 90 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1469
   È™åËØÅÊçüÂ§±: 0.2145
   Êù°‰ª∂Áº©Êîæ: 0.200
üíæ ‰øùÂ≠òÊ£ÄÊü•ÁÇπ: training_results_move_object/controlnet_move_object_epoch_90.pth

=== Epoch 91/200 ===
  Epoch 91, Batch 0, Loss: 0.0464, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 10, Loss: 0.0769, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 20, Loss: 0.0949, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 30, Loss: 0.2116, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 40, Loss: 0.4857, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 50, Loss: 0.0058, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 60, Loss: 0.0974, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 70, Loss: 0.0305, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 80, Loss: 0.0047, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 90, Loss: 0.0343, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 100, Loss: 0.0172, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 110, Loss: 0.1019, LR: 5.82e-05, Scale: 0.200
  Epoch 91, Batch 120, Loss: 0.0229, LR: 5.82e-05, Scale: 0.200
‚úÖ Epoch 91 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1600
   È™åËØÅÊçüÂ§±: 0.2348
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 92/200 ===
  Epoch 92, Batch 0, Loss: 0.3157, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 10, Loss: 0.3083, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 20, Loss: 0.2359, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 30, Loss: 0.0612, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 40, Loss: 0.4840, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 50, Loss: 0.5183, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 60, Loss: 0.0206, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 70, Loss: 0.0373, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 80, Loss: 0.1157, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 90, Loss: 0.1044, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 100, Loss: 0.1615, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 110, Loss: 0.1621, LR: 5.75e-05, Scale: 0.200
  Epoch 92, Batch 120, Loss: 0.0550, LR: 5.75e-05, Scale: 0.200
‚úÖ Epoch 92 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1648
   È™åËØÅÊçüÂ§±: 0.1915
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 93/200 ===
  Epoch 93, Batch 0, Loss: 0.1694, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 10, Loss: 0.1132, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 20, Loss: 0.0806, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 30, Loss: 0.0630, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 40, Loss: 0.0429, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 50, Loss: 0.0183, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 60, Loss: 0.1172, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 70, Loss: 0.0111, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 80, Loss: 0.0565, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 90, Loss: 0.4444, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 100, Loss: 0.1260, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 110, Loss: 0.0881, LR: 5.67e-05, Scale: 0.200
  Epoch 93, Batch 120, Loss: 0.2097, LR: 5.67e-05, Scale: 0.200
‚úÖ Epoch 93 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1645
   È™åËØÅÊçüÂ§±: 0.2488
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 94/200 ===
  Epoch 94, Batch 0, Loss: 0.0555, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 10, Loss: 0.2968, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 20, Loss: 0.5403, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 30, Loss: 0.1235, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 40, Loss: 0.0174, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 50, Loss: 0.3458, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 60, Loss: 0.1927, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 70, Loss: 0.3155, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 80, Loss: 0.0053, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 90, Loss: 0.0160, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 100, Loss: 0.2272, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 110, Loss: 0.1885, LR: 5.59e-05, Scale: 0.200
  Epoch 94, Batch 120, Loss: 0.1573, LR: 5.59e-05, Scale: 0.200
‚úÖ Epoch 94 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1681
   È™åËØÅÊçüÂ§±: 0.2067
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 95/200 ===
  Epoch 95, Batch 0, Loss: 0.3806, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 10, Loss: 0.3192, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 20, Loss: 0.0653, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 30, Loss: 0.0919, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 40, Loss: 0.2508, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 50, Loss: 0.0204, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 60, Loss: 0.3125, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 70, Loss: 0.4807, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 80, Loss: 0.3327, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 90, Loss: 0.2415, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 100, Loss: 0.4638, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 110, Loss: 0.0341, LR: 5.52e-05, Scale: 0.200
  Epoch 95, Batch 120, Loss: 0.1067, LR: 5.52e-05, Scale: 0.200
‚úÖ Epoch 95 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1926
   È™åËØÅÊçüÂ§±: 0.2146
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 96/200 ===
  Epoch 96, Batch 0, Loss: 0.0480, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 10, Loss: 0.2140, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 20, Loss: 0.0518, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 30, Loss: 0.0873, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 40, Loss: 0.1873, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 50, Loss: 0.0253, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 60, Loss: 0.0121, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 70, Loss: 0.1494, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 80, Loss: 0.0420, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 90, Loss: 0.0270, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 100, Loss: 0.3860, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 110, Loss: 0.5351, LR: 5.44e-05, Scale: 0.200
  Epoch 96, Batch 120, Loss: 0.1840, LR: 5.44e-05, Scale: 0.200
‚úÖ Epoch 96 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1589
   È™åËØÅÊçüÂ§±: 0.1918
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 97/200 ===
  Epoch 97, Batch 0, Loss: 0.3933, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 10, Loss: 0.2212, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 20, Loss: 0.1675, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 30, Loss: 0.0946, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 40, Loss: 0.1771, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 50, Loss: 0.4703, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 60, Loss: 0.0271, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 70, Loss: 0.2246, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 80, Loss: 0.2723, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 90, Loss: 0.0194, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 100, Loss: 0.4435, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 110, Loss: 0.5390, LR: 5.36e-05, Scale: 0.200
  Epoch 97, Batch 120, Loss: 0.1212, LR: 5.36e-05, Scale: 0.200
‚úÖ Epoch 97 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1680
   È™åËØÅÊçüÂ§±: 0.2109
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 98/200 ===
  Epoch 98, Batch 0, Loss: 0.3219, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 10, Loss: 0.1593, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 20, Loss: 0.0580, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 30, Loss: 0.2609, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 40, Loss: 0.1643, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 50, Loss: 0.2008, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 60, Loss: 0.0207, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 70, Loss: 0.4420, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 80, Loss: 0.3908, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 90, Loss: 0.1688, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 100, Loss: 0.0531, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 110, Loss: 0.1073, LR: 5.28e-05, Scale: 0.200
  Epoch 98, Batch 120, Loss: 0.4989, LR: 5.28e-05, Scale: 0.200
‚úÖ Epoch 98 ÂÆåÊàê
   ËÆ≠ÁªÉÊçüÂ§±: 0.1750
   È™åËØÅÊçüÂ§±: 0.2459
   Êù°‰ª∂Áº©Êîæ: 0.200

=== Epoch 99/200 ===
