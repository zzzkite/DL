#!/usr/bin/env python3
"""
æ¨¡å‹å®‰è£…éªŒè¯è„šæœ¬
æ£€æŸ¥ControlNetå’ŒStable Diffusionæ¨¡å‹å®Œæ•´æ€§
"""

import os
import sys
import torch
import yaml
from pathlib import Path
import json
import hashlib

class ModelVerifier:
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.setup_paths()
        
    def setup_paths(self):
        """è®¾ç½®æ¨¡å‹è·¯å¾„"""
        self.paths = {
            # ControlNet è·¯å¾„
            'controlnet_root': self.project_root / "ControlNet",
            'controlnet_models': self.project_root / "ControlNet/models",
            'controlnet_annotator': self.project_root / "ControlNet/annotator/ckpts",
            
            # Stable Diffusion è·¯å¾„
            'sd_root': self.project_root / "stable-diffusion-v1-5",
            'sd_components': {
                'safety_checker': self.project_root / "stable-diffusion-v1-5/safety_checker",
                'text_encoder': self.project_root / "stable-diffusion-v1-5/text_encoder", 
                'unet': self.project_root / "stable-diffusion-v1-5/unet",
                'vae': self.project_root / "stable-diffusion-v1-5/vae"
            }
        }
        
    def check_directory_structure(self):
        """æ£€æŸ¥ç›®å½•ç»“æ„"""
        print("ğŸ“ æ£€æŸ¥ç›®å½•ç»“æ„...")
        
        issues = []
        
        # æ£€æŸ¥ControlNetç›®å½•
        if not self.paths['controlnet_root'].exists():
            issues.append("âŒ ControlNetæ ¹ç›®å½•ä¸å­˜åœ¨")
        else:
            print("âœ… ControlNetæ ¹ç›®å½•å­˜åœ¨")
            
        # æ£€æŸ¥ControlNetæ¨¡å‹ç›®å½•
        if not self.paths['controlnet_models'].exists():
            issues.append("âŒ ControlNetæ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
        else:
            print("âœ… ControlNetæ¨¡å‹ç›®å½•å­˜åœ¨")
            
        # æ£€æŸ¥Stable Diffusionç›®å½•
        if not self.paths['sd_root'].exists():
            issues.append("âŒ Stable Diffusionæ ¹ç›®å½•ä¸å­˜åœ¨")
        else:
            print("âœ… Stable Diffusionæ ¹ç›®å½•å­˜åœ¨")
            
        # æ£€æŸ¥SDç»„ä»¶ç›®å½•
        for name, path in self.paths['sd_components'].items():
            if not path.exists():
                issues.append(f"âŒ Stable Diffusion {name} ç›®å½•ä¸å­˜åœ¨")
            else:
                print(f"âœ… Stable Diffusion {name} ç›®å½•å­˜åœ¨")
                
        return len(issues) == 0, issues
    
    def check_controlnet_files(self):
        """æ£€æŸ¥ControlNetæ¨¡å‹æ–‡ä»¶"""
        print("\nğŸ” æ£€æŸ¥ControlNetæ¨¡å‹æ–‡ä»¶...")
        
        required_files = [
            "control_sd15_canny.pth",
            "control_sd15_depth.pth", 
            "control_sd15_hed.pth",
            "control_sd15_mlsd.pth",
            "control_sd15_normal.pth",
            "control_sd15_openpose.pth",
            "control_sd15_scribble.pth", 
            "control_sd15_seg.pth"
        ]
        
        config_files = ["cldm_v15.yaml"]
        
        found_files = []
        missing_files = []
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        for file in required_files:
            file_path = self.paths['controlnet_models'] / file
            if file_path.exists():
                size = file_path.stat().st_size / (1024**2)  # MB
                print(f"âœ… {file}: {size:.1f} MB")
                found_files.append(file)
            else:
                print(f"âŒ {file}: ç¼ºå¤±")
                missing_files.append(file)
                
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        for file in config_files:
            file_path = self.paths['controlnet_models'] / file
            if file_path.exists():
                print(f"âœ… {file}: å­˜åœ¨")
                found_files.append(file)
            else:
                print(f"âŒ {file}: ç¼ºå¤±")
                missing_files.append(file)
                
        return len(missing_files) == 0, found_files, missing_files
    
    def check_sd_files(self):
        """æ£€æŸ¥Stable Diffusionæ–‡ä»¶"""
        print("\nğŸ” æ£€æŸ¥Stable Diffusionæ–‡ä»¶...")
        
        required_files = {
            'safety_checker': ['config.json', 'model.safetensors'],
            'text_encoder': ['config.json', 'model.safetensors'],
            'unet': ['config.json', 'diffusion_pytorch_model.safetensors'],
            'vae': ['config.json', 'diffusion_pytorch_model.safetensors']
        }
        
        found_files = []
        missing_files = []
        
        for component, files in required_files.items():
            component_path = self.paths['sd_components'][component]
            
            if not component_path.exists():
                for file in files:
                    missing_files.append(f"{component}/{file}")
                continue
                    
            for file in files:
                file_path = component_path / file
                if file_path.exists():
                    size = file_path.stat().st_size / (1024**2)  # MB
                    print(f"âœ… {component}/{file}: {size:.1f} MB")
                    found_files.append(f"{component}/{file}")
                else:
                    print(f"âŒ {component}/{file}: ç¼ºå¤±")
                    missing_files.append(f"{component}/{file}")
                    
        return len(missing_files) == 0, found_files, missing_files
    
    def check_annotator_files(self):
        """æ£€æŸ¥æ³¨é‡Šå™¨æ–‡ä»¶"""
        print("\nğŸ” æ£€æŸ¥æ³¨é‡Šå™¨æ–‡ä»¶...")
        
        required_files = [
            "body_pose_model.pth",
            "dpt_hybrid-midas-501f0c75.pt", 
            "hand_pose_model.pth",
            "mlsd_large_512_fp32.pth",
            "network-bsds500.pth",
            "upernet_global_small.pth"
        ]
        
        found_files = []
        missing_files = []
        
        for file in required_files:
            file_path = self.paths['controlnet_annotator'] / file
            if file_path.exists():
                size = file_path.stat().st_size / (1024**2)  # MB
                print(f"âœ… {file}: {size:.1f} MB")
                found_files.append(file)
            else:
                print(f"âš ï¸  {file}: ç¼ºå¤± (å¯é€‰)")
                # æ³¨é‡Šå™¨æ–‡ä»¶æ˜¯å¯é€‰çš„ï¼Œæ‰€ä»¥ä¸æ ‡è®°ä¸ºä¸¥é‡é”™è¯¯
                
        return len(found_files) > 0, found_files, missing_files
    
    def test_model_loading(self):
        """æµ‹è¯•æ¨¡å‹åŠ è½½èƒ½åŠ›"""
        print("\nğŸš€ æµ‹è¯•æ¨¡å‹åŠ è½½...")
        
        try:
            # æµ‹è¯•PyTorchåŸºç¡€åŠŸèƒ½
            print("æµ‹è¯•PyTorch...")
            print(f"  PyTorchç‰ˆæœ¬: {torch.__version__}")
            print(f"  CUDAå¯ç”¨: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"  GPU: {torch.cuda.get_device_name(0)}")
                print(f"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            
            # æµ‹è¯•æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
            print("\næµ‹è¯•æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§...")
            
            # æµ‹è¯•ControlNetæ¨¡å‹æ–‡ä»¶
            canny_path = self.paths['controlnet_models'] / "control_sd15_canny.pth"
            if canny_path.exists():
                try:
                    state_dict = torch.load(canny_path, map_location='cpu')
                    print(f"âœ… ControlNetæ¨¡å‹å¯åŠ è½½ï¼Œå‚æ•°æ•°é‡: {len(state_dict)}")
                except Exception as e:
                    print(f"âŒ ControlNetæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                    return False
            
            # æµ‹è¯•Stable Diffusionç»„ä»¶
            try:
                from transformers import CLIPTextModel, CLIPTokenizer
                from diffusers import AutoencoderKL, UNet2DConditionModel
                
                # æµ‹è¯•æ–‡æœ¬ç¼–ç å™¨
                text_encoder = CLIPTextModel.from_pretrained(
                    self.paths['sd_components']['text_encoder']
                )
                print("âœ… æ–‡æœ¬ç¼–ç å™¨åŠ è½½æˆåŠŸ")
                
                # æµ‹è¯•VAE
                vae = AutoencoderKL.from_pretrained(
                    self.paths['sd_components']['vae'] 
                )
                print("âœ… VAEåŠ è½½æˆåŠŸ")
                
                # æµ‹è¯•UNet
                unet = UNet2DConditionModel.from_pretrained(
                    self.paths['sd_components']['unet']
                )
                print("âœ… UNetåŠ è½½æˆåŠŸ")
                
            except Exception as e:
                print(f"âŒ Stable Diffusionç»„ä»¶åŠ è½½å¤±è´¥: {e}")
                return False
                
            print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½æµ‹è¯•é€šè¿‡!")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def check_dependencies(self):
        """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
        print("\nğŸ“¦ æ£€æŸ¥ä¾èµ–...")
        
        dependencies = [
            'torch', 'torchvision', 'numpy', 'PIL', 'opencv-python',
            'transformers', 'diffusers', 'accelerate', 'safetensors',
            'omegaconf', 'einops', 'xformers'
        ]
        
        missing_deps = []
        for dep in dependencies:
            try:
                if dep == 'PIL':
                    import PIL
                    version = PIL.__version__
                elif dep == 'opencv-python':
                    import cv2
                    version = cv2.__version__
                else:
                    module = __import__(dep)
                    version = getattr(module, '__version__', 'æœªçŸ¥')
                print(f"âœ… {dep}: {version}")
            except ImportError:
                print(f"âŒ {dep}: æœªå®‰è£…")
                missing_deps.append(dep)
                
        if missing_deps:
            print(f"\nâš ï¸  ç¼ºå°‘ä¾èµ–ï¼Œå®‰è£…å‘½ä»¤:")
            print(f"pip install {' '.join(missing_deps)}")
            return False
        return True
    
    def create_project_structure(self):
        """åˆ›å»ºæ ‡å‡†é¡¹ç›®ç»“æ„"""
        print("\nğŸ“ åˆ›å»ºæ ‡å‡†é¡¹ç›®ç»“æ„...")
        
        directories = [
            "checkpoints",
            "results/training_results",
            "results/generated_frames", 
            "results/evaluation",
            "logs",
            "configs",
            "scripts",
            "data/raw",
            "data/processed"
        ]
        
        for dir_path in directories:
            full_path = self.project_root / dir_path
            full_path.mkdir(parents=True, exist_ok=True)
            print(f"  åˆ›å»º: {dir_path}")
            
        # åˆ›å»ºç¬¦å·é“¾æ¥åˆ°æ ‡å‡†ä½ç½®
        self.create_symbolic_links()
        
        print("âœ… é¡¹ç›®ç»“æ„åˆ›å»ºå®Œæˆ")
    
    def create_symbolic_links(self):
        """åˆ›å»ºç¬¦å·é“¾æ¥"""
        try:
            # é“¾æ¥ControlNetæ¨¡å‹åˆ°æ ‡å‡†ä½ç½®
            models_target = self.project_root / "models"
            models_target.mkdir(exist_ok=True)
            
            controlnet_link = models_target / "controlnet"
            if not controlnet_link.exists():
                os.symlink(self.paths['controlnet_models'], controlnet_link)
                print(f"ğŸ”— åˆ›å»ºç¬¦å·é“¾æ¥: models/controlnet -> ControlNet/models")
                
            # é“¾æ¥Stable Diffusionåˆ°æ ‡å‡†ä½ç½®  
            sd_link = models_target / "stable-diffusion"
            if not sd_link.exists():
                os.symlink(self.paths['sd_root'], sd_link)
                print(f"ğŸ”— åˆ›å»ºç¬¦å·é“¾æ¥: models/stable-diffusion -> stable-diffusion-v1-5")
                
        except Exception as e:
            print(f"âš ï¸  åˆ›å»ºç¬¦å·é“¾æ¥å¤±è´¥: {e}")
            print("  å°†ä½¿ç”¨åŸå§‹è·¯å¾„")
    
    def save_verification_report(self, results):
        """ä¿å­˜éªŒè¯æŠ¥å‘Š"""
        report = {
            "verification_date": str(torch.datetime.now()) if hasattr(torch, 'datetime') else "unknown",
            "system_info": {
                "pytorch_version": torch.__version__,
                "cuda_available": torch.cuda.is_available(),
                "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "None"
            },
            "results": results
        }
        
        report_path = self.project_root / "model_verification_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
            
        print(f"ğŸ“Š éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    def run_full_verification(self):
        """è¿è¡Œå®Œæ•´éªŒè¯"""
        print("=" * 60)
        print("ğŸ” å¼€å§‹æ¨¡å‹å®Œæ•´æ€§éªŒè¯")
        print("=" * 60)
        
        results = {
            'directory_structure': False,
            'controlnet_files': False, 
            'sd_files': False,
            'annotator_files': False,
            'dependencies': False,
            'model_loading': False
        }
        
        issues = []
        
        # 1. æ£€æŸ¥ç›®å½•ç»“æ„
        results['directory_structure'], dir_issues = self.check_directory_structure()
        issues.extend(dir_issues)
        
        # 2. æ£€æŸ¥ControlNetæ–‡ä»¶
        results['controlnet_files'], found_ctrl, missing_ctrl = self.check_controlnet_files()
        if not results['controlnet_files']:
            issues.append(f"ControlNetæ–‡ä»¶ç¼ºå¤±: {missing_ctrl}")
        
        # 3. æ£€æŸ¥Stable Diffusionæ–‡ä»¶  
        results['sd_files'], found_sd, missing_sd = self.check_sd_files()
        if not results['sd_files']:
            issues.append(f"Stable Diffusionæ–‡ä»¶ç¼ºå¤±: {missing_sd}")
            
        # 4. æ£€æŸ¥æ³¨é‡Šå™¨æ–‡ä»¶
        results['annotator_files'], found_ann, missing_ann = self.check_annotator_files()
        
        # 5. æ£€æŸ¥ä¾èµ–
        results['dependencies'] = self.check_dependencies()
        if not results['dependencies']:
            issues.append("ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…")
            
        # 6. æµ‹è¯•æ¨¡å‹åŠ è½½ï¼ˆåªåœ¨å…¶ä»–æ£€æŸ¥é€šè¿‡æ—¶è¿›è¡Œï¼‰
        if all([results['directory_structure'], results['controlnet_files'], results['sd_files']]):
            results['model_loading'] = self.test_model_loading()
            if not results['model_loading']:
                issues.append("æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥")
        else:
            print("\nâš ï¸  è·³è¿‡æ¨¡å‹åŠ è½½æµ‹è¯•ï¼ˆåŸºç¡€æ£€æŸ¥æœªé€šè¿‡ï¼‰")
            results['model_loading'] = False
            
        # åˆ›å»ºé¡¹ç›®ç»“æ„
        self.create_project_structure()
        
        # ä¿å­˜æŠ¥å‘Š
        self.save_verification_report(results)
        
        # è¾“å‡ºæ€»ç»“
        print("\n" + "=" * 60)
        print("éªŒè¯æ€»ç»“")
        print("=" * 60)
        
        success_count = sum(results.values())
        total_count = len(results)
        
        if success_count == total_count:
            print("ğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼é¡¹ç›®å‡†å¤‡å°±ç»ªã€‚")
            return True, issues
        else:
            print(f"âš ï¸  {success_count}/{total_count} é¡¹éªŒè¯é€šè¿‡")
            if issues:
                print("\néœ€è¦è§£å†³çš„é—®é¢˜:")
                for issue in issues:
                    print(f"  - {issue}")
            return False, issues

def main():
    """ä¸»å‡½æ•°"""
    verifier = ModelVerifier()
    success, issues = verifier.run_full_verification()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ ä¸‹ä¸€æ­¥è¡ŒåŠ¨æŒ‡å—")
        print("=" * 60)
        print("1. ğŸ“Š éªŒè¯æ•°æ®åŠ è½½å™¨:")
        print("   python -c \"from dataloader import test_data_loader; test_data_loader()\"")
        print("")
        print("2. ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ:")
        print("   python scripts/train_frame_prediction.py")
        print("")
        print("3. ğŸ“ˆ ç›‘æ§è®­ç»ƒè¿›åº¦:")
        print("   tail -f logs/training.log")
        print("")
        print("4. ğŸ§ª è®­ç»ƒå®Œæˆåè¿›è¡Œæ¨ç†æµ‹è¯•:")
        print("   python scripts/inference.py")
        print("")
        print("5. ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½:")
        print("   python scripts/evaluate.py")
        print("")
        print("ğŸ’¡ æç¤º: ä½ çš„æ•°æ®åŠ è½½å™¨å·²ç»å‡†å¤‡å¥½ï¼Œå¯ä»¥ç›´æ¥å¼€å§‹è®­ç»ƒ!")
    else:
        print("âŒ éªŒè¯å¤±è´¥")
        print("=" * 60)
        print("è¯·å…ˆè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œç„¶åé‡æ–°è¿è¡ŒéªŒè¯è„šæœ¬ã€‚")
        sys.exit(1)

if __name__ == "__main__":
    main()