#!/usr/bin/env python3
"""
ControlNet 1.1 256x256è®­ç»ƒè„šæœ¬ - ä¿®å¤ç‰ˆæœ¬
ä¿®å¤å°ºå¯¸ä¸åŒ¹é…é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset, ConcatDataset
import torch.optim as optim
import cv2
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import sys
import os
import gc
import time
import math  # æ·»åŠ mathå¯¼å…¥
from typing import Dict, List, Optional, Tuple
from PIL import Image

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

try:
    from diffusers import DDPMScheduler, AutoencoderKL, UNet2DConditionModel, StableDiffusionControlNetPipeline, ControlNetModel
    from transformers import CLIPTokenizer, CLIPTextModel
    from loaderData256 import create_task_specific_loaders  # ä¿®æ”¹ä¸º256æ•°æ®åŠ è½½å™¨
    
    try:
        from cldm.model import create_model, load_state_dict
        CONTROLNET_AVAILABLE = True
        print("âœ… æˆåŠŸå¯¼å…¥ControlNetæ¨¡å—")
    except ImportError as e:
        print(f"âš ï¸  æ— æ³•å¯¼å…¥cldm: {e}")
        CONTROLNET_AVAILABLE = False
        
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

class ControlNet256Trainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.task_name = config.get('task_name', 'unknown_task')
        
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ¯ ä»»åŠ¡: {self.task_name}")
        print(f"ğŸ“ åˆ†è¾¨ç‡: 256x256")
        
        # è®­ç»ƒçŠ¶æ€
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        self.max_patience = config.get('patience', 12)
        
        # æ¢¯åº¦ç¼©æ”¾å™¨
        self.scaler = torch.amp.GradScaler('cuda')
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.setup_models()
        self.setup_optimizers()
        
    def setup_models(self):
        """æ¨¡å‹åˆå§‹åŒ–"""
        print("ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...")
        
        # 1. åŠ è½½ç»„ä»¶
        self.tokenizer = CLIPTokenizer.from_pretrained("stable-diffusion-v1-5/tokenizer", local_files_only=True)
        self.text_encoder = CLIPTextModel.from_pretrained("stable-diffusion-v1-5/text_encoder", local_files_only=True).to(self.device)
        self.vae = AutoencoderKL.from_pretrained("stable-diffusion-v1-5/vae", local_files_only=True).to(self.device)
        self.unet = UNet2DConditionModel.from_pretrained("stable-diffusion-v1-5/unet", local_files_only=True).to(self.device)
        self.noise_scheduler = DDPMScheduler.from_pretrained("stable-diffusion-v1-5/scheduler", local_files_only=True)
        
        # 2. åŠ è½½ ControlNet
        self.controlnet = self.load_controlnet().to(self.device)
        
        # 3. å†»ç»“å‚æ•°
        self.text_encoder.requires_grad_(False)
        self.vae.requires_grad_(False)
        self.unet.requires_grad_(False)
        self.controlnet.requires_grad_(True)
        
        # æ‰“å°å‚æ•°é‡
        trainable_params = sum(p.numel() for p in self.controlnet.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in self.controlnet.parameters())
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå¯è®­ç»ƒå‚æ•°: {trainable_params:,} / æ€»å‚æ•°: {total_params:,}")
        
        # æ£€æŸ¥VAEè¾“å…¥å°ºå¯¸å…¼å®¹æ€§
        vae_sample_size = self.vae.config.sample_size
        print(f"ğŸ” VAEæ ·æœ¬å°ºå¯¸: {vae_sample_size}")
        if vae_sample_size != 256 and vae_sample_size != 512:
            print(f"âš ï¸  VAEé¢„æœŸè¾“å…¥å°ºå¯¸ä¸º{vae_sample_size}x{vae_sample_size}ï¼Œæ•°æ®ä¸º256x256")

    def load_controlnet(self):
        """åŠ è½½ControlNetæ¨¡å‹"""
        try:
            if CONTROLNET_AVAILABLE:
                controlnet_dir = Path("ControlNet-v1-1")
                model_path = controlnet_dir / "control_sd15_canny.pth"
                config_path = controlnet_dir / "cldm_v15.yaml"
                
                if model_path.exists():
                    print(f"ğŸ“‚ åŠ è½½é¢„è®­ç»ƒæƒé‡: {model_path}")
                    model = create_model(str(config_path)).to(self.device)
                    model.load_state_dict(load_state_dict(str(model_path), location='cpu'))
                    return model.control_model
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œå°†å°è¯•ä»UNetåˆå§‹åŒ–")
            
            # å¤‡é€‰æ–¹æ¡ˆï¼šä» UNet åˆå§‹åŒ–
            from diffusers import ControlNetModel
            print("ğŸ†• ä» UNet å¤åˆ¶æƒé‡åˆå§‹åŒ– ControlNet")
            controlnet = ControlNetModel.from_unet(self.unet, conditioning_channels=3)
            return controlnet
                
        except Exception as e:
            print(f"âŒ åŠ è½½ControlNetå¤±è´¥: {e}")
            raise

    def setup_optimizers(self):
        """ä¼˜åŒ–å™¨é…ç½® - ç«‹å³æ”¹è¿›ï¼šæ·»åŠ warmup + æ›´å¤§å­¦ä¹ ç‡"""
        # ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡å’Œæ›´å°çš„æƒé‡è¡°å‡
        base_lr = self.config.get('learning_rate', 5e-5)  # æé«˜å­¦ä¹ ç‡
        
        no_decay = ["bias", "LayerNorm.weight"]
        optimizer_grouped_parameters = [
            {
                "params": [p for n, p in self.controlnet.named_parameters() 
                          if not any(nd in n for nd in no_decay) and p.requires_grad],
                "weight_decay": self.config.get('weight_decay', 1e-4),  # å‡å°æƒé‡è¡°å‡
                "lr": base_lr,
            },
            {
                "params": [p for n, p in self.controlnet.named_parameters() 
                          if any(nd in n for nd in no_decay) and p.requires_grad],
                "weight_decay": 0.0,
                "lr": base_lr,
            },
        ]
        
        self.optimizer = optim.AdamW(
            optimizer_grouped_parameters,
            lr=base_lr,
            betas=(0.9, 0.999),
            weight_decay=1e-4,  # ç»Ÿä¸€çš„æƒé‡è¡°å‡
            eps=1e-8
        )
        
        # ä½¿ç”¨å¸¦warmupçš„ä½™å¼¦é€€ç«è°ƒåº¦å™¨
        self.lr_scheduler = self.get_cosine_schedule_with_warmup(
            self.optimizer,
            num_warmup_steps=self.config.get('warmup_steps', 500),
            num_training_steps=self.config.get('num_epochs', 40) * 100,  # ä¼°è®¡çš„æ­¥æ•°
            num_cycles=0.5
        )

    def get_cosine_schedule_with_warmup(self, optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5):
        """åˆ›å»ºå¸¦warmupçš„ä½™å¼¦é€€ç«è°ƒåº¦å™¨"""
        def lr_lambda(current_step):
            if current_step < num_warmup_steps:
                return float(current_step) / float(max(1, num_warmup_steps))
            progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
            return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))
        
        return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)

    def prepare_images_for_vae(self, images):
        """å‡†å¤‡å›¾åƒä»¥é€‚åº”VAEè¾“å…¥ - ä¿®å¤å°ºå¯¸é—®é¢˜"""
        # ç¡®ä¿å›¾åƒåœ¨[-1, 1]èŒƒå›´å†…
        if torch.max(images) <= 1.0 and torch.min(images) >= 0.0:
            images = images * 2.0 - 1.0
        
        # å¦‚æœVAEéœ€è¦ç‰¹å®šå°ºå¯¸ï¼Œè¿›è¡Œè°ƒæ•´
        vae_sample_size = self.vae.config.sample_size
        current_size = images.shape[-1]
        
        if current_size != vae_sample_size:
            # åªåœ¨å¿…è¦æ—¶æ‰“å°è°ƒæ•´ä¿¡æ¯
            if hasattr(self, '_vae_resize_warning_printed'):
                pass
            else:
                print(f"ğŸ”§ è°ƒæ•´å›¾åƒå°ºå¯¸ä» {current_size}x{current_size} åˆ° {vae_sample_size}x{vae_sample_size}")
                self._vae_resize_warning_printed = True
            images = F.interpolate(images, size=(vae_sample_size, vae_sample_size), 
                                 mode='bilinear', align_corners=False)
        
        return images

    def prepare_controlnet_condition(self, control_cond):
        """å‡†å¤‡ControlNetæ¡ä»¶è¾“å…¥ - ä¿®å¤å°ºå¯¸é—®é¢˜"""
        # ç¡®ä¿æ§åˆ¶æ¡ä»¶ä¸æ½œåœ¨ç©ºé—´å°ºå¯¸åŒ¹é…
        vae_sample_size = self.vae.config.sample_size
        current_size = control_cond.shape[-1]
        
        # ControlNetæœŸæœ›è¾“å…¥å°ºå¯¸ä¸VAEæ½œåœ¨ç©ºé—´ä¸‹é‡‡æ ·åçš„å°ºå¯¸ç›¸å…³
        # å¯¹äº512x512è¾“å…¥ï¼Œæ½œåœ¨ç©ºé—´æ˜¯64x64ï¼Œæ‰€ä»¥ControlNetæ¡ä»¶åº”è¯¥è°ƒæ•´ä¸º512x512
        if current_size != vae_sample_size:
            control_cond = F.interpolate(control_cond, size=(vae_sample_size, vae_sample_size), 
                                       mode='bilinear', align_corners=False)
        
        return control_cond

    def get_canny_edges(self, image_tensor, training=False):
        """
        Cannyè¾¹ç¼˜æ£€æµ‹ - ç«‹å³æ”¹è¿›ï¼šæ›´å¥½çš„å‚æ•°å’Œæ•°æ®å¢å¼º
        """
        batch_size = image_tensor.shape[0]
        
        # ç¡®ä¿è¾“å…¥åœ¨ [0, 1] èŒƒå›´å†…
        if torch.max(image_tensor) > 1.0:
            image_tensor = (image_tensor + 1.0) / 2.0
        
        # è®­ç»ƒæ—¶æ·»åŠ æ•°æ®å¢å¼º
        if training:
            # éšæœºè°ƒæ•´äº®åº¦å’Œå¯¹æ¯”åº¦ - ä¿®å¤ï¼šç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            brightness = 0.1 * torch.randn(batch_size, 1, 1, 1, device=image_tensor.device)
            contrast = 1.0 + 0.2 * torch.randn(batch_size, 1, 1, 1, device=image_tensor.device)
            image_tensor = image_tensor * contrast + brightness
            image_tensor = torch.clamp(image_tensor, 0, 1)
        
        images_np = image_tensor.permute(0, 2, 3, 1).cpu().numpy()
        images_np = (images_np * 255).astype(np.uint8)
        
        edges_list = []
        for i in range(batch_size):
            img_gray = cv2.cvtColor(images_np[i], cv2.COLOR_RGB2GRAY)
            
            # ç«‹å³æ”¹è¿›ï¼šæ›´å®½çš„é˜ˆå€¼èŒƒå›´ï¼Œæ›´å¥½çš„è¾¹ç¼˜æ£€æµ‹
            v = np.median(img_gray)
            sigma = 0.33
            # ä½¿ç”¨æ›´å®½çš„é˜ˆå€¼èŒƒå›´ï¼Œç¡®ä¿æ•æ‰åˆ°è¶³å¤Ÿå¤šçš„è¾¹ç¼˜
            lower = int(max(0, (1.0 - 2 * sigma) * v))  # æ›´ä½çš„é˜ˆå€¼
            upper = int(min(255, (1.0 + 2 * sigma) * v))  # æ›´é«˜çš„é˜ˆå€¼
            
            edge = cv2.Canny(img_gray, lower, upper)
            
            # ç«‹å³æ”¹è¿›ï¼šæ›´å¥½çš„å½¢æ€å­¦æ“ä½œï¼Œæ”¹å–„è¾¹ç¼˜è¿ç»­æ€§
            kernel = np.ones((2, 2), np.uint8)  # ç¨å¤§çš„æ ¸
            edge = cv2.morphologyEx(edge, cv2.MORPH_CLOSE, kernel)
            
            # æ‰©å±•å›3é€šé“
            edge = np.stack([edge] * 3, axis=-1)
            edges_list.append(edge)
            
        edges_np = np.stack(edges_list)
        edges_tensor = torch.from_numpy(edges_np).float() / 255.0
        edges_tensor = edges_tensor.permute(0, 3, 1, 2).to(self.device)
        
        # ç¡®ä¿æ§åˆ¶æ¡ä»¶å°ºå¯¸æ­£ç¡®
        edges_tensor = self.prepare_controlnet_condition(edges_tensor)
        
        return edges_tensor

    def compute_loss(self, batch, training=True):
        """ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° - ä¿®å¤å°ºå¯¸é—®é¢˜"""
        try:
            # 1. å‡†å¤‡æ•°æ®
            current_frame_20 = batch['input_frames'][:, -1].to(self.device) 
            target_frame_25 = batch['target_frame'].to(self.device)
            text_descriptions = batch.get('label_text', ['interaction'] * len(current_frame_20))
            
            # 2. VAEç¼–ç ç›®æ ‡å›¾ - é€‚é…å°ºå¯¸
            target_frame_prepared = self.prepare_images_for_vae(target_frame_25)
            target_latents = self.vae.encode(target_frame_prepared).latent_dist.sample()
            target_latents = target_latents * self.vae.config.scaling_factor
            
            # 3. CLIPç¼–ç æ–‡æœ¬
            inputs = self.tokenizer(
                text_descriptions, 
                max_length=77, 
                padding="max_length", 
                truncation=True, 
                return_tensors="pt"
            ).to(self.device)
            encoder_hidden_states = self.text_encoder(inputs.input_ids)[0]
            
            # 4. å‡†å¤‡ControlNetæ¡ä»¶ - ç¡®ä¿å°ºå¯¸æ­£ç¡®
            control_cond = self.get_canny_edges(current_frame_20, training=training)
            
            # 5. é‡‡æ ·timestepå’Œå™ªå£° - ä½¿ç”¨å›ºå®šçš„å…¨èŒƒå›´
            timesteps = torch.randint(
                0, 
                self.noise_scheduler.config.num_train_timesteps, 
                (target_latents.shape[0],), 
                device=self.device
            ).long()
            
            noise = torch.randn_like(target_latents)
            noisy_latents = self.noise_scheduler.add_noise(target_latents, noise, timesteps)
            
            # 6. ControlNetå‰å‘
            down_block_res_samples, mid_block_res_sample = self.controlnet(
                noisy_latents,
                timesteps,
                encoder_hidden_states=encoder_hidden_states,
                controlnet_cond=control_cond,
                return_dict=False,
            )
            
            # 7. UNeté¢„æµ‹
            noise_pred = self.unet(
                noisy_latents,
                timesteps,
                encoder_hidden_states=encoder_hidden_states,
                down_block_additional_residuals=down_block_res_samples,
                mid_block_additional_residual=mid_block_res_sample,
            ).sample
            
            # 8. è®¡ç®—æŸå¤±
            loss = F.mse_loss(noise_pred, noise)
            
            return loss
            
        except Exception as e:
            print(f"âŒ æŸå¤±è®¡ç®—å‡ºé”™: {e}")
            # è¿”å›ä¸€ä¸ªè™šæ‹ŸæŸå¤±ï¼Œé¿å…è®­ç»ƒä¸­æ–­
            return torch.tensor(0.0, requires_grad=True, device=self.device)

    def train_epoch(self, train_loader, epoch):
        """è®­ç»ƒepoch - ä¿®å¤é”™è¯¯å¤„ç†"""
        self.controlnet.train()
        total_loss = 0
        num_batches = 0
        
        accumulation_steps = self.config.get('accumulation_steps', 2)
        
        print(f"ğŸ“š å¼€å§‹ç¬¬ {epoch} è½®è®­ç»ƒï¼Œå…±æœ‰ {len(train_loader)} ä¸ªæ‰¹æ¬¡")
        
        # è·Ÿè¸ªæ‰¹æ¬¡æŸå¤±ç”¨äºåŠ¨æ€è°ƒæ•´
        batch_losses = []
        
        for batch_idx, batch in enumerate(train_loader):
            if batch is None: 
                continue
                
            # é‡ç½®æ¢¯åº¦
            self.optimizer.zero_grad()
            
            try:
                # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦
                with torch.amp.autocast('cuda'):
                    loss = self.compute_loss(batch, training=True)
                
                # å¦‚æœæŸå¤±æ˜¯NaNï¼Œè·³è¿‡è¿™ä¸ªbatch
                if torch.isnan(loss) or torch.isinf(loss):
                    print(f"âš ï¸  æ‰¹æ¬¡ {batch_idx} æŸå¤±ä¸ºNaNæˆ–Infï¼Œè·³è¿‡")
                    continue
                
                # æ¢¯åº¦ç´¯ç§¯
                loss = loss / accumulation_steps
                
                # åå‘ä¼ æ’­
                self.scaler.scale(loss).backward()
                
                if (batch_idx + 1) % accumulation_steps == 0:
                    # æ¢¯åº¦è£å‰ª
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.controlnet.parameters(), max_norm=1.0)
                    
                    # ä¼˜åŒ–å™¨æ­¥è¿›
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()
                    
                    # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                    if hasattr(self, 'lr_scheduler'):
                        self.lr_scheduler.step()
                
                # è®°å½•æŸå¤±
                loss_value = loss.item() * accumulation_steps
                total_loss += loss_value
                num_batches += 1
                batch_losses.append(loss_value)
                
                # ç«‹å³æ”¹è¿›ï¼šæ›´é¢‘ç¹çš„æ—¥å¿—è¾“å‡ºï¼ˆæ¯5ä¸ªbatchï¼‰
                if batch_idx % 5 == 0:  # ä»10æ”¹ä¸º5ï¼Œæ›´é¢‘ç¹çš„ç›‘æ§
                    current_lr = self.optimizer.param_groups[0]['lr']
                    current_step = (epoch - 1) * len(train_loader) + batch_idx
                    
                    # è®¡ç®—æœ€è¿‘å‡ ä¸ªbatchçš„å¹³å‡æŸå¤±
                    recent_avg = np.mean(batch_losses[-10:]) if len(batch_losses) >= 10 else loss_value
                    
                    print(f"Epoch {epoch} | Batch {batch_idx:3d}/{len(train_loader)} | "
                          f"Loss: {loss_value:.6f} | Recent: {recent_avg:.6f} | "
                          f"LR: {current_lr:.2e} | Step: {current_step}")
                
                # å®šæœŸæ¸…ç†æ˜¾å­˜
                if batch_idx % 20 == 0 and self.device.type == 'cuda':
                    torch.cuda.empty_cache()
                    if batch_idx % 40 == 0:
                        self._log_gpu_memory(f"Epoch{epoch} Batch{batch_idx}")
                    
            except Exception as e:
                print(f"âŒ è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                continue
        
        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')
        print(f"âœ… ç¬¬ {epoch} è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
        return avg_loss

    def _log_gpu_memory(self, label: str = ""):
        """GPUå†…å­˜ç›‘æ§"""
        if self.device.type != 'cuda':
            return
        try:
            allocated = torch.cuda.memory_allocated() / 1024**3  # GB
            reserved = torch.cuda.memory_reserved() / 1024**3    # GB
            print(f"[GPU MEM] {label} allocated={allocated:.2f}GB reserved={reserved:.2f}GB")
        except Exception:
            pass

    def validate(self, val_loader):
        """éªŒè¯å‡½æ•° - ä¿®å¤é”™è¯¯å¤„ç†"""
        self.controlnet.eval()
        total_loss = 0.0
        num_batches = 0
        
        print(f"ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ {len(val_loader)} ä¸ªæ‰¹æ¬¡")
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                if batch is None:
                    continue
                
                try:
                    with torch.amp.autocast('cuda'):
                        loss = self.compute_loss(batch, training=False)
                    
                    # å¦‚æœæŸå¤±æ˜¯NaNï¼Œè·³è¿‡è¿™ä¸ªbatch
                    if torch.isnan(loss) or torch.isinf(loss):
                        print(f"âš ï¸  éªŒè¯æ‰¹æ¬¡ {batch_idx} æŸå¤±ä¸ºNaNæˆ–Infï¼Œè·³è¿‡")
                        continue
                    
                    loss_value = loss.item()
                    total_loss += loss_value
                    num_batches += 1
                    
                    # æ›´é¢‘ç¹çš„éªŒè¯æ—¥å¿—
                    if batch_idx % 3 == 0:  # ä»5æ”¹ä¸º3ï¼Œæ›´é¢‘ç¹çš„éªŒè¯ç›‘æ§
                        print(f"éªŒè¯æ‰¹æ¬¡ {batch_idx}/{len(val_loader)} | Loss: {loss_value:.6f}")
                        
                except Exception as e:
                    print(f"âŒ éªŒè¯æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    continue
        
        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')
        print(f"âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
        return avg_loss

    def log_validation(self, val_loader, epoch, save_dir):
        """ç”Ÿæˆé¢„è§ˆå›¾ç”¨äºå¯è§†åŒ–è¯„ä¼° - åŸºäºç¬¬20å¸§ç»˜åˆ¶ç¬¬25å¸§"""
        print(f"ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆ Epoch {epoch} çš„é¢„è§ˆå›¾...")
        self.controlnet.eval()
        self.unet.eval()
        
        # ä¸´æ—¶æ„å»ºä¸€ä¸ª pipeline ç”¨äºæ¨ç†
        from diffusers import StableDiffusionControlNetPipeline
        
        pipeline = StableDiffusionControlNetPipeline(
            vae=self.vae,
            text_encoder=self.text_encoder,
            tokenizer=self.tokenizer,
            unet=self.unet,
            controlnet=self.controlnet,
            scheduler=self.noise_scheduler,
            safety_checker=None,
            feature_extractor=None,
            requires_safety_checker=False
        )
        pipeline.set_progress_bar_config(disable=True)
        pipeline = pipeline.to(self.device)

        # åªå–éªŒè¯é›†çš„ç¬¬ä¸€æ‰¹æ•°æ®æ¥åšæ¼”ç¤º
        try:
            batch = next(iter(val_loader))
        except StopIteration:
            print("âš ï¸  éªŒè¯é›†ä¸ºç©ºï¼Œè·³è¿‡é¢„è§ˆå›¾ç”Ÿæˆ")
            return
        
        # å‡†å¤‡æ•°æ® - åŸºäºç¬¬20å¸§ç»˜åˆ¶ç¬¬25å¸§
        # input_frame (Condition): ç¬¬20å¸§
        current_frame_20 = batch['input_frames'][:, -1].to(self.device)
        # target_frame (GT): ç¬¬25å¸§ (ç”¨äºå¯¹æ¯”)
        target_frame_25 = batch['target_frame'].to(self.device)
        prompts = batch.get('label_text', ['interaction'] * len(current_frame_20))
        
        # å‡†å¤‡ Canny æ¡ä»¶å›¾ - åŸºäºç¬¬20å¸§
        control_cond = self.get_canny_edges(current_frame_20, training=False)
        
        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        save_dir = Path(save_dir)
        save_dir.mkdir(exist_ok=True, parents=True)
        
        image_logs = []
        # ç”Ÿæˆå›¾åƒ (åªç”Ÿæˆå‰4å¼ ï¼Œé¿å…å¤ªæ…¢)
        num_images = min(len(current_frame_20), 4)
        
        for i in range(num_images):
            try:
                # 1. æ¨¡å‹ç”Ÿæˆ - åŸºäºç¬¬20å¸§çš„Cannyè¾¹ç¼˜ç”Ÿæˆç¬¬25å¸§
                with torch.autocast("cuda"):
                    generated_image = pipeline(
                        prompt=prompts[i],
                        image=control_cond[i:i+1], # è¾“å…¥æ˜¯ç¬¬20å¸§çš„Cannyå›¾
                        num_inference_steps=20,    # æ¨ç†æ­¥æ•°ï¼Œ20æ­¥å¤Ÿå¿«äº†
                        guidance_scale=7.5,
                        controlnet_conditioning_scale=1.0, # å‡è®¾ç”¨ 1.0 å¼ºåº¦
                        height=256,  # è®¾ç½®é«˜åº¦ä¸º256
                        width=256,   # è®¾ç½®å®½åº¦ä¸º256
                    ).images[0]
                
                # 2. å¤„ç†åŸå›¾ç”¨äºå¯¹æ¯” (Tensor -> PIL)
                # åŸå§‹ç¬¬20å¸§ (ç”¨äºæ˜¾ç¤ºè¾“å…¥)
                input_np = current_frame_20[i].permute(1, 2, 0).cpu().numpy()
                input_img = ((input_np + 1) / 2 * 255).astype(np.uint8)  # å‡è®¾ä¹‹å‰ norm åˆ°äº† [-1, 1]
                input_pil = Image.fromarray(input_img)
                
                # Canny æ¡ä»¶å›¾
                canny_np = control_cond[i].permute(1, 2, 0).cpu().numpy()  # (H, W, 3)
                if canny_np.shape[2] == 1: 
                    canny_np = np.concatenate([canny_np]*3, axis=2)
                canny_img = (canny_np * 255).astype(np.uint8)
                canny_pil = Image.fromarray(canny_img)
                
                # æ¨¡å‹ç”Ÿæˆçš„ç»“æœ
                gen_pil = generated_image
                
                # çœŸå®ç¬¬25å¸§ (GT)
                gt_np = target_frame_25[i].permute(1, 2, 0).cpu().numpy()
                gt_img = ((gt_np + 1) / 2 * 255).astype(np.uint8)  # å‡è®¾ä¹‹å‰ norm åˆ°äº† [-1, 1]
                gt_pil = Image.fromarray(gt_img)
                
                # ç¡®ä¿æ‰€æœ‰å›¾åƒå¤§å°ä¸€è‡´
                target_size = (256, 256)
                input_pil = input_pil.resize(target_size, Image.Resampling.LANCZOS)
                canny_pil = canny_pil.resize(target_size, Image.Resampling.LANCZOS)
                gen_pil = gen_pil.resize(target_size, Image.Resampling.LANCZOS)
                gt_pil = gt_pil.resize(target_size, Image.Resampling.LANCZOS)
                
                # åˆ›å»ºæ ‡ç­¾å›¾åƒ
                def create_label_image(text, height=30, width=256):
                    """åˆ›å»ºæ–‡æœ¬æ ‡ç­¾å›¾åƒ"""
                    from PIL import ImageDraw, ImageFont
                    img = Image.new('RGB', (width, height), color='white')
                    draw = ImageDraw.Draw(img)
                    try:
                        font = ImageFont.truetype("arial.ttf", 14)
                    except:
                        font = ImageFont.load_default()
                    # è®¡ç®—æ–‡æœ¬ä½ç½®
                    text_bbox = draw.textbbox((0, 0), text, font=font)
                    text_width = text_bbox[2] - text_bbox[0]
                    text_height = text_bbox[3] - text_bbox[1]
                    x = (width - text_width) // 2
                    y = (height - text_height) // 2
                    draw.text((x, y), text, fill='black', font=font)
                    return img
                
                # åˆ›å»ºæ ‡ç­¾
                input_label = create_label_image("ç¬¬20å¸§ (è¾“å…¥)", width=256)
                canny_label = create_label_image("Cannyè¾¹ç¼˜", width=256)
                gen_label = create_label_image(f"ç”Ÿæˆç¬¬25å¸§ (E{epoch})", width=256)
                gt_label = create_label_image("çœŸå®ç¬¬25å¸§", width=256)
                
                # æ‹¼æ¥: ç¬¬20å¸§è¾“å…¥ | Cannyæ¡ä»¶ | ç”Ÿæˆç»“æœ | çœŸå®ç»“æœ
                total_height = 256 + 30  # å›¾åƒé«˜åº¦ + æ ‡ç­¾é«˜åº¦
                combined_img = Image.new('RGB', (256 * 4, total_height))
                
                # ç¬¬ä¸€åˆ—ï¼šç¬¬20å¸§è¾“å…¥
                combined_img.paste(input_pil, (0, 0))
                combined_img.paste(input_label, (0, 256))
                
                # ç¬¬äºŒåˆ—ï¼šCannyæ¡ä»¶
                combined_img.paste(canny_pil, (256, 0))
                combined_img.paste(canny_label, (256, 256))
                
                # ç¬¬ä¸‰åˆ—ï¼šç”Ÿæˆç»“æœ
                combined_img.paste(gen_pil, (512, 0))
                combined_img.paste(gen_label, (512, 256))
                
                # ç¬¬å››åˆ—ï¼šçœŸå®ç»“æœ
                combined_img.paste(gt_pil, (768, 0))
                combined_img.paste(gt_label, (768, 256))
                
                # ä¿å­˜
                save_path = save_dir / f"epoch_{epoch}_sample_{i}.jpg"
                combined_img.save(save_path, quality=95)
                print(f"ğŸ’¾ é¢„è§ˆå›¾å·²ä¿å­˜: {save_path}")
                
                image_logs.append(save_path)
                
            except Exception as e:
                print(f"âŒ ç”Ÿæˆç¬¬ {i} å¼ é¢„è§ˆå›¾å¤±è´¥: {e}")
                continue
            
        print(f"âœ¨ é¢„è§ˆå›¾å·²ä¿å­˜åˆ° {save_dir}")
        
        # é‡Šæ”¾æ˜¾å­˜
        del pipeline
        torch.cuda.empty_cache()
        
        return image_logs

    def save_checkpoint(self, epoch, task_name, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(exist_ok=True, parents=True)
        
        if is_best:
            save_path = output_dir / f"controlnet_{task_name}_best.pth"
        else:
            save_path = output_dir / f"controlnet_{task_name}_epoch_{epoch}.pth"
            
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.controlnet.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'lr_scheduler_state_dict': self.lr_scheduler.state_dict() if hasattr(self, 'lr_scheduler') else None,
            'best_val_loss': self.best_val_loss,
            'config': self.config
        }
        
        torch.save(checkpoint, save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}")

    def plot_and_save_losses(self, train_losses, val_losses=None):
        """ç»˜åˆ¶è®­ç»ƒ/éªŒè¯æŸå¤±"""
        try:
            output_dir = Path(self.config['output_dir'])
            output_dir.mkdir(parents=True, exist_ok=True)

            plt.figure(figsize=(10, 6))
            epochs = list(range(1, len(train_losses) + 1))
            
            plt.plot(epochs, train_losses, marker='o', color='tab:blue', label='Train Loss', linewidth=2)
            if val_losses is not None and len(val_losses) == len(train_losses):
                plt.plot(epochs, val_losses, marker='s', color='tab:orange', label='Val Loss', linewidth=2)
                
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title(f'Training / Validation Loss - {self.task_name} (256x256)')
            plt.grid(alpha=0.3)
            plt.legend()
            
            save_path = output_dir / f'training_val_loss_{self.task_name}_256.png'
            plt.savefig(save_path, dpi=200, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“ˆ Loss å›¾å·²ä¿å­˜: {save_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ Loss å›¾å¤±è´¥: {e}")

    def train(self, train_loader, val_loader):
        """è®­ç»ƒå¾ªç¯ - ä¿®å¤é”™è¯¯å¤„ç†"""
        print("ğŸš€ å¼€å§‹256x256è®­ç»ƒ...")
        print(f"ğŸ“ è¾“å…¥åˆ†è¾¨ç‡: 256x256")
        print(f"ğŸ¯ ä»»åŠ¡: {self.task_name}")
        print(f"ğŸ’¡ ä¼˜åŠ¿: ç›¸æ¯”512x512ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå†…å­˜éœ€æ±‚æ›´ä½")
        
        train_losses = []
        val_losses = []
        
        # åˆ›å»ºé¢„è§ˆå›¾ä¿å­˜ç›®å½•
        preview_dir = Path(self.config['output_dir']) / "previews"
        preview_dir.mkdir(exist_ok=True, parents=True)
        
        # åˆå§‹éªŒè¯
        print("\nğŸ” è¿›è¡Œåˆå§‹éªŒè¯...")
        initial_val_loss = self.validate(val_loader)
        print(f"åˆå§‹éªŒè¯æŸå¤±: {initial_val_loss:.6f}")
        
        # åˆå§‹é¢„è§ˆå›¾ï¼ˆepoch 0ï¼‰
        print("\nğŸ–¼ï¸ ç”Ÿæˆåˆå§‹é¢„è§ˆå›¾...")
        self.log_validation(val_loader, 0, preview_dir)
        
        for epoch in range(1, self.config['num_epochs'] + 1):
            epoch_start_time = time.time()
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(train_loader, epoch)
            train_losses.append(train_loss)
            
            # éªŒè¯
            val_loss = self.validate(val_loader)
            val_losses.append(val_loss)
            
            epoch_time = time.time() - epoch_start_time
            current_lr = self.optimizer.param_groups[0]['lr']
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š Epoch {epoch}/{self.config['num_epochs']} å®Œæˆ")
            print(f"   Train Loss: {train_loss:.6f}")
            print(f"   Val Loss: {val_loss:.6f}")
            print(f"   LR: {current_lr:.2e} | Time: {epoch_time:.1f}s")
            print(f"{'='*60}")
            
            # ç”Ÿæˆé¢„è§ˆå›¾ï¼ˆæ¯éš”ä¸€å®šçš„epochï¼‰
            preview_interval = self.config.get('preview_interval', 5)
            if epoch % preview_interval == 0 or epoch == self.config['num_epochs']:
                print(f"\nğŸ–¼ï¸ ç”Ÿæˆ Epoch {epoch} çš„é¢„è§ˆå›¾...")
                self.log_validation(val_loader, epoch, preview_dir)
            
            # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
                self.save_checkpoint(epoch, self.config['task_name'], is_best=True)
                print(f"ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: {val_loss:.6f}")
            else:
                self.patience_counter += 1
                print(f"â³ æ—©åœè®¡æ•°: {self.patience_counter}/{self.max_patience}")
            
            # å®šæœŸä¿å­˜
            if epoch % self.config['save_interval'] == 0:
                self.save_checkpoint(epoch, self.config['task_name'])
            
            # æ—©åœæ£€æŸ¥
            if self.patience_counter >= self.max_patience:
                print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨ epoch {epoch} åœæ­¢è®­ç»ƒ")
                break
            
            # æ¸…ç†æ˜¾å­˜
            if self.device.type == 'cuda':
                torch.cuda.empty_cache()
                if epoch % 5 == 0:  # æ¯5ä¸ªepochè®°å½•ä¸€æ¬¡å†…å­˜
                    self._log_gpu_memory(f"End of Epoch {epoch}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹å’ŒæŸå¤±æ›²çº¿
        self.save_checkpoint(self.config['num_epochs'], self.config['task_name'])
        self.plot_and_save_losses(train_losses, val_losses)
        
        # æœ€ç»ˆé¢„è§ˆå›¾
        print(f"\nğŸ–¼ï¸ ç”Ÿæˆæœ€ç»ˆé¢„è§ˆå›¾...")
        self.log_validation(val_loader, self.config['num_epochs'], preview_dir)
        
        print(f"\nğŸ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.6f}")

def main():
    # 256x256é…ç½® - ç«‹å³æ”¹è¿›çš„å‚æ•°
    config = {
        'learning_rate': 5e-5,      # ç«‹å³æ”¹è¿›ï¼šæé«˜å­¦ä¹ ç‡
        'num_epochs': 40,
        'batch_size': 4,
        'save_interval': 5,
        'preview_interval': 5,      # æ–°å¢ï¼šé¢„è§ˆå›¾ç”Ÿæˆé—´éš”ï¼ˆæ¯5ä¸ªepochï¼‰
        'accumulation_steps': 2,
        'weight_decay': 1e-4,       # ç«‹å³æ”¹è¿›ï¼šå‡å°æƒé‡è¡°å‡
        'patience': 12,
        'warmup_steps': 500,        # ç«‹å³æ”¹è¿›ï¼šæ·»åŠ warmup
    }

    tasks = [
        {'name': 'move_object', 'display': 'ç§»åŠ¨ç‰©ä½“'},
        {'name': 'drop_object', 'display': 'æ‰è½ç‰©ä½“'},
        {'name': 'cover_object', 'display': 'è¦†ç›–ç‰©ä½“'}
    ]

    for task in tasks:
        task_name = task['name']
        print(f"\n{'='*60}")
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: {task['display']}")
        print(f"ğŸ“ åˆ†è¾¨ç‡: 256x256")
        print(f"{'='*60}")
        
        task_config = config.copy()
        task_config['task_name'] = task_name
        task_config['output_dir'] = f'training_results_{task_name}_256'
        
        # åŠ è½½æ•°æ® - ä½¿ç”¨256æ•°æ®é›†
        try:
            train_loader, val_loader, test_loader = create_task_specific_loaders(
                task_name=task_name,
                batch_size=task_config['batch_size'],
                data_path="processed_data_256"  # ä¿®æ”¹ä¸º256æ•°æ®é›†è·¯å¾„
            )
        except Exception as e:
            print(f"âŒ è·³è¿‡ä»»åŠ¡ {task_name}: {e}")
            continue

        # ä½¿ç”¨1000ä¸ªæ ·æœ¬
        max_samples = 1000
        if max_samples is not None:
            orig_train_ds = train_loader.dataset
            orig_val_ds = val_loader.dataset
            orig_test_ds = test_loader.dataset
            combined = ConcatDataset([orig_train_ds, orig_val_ds, orig_test_ds])
            total = len(combined)
            
            if max_samples > total:
                print(f"âš ï¸ è¯·æ±‚çš„æ ·æœ¬æ•° {max_samples} è¶…è¿‡å¯ç”¨æ ·æœ¬ {total}ï¼Œä½¿ç”¨å…¨éƒ¨æ ·æœ¬")
                max_samples = total

            print(f"ğŸ“Š ä»æ€»æ ·æœ¬ {total} ä¸­éšæœºæŠ½å– {max_samples} ä¸ªï¼ˆæŒ‰ 8:1:1 åˆ’åˆ†ï¼‰")

            generator = torch.Generator()
            generator.manual_seed(42)
            perm = torch.randperm(total, generator=generator)[:max_samples].tolist()

            n_train = int(max_samples * 0.8)
            n_val = int(max_samples * 0.1)
            n_test = max_samples - n_train - n_val

            train_idx = perm[:n_train]
            val_idx = perm[n_train:n_train + n_val]
            test_idx = perm[n_train + n_val:]

            small_train_ds = Subset(combined, train_idx)
            small_val_ds = Subset(combined, val_idx)
            small_test_ds = Subset(combined, test_idx)

            train_loader = DataLoader(small_train_ds, batch_size=task_config['batch_size'], 
                                    shuffle=True, num_workers=4, pin_memory=True)
            val_loader = DataLoader(small_val_ds, batch_size=task_config['batch_size'], 
                                  shuffle=False, num_workers=4, pin_memory=True)

            print(f"âœ… æ•°æ®é›†åˆ†é…: train={len(small_train_ds)} val={len(small_val_ds)}")

        if len(train_loader) == 0:
            print(f"âš ï¸ ä»»åŠ¡ {task_name} æ— è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡")
            continue

        # åˆå§‹åŒ–å¹¶è®­ç»ƒ
        try:
            trainer = ControlNet256Trainer(task_config)
            trainer.train(train_loader, val_loader)
        except Exception as e:
            print(f"âŒ è®­ç»ƒä»»åŠ¡ {task_name} å¤±è´¥: {e}")
            continue

if __name__ == "__main__":
    main()