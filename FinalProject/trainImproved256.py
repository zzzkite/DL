#!/usr/bin/env python3
"""
ControlNet 1.1 256x256è®­ç»ƒè„šæœ¬ - ä¼˜åŒ–ç‰ˆæœ¬
é’ˆå¯¹è®­ç»ƒæ•ˆæœä¸ä½³çš„ç«‹å³æ”¹è¿›
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset, ConcatDataset
import torch.optim as optim
import cv2
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import sys
import os
import gc
import time
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

try:
    from diffusers import DDPMScheduler, AutoencoderKL, UNet2DConditionModel
    from transformers import CLIPTokenizer, CLIPTextModel
    from loaderData256 import create_task_specific_loaders  # ä¿®æ”¹ä¸º256æ•°æ®åŠ è½½å™¨
    
    try:
        from cldm.model import create_model, load_state_dict
        CONTROLNET_AVAILABLE = True
        print("âœ… æˆåŠŸå¯¼å…¥ControlNetæ¨¡å—")
    except ImportError as e:
        print(f"âš ï¸  æ— æ³•å¯¼å…¥cldm: {e}")
        CONTROLNET_AVAILABLE = False
        
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

class ControlNet256Trainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.task_name = config.get('task_name', 'unknown_task')
        
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ¯ ä»»åŠ¡: {self.task_name}")
        print(f"ğŸ“ åˆ†è¾¨ç‡: 256x256")
        
        # è®­ç»ƒçŠ¶æ€
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        self.max_patience = config.get('patience', 12)
        
        # æ¢¯åº¦ç¼©æ”¾å™¨
        self.scaler = torch.amp.GradScaler('cuda')
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.setup_models()
        self.setup_optimizers()
        
    def setup_models(self):
        """æ¨¡å‹åˆå§‹åŒ–"""
        print("ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...")
        
        # 1. åŠ è½½ç»„ä»¶
        self.tokenizer = CLIPTokenizer.from_pretrained("stable-diffusion-v1-5/tokenizer", local_files_only=True)
        self.text_encoder = CLIPTextModel.from_pretrained("stable-diffusion-v1-5/text_encoder", local_files_only=True).to(self.device)
        self.vae = AutoencoderKL.from_pretrained("stable-diffusion-v1-5/vae", local_files_only=True).to(self.device)
        self.unet = UNet2DConditionModel.from_pretrained("stable-diffusion-v1-5/unet", local_files_only=True).to(self.device)
        self.noise_scheduler = DDPMScheduler.from_pretrained("stable-diffusion-v1-5/scheduler", local_files_only=True)
        
        # 2. åŠ è½½ ControlNet
        self.controlnet = self.load_controlnet().to(self.device)
        
        # 3. å†»ç»“å‚æ•°
        self.text_encoder.requires_grad_(False)
        self.vae.requires_grad_(False)
        self.unet.requires_grad_(False)
        self.controlnet.requires_grad_(True)
        
        # æ‰“å°å‚æ•°é‡
        trainable_params = sum(p.numel() for p in self.controlnet.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in self.controlnet.parameters())
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå¯è®­ç»ƒå‚æ•°: {trainable_params:,} / æ€»å‚æ•°: {total_params:,}")
        
        # æ£€æŸ¥VAEè¾“å…¥å°ºå¯¸å…¼å®¹æ€§
        vae_sample_size = self.vae.config.sample_size
        print(f"ğŸ” VAEæ ·æœ¬å°ºå¯¸: {vae_sample_size}")
        if vae_sample_size != 256 and vae_sample_size != 512:
            print(f"âš ï¸  VAEé¢„æœŸè¾“å…¥å°ºå¯¸ä¸º{vae_sample_size}x{vae_sample_size}ï¼Œæ•°æ®ä¸º256x256")

    def load_controlnet(self):
        """åŠ è½½ControlNetæ¨¡å‹"""
        try:
            if CONTROLNET_AVAILABLE:
                controlnet_dir = Path("ControlNet-v1-1")
                model_path = controlnet_dir / "control_sd15_canny.pth"
                config_path = controlnet_dir / "cldm_v15.yaml"
                
                if model_path.exists():
                    print(f"ğŸ“‚ åŠ è½½é¢„è®­ç»ƒæƒé‡: {model_path}")
                    model = create_model(str(config_path)).to(self.device)
                    model.load_state_dict(load_state_dict(str(model_path), location='cpu'))
                    return model.control_model
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œå°†å°è¯•ä»UNetåˆå§‹åŒ–")
            
            # å¤‡é€‰æ–¹æ¡ˆï¼šä» UNet åˆå§‹åŒ–
            from diffusers import ControlNetModel
            print("ğŸ†• ä» UNet å¤åˆ¶æƒé‡åˆå§‹åŒ– ControlNet")
            controlnet = ControlNetModel.from_unet(self.unet, conditioning_channels=3)
            return controlnet
                
        except Exception as e:
            print(f"âŒ åŠ è½½ControlNetå¤±è´¥: {e}")
            raise

    def setup_optimizers(self):
        """ä¼˜åŒ–å™¨é…ç½® - ç«‹å³æ”¹è¿›ï¼šæ·»åŠ warmup + æ›´å¤§å­¦ä¹ ç‡"""
        # ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡å’Œæ›´å°çš„æƒé‡è¡°å‡
        base_lr = self.config.get('learning_rate', 5e-5)  # æé«˜å­¦ä¹ ç‡
        
        no_decay = ["bias", "LayerNorm.weight"]
        optimizer_grouped_parameters = [
            {
                "params": [p for n, p in self.controlnet.named_parameters() 
                          if not any(nd in n for nd in no_decay) and p.requires_grad],
                "weight_decay": self.config.get('weight_decay', 1e-4),  # å‡å°æƒé‡è¡°å‡
                "lr": base_lr,
            },
            {
                "params": [p for n, p in self.controlnet.named_parameters() 
                          if any(nd in n for nd in no_decay) and p.requires_grad],
                "weight_decay": 0.0,
                "lr": base_lr,
            },
        ]
        
        self.optimizer = optim.AdamW(
            optimizer_grouped_parameters,
            lr=base_lr,
            betas=(0.9, 0.999),
            weight_decay=1e-4,  # ç»Ÿä¸€çš„æƒé‡è¡°å‡
            eps=1e-8
        )
        
        # ä½¿ç”¨å¸¦warmupçš„ä½™å¼¦é€€ç«è°ƒåº¦å™¨
        self.lr_scheduler = self.get_cosine_schedule_with_warmup(
            self.optimizer,
            num_warmup_steps=self.config.get('warmup_steps', 500),
            num_training_steps=self.config.get('num_epochs', 40) * 100,  # ä¼°è®¡çš„æ­¥æ•°
            num_cycles=0.5
        )

    def get_cosine_schedule_with_warmup(self, optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5):
        """åˆ›å»ºå¸¦warmupçš„ä½™å¼¦é€€ç«è°ƒåº¦å™¨"""
        def lr_lambda(current_step):
            if current_step < num_warmup_steps:
                return float(current_step) / float(max(1, num_warmup_steps))
            progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
            return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))
        
        return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)

    def prepare_images_for_vae(self, images):
        """å‡†å¤‡å›¾åƒä»¥é€‚åº”VAEè¾“å…¥"""
        # ç¡®ä¿å›¾åƒåœ¨[-1, 1]èŒƒå›´å†…
        if torch.max(images) <= 1.0 and torch.min(images) >= 0.0:
            images = images * 2.0 - 1.0
        
        # å¦‚æœVAEéœ€è¦ç‰¹å®šå°ºå¯¸ï¼Œè¿›è¡Œè°ƒæ•´
        vae_sample_size = self.vae.config.sample_size
        current_size = images.shape[-1]
        
        if current_size != vae_sample_size:
            print(f"ğŸ”§ è°ƒæ•´å›¾åƒå°ºå¯¸ä» {current_size}x{current_size} åˆ° {vae_sample_size}x{vae_sample_size}")
            images = F.interpolate(images, size=(vae_sample_size, vae_sample_size), 
                                 mode='bilinear', align_corners=False)
        
        return images

    def get_canny_edges(self, image_tensor, training=False):
        """
        Cannyè¾¹ç¼˜æ£€æµ‹ - ç«‹å³æ”¹è¿›ï¼šæ›´å¥½çš„å‚æ•°å’Œæ•°æ®å¢å¼º
        """
        batch_size = image_tensor.shape[0]
        
        # ç¡®ä¿è¾“å…¥åœ¨ [0, 1] èŒƒå›´å†…
        if torch.max(image_tensor) > 1.0:
            image_tensor = (image_tensor + 1.0) / 2.0
        
        # è®­ç»ƒæ—¶æ·»åŠ æ•°æ®å¢å¼º
        if training:
            # éšæœºè°ƒæ•´äº®åº¦å’Œå¯¹æ¯”åº¦
            brightness = 0.1 * torch.randn(batch_size, 1, 1, 1, device=self.device)
            contrast = 1.0 + 0.2 * torch.randn(batch_size, 1, 1, 1, device=self.device)
            image_tensor = image_tensor * contrast + brightness
            image_tensor = torch.clamp(image_tensor, 0, 1)
        
        images_np = image_tensor.permute(0, 2, 3, 1).cpu().numpy()
        images_np = (images_np * 255).astype(np.uint8)
        
        edges_list = []
        for i in range(batch_size):
            img_gray = cv2.cvtColor(images_np[i], cv2.COLOR_RGB2GRAY)
            
            # ç«‹å³æ”¹è¿›ï¼šæ›´å®½çš„é˜ˆå€¼èŒƒå›´ï¼Œæ›´å¥½çš„è¾¹ç¼˜æ£€æµ‹
            v = np.median(img_gray)
            sigma = 0.33
            # ä½¿ç”¨æ›´å®½çš„é˜ˆå€¼èŒƒå›´ï¼Œç¡®ä¿æ•æ‰åˆ°è¶³å¤Ÿå¤šçš„è¾¹ç¼˜
            lower = int(max(0, (1.0 - 2 * sigma) * v))  # æ›´ä½çš„é˜ˆå€¼
            upper = int(min(255, (1.0 + 2 * sigma) * v))  # æ›´é«˜çš„é˜ˆå€¼
            
            edge = cv2.Canny(img_gray, lower, upper)
            
            # ç«‹å³æ”¹è¿›ï¼šæ›´å¥½çš„å½¢æ€å­¦æ“ä½œï¼Œæ”¹å–„è¾¹ç¼˜è¿ç»­æ€§
            kernel = np.ones((2, 2), np.uint8)  # ç¨å¤§çš„æ ¸
            edge = cv2.morphologyEx(edge, cv2.MORPH_CLOSE, kernel)
            
            # æ‰©å±•å›3é€šé“
            edge = np.stack([edge] * 3, axis=-1)
            edges_list.append(edge)
            
        edges_np = np.stack(edges_list)
        edges_tensor = torch.from_numpy(edges_np).float() / 255.0
        return edges_tensor.permute(0, 3, 1, 2).to(self.device)

    def compute_loss(self, batch, training=True):
        """ç»Ÿä¸€çš„æŸå¤±è®¡ç®—å‡½æ•° - é€‚é…256x256"""
        # 1. å‡†å¤‡æ•°æ®
        current_frame_20 = batch['input_frames'][:, -1].to(self.device) 
        target_frame_25 = batch['target_frame'].to(self.device)
        text_descriptions = batch.get('label_text', ['interaction'] * len(current_frame_20))
        
        # 2. VAEç¼–ç ç›®æ ‡å›¾ - é€‚é…å°ºå¯¸
        target_frame_prepared = self.prepare_images_for_vae(target_frame_25)
        target_latents = self.vae.encode(target_frame_prepared).latent_dist.sample()
        target_latents = target_latents * self.vae.config.scaling_factor
        
        # 3. CLIPç¼–ç æ–‡æœ¬
        inputs = self.tokenizer(
            text_descriptions, 
            max_length=77, 
            padding="max_length", 
            truncation=True, 
            return_tensors="pt"
        ).to(self.device)
        encoder_hidden_states = self.text_encoder(inputs.input_ids)[0]
        
        # 4. å‡†å¤‡ControlNetæ¡ä»¶
        control_cond = self.get_canny_edges(current_frame_20, training=training)
        
        # 5. é‡‡æ ·timestepå’Œå™ªå£° - ä½¿ç”¨å›ºå®šçš„å…¨èŒƒå›´
        timesteps = torch.randint(
            0, 
            self.noise_scheduler.config.num_train_timesteps, 
            (target_latents.shape[0],), 
            device=self.device
        ).long()
        
        noise = torch.randn_like(target_latents)
        noisy_latents = self.noise_scheduler.add_noise(target_latents, noise, timesteps)
        
        # 6. ControlNetå‰å‘
        down_block_res_samples, mid_block_res_sample = self.controlnet(
            noisy_latents,
            timesteps,
            encoder_hidden_states=encoder_hidden_states,
            controlnet_cond=control_cond,
            return_dict=False,
        )
        
        # 7. UNeté¢„æµ‹
        noise_pred = self.unet(
            noisy_latents,
            timesteps,
            encoder_hidden_states=encoder_hidden_states,
            down_block_additional_residuals=down_block_res_samples,
            mid_block_additional_residual=mid_block_res_sample,
        ).sample
        
        # 8. è®¡ç®—æŸå¤±
        loss = F.mse_loss(noise_pred, noise)
        
        return loss

    def train_epoch(self, train_loader, epoch):
        """è®­ç»ƒepoch - ç«‹å³æ”¹è¿›ï¼šæ›´é¢‘ç¹çš„æ—¥å¿—å’ŒåŠ¨æ€ç›‘æ§"""
        self.controlnet.train()
        total_loss = 0
        num_batches = 0
        
        accumulation_steps = self.config.get('accumulation_steps', 2)
        
        print(f"ğŸ“š å¼€å§‹ç¬¬ {epoch} è½®è®­ç»ƒï¼Œå…±æœ‰ {len(train_loader)} ä¸ªæ‰¹æ¬¡")
        
        # è·Ÿè¸ªæ‰¹æ¬¡æŸå¤±ç”¨äºåŠ¨æ€è°ƒæ•´
        batch_losses = []
        
        for batch_idx, batch in enumerate(train_loader):
            if batch is None: 
                continue
                
            # é‡ç½®æ¢¯åº¦
            self.optimizer.zero_grad()
            
            try:
                # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦
                with torch.amp.autocast('cuda'):
                    loss = self.compute_loss(batch, training=True)
                
                # æ¢¯åº¦ç´¯ç§¯
                loss = loss / accumulation_steps
                
                # åå‘ä¼ æ’­
                self.scaler.scale(loss).backward()
                
                if (batch_idx + 1) % accumulation_steps == 0:
                    # æ¢¯åº¦è£å‰ª
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.controlnet.parameters(), max_norm=1.0)
                    
                    # ä¼˜åŒ–å™¨æ­¥è¿›
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()
                    
                    # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                    if hasattr(self, 'lr_scheduler'):
                        self.lr_scheduler.step()
                
                # è®°å½•æŸå¤±
                loss_value = loss.item() * accumulation_steps
                total_loss += loss_value
                num_batches += 1
                batch_losses.append(loss_value)
                
                # ç«‹å³æ”¹è¿›ï¼šæ›´é¢‘ç¹çš„æ—¥å¿—è¾“å‡ºï¼ˆæ¯5ä¸ªbatchï¼‰
                if batch_idx % 5 == 0:  # ä»10æ”¹ä¸º5ï¼Œæ›´é¢‘ç¹çš„ç›‘æ§
                    current_lr = self.optimizer.param_groups[0]['lr']
                    current_step = (epoch - 1) * len(train_loader) + batch_idx
                    
                    # è®¡ç®—æœ€è¿‘å‡ ä¸ªbatchçš„å¹³å‡æŸå¤±
                    recent_avg = np.mean(batch_losses[-10:]) if len(batch_losses) >= 10 else loss_value
                    
                    print(f"Epoch {epoch} | Batch {batch_idx:3d}/{len(train_loader)} | "
                          f"Loss: {loss_value:.6f} | Recent: {recent_avg:.6f} | "
                          f"LR: {current_lr:.2e} | Step: {current_step}")
                
                # å®šæœŸæ¸…ç†æ˜¾å­˜
                if batch_idx % 20 == 0 and self.device.type == 'cuda':
                    torch.cuda.empty_cache()
                    if batch_idx % 40 == 0:
                        self._log_gpu_memory(f"Epoch{epoch} Batch{batch_idx}")
                    
            except Exception as e:
                print(f"âŒ è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                continue
        
        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')
        print(f"âœ… ç¬¬ {epoch} è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
        return avg_loss

    def _log_gpu_memory(self, label: str = ""):
        """GPUå†…å­˜ç›‘æ§"""
        if self.device.type != 'cuda':
            return
        try:
            allocated = torch.cuda.memory_allocated() / 1024**3  # GB
            reserved = torch.cuda.memory_reserved() / 1024**3    # GB
            print(f"[GPU MEM] {label} allocated={allocated:.2f}GB reserved={reserved:.2f}GB")
        except Exception:
            pass

    def validate(self, val_loader):
        """éªŒè¯å‡½æ•° - é€‚é…256x256"""
        self.controlnet.eval()
        total_loss = 0.0
        num_batches = 0
        
        print(f"ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ {len(val_loader)} ä¸ªæ‰¹æ¬¡")
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                if batch is None:
                    continue
                
                try:
                    with torch.amp.autocast('cuda'):
                        loss = self.compute_loss(batch, training=False)
                    
                    loss_value = loss.item()
                    total_loss += loss_value
                    num_batches += 1
                    
                    # æ›´é¢‘ç¹çš„éªŒè¯æ—¥å¿—
                    if batch_idx % 3 == 0:  # ä»5æ”¹ä¸º3ï¼Œæ›´é¢‘ç¹çš„éªŒè¯ç›‘æ§
                        print(f"éªŒè¯æ‰¹æ¬¡ {batch_idx}/{len(val_loader)} | Loss: {loss_value:.6f}")
                        
                except Exception as e:
                    print(f"âŒ éªŒè¯æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    continue
        
        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')
        print(f"âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.6f}")
        return avg_loss

    def save_checkpoint(self, epoch, task_name, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(exist_ok=True, parents=True)
        
        if is_best:
            save_path = output_dir / f"controlnet_{task_name}_best.pth"
        else:
            save_path = output_dir / f"controlnet_{task_name}_epoch_{epoch}.pth"
            
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.controlnet.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'lr_scheduler_state_dict': self.lr_scheduler.state_dict() if hasattr(self, 'lr_scheduler') else None,
            'best_val_loss': self.best_val_loss,
            'config': self.config
        }
        
        torch.save(checkpoint, save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}")

    def plot_and_save_losses(self, train_losses, val_losses=None):
        """ç»˜åˆ¶è®­ç»ƒ/éªŒè¯æŸå¤±"""
        try:
            output_dir = Path(self.config['output_dir'])
            output_dir.mkdir(parents=True, exist_ok=True)

            plt.figure(figsize=(10, 6))
            epochs = list(range(1, len(train_losses) + 1))
            
            plt.plot(epochs, train_losses, marker='o', color='tab:blue', label='Train Loss', linewidth=2)
            if val_losses is not None and len(val_losses) == len(train_losses):
                plt.plot(epochs, val_losses, marker='s', color='tab:orange', label='Val Loss', linewidth=2)
                
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title(f'Training / Validation Loss - {self.task_name} (256x256)')
            plt.grid(alpha=0.3)
            plt.legend()
            
            save_path = output_dir / f'training_val_loss_{self.task_name}_256.png'
            plt.savefig(save_path, dpi=200, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“ˆ Loss å›¾å·²ä¿å­˜: {save_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ Loss å›¾å¤±è´¥: {e}")

    def train(self, train_loader, val_loader):
        """è®­ç»ƒå¾ªç¯ - é€‚é…256x256"""
        print("ğŸš€ å¼€å§‹256x256è®­ç»ƒ...")
        print(f"ğŸ“ è¾“å…¥åˆ†è¾¨ç‡: 256x256")
        print(f"ğŸ¯ ä»»åŠ¡: {self.task_name}")
        print(f"ğŸ’¡ ä¼˜åŠ¿: ç›¸æ¯”512x512ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå†…å­˜éœ€æ±‚æ›´ä½")
        
        train_losses = []
        val_losses = []
        
        # åˆå§‹éªŒè¯
        print("\nğŸ” è¿›è¡Œåˆå§‹éªŒè¯...")
        initial_val_loss = self.validate(val_loader)
        print(f"åˆå§‹éªŒè¯æŸå¤±: {initial_val_loss:.6f}")
        
        for epoch in range(1, self.config['num_epochs'] + 1):
            epoch_start_time = time.time()
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(train_loader, epoch)
            train_losses.append(train_loss)
            
            # éªŒè¯
            val_loss = self.validate(val_loader)
            val_losses.append(val_loss)
            
            epoch_time = time.time() - epoch_start_time
            current_lr = self.optimizer.param_groups[0]['lr']
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š Epoch {epoch}/{self.config['num_epochs']} å®Œæˆ")
            print(f"   Train Loss: {train_loss:.6f}")
            print(f"   Val Loss: {val_loss:.6f}")
            print(f"   LR: {current_lr:.2e} | Time: {epoch_time:.1f}s")
            print(f"{'='*60}")
            
            # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
                self.save_checkpoint(epoch, self.config['task_name'], is_best=True)
                print(f"ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: {val_loss:.6f}")
            else:
                self.patience_counter += 1
                print(f"â³ æ—©åœè®¡æ•°: {self.patience_counter}/{self.max_patience}")
            
            # å®šæœŸä¿å­˜
            if epoch % self.config['save_interval'] == 0:
                self.save_checkpoint(epoch, self.config['task_name'])
            
            # æ—©åœæ£€æŸ¥
            if self.patience_counter >= self.max_patience:
                print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨ epoch {epoch} åœæ­¢è®­ç»ƒ")
                break
            
            # æ¸…ç†æ˜¾å­˜
            if self.device.type == 'cuda':
                torch.cuda.empty_cache()
                if epoch % 5 == 0:  # æ¯5ä¸ªepochè®°å½•ä¸€æ¬¡å†…å­˜
                    self._log_gpu_memory(f"End of Epoch {epoch}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹å’ŒæŸå¤±æ›²çº¿
        self.save_checkpoint(self.config['num_epochs'], self.config['task_name'])
        self.plot_and_save_losses(train_losses, val_losses)
        
        print(f"\nğŸ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.6f}")

def main():
    # 256x256é…ç½® - ç«‹å³æ”¹è¿›çš„å‚æ•°
    config = {
        'learning_rate': 5e-5,      # ç«‹å³æ”¹è¿›ï¼šæé«˜å­¦ä¹ ç‡
        'num_epochs': 40,
        'batch_size': 4,
        'save_interval': 5,
        'accumulation_steps': 2,
        'weight_decay': 1e-4,       # ç«‹å³æ”¹è¿›ï¼šå‡å°æƒé‡è¡°å‡
        'patience': 12,
        'warmup_steps': 500,        # ç«‹å³æ”¹è¿›ï¼šæ·»åŠ warmup
    }

    tasks = [
        {'name': 'move_object', 'display': 'ç§»åŠ¨ç‰©ä½“'},
        {'name': 'drop_object', 'display': 'æ‰è½ç‰©ä½“'},
        {'name': 'cover_object', 'display': 'è¦†ç›–ç‰©ä½“'}
    ]

    for task in tasks:
        task_name = task['name']
        print(f"\n{'='*60}")
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: {task['display']}")
        print(f"ğŸ“ åˆ†è¾¨ç‡: 256x256")
        print(f"{'='*60}")
        
        task_config = config.copy()
        task_config['task_name'] = task_name
        task_config['output_dir'] = f'training_results_{task_name}_256'
        
        # åŠ è½½æ•°æ® - ä½¿ç”¨256æ•°æ®é›†
        try:
            train_loader, val_loader, test_loader = create_task_specific_loaders(
                task_name=task_name,
                batch_size=task_config['batch_size'],
                data_path="processed_data_256"  # ä¿®æ”¹ä¸º256æ•°æ®é›†è·¯å¾„
            )
        except Exception as e:
            print(f"âŒ è·³è¿‡ä»»åŠ¡ {task_name}: {e}")
            continue

        # ä½¿ç”¨1000ä¸ªæ ·æœ¬
        max_samples = 1000
        if max_samples is not None:
            orig_train_ds = train_loader.dataset
            orig_val_ds = val_loader.dataset
            orig_test_ds = test_loader.dataset
            combined = ConcatDataset([orig_train_ds, orig_val_ds, orig_test_ds])
            total = len(combined)
            
            if max_samples > total:
                print(f"âš ï¸ è¯·æ±‚çš„æ ·æœ¬æ•° {max_samples} è¶…è¿‡å¯ç”¨æ ·æœ¬ {total}ï¼Œä½¿ç”¨å…¨éƒ¨æ ·æœ¬")
                max_samples = total

            print(f"ğŸ“Š ä»æ€»æ ·æœ¬ {total} ä¸­éšæœºæŠ½å– {max_samples} ä¸ªï¼ˆæŒ‰ 8:1:1 åˆ’åˆ†ï¼‰")

            generator = torch.Generator()
            generator.manual_seed(42)
            perm = torch.randperm(total, generator=generator)[:max_samples].tolist()

            n_train = int(max_samples * 0.8)
            n_val = int(max_samples * 0.1)
            n_test = max_samples - n_train - n_val

            train_idx = perm[:n_train]
            val_idx = perm[n_train:n_train + n_val]
            test_idx = perm[n_train + n_val:]

            small_train_ds = Subset(combined, train_idx)
            small_val_ds = Subset(combined, val_idx)
            small_test_ds = Subset(combined, test_idx)

            train_loader = DataLoader(small_train_ds, batch_size=task_config['batch_size'], 
                                    shuffle=True, num_workers=4, pin_memory=True)
            val_loader = DataLoader(small_val_ds, batch_size=task_config['batch_size'], 
                                  shuffle=False, num_workers=4, pin_memory=True)

            print(f"âœ… æ•°æ®é›†åˆ†é…: train={len(small_train_ds)} val={len(small_val_ds)}")

        if len(train_loader) == 0:
            print(f"âš ï¸ ä»»åŠ¡ {task_name} æ— è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡")
            continue

        # åˆå§‹åŒ–å¹¶è®­ç»ƒ
        try:
            trainer = ControlNet256Trainer(task_config)
            trainer.train(train_loader, val_loader)
        except Exception as e:
            print(f"âŒ è®­ç»ƒä»»åŠ¡ {task_name} å¤±è´¥: {e}")
            continue

if __name__ == "__main__":
    import math  # æ·»åŠ mathå¯¼å…¥ç”¨äºå­¦ä¹ ç‡è°ƒåº¦å™¨
    main()