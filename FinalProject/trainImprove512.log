nohup: ignoring input
/home/zhangzhikui/enter/envs/dl/lib/python3.10/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
âš ï¸  æ— æ³•å¯¼å…¥cldm: No module named 'cldm'

============================================================
ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: ç§»åŠ¨ç‰©ä½“
ğŸ“ åˆ†è¾¨ç‡: 512x512
============================================================
   ç­›é€‰ä»»åŠ¡ 'move_object': 2014/6000 ä¸ªæ ·æœ¬
âœ… åŠ è½½æ•°æ®é›† (move_object): 2014 ä¸ªæ ·æœ¬
   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰
   åˆ†è¾¨ç‡: 512x512
   move_object: 2014 ä¸ªæ ·æœ¬
   ç­›é€‰ä»»åŠ¡ 'move_object': 245/750 ä¸ªæ ·æœ¬
âœ… åŠ è½½æ•°æ®é›† (move_object): 245 ä¸ªæ ·æœ¬
   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰
   åˆ†è¾¨ç‡: 512x512
   move_object: 245 ä¸ªæ ·æœ¬
   ç­›é€‰ä»»åŠ¡ 'move_object': 241/750 ä¸ªæ ·æœ¬
âœ… åŠ è½½æ•°æ®é›† (move_object): 241 ä¸ªæ ·æœ¬
   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰
   åˆ†è¾¨ç‡: 512x512
   move_object: 241 ä¸ªæ ·æœ¬
âœ… åˆ›å»ºä»»åŠ¡ 'move_object' æ•°æ®åŠ è½½å™¨å®Œæˆ
   è®­ç»ƒé›†: 2014 ä¸ªæ ·æœ¬, 1007 ä¸ªæ‰¹æ¬¡
   éªŒè¯é›†: 245 ä¸ªæ ·æœ¬, 123 ä¸ªæ‰¹æ¬¡
   æµ‹è¯•é›†: 241 ä¸ªæ ·æœ¬, 121 ä¸ªæ‰¹æ¬¡
   æ‰¹æ¬¡å¤§å°: 2
   åˆ†è¾¨ç‡: 512x512
   è¾“å…¥å¸§å½¢çŠ¶: (20, 3, 512, 512)
   ç›®æ ‡å¸§å½¢çŠ¶: (3, 512, 512)
ğŸ“Š ä»æ€»æ ·æœ¬ 2500 ä¸­éšæœºæŠ½å– 1000 ä¸ªï¼ˆæŒ‰ 8:1:1 åˆ’åˆ†ï¼‰
âœ… æ•°æ®é›†åˆ†é…: train=800 val=100
ğŸš€ ä½¿ç”¨è®¾å¤‡: cuda
ğŸ¯ ä»»åŠ¡: move_object
ğŸ“ åˆ†è¾¨ç‡: 512x512
ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...
ğŸ†• ä» UNet å¤åˆ¶æƒé‡åˆå§‹åŒ– ControlNet
âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå¯è®­ç»ƒå‚æ•°: 361,279,120 / æ€»å‚æ•°: 361,279,120
ğŸ” VAEæ ·æœ¬å°ºå¯¸: 512
ğŸš€ å¼€å§‹512x512è®­ç»ƒ...
ğŸ“ è¾“å…¥åˆ†è¾¨ç‡: 512x512
ğŸ¯ ä»»åŠ¡: move_object

ğŸ” è¿›è¡Œåˆå§‹éªŒè¯...
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.105216
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.351200
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.084220
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.127041
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.068982
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.360135
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.109767
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.151267
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.023100
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.429429
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.032493
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.070206
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.113356
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.136625
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.184684
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.248102
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.007672
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.148389
åˆå§‹éªŒè¯æŸå¤±: 0.148389
ğŸ“š å¼€å§‹ç¬¬ 1 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 1 | Batch 0/400 | Loss: 0.148742 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch0 allocated=6.73GB reserved=7.59GB
Epoch 1 | Batch 5/400 | Loss: 0.040291 | LR: 1.00e-05
Epoch 1 | Batch 10/400 | Loss: 0.376859 | LR: 1.00e-05
Epoch 1 | Batch 15/400 | Loss: 0.167920 | LR: 1.00e-05
Epoch 1 | Batch 20/400 | Loss: 0.027060 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch20 allocated=9.44GB reserved=10.55GB
Epoch 1 | Batch 25/400 | Loss: 0.101525 | LR: 1.00e-05
Epoch 1 | Batch 30/400 | Loss: 0.025619 | LR: 1.00e-05
Epoch 1 | Batch 35/400 | Loss: 0.066156 | LR: 1.00e-05
Epoch 1 | Batch 40/400 | Loss: 0.147871 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch40 allocated=9.44GB reserved=10.70GB
Epoch 1 | Batch 45/400 | Loss: 0.002746 | LR: 1.00e-05
Epoch 1 | Batch 50/400 | Loss: 0.084268 | LR: 1.00e-05
Epoch 1 | Batch 55/400 | Loss: 0.157973 | LR: 1.00e-05
Epoch 1 | Batch 60/400 | Loss: 0.050145 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch60 allocated=9.44GB reserved=10.68GB
Epoch 1 | Batch 65/400 | Loss: 0.176479 | LR: 1.00e-05
Epoch 1 | Batch 70/400 | Loss: 0.143233 | LR: 1.00e-05
Epoch 1 | Batch 75/400 | Loss: 0.051425 | LR: 1.00e-05
Epoch 1 | Batch 80/400 | Loss: 0.100609 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch80 allocated=9.44GB reserved=10.70GB
Epoch 1 | Batch 85/400 | Loss: 0.054226 | LR: 1.00e-05
Epoch 1 | Batch 90/400 | Loss: 0.023455 | LR: 1.00e-05
Epoch 1 | Batch 95/400 | Loss: 0.235676 | LR: 1.00e-05
Epoch 1 | Batch 100/400 | Loss: 0.171425 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch100 allocated=9.44GB reserved=10.66GB
Epoch 1 | Batch 105/400 | Loss: 0.011389 | LR: 1.00e-05
Epoch 1 | Batch 110/400 | Loss: 0.081080 | LR: 1.00e-05
Epoch 1 | Batch 115/400 | Loss: 0.033159 | LR: 1.00e-05
Epoch 1 | Batch 120/400 | Loss: 0.140777 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch120 allocated=9.44GB reserved=10.68GB
Epoch 1 | Batch 125/400 | Loss: 0.202416 | LR: 1.00e-05
Epoch 1 | Batch 130/400 | Loss: 0.035252 | LR: 1.00e-05
Epoch 1 | Batch 135/400 | Loss: 0.201954 | LR: 1.00e-05
Epoch 1 | Batch 140/400 | Loss: 0.139331 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch140 allocated=9.44GB reserved=10.74GB
Epoch 1 | Batch 145/400 | Loss: 0.082490 | LR: 1.00e-05
Epoch 1 | Batch 150/400 | Loss: 0.267128 | LR: 1.00e-05
Epoch 1 | Batch 155/400 | Loss: 0.051550 | LR: 1.00e-05
Epoch 1 | Batch 160/400 | Loss: 0.498848 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch160 allocated=9.44GB reserved=10.60GB
Epoch 1 | Batch 165/400 | Loss: 0.060094 | LR: 1.00e-05
Epoch 1 | Batch 170/400 | Loss: 0.018592 | LR: 1.00e-05
Epoch 1 | Batch 175/400 | Loss: 0.027861 | LR: 1.00e-05
Epoch 1 | Batch 180/400 | Loss: 0.064166 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch180 allocated=9.44GB reserved=10.65GB
Epoch 1 | Batch 185/400 | Loss: 0.153841 | LR: 1.00e-05
Epoch 1 | Batch 190/400 | Loss: 0.353740 | LR: 1.00e-05
Epoch 1 | Batch 195/400 | Loss: 0.240171 | LR: 1.00e-05
Epoch 1 | Batch 200/400 | Loss: 0.205920 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch200 allocated=9.44GB reserved=10.72GB
Epoch 1 | Batch 205/400 | Loss: 0.211723 | LR: 1.00e-05
Epoch 1 | Batch 210/400 | Loss: 0.295190 | LR: 1.00e-05
Epoch 1 | Batch 215/400 | Loss: 0.037636 | LR: 1.00e-05
Epoch 1 | Batch 220/400 | Loss: 0.040998 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch220 allocated=9.44GB reserved=10.55GB
Epoch 1 | Batch 225/400 | Loss: 0.012216 | LR: 1.00e-05
Epoch 1 | Batch 230/400 | Loss: 0.257590 | LR: 1.00e-05
Epoch 1 | Batch 235/400 | Loss: 0.128571 | LR: 1.00e-05
Epoch 1 | Batch 240/400 | Loss: 0.213940 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch240 allocated=9.44GB reserved=10.73GB
Epoch 1 | Batch 245/400 | Loss: 0.178560 | LR: 1.00e-05
Epoch 1 | Batch 250/400 | Loss: 0.090550 | LR: 1.00e-05
Epoch 1 | Batch 255/400 | Loss: 0.050265 | LR: 1.00e-05
Epoch 1 | Batch 260/400 | Loss: 0.053745 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch260 allocated=9.44GB reserved=10.65GB
Epoch 1 | Batch 265/400 | Loss: 0.008216 | LR: 1.00e-05
Epoch 1 | Batch 270/400 | Loss: 0.010809 | LR: 1.00e-05
Epoch 1 | Batch 275/400 | Loss: 0.071659 | LR: 1.00e-05
Epoch 1 | Batch 280/400 | Loss: 0.085414 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch280 allocated=9.44GB reserved=10.84GB
Epoch 1 | Batch 285/400 | Loss: 0.253094 | LR: 1.00e-05
Epoch 1 | Batch 290/400 | Loss: 0.171058 | LR: 1.00e-05
Epoch 1 | Batch 295/400 | Loss: 0.014172 | LR: 1.00e-05
Epoch 1 | Batch 300/400 | Loss: 0.229117 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch300 allocated=9.44GB reserved=10.86GB
Epoch 1 | Batch 305/400 | Loss: 0.093942 | LR: 1.00e-05
Epoch 1 | Batch 310/400 | Loss: 0.260567 | LR: 1.00e-05
Epoch 1 | Batch 315/400 | Loss: 0.048389 | LR: 1.00e-05
Epoch 1 | Batch 320/400 | Loss: 0.036368 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch320 allocated=9.44GB reserved=10.67GB
Epoch 1 | Batch 325/400 | Loss: 0.101034 | LR: 1.00e-05
Epoch 1 | Batch 330/400 | Loss: 0.266806 | LR: 1.00e-05
Epoch 1 | Batch 335/400 | Loss: 0.009084 | LR: 1.00e-05
Epoch 1 | Batch 340/400 | Loss: 0.130343 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch340 allocated=9.44GB reserved=10.68GB
Epoch 1 | Batch 345/400 | Loss: 0.041428 | LR: 1.00e-05
Epoch 1 | Batch 350/400 | Loss: 0.190026 | LR: 1.00e-05
Epoch 1 | Batch 355/400 | Loss: 0.221789 | LR: 1.00e-05
Epoch 1 | Batch 360/400 | Loss: 0.116239 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch360 allocated=9.44GB reserved=10.61GB
Epoch 1 | Batch 365/400 | Loss: 0.194329 | LR: 1.00e-05
Epoch 1 | Batch 370/400 | Loss: 0.008286 | LR: 1.00e-05
Epoch 1 | Batch 375/400 | Loss: 0.240588 | LR: 1.00e-05
Epoch 1 | Batch 380/400 | Loss: 0.117196 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch380 allocated=9.44GB reserved=10.68GB
Epoch 1 | Batch 385/400 | Loss: 0.042415 | LR: 1.00e-05
Epoch 1 | Batch 390/400 | Loss: 0.155821 | LR: 1.00e-05
Epoch 1 | Batch 395/400 | Loss: 0.117392 | LR: 1.00e-05
âœ… ç¬¬ 1 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.130272
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.100257
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.161139
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.022406
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.246622
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.167595
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.097349
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.141089
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.053477
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.189482
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.089761
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.006733
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.024151
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.089979
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.178503
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.132767
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.202047
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.030719
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.120830

============================================================
ğŸ“Š Epoch 1/50 å®Œæˆ
   Train Loss: 0.130272
   Val Loss: 0.120830
   LR: 1.00e-05 | Time: 230.8s
============================================================
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_move_object_512/controlnet_move_object_best.pth
ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: 0.120830
[GPU MEM] End of Epoch 1 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 2 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 2 | Batch 0/400 | Loss: 0.267361 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 2 | Batch 5/400 | Loss: 0.090000 | LR: 9.99e-06
Epoch 2 | Batch 10/400 | Loss: 0.015490 | LR: 9.99e-06
Epoch 2 | Batch 15/400 | Loss: 0.178479 | LR: 9.99e-06
Epoch 2 | Batch 20/400 | Loss: 0.029773 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch20 allocated=9.44GB reserved=10.54GB
Epoch 2 | Batch 25/400 | Loss: 0.058768 | LR: 9.99e-06
Epoch 2 | Batch 30/400 | Loss: 0.175999 | LR: 9.99e-06
Epoch 2 | Batch 35/400 | Loss: 0.009452 | LR: 9.99e-06
Epoch 2 | Batch 40/400 | Loss: 0.128969 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch40 allocated=9.44GB reserved=10.59GB
Epoch 2 | Batch 45/400 | Loss: 0.143337 | LR: 9.99e-06
Epoch 2 | Batch 50/400 | Loss: 0.156608 | LR: 9.99e-06
Epoch 2 | Batch 55/400 | Loss: 0.054746 | LR: 9.99e-06
Epoch 2 | Batch 60/400 | Loss: 0.155832 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch60 allocated=9.44GB reserved=10.60GB
Epoch 2 | Batch 65/400 | Loss: 0.176958 | LR: 9.99e-06
Epoch 2 | Batch 70/400 | Loss: 0.232715 | LR: 9.99e-06
Epoch 2 | Batch 75/400 | Loss: 0.139397 | LR: 9.99e-06
Epoch 2 | Batch 80/400 | Loss: 0.105672 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch80 allocated=9.44GB reserved=10.50GB
Epoch 2 | Batch 85/400 | Loss: 0.216651 | LR: 9.99e-06
Epoch 2 | Batch 90/400 | Loss: 0.238072 | LR: 9.99e-06
Epoch 2 | Batch 95/400 | Loss: 0.060477 | LR: 9.99e-06
Epoch 2 | Batch 100/400 | Loss: 0.212114 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch100 allocated=9.44GB reserved=10.55GB
Epoch 2 | Batch 105/400 | Loss: 0.073506 | LR: 9.99e-06
Epoch 2 | Batch 110/400 | Loss: 0.133697 | LR: 9.99e-06
Epoch 2 | Batch 115/400 | Loss: 0.304477 | LR: 9.99e-06
Epoch 2 | Batch 120/400 | Loss: 0.012791 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch120 allocated=9.44GB reserved=10.57GB
Epoch 2 | Batch 125/400 | Loss: 0.116531 | LR: 9.99e-06
Epoch 2 | Batch 130/400 | Loss: 0.229415 | LR: 9.99e-06
Epoch 2 | Batch 135/400 | Loss: 0.120999 | LR: 9.99e-06
Epoch 2 | Batch 140/400 | Loss: 0.115845 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch140 allocated=9.44GB reserved=10.60GB
Epoch 2 | Batch 145/400 | Loss: 0.295569 | LR: 9.99e-06
Epoch 2 | Batch 150/400 | Loss: 0.290584 | LR: 9.99e-06
Epoch 2 | Batch 155/400 | Loss: 0.256643 | LR: 9.99e-06
Epoch 2 | Batch 160/400 | Loss: 0.345264 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch160 allocated=9.44GB reserved=10.54GB
Epoch 2 | Batch 165/400 | Loss: 0.102742 | LR: 9.99e-06
Epoch 2 | Batch 170/400 | Loss: 0.055203 | LR: 9.99e-06
Epoch 2 | Batch 175/400 | Loss: 0.124068 | LR: 9.99e-06
Epoch 2 | Batch 180/400 | Loss: 0.017221 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch180 allocated=9.44GB reserved=10.65GB
Epoch 2 | Batch 185/400 | Loss: 0.151553 | LR: 9.99e-06
Epoch 2 | Batch 190/400 | Loss: 0.019108 | LR: 9.99e-06
Epoch 2 | Batch 195/400 | Loss: 0.016956 | LR: 9.99e-06
Epoch 2 | Batch 200/400 | Loss: 0.041114 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch200 allocated=9.44GB reserved=10.62GB
Epoch 2 | Batch 205/400 | Loss: 0.015316 | LR: 9.99e-06
Epoch 2 | Batch 210/400 | Loss: 0.056338 | LR: 9.99e-06
Epoch 2 | Batch 215/400 | Loss: 0.187960 | LR: 9.99e-06
Epoch 2 | Batch 220/400 | Loss: 0.156849 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch220 allocated=9.44GB reserved=10.60GB
Epoch 2 | Batch 225/400 | Loss: 0.021415 | LR: 9.99e-06
Epoch 2 | Batch 230/400 | Loss: 0.083971 | LR: 9.99e-06
Epoch 2 | Batch 235/400 | Loss: 0.091487 | LR: 9.99e-06
Epoch 2 | Batch 240/400 | Loss: 0.149289 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch240 allocated=9.44GB reserved=10.60GB
Epoch 2 | Batch 245/400 | Loss: 0.530885 | LR: 9.99e-06
Epoch 2 | Batch 250/400 | Loss: 0.005662 | LR: 9.99e-06
Epoch 2 | Batch 255/400 | Loss: 0.247134 | LR: 9.99e-06
Epoch 2 | Batch 260/400 | Loss: 0.039886 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch260 allocated=9.44GB reserved=10.58GB
Epoch 2 | Batch 265/400 | Loss: 0.009204 | LR: 9.99e-06
Epoch 2 | Batch 270/400 | Loss: 0.058976 | LR: 9.99e-06
Epoch 2 | Batch 275/400 | Loss: 0.316663 | LR: 9.99e-06
Epoch 2 | Batch 280/400 | Loss: 0.010178 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch280 allocated=9.44GB reserved=10.61GB
Epoch 2 | Batch 285/400 | Loss: 0.476579 | LR: 9.99e-06
Epoch 2 | Batch 290/400 | Loss: 0.049026 | LR: 9.99e-06
Epoch 2 | Batch 295/400 | Loss: 0.299465 | LR: 9.99e-06
Epoch 2 | Batch 300/400 | Loss: 0.344974 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch300 allocated=9.44GB reserved=10.65GB
Epoch 2 | Batch 305/400 | Loss: 0.154357 | LR: 9.99e-06
Epoch 2 | Batch 310/400 | Loss: 0.036313 | LR: 9.99e-06
Epoch 2 | Batch 315/400 | Loss: 0.200714 | LR: 9.99e-06
Epoch 2 | Batch 320/400 | Loss: 0.130611 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch320 allocated=9.44GB reserved=10.57GB
Epoch 2 | Batch 325/400 | Loss: 0.289293 | LR: 9.99e-06
Epoch 2 | Batch 330/400 | Loss: 0.014693 | LR: 9.99e-06
Epoch 2 | Batch 335/400 | Loss: 0.142846 | LR: 9.99e-06
Epoch 2 | Batch 340/400 | Loss: 0.300694 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch340 allocated=9.44GB reserved=10.58GB
Epoch 2 | Batch 345/400 | Loss: 0.017120 | LR: 9.99e-06
Epoch 2 | Batch 350/400 | Loss: 0.191549 | LR: 9.99e-06
Epoch 2 | Batch 355/400 | Loss: 0.480467 | LR: 9.99e-06
Epoch 2 | Batch 360/400 | Loss: 0.087673 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch360 allocated=9.44GB reserved=10.63GB
Epoch 2 | Batch 365/400 | Loss: 0.135267 | LR: 9.99e-06
Epoch 2 | Batch 370/400 | Loss: 0.085121 | LR: 9.99e-06
Epoch 2 | Batch 375/400 | Loss: 0.158884 | LR: 9.99e-06
Epoch 2 | Batch 380/400 | Loss: 0.135040 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch380 allocated=9.44GB reserved=10.52GB
Epoch 2 | Batch 385/400 | Loss: 0.233693 | LR: 9.99e-06
Epoch 2 | Batch 390/400 | Loss: 0.021544 | LR: 9.99e-06
Epoch 2 | Batch 395/400 | Loss: 0.011606 | LR: 9.99e-06
âœ… ç¬¬ 2 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.140364
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.031864
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.091536
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.010624
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.008238
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.028094
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.152304
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.149764
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.151491
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.332970
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.026092
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.006880
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.126243
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.032026
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.023316
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.019431
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.444340
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.046225
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.153012

============================================================
ğŸ“Š Epoch 2/50 å®Œæˆ
   Train Loss: 0.140364
   Val Loss: 0.153012
   LR: 9.99e-06 | Time: 229.4s
============================================================
â³ æ—©åœè®¡æ•°: 1/10
[GPU MEM] End of Epoch 2 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 3 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 3 | Batch 0/400 | Loss: 0.563523 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 3 | Batch 5/400 | Loss: 0.088744 | LR: 9.96e-06
Epoch 3 | Batch 10/400 | Loss: 0.351814 | LR: 9.96e-06
Epoch 3 | Batch 15/400 | Loss: 0.510064 | LR: 9.96e-06
Epoch 3 | Batch 20/400 | Loss: 0.033247 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch20 allocated=9.44GB reserved=10.54GB
Epoch 3 | Batch 25/400 | Loss: 0.171656 | LR: 9.96e-06
Epoch 3 | Batch 30/400 | Loss: 0.087803 | LR: 9.96e-06
Epoch 3 | Batch 35/400 | Loss: 0.024053 | LR: 9.96e-06
Epoch 3 | Batch 40/400 | Loss: 0.042272 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch40 allocated=9.44GB reserved=10.59GB
Epoch 3 | Batch 45/400 | Loss: 0.257883 | LR: 9.96e-06
Epoch 3 | Batch 50/400 | Loss: 0.170028 | LR: 9.96e-06
Epoch 3 | Batch 55/400 | Loss: 0.177551 | LR: 9.96e-06
Epoch 3 | Batch 60/400 | Loss: 0.149344 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch60 allocated=9.44GB reserved=10.55GB
Epoch 3 | Batch 65/400 | Loss: 0.152464 | LR: 9.96e-06
Epoch 3 | Batch 70/400 | Loss: 0.051424 | LR: 9.96e-06
Epoch 3 | Batch 75/400 | Loss: 0.205722 | LR: 9.96e-06
Epoch 3 | Batch 80/400 | Loss: 0.183964 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch80 allocated=9.44GB reserved=10.57GB
Epoch 3 | Batch 85/400 | Loss: 0.116672 | LR: 9.96e-06
Epoch 3 | Batch 90/400 | Loss: 0.019855 | LR: 9.96e-06
Epoch 3 | Batch 95/400 | Loss: 0.056344 | LR: 9.96e-06
Epoch 3 | Batch 100/400 | Loss: 0.009949 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch100 allocated=9.44GB reserved=10.57GB
Epoch 3 | Batch 105/400 | Loss: 0.290948 | LR: 9.96e-06
Epoch 3 | Batch 110/400 | Loss: 0.116041 | LR: 9.96e-06
Epoch 3 | Batch 115/400 | Loss: 0.030456 | LR: 9.96e-06
Epoch 3 | Batch 120/400 | Loss: 0.079512 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch120 allocated=9.44GB reserved=10.54GB
Epoch 3 | Batch 125/400 | Loss: 0.084565 | LR: 9.96e-06
Epoch 3 | Batch 130/400 | Loss: 0.012627 | LR: 9.96e-06
Epoch 3 | Batch 135/400 | Loss: 0.020553 | LR: 9.96e-06
Epoch 3 | Batch 140/400 | Loss: 0.071157 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch140 allocated=9.44GB reserved=10.57GB
Epoch 3 | Batch 145/400 | Loss: 0.063116 | LR: 9.96e-06
Epoch 3 | Batch 150/400 | Loss: 0.264206 | LR: 9.96e-06
Epoch 3 | Batch 155/400 | Loss: 0.201017 | LR: 9.96e-06
Epoch 3 | Batch 160/400 | Loss: 0.318699 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch160 allocated=9.44GB reserved=10.53GB
Epoch 3 | Batch 165/400 | Loss: 0.166009 | LR: 9.96e-06
Epoch 3 | Batch 170/400 | Loss: 0.387950 | LR: 9.96e-06
Epoch 3 | Batch 175/400 | Loss: 0.021188 | LR: 9.96e-06
Epoch 3 | Batch 180/400 | Loss: 0.023002 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch180 allocated=9.43GB reserved=10.59GB
Epoch 3 | Batch 185/400 | Loss: 0.260399 | LR: 9.96e-06
Epoch 3 | Batch 190/400 | Loss: 0.038620 | LR: 9.96e-06
Epoch 3 | Batch 195/400 | Loss: 0.042139 | LR: 9.96e-06
Epoch 3 | Batch 200/400 | Loss: 0.022009 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch200 allocated=9.44GB reserved=10.56GB
Epoch 3 | Batch 205/400 | Loss: 0.083906 | LR: 9.96e-06
Epoch 3 | Batch 210/400 | Loss: 0.130528 | LR: 9.96e-06
Epoch 3 | Batch 215/400 | Loss: 0.098130 | LR: 9.96e-06
Epoch 3 | Batch 220/400 | Loss: 0.134242 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch220 allocated=9.44GB reserved=10.60GB
Epoch 3 | Batch 225/400 | Loss: 0.260391 | LR: 9.96e-06
Epoch 3 | Batch 230/400 | Loss: 0.009100 | LR: 9.96e-06
Epoch 3 | Batch 235/400 | Loss: 0.210588 | LR: 9.96e-06
Epoch 3 | Batch 240/400 | Loss: 0.424025 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch240 allocated=9.44GB reserved=10.62GB
Epoch 3 | Batch 245/400 | Loss: 0.027583 | LR: 9.96e-06
Epoch 3 | Batch 250/400 | Loss: 0.592533 | LR: 9.96e-06
Epoch 3 | Batch 255/400 | Loss: 0.056478 | LR: 9.96e-06
Epoch 3 | Batch 260/400 | Loss: 0.119376 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch260 allocated=9.44GB reserved=10.62GB
Epoch 3 | Batch 265/400 | Loss: 0.227233 | LR: 9.96e-06
Epoch 3 | Batch 270/400 | Loss: 0.449476 | LR: 9.96e-06
Epoch 3 | Batch 275/400 | Loss: 0.024759 | LR: 9.96e-06
Epoch 3 | Batch 280/400 | Loss: 0.085694 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch280 allocated=9.44GB reserved=10.66GB
Epoch 3 | Batch 285/400 | Loss: 0.131987 | LR: 9.96e-06
Epoch 3 | Batch 290/400 | Loss: 0.098581 | LR: 9.96e-06
Epoch 3 | Batch 295/400 | Loss: 0.012747 | LR: 9.96e-06
Epoch 3 | Batch 300/400 | Loss: 0.010336 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch300 allocated=9.44GB reserved=10.61GB
Epoch 3 | Batch 305/400 | Loss: 0.055921 | LR: 9.96e-06
Epoch 3 | Batch 310/400 | Loss: 0.021096 | LR: 9.96e-06
Epoch 3 | Batch 315/400 | Loss: 0.348143 | LR: 9.96e-06
Epoch 3 | Batch 320/400 | Loss: 0.008857 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch320 allocated=9.44GB reserved=10.55GB
Epoch 3 | Batch 325/400 | Loss: 0.036215 | LR: 9.96e-06
Epoch 3 | Batch 330/400 | Loss: 0.647944 | LR: 9.96e-06
Epoch 3 | Batch 335/400 | Loss: 0.209714 | LR: 9.96e-06
Epoch 3 | Batch 340/400 | Loss: 0.007910 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch340 allocated=9.44GB reserved=10.62GB
Epoch 3 | Batch 345/400 | Loss: 0.191683 | LR: 9.96e-06
Epoch 3 | Batch 350/400 | Loss: 0.374310 | LR: 9.96e-06
Epoch 3 | Batch 355/400 | Loss: 0.003759 | LR: 9.96e-06
Epoch 3 | Batch 360/400 | Loss: 0.018537 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch360 allocated=9.44GB reserved=10.60GB
Epoch 3 | Batch 365/400 | Loss: 0.028613 | LR: 9.96e-06
Epoch 3 | Batch 370/400 | Loss: 0.137301 | LR: 9.96e-06
Epoch 3 | Batch 375/400 | Loss: 0.108908 | LR: 9.96e-06
Epoch 3 | Batch 380/400 | Loss: 0.164378 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch380 allocated=9.44GB reserved=10.62GB
Epoch 3 | Batch 385/400 | Loss: 0.325965 | LR: 9.96e-06
Epoch 3 | Batch 390/400 | Loss: 0.187718 | LR: 9.96e-06
Epoch 3 | Batch 395/400 | Loss: 0.164661 | LR: 9.96e-06
âœ… ç¬¬ 3 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.137678
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.203364
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.079313
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.103892
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.128684
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.101727
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.190461
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.251904
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.205002
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.333954
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.067500
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.133368
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.046358
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.110998
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.117880
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.004764
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.009541
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.262336
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.167025

============================================================
ğŸ“Š Epoch 3/50 å®Œæˆ
   Train Loss: 0.137678
   Val Loss: 0.167025
   LR: 9.96e-06 | Time: 229.5s
============================================================
â³ æ—©åœè®¡æ•°: 2/10
[GPU MEM] End of Epoch 3 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 4 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 4 | Batch 0/400 | Loss: 0.036677 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 4 | Batch 5/400 | Loss: 0.025144 | LR: 9.91e-06
Epoch 4 | Batch 10/400 | Loss: 0.007709 | LR: 9.91e-06
Epoch 4 | Batch 15/400 | Loss: 0.025665 | LR: 9.91e-06
Epoch 4 | Batch 20/400 | Loss: 0.031908 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch20 allocated=9.44GB reserved=10.56GB
Epoch 4 | Batch 25/400 | Loss: 0.005148 | LR: 9.91e-06
Epoch 4 | Batch 30/400 | Loss: 0.112872 | LR: 9.91e-06
Epoch 4 | Batch 35/400 | Loss: 0.222837 | LR: 9.91e-06
Epoch 4 | Batch 40/400 | Loss: 0.183801 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch40 allocated=9.44GB reserved=10.55GB
Epoch 4 | Batch 45/400 | Loss: 0.545699 | LR: 9.91e-06
Epoch 4 | Batch 50/400 | Loss: 0.026516 | LR: 9.91e-06
Epoch 4 | Batch 55/400 | Loss: 0.023544 | LR: 9.91e-06
Epoch 4 | Batch 60/400 | Loss: 0.505980 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch60 allocated=9.44GB reserved=10.54GB
Epoch 4 | Batch 65/400 | Loss: 0.204148 | LR: 9.91e-06
Epoch 4 | Batch 70/400 | Loss: 0.125688 | LR: 9.91e-06
Epoch 4 | Batch 75/400 | Loss: 0.008040 | LR: 9.91e-06
Epoch 4 | Batch 80/400 | Loss: 0.064387 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch80 allocated=9.44GB reserved=10.52GB
Epoch 4 | Batch 85/400 | Loss: 0.374132 | LR: 9.91e-06
Epoch 4 | Batch 90/400 | Loss: 0.058470 | LR: 9.91e-06
Epoch 4 | Batch 95/400 | Loss: 0.256019 | LR: 9.91e-06
Epoch 4 | Batch 100/400 | Loss: 0.162233 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch100 allocated=9.44GB reserved=10.52GB
Epoch 4 | Batch 105/400 | Loss: 0.115879 | LR: 9.91e-06
Epoch 4 | Batch 110/400 | Loss: 0.204585 | LR: 9.91e-06
Epoch 4 | Batch 115/400 | Loss: 0.026532 | LR: 9.91e-06
Epoch 4 | Batch 120/400 | Loss: 0.095166 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch120 allocated=9.44GB reserved=10.52GB
Epoch 4 | Batch 125/400 | Loss: 0.194890 | LR: 9.91e-06
Epoch 4 | Batch 130/400 | Loss: 0.108324 | LR: 9.91e-06
Epoch 4 | Batch 135/400 | Loss: 0.098618 | LR: 9.91e-06
Epoch 4 | Batch 140/400 | Loss: 0.010358 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch140 allocated=9.44GB reserved=10.54GB
Epoch 4 | Batch 145/400 | Loss: 0.137162 | LR: 9.91e-06
Epoch 4 | Batch 150/400 | Loss: 0.030634 | LR: 9.91e-06
Epoch 4 | Batch 155/400 | Loss: 0.040973 | LR: 9.91e-06
Epoch 4 | Batch 160/400 | Loss: 0.079588 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch160 allocated=9.44GB reserved=10.62GB
Epoch 4 | Batch 165/400 | Loss: 0.250960 | LR: 9.91e-06
Epoch 4 | Batch 170/400 | Loss: 0.140325 | LR: 9.91e-06
Epoch 4 | Batch 175/400 | Loss: 0.028253 | LR: 9.91e-06
Epoch 4 | Batch 180/400 | Loss: 0.335200 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch180 allocated=9.44GB reserved=10.55GB
Epoch 4 | Batch 185/400 | Loss: 0.299963 | LR: 9.91e-06
Epoch 4 | Batch 190/400 | Loss: 0.174269 | LR: 9.91e-06
Epoch 4 | Batch 195/400 | Loss: 0.106013 | LR: 9.91e-06
Epoch 4 | Batch 200/400 | Loss: 0.057508 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch200 allocated=9.44GB reserved=10.59GB
Epoch 4 | Batch 205/400 | Loss: 0.233062 | LR: 9.91e-06
Epoch 4 | Batch 210/400 | Loss: 0.061659 | LR: 9.91e-06
Epoch 4 | Batch 215/400 | Loss: 0.433291 | LR: 9.91e-06
Epoch 4 | Batch 220/400 | Loss: 0.146623 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch220 allocated=9.44GB reserved=10.60GB
Epoch 4 | Batch 225/400 | Loss: 0.207635 | LR: 9.91e-06
Epoch 4 | Batch 230/400 | Loss: 0.222332 | LR: 9.91e-06
Epoch 4 | Batch 235/400 | Loss: 0.142156 | LR: 9.91e-06
Epoch 4 | Batch 240/400 | Loss: 0.190206 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch240 allocated=9.44GB reserved=10.60GB
Epoch 4 | Batch 245/400 | Loss: 0.238184 | LR: 9.91e-06
Epoch 4 | Batch 250/400 | Loss: 0.093739 | LR: 9.91e-06
Epoch 4 | Batch 255/400 | Loss: 0.064109 | LR: 9.91e-06
Epoch 4 | Batch 260/400 | Loss: 0.021250 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch260 allocated=9.44GB reserved=10.56GB
Epoch 4 | Batch 265/400 | Loss: 0.047518 | LR: 9.91e-06
Epoch 4 | Batch 270/400 | Loss: 0.093561 | LR: 9.91e-06
Epoch 4 | Batch 275/400 | Loss: 0.066225 | LR: 9.91e-06
Epoch 4 | Batch 280/400 | Loss: 0.050721 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch280 allocated=9.44GB reserved=10.65GB
Epoch 4 | Batch 285/400 | Loss: 0.047924 | LR: 9.91e-06
Epoch 4 | Batch 290/400 | Loss: 0.035322 | LR: 9.91e-06
Epoch 4 | Batch 295/400 | Loss: 0.211562 | LR: 9.91e-06
Epoch 4 | Batch 300/400 | Loss: 0.026589 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch300 allocated=9.43GB reserved=10.55GB
Epoch 4 | Batch 305/400 | Loss: 0.050745 | LR: 9.91e-06
Epoch 4 | Batch 310/400 | Loss: 0.020642 | LR: 9.91e-06
Epoch 4 | Batch 315/400 | Loss: 0.031656 | LR: 9.91e-06
Epoch 4 | Batch 320/400 | Loss: 0.124973 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch320 allocated=9.44GB reserved=10.54GB
Epoch 4 | Batch 325/400 | Loss: 0.048081 | LR: 9.91e-06
Epoch 4 | Batch 330/400 | Loss: 0.063821 | LR: 9.91e-06
Epoch 4 | Batch 335/400 | Loss: 0.115106 | LR: 9.91e-06
Epoch 4 | Batch 340/400 | Loss: 0.016198 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch340 allocated=9.44GB reserved=10.53GB
Epoch 4 | Batch 345/400 | Loss: 0.224581 | LR: 9.91e-06
Epoch 4 | Batch 350/400 | Loss: 0.032540 | LR: 9.91e-06
Epoch 4 | Batch 355/400 | Loss: 0.152830 | LR: 9.91e-06
Epoch 4 | Batch 360/400 | Loss: 0.257621 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch360 allocated=9.44GB reserved=10.58GB
Epoch 4 | Batch 365/400 | Loss: 0.103984 | LR: 9.91e-06
Epoch 4 | Batch 370/400 | Loss: 0.032708 | LR: 9.91e-06
Epoch 4 | Batch 375/400 | Loss: 0.178322 | LR: 9.91e-06
Epoch 4 | Batch 380/400 | Loss: 0.077328 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch380 allocated=9.44GB reserved=10.53GB
Epoch 4 | Batch 385/400 | Loss: 0.200251 | LR: 9.91e-06
Epoch 4 | Batch 390/400 | Loss: 0.017277 | LR: 9.91e-06
Epoch 4 | Batch 395/400 | Loss: 0.072995 | LR: 9.91e-06
âœ… ç¬¬ 4 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.133534
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.034817
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.170597
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.069857
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.003615
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.031990
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.062746
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.217319
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.274509
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.098272
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.005848
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.009083
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.320941
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.022779
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.439247
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.321797
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.147598
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.188154
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.124303

============================================================
ğŸ“Š Epoch 4/50 å®Œæˆ
   Train Loss: 0.133534
   Val Loss: 0.124303
   LR: 9.91e-06 | Time: 230.7s
============================================================
â³ æ—©åœè®¡æ•°: 3/10
[GPU MEM] End of Epoch 4 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 5 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 5 | Batch 0/400 | Loss: 0.080999 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 5 | Batch 5/400 | Loss: 0.092306 | LR: 9.84e-06
Epoch 5 | Batch 10/400 | Loss: 0.270315 | LR: 9.84e-06
Epoch 5 | Batch 15/400 | Loss: 0.138286 | LR: 9.84e-06
Epoch 5 | Batch 20/400 | Loss: 0.040386 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch20 allocated=9.44GB reserved=10.55GB
Epoch 5 | Batch 25/400 | Loss: 0.180926 | LR: 9.84e-06
Epoch 5 | Batch 30/400 | Loss: 0.387382 | LR: 9.84e-06
Epoch 5 | Batch 35/400 | Loss: 0.073864 | LR: 9.84e-06
Epoch 5 | Batch 40/400 | Loss: 0.173405 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch40 allocated=9.44GB reserved=10.58GB
Epoch 5 | Batch 45/400 | Loss: 0.451141 | LR: 9.84e-06
Epoch 5 | Batch 50/400 | Loss: 0.056278 | LR: 9.84e-06
Epoch 5 | Batch 55/400 | Loss: 0.054407 | LR: 9.84e-06
Epoch 5 | Batch 60/400 | Loss: 0.026285 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch60 allocated=9.44GB reserved=10.53GB
Epoch 5 | Batch 65/400 | Loss: 0.145137 | LR: 9.84e-06
Epoch 5 | Batch 70/400 | Loss: 0.094603 | LR: 9.84e-06
Epoch 5 | Batch 75/400 | Loss: 0.114832 | LR: 9.84e-06
Epoch 5 | Batch 80/400 | Loss: 0.087318 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch80 allocated=9.44GB reserved=10.62GB
Epoch 5 | Batch 85/400 | Loss: 0.057589 | LR: 9.84e-06
Epoch 5 | Batch 90/400 | Loss: 0.020896 | LR: 9.84e-06
Epoch 5 | Batch 95/400 | Loss: 0.142164 | LR: 9.84e-06
Epoch 5 | Batch 100/400 | Loss: 0.033876 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch100 allocated=9.44GB reserved=10.57GB
Epoch 5 | Batch 105/400 | Loss: 0.118843 | LR: 9.84e-06
Epoch 5 | Batch 110/400 | Loss: 0.030342 | LR: 9.84e-06
Epoch 5 | Batch 115/400 | Loss: 0.291545 | LR: 9.84e-06
Epoch 5 | Batch 120/400 | Loss: 0.073651 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch120 allocated=9.44GB reserved=10.60GB
Epoch 5 | Batch 125/400 | Loss: 0.185280 | LR: 9.84e-06
Epoch 5 | Batch 130/400 | Loss: 0.189154 | LR: 9.84e-06
Epoch 5 | Batch 135/400 | Loss: 0.328592 | LR: 9.84e-06
Epoch 5 | Batch 140/400 | Loss: 0.030750 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch140 allocated=9.44GB reserved=10.60GB
Epoch 5 | Batch 145/400 | Loss: 0.215878 | LR: 9.84e-06
Epoch 5 | Batch 150/400 | Loss: 0.121155 | LR: 9.84e-06
Epoch 5 | Batch 155/400 | Loss: 0.326002 | LR: 9.84e-06
Epoch 5 | Batch 160/400 | Loss: 0.299225 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch160 allocated=9.44GB reserved=10.60GB
Epoch 5 | Batch 165/400 | Loss: 0.169953 | LR: 9.84e-06
Epoch 5 | Batch 170/400 | Loss: 0.202211 | LR: 9.84e-06
Epoch 5 | Batch 175/400 | Loss: 0.204803 | LR: 9.84e-06
Epoch 5 | Batch 180/400 | Loss: 0.057582 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch180 allocated=9.44GB reserved=10.55GB
Epoch 5 | Batch 185/400 | Loss: 0.325846 | LR: 9.84e-06
Epoch 5 | Batch 190/400 | Loss: 0.056676 | LR: 9.84e-06
Epoch 5 | Batch 195/400 | Loss: 0.343829 | LR: 9.84e-06
Epoch 5 | Batch 200/400 | Loss: 0.129253 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch200 allocated=9.44GB reserved=10.54GB
Epoch 5 | Batch 205/400 | Loss: 0.159270 | LR: 9.84e-06
Epoch 5 | Batch 210/400 | Loss: 0.005824 | LR: 9.84e-06
Epoch 5 | Batch 215/400 | Loss: 0.012339 | LR: 9.84e-06
Epoch 5 | Batch 220/400 | Loss: 0.046465 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch220 allocated=9.44GB reserved=10.53GB
Epoch 5 | Batch 225/400 | Loss: 0.051204 | LR: 9.84e-06
Epoch 5 | Batch 230/400 | Loss: 0.024867 | LR: 9.84e-06
Epoch 5 | Batch 235/400 | Loss: 0.330771 | LR: 9.84e-06
Epoch 5 | Batch 240/400 | Loss: 0.141325 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch240 allocated=9.44GB reserved=10.59GB
Epoch 5 | Batch 245/400 | Loss: 0.023896 | LR: 9.84e-06
Epoch 5 | Batch 250/400 | Loss: 0.065620 | LR: 9.84e-06
Epoch 5 | Batch 255/400 | Loss: 0.103868 | LR: 9.84e-06
Epoch 5 | Batch 260/400 | Loss: 0.009332 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch260 allocated=9.44GB reserved=10.55GB
Epoch 5 | Batch 265/400 | Loss: 0.060986 | LR: 9.84e-06
Epoch 5 | Batch 270/400 | Loss: 0.114486 | LR: 9.84e-06
Epoch 5 | Batch 275/400 | Loss: 0.149007 | LR: 9.84e-06
Epoch 5 | Batch 280/400 | Loss: 0.128334 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch280 allocated=9.44GB reserved=10.59GB
Epoch 5 | Batch 285/400 | Loss: 0.003352 | LR: 9.84e-06
Epoch 5 | Batch 290/400 | Loss: 0.050428 | LR: 9.84e-06
Epoch 5 | Batch 295/400 | Loss: 0.134906 | LR: 9.84e-06
Epoch 5 | Batch 300/400 | Loss: 0.273357 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch300 allocated=9.43GB reserved=10.57GB
Epoch 5 | Batch 305/400 | Loss: 0.393150 | LR: 9.84e-06
Epoch 5 | Batch 310/400 | Loss: 0.009869 | LR: 9.84e-06
Epoch 5 | Batch 315/400 | Loss: 0.005896 | LR: 9.84e-06
Epoch 5 | Batch 320/400 | Loss: 0.147711 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch320 allocated=9.44GB reserved=10.54GB
Epoch 5 | Batch 325/400 | Loss: 0.158488 | LR: 9.84e-06
Epoch 5 | Batch 330/400 | Loss: 0.142688 | LR: 9.84e-06
Epoch 5 | Batch 335/400 | Loss: 0.104959 | LR: 9.84e-06
Epoch 5 | Batch 340/400 | Loss: 0.154089 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch340 allocated=9.44GB reserved=10.58GB
Epoch 5 | Batch 345/400 | Loss: 0.134936 | LR: 9.84e-06
Epoch 5 | Batch 350/400 | Loss: 0.120954 | LR: 9.84e-06
Epoch 5 | Batch 355/400 | Loss: 0.033627 | LR: 9.84e-06
Epoch 5 | Batch 360/400 | Loss: 0.139997 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch360 allocated=9.44GB reserved=10.54GB
Epoch 5 | Batch 365/400 | Loss: 0.135271 | LR: 9.84e-06
Epoch 5 | Batch 370/400 | Loss: 0.267220 | LR: 9.84e-06
Epoch 5 | Batch 375/400 | Loss: 0.356659 | LR: 9.84e-06
Epoch 5 | Batch 380/400 | Loss: 0.045339 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch380 allocated=9.44GB reserved=10.58GB
Epoch 5 | Batch 385/400 | Loss: 0.207278 | LR: 9.84e-06
Epoch 5 | Batch 390/400 | Loss: 0.194203 | LR: 9.84e-06
Epoch 5 | Batch 395/400 | Loss: 0.073488 | LR: 9.84e-06
âœ… ç¬¬ 5 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.128502
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.028263
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.117400
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.135653
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.107910
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.016273
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.496559
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.023995
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.442067
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.022036
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.264208
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.050815
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.142290
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.137582
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.147183
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.272679
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.069710
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.061035
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.134365
ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆ Epoch 5 çš„é¢„è§ˆå›¾...
âœ¨ é¢„è§ˆå›¾å·²ä¿å­˜åˆ° training_results_move_object_512

============================================================
ğŸ“Š Epoch 5/50 å®Œæˆ
   Train Loss: 0.128502
   Val Loss: 0.134365
   LR: 9.84e-06 | Time: 239.1s
============================================================
â³ æ—©åœè®¡æ•°: 4/10
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_move_object_512/controlnet_move_object_epoch_5.pth
[GPU MEM] End of Epoch 5 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 6 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 6 | Batch 0/400 | Loss: 0.093579 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 6 | Batch 5/400 | Loss: 0.223188 | LR: 9.76e-06
Epoch 6 | Batch 10/400 | Loss: 0.009837 | LR: 9.76e-06
Epoch 6 | Batch 15/400 | Loss: 0.035347 | LR: 9.76e-06
Epoch 6 | Batch 20/400 | Loss: 0.036756 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch20 allocated=9.44GB reserved=10.55GB
Epoch 6 | Batch 25/400 | Loss: 0.167054 | LR: 9.76e-06
Epoch 6 | Batch 30/400 | Loss: 0.095299 | LR: 9.76e-06
Epoch 6 | Batch 35/400 | Loss: 0.099548 | LR: 9.76e-06
Epoch 6 | Batch 40/400 | Loss: 0.249298 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch40 allocated=9.44GB reserved=10.60GB
Epoch 6 | Batch 45/400 | Loss: 0.199948 | LR: 9.76e-06
Epoch 6 | Batch 50/400 | Loss: 0.015336 | LR: 9.76e-06
Epoch 6 | Batch 55/400 | Loss: 0.011968 | LR: 9.76e-06
Epoch 6 | Batch 60/400 | Loss: 0.242473 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch60 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 65/400 | Loss: 0.211137 | LR: 9.76e-06
Epoch 6 | Batch 70/400 | Loss: 0.059209 | LR: 9.76e-06
Epoch 6 | Batch 75/400 | Loss: 0.042225 | LR: 9.76e-06
Epoch 6 | Batch 80/400 | Loss: 0.022068 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch80 allocated=9.44GB reserved=10.55GB
Epoch 6 | Batch 85/400 | Loss: 0.075977 | LR: 9.76e-06
Epoch 6 | Batch 90/400 | Loss: 0.016391 | LR: 9.76e-06
Epoch 6 | Batch 95/400 | Loss: 0.013761 | LR: 9.76e-06
Epoch 6 | Batch 100/400 | Loss: 0.283491 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch100 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 105/400 | Loss: 0.158333 | LR: 9.76e-06
Epoch 6 | Batch 110/400 | Loss: 0.026278 | LR: 9.76e-06
Epoch 6 | Batch 115/400 | Loss: 0.012595 | LR: 9.76e-06
Epoch 6 | Batch 120/400 | Loss: 0.259357 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch120 allocated=9.44GB reserved=10.55GB
Epoch 6 | Batch 125/400 | Loss: 0.058372 | LR: 9.76e-06
Epoch 6 | Batch 130/400 | Loss: 0.402929 | LR: 9.76e-06
Epoch 6 | Batch 135/400 | Loss: 0.399317 | LR: 9.76e-06
Epoch 6 | Batch 140/400 | Loss: 0.089885 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch140 allocated=9.44GB reserved=10.60GB
Epoch 6 | Batch 145/400 | Loss: 0.052339 | LR: 9.76e-06
Epoch 6 | Batch 150/400 | Loss: 0.131009 | LR: 9.76e-06
Epoch 6 | Batch 155/400 | Loss: 0.062071 | LR: 9.76e-06
Epoch 6 | Batch 160/400 | Loss: 0.079021 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch160 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 165/400 | Loss: 0.035253 | LR: 9.76e-06
Epoch 6 | Batch 170/400 | Loss: 0.041639 | LR: 9.76e-06
Epoch 6 | Batch 175/400 | Loss: 0.007915 | LR: 9.76e-06
Epoch 6 | Batch 180/400 | Loss: 0.058747 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch180 allocated=9.44GB reserved=10.57GB
Epoch 6 | Batch 185/400 | Loss: 0.079924 | LR: 9.76e-06
Epoch 6 | Batch 190/400 | Loss: 0.102203 | LR: 9.76e-06
Epoch 6 | Batch 195/400 | Loss: 0.064461 | LR: 9.76e-06
Epoch 6 | Batch 200/400 | Loss: 0.010747 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch200 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 205/400 | Loss: 0.002761 | LR: 9.76e-06
Epoch 6 | Batch 210/400 | Loss: 0.089125 | LR: 9.76e-06
Epoch 6 | Batch 215/400 | Loss: 0.052886 | LR: 9.76e-06
Epoch 6 | Batch 220/400 | Loss: 0.070073 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch220 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 225/400 | Loss: 0.237936 | LR: 9.76e-06
Epoch 6 | Batch 230/400 | Loss: 0.014152 | LR: 9.76e-06
Epoch 6 | Batch 235/400 | Loss: 0.149746 | LR: 9.76e-06
Epoch 6 | Batch 240/400 | Loss: 0.187656 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch240 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 245/400 | Loss: 0.005724 | LR: 9.76e-06
Epoch 6 | Batch 250/400 | Loss: 0.333991 | LR: 9.76e-06
Epoch 6 | Batch 255/400 | Loss: 0.007743 | LR: 9.76e-06
Epoch 6 | Batch 260/400 | Loss: 0.015017 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch260 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 265/400 | Loss: 0.051821 | LR: 9.76e-06
Epoch 6 | Batch 270/400 | Loss: 0.078299 | LR: 9.76e-06
Epoch 6 | Batch 275/400 | Loss: 0.105377 | LR: 9.76e-06
Epoch 6 | Batch 280/400 | Loss: 0.072131 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch280 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 285/400 | Loss: 0.101260 | LR: 9.76e-06
Epoch 6 | Batch 290/400 | Loss: 0.461940 | LR: 9.76e-06
Epoch 6 | Batch 295/400 | Loss: 0.255446 | LR: 9.76e-06
Epoch 6 | Batch 300/400 | Loss: 0.046268 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch300 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 305/400 | Loss: 0.012286 | LR: 9.76e-06
Epoch 6 | Batch 310/400 | Loss: 0.158105 | LR: 9.76e-06
Epoch 6 | Batch 315/400 | Loss: 0.142775 | LR: 9.76e-06
Epoch 6 | Batch 320/400 | Loss: 0.032349 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch320 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 325/400 | Loss: 0.149249 | LR: 9.76e-06
Epoch 6 | Batch 330/400 | Loss: 0.160434 | LR: 9.76e-06
Epoch 6 | Batch 335/400 | Loss: 0.051944 | LR: 9.76e-06
Epoch 6 | Batch 340/400 | Loss: 0.054219 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch340 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 345/400 | Loss: 0.060718 | LR: 9.76e-06
Epoch 6 | Batch 350/400 | Loss: 0.184951 | LR: 9.76e-06
Epoch 6 | Batch 355/400 | Loss: 0.055342 | LR: 9.76e-06
Epoch 6 | Batch 360/400 | Loss: 0.228587 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch360 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 365/400 | Loss: 0.287755 | LR: 9.76e-06
Epoch 6 | Batch 370/400 | Loss: 0.034662 | LR: 9.76e-06
Epoch 6 | Batch 375/400 | Loss: 0.153703 | LR: 9.76e-06
Epoch 6 | Batch 380/400 | Loss: 0.063518 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch380 allocated=9.44GB reserved=10.59GB
Epoch 6 | Batch 385/400 | Loss: 0.162440 | LR: 9.76e-06
Epoch 6 | Batch 390/400 | Loss: 0.026195 | LR: 9.76e-06
Epoch 6 | Batch 395/400 | Loss: 0.087373 | LR: 9.76e-06
âœ… ç¬¬ 6 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.120289
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.247407
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.084402
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.292432
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.126594
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.011102
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.127058
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.124365
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.060100
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.093614
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.113648
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.123125
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.205572
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.259249
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.109600
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.122828
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.030988
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.276362
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.124496

============================================================
ğŸ“Š Epoch 6/50 å®Œæˆ
   Train Loss: 0.120289
   Val Loss: 0.124496
   LR: 9.76e-06 | Time: 128.3s
============================================================
â³ æ—©åœè®¡æ•°: 5/10
[GPU MEM] End of Epoch 6 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 7 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 7 | Batch 0/400 | Loss: 0.170973 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 7 | Batch 5/400 | Loss: 0.221027 | LR: 9.65e-06
Epoch 7 | Batch 10/400 | Loss: 0.117231 | LR: 9.65e-06
Epoch 7 | Batch 15/400 | Loss: 0.068917 | LR: 9.65e-06
Epoch 7 | Batch 20/400 | Loss: 0.056498 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch20 allocated=9.44GB reserved=10.56GB
Epoch 7 | Batch 25/400 | Loss: 0.105094 | LR: 9.65e-06
Epoch 7 | Batch 30/400 | Loss: 0.065458 | LR: 9.65e-06
Epoch 7 | Batch 35/400 | Loss: 0.006674 | LR: 9.65e-06
Epoch 7 | Batch 40/400 | Loss: 0.320582 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch40 allocated=9.44GB reserved=10.59GB
Epoch 7 | Batch 45/400 | Loss: 0.450889 | LR: 9.65e-06
Epoch 7 | Batch 50/400 | Loss: 0.188793 | LR: 9.65e-06
Epoch 7 | Batch 55/400 | Loss: 0.150792 | LR: 9.65e-06
Epoch 7 | Batch 60/400 | Loss: 0.005562 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch60 allocated=9.44GB reserved=10.55GB
Epoch 7 | Batch 65/400 | Loss: 0.127049 | LR: 9.65e-06
Epoch 7 | Batch 70/400 | Loss: 0.238362 | LR: 9.65e-06
Epoch 7 | Batch 75/400 | Loss: 0.067698 | LR: 9.65e-06
Epoch 7 | Batch 80/400 | Loss: 0.042994 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch80 allocated=9.44GB reserved=10.64GB
Epoch 7 | Batch 85/400 | Loss: 0.108013 | LR: 9.65e-06
Epoch 7 | Batch 90/400 | Loss: 0.097525 | LR: 9.65e-06
Epoch 7 | Batch 95/400 | Loss: 0.080017 | LR: 9.65e-06
Epoch 7 | Batch 100/400 | Loss: 0.067378 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch100 allocated=9.44GB reserved=10.62GB
Epoch 7 | Batch 105/400 | Loss: 0.298338 | LR: 9.65e-06
Epoch 7 | Batch 110/400 | Loss: 0.038704 | LR: 9.65e-06
Epoch 7 | Batch 115/400 | Loss: 0.202717 | LR: 9.65e-06
Epoch 7 | Batch 120/400 | Loss: 0.034900 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch120 allocated=9.44GB reserved=10.62GB
Epoch 7 | Batch 125/400 | Loss: 0.122636 | LR: 9.65e-06
Epoch 7 | Batch 130/400 | Loss: 0.319600 | LR: 9.65e-06
Epoch 7 | Batch 135/400 | Loss: 0.272747 | LR: 9.65e-06
Epoch 7 | Batch 140/400 | Loss: 0.017812 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch140 allocated=9.44GB reserved=10.56GB
Epoch 7 | Batch 145/400 | Loss: 0.181037 | LR: 9.65e-06
Epoch 7 | Batch 150/400 | Loss: 0.016763 | LR: 9.65e-06
Epoch 7 | Batch 155/400 | Loss: 0.395714 | LR: 9.65e-06
Epoch 7 | Batch 160/400 | Loss: 0.084827 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch160 allocated=9.43GB reserved=10.54GB
Epoch 7 | Batch 165/400 | Loss: 0.643245 | LR: 9.65e-06
Epoch 7 | Batch 170/400 | Loss: 0.073424 | LR: 9.65e-06
Epoch 7 | Batch 175/400 | Loss: 0.312572 | LR: 9.65e-06
Epoch 7 | Batch 180/400 | Loss: 0.026621 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch180 allocated=9.44GB reserved=10.53GB
Epoch 7 | Batch 185/400 | Loss: 0.051337 | LR: 9.65e-06
Epoch 7 | Batch 190/400 | Loss: 0.165683 | LR: 9.65e-06
Epoch 7 | Batch 195/400 | Loss: 0.053764 | LR: 9.65e-06
Epoch 7 | Batch 200/400 | Loss: 0.038539 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch200 allocated=9.44GB reserved=10.53GB
Epoch 7 | Batch 205/400 | Loss: 0.116248 | LR: 9.65e-06
Epoch 7 | Batch 210/400 | Loss: 0.106726 | LR: 9.65e-06
Epoch 7 | Batch 215/400 | Loss: 0.018921 | LR: 9.65e-06
Epoch 7 | Batch 220/400 | Loss: 0.014312 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch220 allocated=9.44GB reserved=10.53GB
Epoch 7 | Batch 225/400 | Loss: 0.138539 | LR: 9.65e-06
Epoch 7 | Batch 230/400 | Loss: 0.010212 | LR: 9.65e-06
Epoch 7 | Batch 235/400 | Loss: 0.028373 | LR: 9.65e-06
Epoch 7 | Batch 240/400 | Loss: 0.028410 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch240 allocated=9.43GB reserved=10.60GB
Epoch 7 | Batch 245/400 | Loss: 0.103737 | LR: 9.65e-06
Epoch 7 | Batch 250/400 | Loss: 0.064647 | LR: 9.65e-06
Epoch 7 | Batch 255/400 | Loss: 0.010359 | LR: 9.65e-06
Epoch 7 | Batch 260/400 | Loss: 0.161577 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch260 allocated=9.44GB reserved=10.56GB
Epoch 7 | Batch 265/400 | Loss: 0.162884 | LR: 9.65e-06
Epoch 7 | Batch 270/400 | Loss: 0.145000 | LR: 9.65e-06
Epoch 7 | Batch 275/400 | Loss: 0.461695 | LR: 9.65e-06
Epoch 7 | Batch 280/400 | Loss: 0.451579 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch280 allocated=9.44GB reserved=10.58GB
Epoch 7 | Batch 285/400 | Loss: 0.099087 | LR: 9.65e-06
Epoch 7 | Batch 290/400 | Loss: 0.096328 | LR: 9.65e-06
Epoch 7 | Batch 295/400 | Loss: 0.246124 | LR: 9.65e-06
Epoch 7 | Batch 300/400 | Loss: 0.120824 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch300 allocated=9.44GB reserved=10.58GB
Epoch 7 | Batch 305/400 | Loss: 0.236331 | LR: 9.65e-06
Epoch 7 | Batch 310/400 | Loss: 0.057768 | LR: 9.65e-06
Epoch 7 | Batch 315/400 | Loss: 0.440356 | LR: 9.65e-06
Epoch 7 | Batch 320/400 | Loss: 0.508118 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch320 allocated=9.43GB reserved=10.60GB
Epoch 7 | Batch 325/400 | Loss: 0.023551 | LR: 9.65e-06
Epoch 7 | Batch 330/400 | Loss: 0.427508 | LR: 9.65e-06
Epoch 7 | Batch 335/400 | Loss: 0.125068 | LR: 9.65e-06
Epoch 7 | Batch 340/400 | Loss: 0.014707 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch340 allocated=9.44GB reserved=10.55GB
Epoch 7 | Batch 345/400 | Loss: 0.033589 | LR: 9.65e-06
Epoch 7 | Batch 350/400 | Loss: 0.060054 | LR: 9.65e-06
Epoch 7 | Batch 355/400 | Loss: 0.163209 | LR: 9.65e-06
Epoch 7 | Batch 360/400 | Loss: 0.035378 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch360 allocated=9.44GB reserved=10.62GB
Epoch 7 | Batch 365/400 | Loss: 0.014404 | LR: 9.65e-06
Epoch 7 | Batch 370/400 | Loss: 0.236181 | LR: 9.65e-06
Epoch 7 | Batch 375/400 | Loss: 0.050108 | LR: 9.65e-06
Epoch 7 | Batch 380/400 | Loss: 0.178396 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch380 allocated=9.44GB reserved=10.52GB
Epoch 7 | Batch 385/400 | Loss: 0.048776 | LR: 9.65e-06
Epoch 7 | Batch 390/400 | Loss: 0.011393 | LR: 9.65e-06
Epoch 7 | Batch 395/400 | Loss: 0.192443 | LR: 9.65e-06
âœ… ç¬¬ 7 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.135259
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.288923
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.221903
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.078438
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.064552
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.047152
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.111248
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.223173
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.104679
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.021768
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.050639
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.165234
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.042700
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.245554
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.209763
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.028374
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.026841
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.110475
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.131612

============================================================
ğŸ“Š Epoch 7/50 å®Œæˆ
   Train Loss: 0.135259
   Val Loss: 0.131612
   LR: 9.65e-06 | Time: 128.8s
============================================================
â³ æ—©åœè®¡æ•°: 6/10
[GPU MEM] End of Epoch 7 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 8 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 8 | Batch 0/400 | Loss: 0.364700 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 8 | Batch 5/400 | Loss: 0.144186 | LR: 9.53e-06
Epoch 8 | Batch 10/400 | Loss: 0.013893 | LR: 9.53e-06
Epoch 8 | Batch 15/400 | Loss: 0.141208 | LR: 9.53e-06
Epoch 8 | Batch 20/400 | Loss: 0.384361 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch20 allocated=9.44GB reserved=10.56GB
Epoch 8 | Batch 25/400 | Loss: 0.007001 | LR: 9.53e-06
Epoch 8 | Batch 30/400 | Loss: 0.007309 | LR: 9.53e-06
Epoch 8 | Batch 35/400 | Loss: 0.063562 | LR: 9.53e-06
Epoch 8 | Batch 40/400 | Loss: 0.089324 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch40 allocated=9.44GB reserved=10.55GB
Epoch 8 | Batch 45/400 | Loss: 0.024752 | LR: 9.53e-06
Epoch 8 | Batch 50/400 | Loss: 0.044010 | LR: 9.53e-06
Epoch 8 | Batch 55/400 | Loss: 0.048772 | LR: 9.53e-06
Epoch 8 | Batch 60/400 | Loss: 0.037521 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch60 allocated=9.44GB reserved=10.55GB
Epoch 8 | Batch 65/400 | Loss: 0.066174 | LR: 9.53e-06
Epoch 8 | Batch 70/400 | Loss: 0.027819 | LR: 9.53e-06
Epoch 8 | Batch 75/400 | Loss: 0.090872 | LR: 9.53e-06
Epoch 8 | Batch 80/400 | Loss: 0.015766 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch80 allocated=9.44GB reserved=10.59GB
Epoch 8 | Batch 85/400 | Loss: 0.428837 | LR: 9.53e-06
Epoch 8 | Batch 90/400 | Loss: 0.050482 | LR: 9.53e-06
Epoch 8 | Batch 95/400 | Loss: 0.152375 | LR: 9.53e-06
Epoch 8 | Batch 100/400 | Loss: 0.068973 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch100 allocated=9.44GB reserved=10.56GB
Epoch 8 | Batch 105/400 | Loss: 0.214321 | LR: 9.53e-06
Epoch 8 | Batch 110/400 | Loss: 0.101996 | LR: 9.53e-06
Epoch 8 | Batch 115/400 | Loss: 0.198062 | LR: 9.53e-06
Epoch 8 | Batch 120/400 | Loss: 0.342644 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch120 allocated=9.44GB reserved=10.66GB
Epoch 8 | Batch 125/400 | Loss: 0.149147 | LR: 9.53e-06
Epoch 8 | Batch 130/400 | Loss: 0.040180 | LR: 9.53e-06
Epoch 8 | Batch 135/400 | Loss: 0.020031 | LR: 9.53e-06
Epoch 8 | Batch 140/400 | Loss: 0.149964 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch140 allocated=9.44GB reserved=10.53GB
Epoch 8 | Batch 145/400 | Loss: 0.314789 | LR: 9.53e-06
Epoch 8 | Batch 150/400 | Loss: 0.073761 | LR: 9.53e-06
Epoch 8 | Batch 155/400 | Loss: 0.425926 | LR: 9.53e-06
Epoch 8 | Batch 160/400 | Loss: 0.043757 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch160 allocated=9.44GB reserved=10.51GB
Epoch 8 | Batch 165/400 | Loss: 0.174187 | LR: 9.53e-06
Epoch 8 | Batch 170/400 | Loss: 0.141278 | LR: 9.53e-06
Epoch 8 | Batch 175/400 | Loss: 0.263857 | LR: 9.53e-06
Epoch 8 | Batch 180/400 | Loss: 0.077424 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch180 allocated=9.44GB reserved=10.60GB
Epoch 8 | Batch 185/400 | Loss: 0.153079 | LR: 9.53e-06
Epoch 8 | Batch 190/400 | Loss: 0.019104 | LR: 9.53e-06
Epoch 8 | Batch 195/400 | Loss: 0.462511 | LR: 9.53e-06
Epoch 8 | Batch 200/400 | Loss: 0.007665 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch200 allocated=9.44GB reserved=10.57GB
Epoch 8 | Batch 205/400 | Loss: 0.033819 | LR: 9.53e-06
Epoch 8 | Batch 210/400 | Loss: 0.127501 | LR: 9.53e-06
Epoch 8 | Batch 215/400 | Loss: 0.083529 | LR: 9.53e-06
Epoch 8 | Batch 220/400 | Loss: 0.123386 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch220 allocated=9.44GB reserved=10.57GB
Epoch 8 | Batch 225/400 | Loss: 0.009604 | LR: 9.53e-06
Epoch 8 | Batch 230/400 | Loss: 0.235273 | LR: 9.53e-06
Epoch 8 | Batch 235/400 | Loss: 0.027827 | LR: 9.53e-06
Epoch 8 | Batch 240/400 | Loss: 0.034396 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch240 allocated=9.44GB reserved=10.58GB
Epoch 8 | Batch 245/400 | Loss: 0.053408 | LR: 9.53e-06
Epoch 8 | Batch 250/400 | Loss: 0.279381 | LR: 9.53e-06
Epoch 8 | Batch 255/400 | Loss: 0.057460 | LR: 9.53e-06
Epoch 8 | Batch 260/400 | Loss: 0.012620 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch260 allocated=9.43GB reserved=10.57GB
Epoch 8 | Batch 265/400 | Loss: 0.419384 | LR: 9.53e-06
Epoch 8 | Batch 270/400 | Loss: 0.016079 | LR: 9.53e-06
Epoch 8 | Batch 275/400 | Loss: 0.316307 | LR: 9.53e-06
Epoch 8 | Batch 280/400 | Loss: 0.108392 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch280 allocated=9.43GB reserved=10.59GB
Epoch 8 | Batch 285/400 | Loss: 0.243875 | LR: 9.53e-06
Epoch 8 | Batch 290/400 | Loss: 0.078200 | LR: 9.53e-06
Epoch 8 | Batch 295/400 | Loss: 0.049524 | LR: 9.53e-06
Epoch 8 | Batch 300/400 | Loss: 0.214031 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch300 allocated=9.44GB reserved=10.57GB
Epoch 8 | Batch 305/400 | Loss: 0.226526 | LR: 9.53e-06
Epoch 8 | Batch 310/400 | Loss: 0.012793 | LR: 9.53e-06
Epoch 8 | Batch 315/400 | Loss: 0.340175 | LR: 9.53e-06
Epoch 8 | Batch 320/400 | Loss: 0.016255 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch320 allocated=9.44GB reserved=10.55GB
Epoch 8 | Batch 325/400 | Loss: 0.351898 | LR: 9.53e-06
Epoch 8 | Batch 330/400 | Loss: 0.515184 | LR: 9.53e-06
Epoch 8 | Batch 335/400 | Loss: 0.418780 | LR: 9.53e-06
Epoch 8 | Batch 340/400 | Loss: 0.156081 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch340 allocated=9.44GB reserved=10.60GB
Epoch 8 | Batch 345/400 | Loss: 0.215815 | LR: 9.53e-06
Epoch 8 | Batch 350/400 | Loss: 0.157214 | LR: 9.53e-06
Epoch 8 | Batch 355/400 | Loss: 0.411325 | LR: 9.53e-06
Epoch 8 | Batch 360/400 | Loss: 0.050966 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch360 allocated=9.43GB reserved=10.61GB
Epoch 8 | Batch 365/400 | Loss: 0.012466 | LR: 9.53e-06
Epoch 8 | Batch 370/400 | Loss: 0.111770 | LR: 9.53e-06
Epoch 8 | Batch 375/400 | Loss: 0.284657 | LR: 9.53e-06
Epoch 8 | Batch 380/400 | Loss: 0.055769 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch380 allocated=9.44GB reserved=10.60GB
Epoch 8 | Batch 385/400 | Loss: 0.214168 | LR: 9.53e-06
Epoch 8 | Batch 390/400 | Loss: 0.163309 | LR: 9.53e-06
Epoch 8 | Batch 395/400 | Loss: 0.146026 | LR: 9.53e-06
âœ… ç¬¬ 8 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.143317
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.055769
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.080164
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.026391
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.043902
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.016987
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.181692
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.027516
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.128978
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.205158
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.016693
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.003602
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.151441
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.294206
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.421333
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.006931
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.028963
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.322889
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.124134

============================================================
ğŸ“Š Epoch 8/50 å®Œæˆ
   Train Loss: 0.143317
   Val Loss: 0.124134
   LR: 9.53e-06 | Time: 128.7s
============================================================
â³ æ—©åœè®¡æ•°: 7/10
[GPU MEM] End of Epoch 8 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 9 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 9 | Batch 0/400 | Loss: 0.019727 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 9 | Batch 5/400 | Loss: 0.348041 | LR: 9.39e-06
Epoch 9 | Batch 10/400 | Loss: 0.239217 | LR: 9.39e-06
Epoch 9 | Batch 15/400 | Loss: 0.144970 | LR: 9.39e-06
Epoch 9 | Batch 20/400 | Loss: 0.021409 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch20 allocated=9.44GB reserved=10.55GB
Epoch 9 | Batch 25/400 | Loss: 0.138326 | LR: 9.39e-06
Epoch 9 | Batch 30/400 | Loss: 0.036308 | LR: 9.39e-06
Epoch 9 | Batch 35/400 | Loss: 0.047995 | LR: 9.39e-06
Epoch 9 | Batch 40/400 | Loss: 0.117622 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch40 allocated=9.44GB reserved=10.55GB
Epoch 9 | Batch 45/400 | Loss: 0.399938 | LR: 9.39e-06
Epoch 9 | Batch 50/400 | Loss: 0.050868 | LR: 9.39e-06
Epoch 9 | Batch 55/400 | Loss: 0.063886 | LR: 9.39e-06
Epoch 9 | Batch 60/400 | Loss: 0.184047 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch60 allocated=9.44GB reserved=10.56GB
Epoch 9 | Batch 65/400 | Loss: 0.112543 | LR: 9.39e-06
Epoch 9 | Batch 70/400 | Loss: 0.143982 | LR: 9.39e-06
Epoch 9 | Batch 75/400 | Loss: 0.250951 | LR: 9.39e-06
Epoch 9 | Batch 80/400 | Loss: 0.096929 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch80 allocated=9.44GB reserved=10.50GB
Epoch 9 | Batch 85/400 | Loss: 0.104396 | LR: 9.39e-06
Epoch 9 | Batch 90/400 | Loss: 0.199316 | LR: 9.39e-06
Epoch 9 | Batch 95/400 | Loss: 0.169142 | LR: 9.39e-06
Epoch 9 | Batch 100/400 | Loss: 0.269911 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch100 allocated=9.44GB reserved=10.54GB
Epoch 9 | Batch 105/400 | Loss: 0.052662 | LR: 9.39e-06
Epoch 9 | Batch 110/400 | Loss: 0.057963 | LR: 9.39e-06
Epoch 9 | Batch 115/400 | Loss: 0.165288 | LR: 9.39e-06
Epoch 9 | Batch 120/400 | Loss: 0.287159 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch120 allocated=9.44GB reserved=10.47GB
Epoch 9 | Batch 125/400 | Loss: 0.106353 | LR: 9.39e-06
Epoch 9 | Batch 130/400 | Loss: 0.450376 | LR: 9.39e-06
Epoch 9 | Batch 135/400 | Loss: 0.070197 | LR: 9.39e-06
Epoch 9 | Batch 140/400 | Loss: 0.091074 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch140 allocated=9.44GB reserved=10.63GB
Epoch 9 | Batch 145/400 | Loss: 0.035743 | LR: 9.39e-06
Epoch 9 | Batch 150/400 | Loss: 0.017441 | LR: 9.39e-06
Epoch 9 | Batch 155/400 | Loss: 0.048664 | LR: 9.39e-06
Epoch 9 | Batch 160/400 | Loss: 0.034965 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch160 allocated=9.44GB reserved=10.63GB
Epoch 9 | Batch 165/400 | Loss: 0.019193 | LR: 9.39e-06
Epoch 9 | Batch 170/400 | Loss: 0.036766 | LR: 9.39e-06
Epoch 9 | Batch 175/400 | Loss: 0.171988 | LR: 9.39e-06
Epoch 9 | Batch 180/400 | Loss: 0.101913 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch180 allocated=9.44GB reserved=10.55GB
Epoch 9 | Batch 185/400 | Loss: 0.130551 | LR: 9.39e-06
Epoch 9 | Batch 190/400 | Loss: 0.316706 | LR: 9.39e-06
Epoch 9 | Batch 195/400 | Loss: 0.133856 | LR: 9.39e-06
Epoch 9 | Batch 200/400 | Loss: 0.121593 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch200 allocated=9.44GB reserved=10.58GB
Epoch 9 | Batch 205/400 | Loss: 0.099790 | LR: 9.39e-06
Epoch 9 | Batch 210/400 | Loss: 0.052186 | LR: 9.39e-06
Epoch 9 | Batch 215/400 | Loss: 0.230371 | LR: 9.39e-06
Epoch 9 | Batch 220/400 | Loss: 0.104489 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch220 allocated=9.44GB reserved=10.52GB
Epoch 9 | Batch 225/400 | Loss: 0.023047 | LR: 9.39e-06
Epoch 9 | Batch 230/400 | Loss: 0.172339 | LR: 9.39e-06
Epoch 9 | Batch 235/400 | Loss: 0.021789 | LR: 9.39e-06
Epoch 9 | Batch 240/400 | Loss: 0.037750 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch240 allocated=9.44GB reserved=10.53GB
Epoch 9 | Batch 245/400 | Loss: 0.261456 | LR: 9.39e-06
Epoch 9 | Batch 250/400 | Loss: 0.049815 | LR: 9.39e-06
Epoch 9 | Batch 255/400 | Loss: 0.035061 | LR: 9.39e-06
Epoch 9 | Batch 260/400 | Loss: 0.130554 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch260 allocated=9.44GB reserved=10.58GB
Epoch 9 | Batch 265/400 | Loss: 0.060492 | LR: 9.39e-06
Epoch 9 | Batch 270/400 | Loss: 0.057511 | LR: 9.39e-06
Epoch 9 | Batch 275/400 | Loss: 0.080996 | LR: 9.39e-06
Epoch 9 | Batch 280/400 | Loss: 0.303333 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch280 allocated=9.44GB reserved=10.53GB
Epoch 9 | Batch 285/400 | Loss: 0.016540 | LR: 9.39e-06
Epoch 9 | Batch 290/400 | Loss: 0.007271 | LR: 9.39e-06
Epoch 9 | Batch 295/400 | Loss: 0.101782 | LR: 9.39e-06
Epoch 9 | Batch 300/400 | Loss: 0.058602 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch300 allocated=9.44GB reserved=10.55GB
Epoch 9 | Batch 305/400 | Loss: 0.091277 | LR: 9.39e-06
Epoch 9 | Batch 310/400 | Loss: 0.243432 | LR: 9.39e-06
Epoch 9 | Batch 315/400 | Loss: 0.031810 | LR: 9.39e-06
Epoch 9 | Batch 320/400 | Loss: 0.041167 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch320 allocated=9.44GB reserved=10.56GB
Epoch 9 | Batch 325/400 | Loss: 0.041125 | LR: 9.39e-06
Epoch 9 | Batch 330/400 | Loss: 0.010898 | LR: 9.39e-06
Epoch 9 | Batch 335/400 | Loss: 0.123331 | LR: 9.39e-06
Epoch 9 | Batch 340/400 | Loss: 0.075557 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch340 allocated=9.43GB reserved=10.63GB
Epoch 9 | Batch 345/400 | Loss: 0.227623 | LR: 9.39e-06
Epoch 9 | Batch 350/400 | Loss: 0.012954 | LR: 9.39e-06
Epoch 9 | Batch 355/400 | Loss: 0.054524 | LR: 9.39e-06
Epoch 9 | Batch 360/400 | Loss: 0.013770 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch360 allocated=9.44GB reserved=10.56GB
Epoch 9 | Batch 365/400 | Loss: 0.054645 | LR: 9.39e-06
Epoch 9 | Batch 370/400 | Loss: 0.112348 | LR: 9.39e-06
Epoch 9 | Batch 375/400 | Loss: 0.028312 | LR: 9.39e-06
Epoch 9 | Batch 380/400 | Loss: 0.065899 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch380 allocated=9.44GB reserved=10.59GB
Epoch 9 | Batch 385/400 | Loss: 0.011331 | LR: 9.39e-06
Epoch 9 | Batch 390/400 | Loss: 0.399608 | LR: 9.39e-06
Epoch 9 | Batch 395/400 | Loss: 0.098276 | LR: 9.39e-06
âœ… ç¬¬ 9 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.120614
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.040421
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.115773
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.017834
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.326848
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.411280
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.174137
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.074964
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.297734
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.024089
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.019948
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.171160
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.025696
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.007127
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.065107
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.470747
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.067547
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.157869
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.122932

============================================================
ğŸ“Š Epoch 9/50 å®Œæˆ
   Train Loss: 0.120614
   Val Loss: 0.122932
   LR: 9.39e-06 | Time: 128.9s
============================================================
â³ æ—©åœè®¡æ•°: 8/10
[GPU MEM] End of Epoch 9 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 10 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 10 | Batch 0/400 | Loss: 0.080363 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 10 | Batch 5/400 | Loss: 0.412473 | LR: 9.23e-06
Epoch 10 | Batch 10/400 | Loss: 0.124949 | LR: 9.23e-06
Epoch 10 | Batch 15/400 | Loss: 0.065057 | LR: 9.23e-06
Epoch 10 | Batch 20/400 | Loss: 0.165888 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch20 allocated=9.44GB reserved=10.56GB
Epoch 10 | Batch 25/400 | Loss: 0.200718 | LR: 9.23e-06
Epoch 10 | Batch 30/400 | Loss: 0.070348 | LR: 9.23e-06
Epoch 10 | Batch 35/400 | Loss: 0.145679 | LR: 9.23e-06
Epoch 10 | Batch 40/400 | Loss: 0.082957 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch40 allocated=9.44GB reserved=10.58GB
Epoch 10 | Batch 45/400 | Loss: 0.035848 | LR: 9.23e-06
Epoch 10 | Batch 50/400 | Loss: 0.224679 | LR: 9.23e-06
Epoch 10 | Batch 55/400 | Loss: 0.082433 | LR: 9.23e-06
Epoch 10 | Batch 60/400 | Loss: 0.010684 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch60 allocated=9.44GB reserved=10.51GB
Epoch 10 | Batch 65/400 | Loss: 0.194977 | LR: 9.23e-06
Epoch 10 | Batch 70/400 | Loss: 0.145397 | LR: 9.23e-06
Epoch 10 | Batch 75/400 | Loss: 0.077958 | LR: 9.23e-06
Epoch 10 | Batch 80/400 | Loss: 0.086637 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch80 allocated=9.44GB reserved=10.54GB
Epoch 10 | Batch 85/400 | Loss: 0.053127 | LR: 9.23e-06
Epoch 10 | Batch 90/400 | Loss: 0.135805 | LR: 9.23e-06
Epoch 10 | Batch 95/400 | Loss: 0.042288 | LR: 9.23e-06
Epoch 10 | Batch 100/400 | Loss: 0.236763 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch100 allocated=9.44GB reserved=10.54GB
Epoch 10 | Batch 105/400 | Loss: 0.005822 | LR: 9.23e-06
Epoch 10 | Batch 110/400 | Loss: 0.014003 | LR: 9.23e-06
Epoch 10 | Batch 115/400 | Loss: 0.309082 | LR: 9.23e-06
Epoch 10 | Batch 120/400 | Loss: 0.011628 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch120 allocated=9.44GB reserved=10.53GB
Epoch 10 | Batch 125/400 | Loss: 0.201273 | LR: 9.23e-06
Epoch 10 | Batch 130/400 | Loss: 0.358296 | LR: 9.23e-06
Epoch 10 | Batch 135/400 | Loss: 0.023821 | LR: 9.23e-06
Epoch 10 | Batch 140/400 | Loss: 0.262690 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch140 allocated=9.44GB reserved=10.62GB
Epoch 10 | Batch 145/400 | Loss: 0.014490 | LR: 9.23e-06
Epoch 10 | Batch 150/400 | Loss: 0.055840 | LR: 9.23e-06
Epoch 10 | Batch 155/400 | Loss: 0.187496 | LR: 9.23e-06
Epoch 10 | Batch 160/400 | Loss: 0.150077 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch160 allocated=9.44GB reserved=10.59GB
Epoch 10 | Batch 165/400 | Loss: 0.434854 | LR: 9.23e-06
Epoch 10 | Batch 170/400 | Loss: 0.118093 | LR: 9.23e-06
Epoch 10 | Batch 175/400 | Loss: 0.004924 | LR: 9.23e-06
Epoch 10 | Batch 180/400 | Loss: 0.072555 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch180 allocated=9.44GB reserved=10.58GB
Epoch 10 | Batch 185/400 | Loss: 0.220203 | LR: 9.23e-06
Epoch 10 | Batch 190/400 | Loss: 0.299795 | LR: 9.23e-06
Epoch 10 | Batch 195/400 | Loss: 0.107224 | LR: 9.23e-06
Epoch 10 | Batch 200/400 | Loss: 0.417425 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch200 allocated=9.44GB reserved=10.59GB
Epoch 10 | Batch 205/400 | Loss: 0.065893 | LR: 9.23e-06
Epoch 10 | Batch 210/400 | Loss: 0.092759 | LR: 9.23e-06
Epoch 10 | Batch 215/400 | Loss: 0.066593 | LR: 9.23e-06
Epoch 10 | Batch 220/400 | Loss: 0.356117 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch220 allocated=9.44GB reserved=10.55GB
Epoch 10 | Batch 225/400 | Loss: 0.041524 | LR: 9.23e-06
Epoch 10 | Batch 230/400 | Loss: 0.207254 | LR: 9.23e-06
Epoch 10 | Batch 235/400 | Loss: 0.155308 | LR: 9.23e-06
Epoch 10 | Batch 240/400 | Loss: 0.238295 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch240 allocated=9.44GB reserved=10.52GB
Epoch 10 | Batch 245/400 | Loss: 0.085570 | LR: 9.23e-06
Epoch 10 | Batch 250/400 | Loss: 0.157827 | LR: 9.23e-06
Epoch 10 | Batch 255/400 | Loss: 0.042511 | LR: 9.23e-06
Epoch 10 | Batch 260/400 | Loss: 0.429551 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch260 allocated=9.44GB reserved=10.58GB
Epoch 10 | Batch 265/400 | Loss: 0.128574 | LR: 9.23e-06
Epoch 10 | Batch 270/400 | Loss: 0.267646 | LR: 9.23e-06
Epoch 10 | Batch 275/400 | Loss: 0.090673 | LR: 9.23e-06
Epoch 10 | Batch 280/400 | Loss: 0.022295 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch280 allocated=9.44GB reserved=10.56GB
Epoch 10 | Batch 285/400 | Loss: 0.031877 | LR: 9.23e-06
Epoch 10 | Batch 290/400 | Loss: 0.037715 | LR: 9.23e-06
Epoch 10 | Batch 295/400 | Loss: 0.041587 | LR: 9.23e-06
Epoch 10 | Batch 300/400 | Loss: 0.008560 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch300 allocated=9.43GB reserved=10.58GB
Epoch 10 | Batch 305/400 | Loss: 0.017873 | LR: 9.23e-06
Epoch 10 | Batch 310/400 | Loss: 0.257782 | LR: 9.23e-06
Epoch 10 | Batch 315/400 | Loss: 0.069204 | LR: 9.23e-06
Epoch 10 | Batch 320/400 | Loss: 0.487363 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch320 allocated=9.44GB reserved=10.59GB
Epoch 10 | Batch 325/400 | Loss: 0.387115 | LR: 9.23e-06
Epoch 10 | Batch 330/400 | Loss: 0.166479 | LR: 9.23e-06
Epoch 10 | Batch 335/400 | Loss: 0.253461 | LR: 9.23e-06
Epoch 10 | Batch 340/400 | Loss: 0.034362 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch340 allocated=9.44GB reserved=10.55GB
Epoch 10 | Batch 345/400 | Loss: 0.071916 | LR: 9.23e-06
Epoch 10 | Batch 350/400 | Loss: 0.236910 | LR: 9.23e-06
Epoch 10 | Batch 355/400 | Loss: 0.291124 | LR: 9.23e-06
Epoch 10 | Batch 360/400 | Loss: 0.140820 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch360 allocated=9.43GB reserved=10.50GB
Epoch 10 | Batch 365/400 | Loss: 0.047193 | LR: 9.23e-06
Epoch 10 | Batch 370/400 | Loss: 0.095372 | LR: 9.23e-06
Epoch 10 | Batch 375/400 | Loss: 0.043547 | LR: 9.23e-06
Epoch 10 | Batch 380/400 | Loss: 0.111864 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch380 allocated=9.44GB reserved=10.58GB
Epoch 10 | Batch 385/400 | Loss: 0.007508 | LR: 9.23e-06
Epoch 10 | Batch 390/400 | Loss: 0.069595 | LR: 9.23e-06
Epoch 10 | Batch 395/400 | Loss: 0.032644 | LR: 9.23e-06
âœ… ç¬¬ 10 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.133958
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.020376
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.008338
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.018024
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.054866
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.033370
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.028057
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.099953
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.096946
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.028709
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.030207
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.319559
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.004653
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.051225
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.013603
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.004387
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.497106
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.083087
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.145299
ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆ Epoch 10 çš„é¢„è§ˆå›¾...
âœ¨ é¢„è§ˆå›¾å·²ä¿å­˜åˆ° training_results_move_object_512

============================================================
ğŸ“Š Epoch 10/50 å®Œæˆ
   Train Loss: 0.133958
   Val Loss: 0.145299
   LR: 9.23e-06 | Time: 133.2s
============================================================
â³ æ—©åœè®¡æ•°: 9/10
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_move_object_512/controlnet_move_object_epoch_10.pth
[GPU MEM] End of Epoch 10 allocated=8.08GB reserved=9.24GB
ğŸ“š å¼€å§‹ç¬¬ 11 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 11 | Batch 0/400 | Loss: 0.382308 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch0 allocated=9.44GB reserved=10.70GB
Epoch 11 | Batch 5/400 | Loss: 0.239407 | LR: 9.05e-06
Epoch 11 | Batch 10/400 | Loss: 0.047461 | LR: 9.05e-06
Epoch 11 | Batch 15/400 | Loss: 0.037237 | LR: 9.05e-06
Epoch 11 | Batch 20/400 | Loss: 0.203019 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch20 allocated=9.44GB reserved=10.54GB
Epoch 11 | Batch 25/400 | Loss: 0.155695 | LR: 9.05e-06
Epoch 11 | Batch 30/400 | Loss: 0.237677 | LR: 9.05e-06
Epoch 11 | Batch 35/400 | Loss: 0.077076 | LR: 9.05e-06
Epoch 11 | Batch 40/400 | Loss: 0.152475 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch40 allocated=9.44GB reserved=10.57GB
Epoch 11 | Batch 45/400 | Loss: 0.003645 | LR: 9.05e-06
Epoch 11 | Batch 50/400 | Loss: 0.007595 | LR: 9.05e-06
Epoch 11 | Batch 55/400 | Loss: 0.015714 | LR: 9.05e-06
Epoch 11 | Batch 60/400 | Loss: 0.013731 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch60 allocated=9.44GB reserved=10.54GB
Epoch 11 | Batch 65/400 | Loss: 0.103790 | LR: 9.05e-06
Epoch 11 | Batch 70/400 | Loss: 0.008357 | LR: 9.05e-06
Epoch 11 | Batch 75/400 | Loss: 0.019751 | LR: 9.05e-06
Epoch 11 | Batch 80/400 | Loss: 0.053817 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch80 allocated=9.44GB reserved=10.55GB
Epoch 11 | Batch 85/400 | Loss: 0.101099 | LR: 9.05e-06
Epoch 11 | Batch 90/400 | Loss: 0.095233 | LR: 9.05e-06
Epoch 11 | Batch 95/400 | Loss: 0.015801 | LR: 9.05e-06
Epoch 11 | Batch 100/400 | Loss: 0.070927 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch100 allocated=9.44GB reserved=10.52GB
Epoch 11 | Batch 105/400 | Loss: 0.074655 | LR: 9.05e-06
Epoch 11 | Batch 110/400 | Loss: 0.050136 | LR: 9.05e-06
Epoch 11 | Batch 115/400 | Loss: 0.071732 | LR: 9.05e-06
Epoch 11 | Batch 120/400 | Loss: 0.161872 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch120 allocated=9.44GB reserved=10.52GB
Epoch 11 | Batch 125/400 | Loss: 0.173683 | LR: 9.05e-06
Epoch 11 | Batch 130/400 | Loss: 0.052605 | LR: 9.05e-06
Epoch 11 | Batch 135/400 | Loss: 0.208789 | LR: 9.05e-06
Epoch 11 | Batch 140/400 | Loss: 0.004379 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch140 allocated=9.44GB reserved=10.52GB
Epoch 11 | Batch 145/400 | Loss: 0.046121 | LR: 9.05e-06
Epoch 11 | Batch 150/400 | Loss: 0.169374 | LR: 9.05e-06
Epoch 11 | Batch 155/400 | Loss: 0.148570 | LR: 9.05e-06
Epoch 11 | Batch 160/400 | Loss: 0.106226 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch160 allocated=9.44GB reserved=10.60GB
Epoch 11 | Batch 165/400 | Loss: 0.434378 | LR: 9.05e-06
Epoch 11 | Batch 170/400 | Loss: 0.227081 | LR: 9.05e-06
Epoch 11 | Batch 175/400 | Loss: 0.228636 | LR: 9.05e-06
Epoch 11 | Batch 180/400 | Loss: 0.078479 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch180 allocated=9.44GB reserved=10.52GB
Epoch 11 | Batch 185/400 | Loss: 0.046361 | LR: 9.05e-06
Epoch 11 | Batch 190/400 | Loss: 0.011109 | LR: 9.05e-06
Epoch 11 | Batch 195/400 | Loss: 0.054505 | LR: 9.05e-06
Epoch 11 | Batch 200/400 | Loss: 0.072388 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch200 allocated=9.44GB reserved=10.59GB
Epoch 11 | Batch 205/400 | Loss: 0.006098 | LR: 9.05e-06
Epoch 11 | Batch 210/400 | Loss: 0.007010 | LR: 9.05e-06
Epoch 11 | Batch 215/400 | Loss: 0.115132 | LR: 9.05e-06
Epoch 11 | Batch 220/400 | Loss: 0.014398 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch220 allocated=9.44GB reserved=10.62GB
Epoch 11 | Batch 225/400 | Loss: 0.111784 | LR: 9.05e-06
Epoch 11 | Batch 230/400 | Loss: 0.009476 | LR: 9.05e-06
Epoch 11 | Batch 235/400 | Loss: 0.008134 | LR: 9.05e-06
Epoch 11 | Batch 240/400 | Loss: 0.026571 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch240 allocated=9.44GB reserved=10.56GB
Epoch 11 | Batch 245/400 | Loss: 0.063887 | LR: 9.05e-06
Epoch 11 | Batch 250/400 | Loss: 0.208555 | LR: 9.05e-06
Epoch 11 | Batch 255/400 | Loss: 0.103282 | LR: 9.05e-06
Epoch 11 | Batch 260/400 | Loss: 0.235465 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch260 allocated=9.44GB reserved=10.56GB
Epoch 11 | Batch 265/400 | Loss: 0.124207 | LR: 9.05e-06
Epoch 11 | Batch 270/400 | Loss: 0.379811 | LR: 9.05e-06
Epoch 11 | Batch 275/400 | Loss: 0.086708 | LR: 9.05e-06
Epoch 11 | Batch 280/400 | Loss: 0.016015 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch280 allocated=9.43GB reserved=10.55GB
Epoch 11 | Batch 285/400 | Loss: 0.078242 | LR: 9.05e-06
Epoch 11 | Batch 290/400 | Loss: 0.035084 | LR: 9.05e-06
Epoch 11 | Batch 295/400 | Loss: 0.255729 | LR: 9.05e-06
Epoch 11 | Batch 300/400 | Loss: 0.131586 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch300 allocated=9.44GB reserved=10.58GB
Epoch 11 | Batch 305/400 | Loss: 0.010404 | LR: 9.05e-06
Epoch 11 | Batch 310/400 | Loss: 0.082135 | LR: 9.05e-06
Epoch 11 | Batch 315/400 | Loss: 0.023643 | LR: 9.05e-06
Epoch 11 | Batch 320/400 | Loss: 0.164588 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch320 allocated=9.44GB reserved=10.59GB
Epoch 11 | Batch 325/400 | Loss: 0.421195 | LR: 9.05e-06
Epoch 11 | Batch 330/400 | Loss: 0.080085 | LR: 9.05e-06
Epoch 11 | Batch 335/400 | Loss: 0.275203 | LR: 9.05e-06
Epoch 11 | Batch 340/400 | Loss: 0.370801 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch340 allocated=9.44GB reserved=10.63GB
Epoch 11 | Batch 345/400 | Loss: 0.287022 | LR: 9.05e-06
Epoch 11 | Batch 350/400 | Loss: 0.075380 | LR: 9.05e-06
Epoch 11 | Batch 355/400 | Loss: 0.134680 | LR: 9.05e-06
Epoch 11 | Batch 360/400 | Loss: 0.037509 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch360 allocated=9.44GB reserved=10.54GB
Epoch 11 | Batch 365/400 | Loss: 0.120498 | LR: 9.05e-06
Epoch 11 | Batch 370/400 | Loss: 0.063007 | LR: 9.05e-06
Epoch 11 | Batch 375/400 | Loss: 0.195580 | LR: 9.05e-06
Epoch 11 | Batch 380/400 | Loss: 0.008309 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch380 allocated=9.44GB reserved=10.50GB
Epoch 11 | Batch 385/400 | Loss: 0.258888 | LR: 9.05e-06
Epoch 11 | Batch 390/400 | Loss: 0.108893 | LR: 9.05e-06
Epoch 11 | Batch 395/400 | Loss: 0.058966 | LR: 9.05e-06
âœ… ç¬¬ 11 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.123083
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.393884
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.102041
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.049346
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.264501
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.024651
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.337607
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.036995
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.081591
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.227481
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.340543
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.237571
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.103163
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.239438
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.097359
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.137970
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.495054
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.082723
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.159599

============================================================
ğŸ“Š Epoch 11/50 å®Œæˆ
   Train Loss: 0.123083
   Val Loss: 0.159599
   LR: 9.05e-06 | Time: 129.7s
============================================================
â³ æ—©åœè®¡æ•°: 10/10
ğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨ epoch 11 åœæ­¢è®­ç»ƒ
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_move_object_512/controlnet_move_object_epoch_50.pth
ğŸ“ˆ Loss å›¾å·²ä¿å­˜: training_results_move_object_512/training_val_loss_move_object_512.png

ğŸ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: 0.120830

============================================================
ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: æ‰è½ç‰©ä½“
ğŸ“ åˆ†è¾¨ç‡: 512x512
============================================================
   ç­›é€‰ä»»åŠ¡ 'drop_object': 2015/6000 ä¸ªæ ·æœ¬
âœ… åŠ è½½æ•°æ®é›† (drop_object): 2015 ä¸ªæ ·æœ¬
   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰
   åˆ†è¾¨ç‡: 512x512
   drop_object: 2015 ä¸ªæ ·æœ¬
   ç­›é€‰ä»»åŠ¡ 'drop_object': 234/750 ä¸ªæ ·æœ¬
âœ… åŠ è½½æ•°æ®é›† (drop_object): 234 ä¸ªæ ·æœ¬
   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰
   åˆ†è¾¨ç‡: 512x512
   drop_object: 234 ä¸ªæ ·æœ¬
   ç­›é€‰ä»»åŠ¡ 'drop_object': 251/750 ä¸ªæ ·æœ¬
âœ… åŠ è½½æ•°æ®é›† (drop_object): 251 ä¸ªæ ·æœ¬
   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰
   åˆ†è¾¨ç‡: 512x512
   drop_object: 251 ä¸ªæ ·æœ¬
âœ… åˆ›å»ºä»»åŠ¡ 'drop_object' æ•°æ®åŠ è½½å™¨å®Œæˆ
   è®­ç»ƒé›†: 2015 ä¸ªæ ·æœ¬, 1007 ä¸ªæ‰¹æ¬¡
   éªŒè¯é›†: 234 ä¸ªæ ·æœ¬, 117 ä¸ªæ‰¹æ¬¡
   æµ‹è¯•é›†: 251 ä¸ªæ ·æœ¬, 126 ä¸ªæ‰¹æ¬¡
   æ‰¹æ¬¡å¤§å°: 2
   åˆ†è¾¨ç‡: 512x512
   è¾“å…¥å¸§å½¢çŠ¶: (20, 3, 512, 512)
   ç›®æ ‡å¸§å½¢çŠ¶: (3, 512, 512)
ğŸ“Š ä»æ€»æ ·æœ¬ 2500 ä¸­éšæœºæŠ½å– 1000 ä¸ªï¼ˆæŒ‰ 8:1:1 åˆ’åˆ†ï¼‰
âœ… æ•°æ®é›†åˆ†é…: train=800 val=100
ğŸš€ ä½¿ç”¨è®¾å¤‡: cuda
ğŸ¯ ä»»åŠ¡: drop_object
ğŸ“ åˆ†è¾¨ç‡: 512x512
ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...
ğŸ†• ä» UNet å¤åˆ¶æƒé‡åˆå§‹åŒ– ControlNet
âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå¯è®­ç»ƒå‚æ•°: 361,279,120 / æ€»å‚æ•°: 361,279,120
ğŸ” VAEæ ·æœ¬å°ºå¯¸: 512
ğŸš€ å¼€å§‹512x512è®­ç»ƒ...
ğŸ“ è¾“å…¥åˆ†è¾¨ç‡: 512x512
ğŸ¯ ä»»åŠ¡: drop_object

ğŸ” è¿›è¡Œåˆå§‹éªŒè¯...
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.033808
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.108723
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.028214
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.137105
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.038784
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.117592
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.058653
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.034503
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.107653
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.155813
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.024473
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.118960
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.047006
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.045065
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.043703
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.206852
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.243675
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.112681
åˆå§‹éªŒè¯æŸå¤±: 0.112681
ğŸ“š å¼€å§‹ç¬¬ 1 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 1 | Batch 0/400 | Loss: 0.033384 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch0 allocated=10.81GB reserved=11.18GB
Epoch 1 | Batch 5/400 | Loss: 0.102552 | LR: 1.00e-05
Epoch 1 | Batch 10/400 | Loss: 0.187714 | LR: 1.00e-05
Epoch 1 | Batch 15/400 | Loss: 0.056757 | LR: 1.00e-05
Epoch 1 | Batch 20/400 | Loss: 0.178472 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch20 allocated=13.52GB reserved=14.59GB
Epoch 1 | Batch 25/400 | Loss: 0.016268 | LR: 1.00e-05
Epoch 1 | Batch 30/400 | Loss: 0.024797 | LR: 1.00e-05
Epoch 1 | Batch 35/400 | Loss: 0.099639 | LR: 1.00e-05
Epoch 1 | Batch 40/400 | Loss: 0.103374 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch40 allocated=13.51GB reserved=14.54GB
Epoch 1 | Batch 45/400 | Loss: 0.275668 | LR: 1.00e-05
Epoch 1 | Batch 50/400 | Loss: 0.079837 | LR: 1.00e-05
Epoch 1 | Batch 55/400 | Loss: 0.011539 | LR: 1.00e-05
Epoch 1 | Batch 60/400 | Loss: 0.311146 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch60 allocated=13.51GB reserved=14.76GB
Epoch 1 | Batch 65/400 | Loss: 0.114834 | LR: 1.00e-05
Epoch 1 | Batch 70/400 | Loss: 0.030478 | LR: 1.00e-05
Epoch 1 | Batch 75/400 | Loss: 0.030697 | LR: 1.00e-05
Epoch 1 | Batch 80/400 | Loss: 0.064752 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch80 allocated=13.51GB reserved=14.55GB
Epoch 1 | Batch 85/400 | Loss: 0.212376 | LR: 1.00e-05
Epoch 1 | Batch 90/400 | Loss: 0.221759 | LR: 1.00e-05
Epoch 1 | Batch 95/400 | Loss: 0.194158 | LR: 1.00e-05
Epoch 1 | Batch 100/400 | Loss: 0.123746 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch100 allocated=13.51GB reserved=14.50GB
Epoch 1 | Batch 105/400 | Loss: 0.031211 | LR: 1.00e-05
Epoch 1 | Batch 110/400 | Loss: 0.077346 | LR: 1.00e-05
Epoch 1 | Batch 115/400 | Loss: 0.154450 | LR: 1.00e-05
Epoch 1 | Batch 120/400 | Loss: 0.020941 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch120 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 125/400 | Loss: 0.129886 | LR: 1.00e-05
Epoch 1 | Batch 130/400 | Loss: 0.038079 | LR: 1.00e-05
Epoch 1 | Batch 135/400 | Loss: 0.174357 | LR: 1.00e-05
Epoch 1 | Batch 140/400 | Loss: 0.035890 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch140 allocated=13.51GB reserved=14.56GB
Epoch 1 | Batch 145/400 | Loss: 0.015131 | LR: 1.00e-05
Epoch 1 | Batch 150/400 | Loss: 0.068264 | LR: 1.00e-05
Epoch 1 | Batch 155/400 | Loss: 0.004572 | LR: 1.00e-05
Epoch 1 | Batch 160/400 | Loss: 0.024996 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch160 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 165/400 | Loss: 0.045738 | LR: 1.00e-05
Epoch 1 | Batch 170/400 | Loss: 0.027899 | LR: 1.00e-05
Epoch 1 | Batch 175/400 | Loss: 0.434108 | LR: 1.00e-05
Epoch 1 | Batch 180/400 | Loss: 0.027137 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch180 allocated=13.51GB reserved=14.56GB
Epoch 1 | Batch 185/400 | Loss: 0.108649 | LR: 1.00e-05
Epoch 1 | Batch 190/400 | Loss: 0.214250 | LR: 1.00e-05
Epoch 1 | Batch 195/400 | Loss: 0.088675 | LR: 1.00e-05
Epoch 1 | Batch 200/400 | Loss: 0.096189 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch200 allocated=13.51GB reserved=14.55GB
Epoch 1 | Batch 205/400 | Loss: 0.107674 | LR: 1.00e-05
Epoch 1 | Batch 210/400 | Loss: 0.049240 | LR: 1.00e-05
Epoch 1 | Batch 215/400 | Loss: 0.463576 | LR: 1.00e-05
Epoch 1 | Batch 220/400 | Loss: 0.128544 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch220 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 225/400 | Loss: 0.109400 | LR: 1.00e-05
Epoch 1 | Batch 230/400 | Loss: 0.108170 | LR: 1.00e-05
Epoch 1 | Batch 235/400 | Loss: 0.012424 | LR: 1.00e-05
Epoch 1 | Batch 240/400 | Loss: 0.023149 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch240 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 245/400 | Loss: 0.142385 | LR: 1.00e-05
Epoch 1 | Batch 250/400 | Loss: 0.276771 | LR: 1.00e-05
Epoch 1 | Batch 255/400 | Loss: 0.159592 | LR: 1.00e-05
Epoch 1 | Batch 260/400 | Loss: 0.115698 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch260 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 265/400 | Loss: 0.016709 | LR: 1.00e-05
Epoch 1 | Batch 270/400 | Loss: 0.172687 | LR: 1.00e-05
Epoch 1 | Batch 275/400 | Loss: 0.456996 | LR: 1.00e-05
Epoch 1 | Batch 280/400 | Loss: 0.182550 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch280 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 285/400 | Loss: 0.058497 | LR: 1.00e-05
Epoch 1 | Batch 290/400 | Loss: 0.215806 | LR: 1.00e-05
Epoch 1 | Batch 295/400 | Loss: 0.171974 | LR: 1.00e-05
Epoch 1 | Batch 300/400 | Loss: 0.012581 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch300 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 305/400 | Loss: 0.199169 | LR: 1.00e-05
Epoch 1 | Batch 310/400 | Loss: 0.017582 | LR: 1.00e-05
Epoch 1 | Batch 315/400 | Loss: 0.026732 | LR: 1.00e-05
Epoch 1 | Batch 320/400 | Loss: 0.021013 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch320 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 325/400 | Loss: 0.102814 | LR: 1.00e-05
Epoch 1 | Batch 330/400 | Loss: 0.109856 | LR: 1.00e-05
Epoch 1 | Batch 335/400 | Loss: 0.063511 | LR: 1.00e-05
Epoch 1 | Batch 340/400 | Loss: 0.008436 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch340 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 345/400 | Loss: 0.066976 | LR: 1.00e-05
Epoch 1 | Batch 350/400 | Loss: 0.173184 | LR: 1.00e-05
Epoch 1 | Batch 355/400 | Loss: 0.231582 | LR: 1.00e-05
Epoch 1 | Batch 360/400 | Loss: 0.046450 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch360 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 365/400 | Loss: 0.344500 | LR: 1.00e-05
Epoch 1 | Batch 370/400 | Loss: 0.207229 | LR: 1.00e-05
Epoch 1 | Batch 375/400 | Loss: 0.172887 | LR: 1.00e-05
Epoch 1 | Batch 380/400 | Loss: 0.060134 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch380 allocated=13.51GB reserved=14.57GB
Epoch 1 | Batch 385/400 | Loss: 0.393504 | LR: 1.00e-05
Epoch 1 | Batch 390/400 | Loss: 0.042337 | LR: 1.00e-05
Epoch 1 | Batch 395/400 | Loss: 0.079677 | LR: 1.00e-05
âœ… ç¬¬ 1 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.135461
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.107949
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.228572
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.041596
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.084840
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.358637
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.115477
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.108474
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.233934
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.147978
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.208158
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.191650
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.078346
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.056971
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.007656
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.008081
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.061540
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.052173
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.135206

============================================================
ğŸ“Š Epoch 1/50 å®Œæˆ
   Train Loss: 0.135461
   Val Loss: 0.135206
   LR: 1.00e-05 | Time: 129.5s
============================================================
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_drop_object_512/controlnet_drop_object_best.pth
ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: 0.135206
[GPU MEM] End of Epoch 1 allocated=12.16GB reserved=13.37GB
ğŸ“š å¼€å§‹ç¬¬ 2 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 2 | Batch 0/400 | Loss: 0.172043 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch0 allocated=13.52GB reserved=14.79GB
Epoch 2 | Batch 5/400 | Loss: 0.518839 | LR: 9.99e-06
Epoch 2 | Batch 10/400 | Loss: 0.011726 | LR: 9.99e-06
Epoch 2 | Batch 15/400 | Loss: 0.143131 | LR: 9.99e-06
Epoch 2 | Batch 20/400 | Loss: 0.313834 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch20 allocated=13.52GB reserved=14.28GB
Epoch 2 | Batch 25/400 | Loss: 0.210347 | LR: 9.99e-06
Epoch 2 | Batch 30/400 | Loss: 0.062107 | LR: 9.99e-06
Epoch 2 | Batch 35/400 | Loss: 0.193889 | LR: 9.99e-06
Epoch 2 | Batch 40/400 | Loss: 0.116940 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch40 allocated=13.51GB reserved=14.47GB
Epoch 2 | Batch 45/400 | Loss: 0.023375 | LR: 9.99e-06
Epoch 2 | Batch 50/400 | Loss: 0.007824 | LR: 9.99e-06
Epoch 2 | Batch 55/400 | Loss: 0.009521 | LR: 9.99e-06
Epoch 2 | Batch 60/400 | Loss: 0.083593 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch60 allocated=13.52GB reserved=14.53GB
Epoch 2 | Batch 65/400 | Loss: 0.108956 | LR: 9.99e-06
Epoch 2 | Batch 70/400 | Loss: 0.028529 | LR: 9.99e-06
Epoch 2 | Batch 75/400 | Loss: 0.193142 | LR: 9.99e-06
Epoch 2 | Batch 80/400 | Loss: 0.112541 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch80 allocated=13.51GB reserved=14.57GB
Epoch 2 | Batch 85/400 | Loss: 0.194326 | LR: 9.99e-06
Epoch 2 | Batch 90/400 | Loss: 0.129455 | LR: 9.99e-06
Epoch 2 | Batch 95/400 | Loss: 0.012176 | LR: 9.99e-06
Epoch 2 | Batch 100/400 | Loss: 0.109571 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch100 allocated=13.52GB reserved=14.51GB
Epoch 2 | Batch 105/400 | Loss: 0.294163 | LR: 9.99e-06
Epoch 2 | Batch 110/400 | Loss: 0.032415 | LR: 9.99e-06
Epoch 2 | Batch 115/400 | Loss: 0.100671 | LR: 9.99e-06
Epoch 2 | Batch 120/400 | Loss: 0.109804 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch120 allocated=13.52GB reserved=14.55GB
Epoch 2 | Batch 125/400 | Loss: 0.005105 | LR: 9.99e-06
Epoch 2 | Batch 130/400 | Loss: 0.027044 | LR: 9.99e-06
Epoch 2 | Batch 135/400 | Loss: 0.407142 | LR: 9.99e-06
Epoch 2 | Batch 140/400 | Loss: 0.026115 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch140 allocated=13.51GB reserved=14.48GB
Epoch 2 | Batch 145/400 | Loss: 0.031305 | LR: 9.99e-06
Epoch 2 | Batch 150/400 | Loss: 0.047673 | LR: 9.99e-06
Epoch 2 | Batch 155/400 | Loss: 0.124077 | LR: 9.99e-06
Epoch 2 | Batch 160/400 | Loss: 0.141461 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch160 allocated=13.51GB reserved=14.50GB
Epoch 2 | Batch 165/400 | Loss: 0.414620 | LR: 9.99e-06
Epoch 2 | Batch 170/400 | Loss: 0.183686 | LR: 9.99e-06
Epoch 2 | Batch 175/400 | Loss: 0.026227 | LR: 9.99e-06
Epoch 2 | Batch 180/400 | Loss: 0.109596 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch180 allocated=13.51GB reserved=14.53GB
Epoch 2 | Batch 185/400 | Loss: 0.018765 | LR: 9.99e-06
Epoch 2 | Batch 190/400 | Loss: 0.034224 | LR: 9.99e-06
Epoch 2 | Batch 195/400 | Loss: 0.093147 | LR: 9.99e-06
Epoch 2 | Batch 200/400 | Loss: 0.077879 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch200 allocated=13.51GB reserved=14.54GB
Epoch 2 | Batch 205/400 | Loss: 0.257822 | LR: 9.99e-06
Epoch 2 | Batch 210/400 | Loss: 0.190760 | LR: 9.99e-06
Epoch 2 | Batch 215/400 | Loss: 0.083449 | LR: 9.99e-06
Epoch 2 | Batch 220/400 | Loss: 0.021448 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch220 allocated=13.51GB reserved=14.46GB
Epoch 2 | Batch 225/400 | Loss: 0.099816 | LR: 9.99e-06
Epoch 2 | Batch 230/400 | Loss: 0.085671 | LR: 9.99e-06
Epoch 2 | Batch 235/400 | Loss: 0.041351 | LR: 9.99e-06
Epoch 2 | Batch 240/400 | Loss: 0.040974 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch240 allocated=13.51GB reserved=14.46GB
Epoch 2 | Batch 245/400 | Loss: 0.422641 | LR: 9.99e-06
Epoch 2 | Batch 250/400 | Loss: 0.070693 | LR: 9.99e-06
Epoch 2 | Batch 255/400 | Loss: 0.053965 | LR: 9.99e-06
Epoch 2 | Batch 260/400 | Loss: 0.186822 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch260 allocated=13.51GB reserved=14.48GB
Epoch 2 | Batch 265/400 | Loss: 0.120814 | LR: 9.99e-06
Epoch 2 | Batch 270/400 | Loss: 0.106008 | LR: 9.99e-06
Epoch 2 | Batch 275/400 | Loss: 0.373045 | LR: 9.99e-06
Epoch 2 | Batch 280/400 | Loss: 0.291381 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch280 allocated=13.52GB reserved=14.48GB
Epoch 2 | Batch 285/400 | Loss: 0.075619 | LR: 9.99e-06
Epoch 2 | Batch 290/400 | Loss: 0.137827 | LR: 9.99e-06
Epoch 2 | Batch 295/400 | Loss: 0.109144 | LR: 9.99e-06
Epoch 2 | Batch 300/400 | Loss: 0.425311 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch300 allocated=13.52GB reserved=14.48GB
Epoch 2 | Batch 305/400 | Loss: 0.363418 | LR: 9.99e-06
Epoch 2 | Batch 310/400 | Loss: 0.087486 | LR: 9.99e-06
Epoch 2 | Batch 315/400 | Loss: 0.165919 | LR: 9.99e-06
Epoch 2 | Batch 320/400 | Loss: 0.037729 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch320 allocated=13.52GB reserved=14.48GB
Epoch 2 | Batch 325/400 | Loss: 0.009087 | LR: 9.99e-06
Epoch 2 | Batch 330/400 | Loss: 0.179901 | LR: 9.99e-06
Epoch 2 | Batch 335/400 | Loss: 0.153681 | LR: 9.99e-06
Epoch 2 | Batch 340/400 | Loss: 0.012605 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch340 allocated=13.52GB reserved=14.48GB
Epoch 2 | Batch 345/400 | Loss: 0.464465 | LR: 9.99e-06
Epoch 2 | Batch 350/400 | Loss: 0.111032 | LR: 9.99e-06
Epoch 2 | Batch 355/400 | Loss: 0.020015 | LR: 9.99e-06
Epoch 2 | Batch 360/400 | Loss: 0.204602 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch360 allocated=13.52GB reserved=14.48GB
Epoch 2 | Batch 365/400 | Loss: 0.176725 | LR: 9.99e-06
Epoch 2 | Batch 370/400 | Loss: 0.034907 | LR: 9.99e-06
Epoch 2 | Batch 375/400 | Loss: 0.024818 | LR: 9.99e-06
Epoch 2 | Batch 380/400 | Loss: 0.357890 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch380 allocated=13.52GB reserved=14.48GB
Epoch 2 | Batch 385/400 | Loss: 0.164254 | LR: 9.99e-06
Epoch 2 | Batch 390/400 | Loss: 0.048638 | LR: 9.99e-06
Epoch 2 | Batch 395/400 | Loss: 0.045944 | LR: 9.99e-06
âœ… ç¬¬ 2 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.134165
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.157026
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.104402
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.118964
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.017014
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.233960
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.124934
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.340006
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.017871
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.144277
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.156595
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.165090
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.024484
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.230565
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.065707
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.010901
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.092441
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.016164
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.124983

============================================================
ğŸ“Š Epoch 2/50 å®Œæˆ
   Train Loss: 0.134165
   Val Loss: 0.124983
   LR: 9.99e-06 | Time: 134.3s
============================================================
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_drop_object_512/controlnet_drop_object_best.pth
ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: 0.124983
[GPU MEM] End of Epoch 2 allocated=12.16GB reserved=13.37GB
ğŸ“š å¼€å§‹ç¬¬ 3 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 3 | Batch 0/400 | Loss: 0.155974 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch0 allocated=13.52GB reserved=14.79GB
Epoch 3 | Batch 5/400 | Loss: 0.159052 | LR: 9.96e-06
Epoch 3 | Batch 10/400 | Loss: 0.217484 | LR: 9.96e-06
Epoch 3 | Batch 15/400 | Loss: 0.010064 | LR: 9.96e-06
Epoch 3 | Batch 20/400 | Loss: 0.316909 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch20 allocated=13.52GB reserved=14.28GB
Epoch 3 | Batch 25/400 | Loss: 0.261837 | LR: 9.96e-06
Epoch 3 | Batch 30/400 | Loss: 0.029787 | LR: 9.96e-06
Epoch 3 | Batch 35/400 | Loss: 0.436608 | LR: 9.96e-06
Epoch 3 | Batch 40/400 | Loss: 0.250122 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch40 allocated=13.51GB reserved=14.47GB
Epoch 3 | Batch 45/400 | Loss: 0.408815 | LR: 9.96e-06
Epoch 3 | Batch 50/400 | Loss: 0.045635 | LR: 9.96e-06
Epoch 3 | Batch 55/400 | Loss: 0.170399 | LR: 9.96e-06
Epoch 3 | Batch 60/400 | Loss: 0.137832 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch60 allocated=13.51GB reserved=14.55GB
Epoch 3 | Batch 65/400 | Loss: 0.128264 | LR: 9.96e-06
Epoch 3 | Batch 70/400 | Loss: 0.021924 | LR: 9.96e-06
Epoch 3 | Batch 75/400 | Loss: 0.028789 | LR: 9.96e-06
Epoch 3 | Batch 80/400 | Loss: 0.111516 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch80 allocated=13.52GB reserved=14.59GB
Epoch 3 | Batch 85/400 | Loss: 0.112970 | LR: 9.96e-06
Epoch 3 | Batch 90/400 | Loss: 0.096288 | LR: 9.96e-06
Epoch 3 | Batch 95/400 | Loss: 0.059353 | LR: 9.96e-06
Epoch 3 | Batch 100/400 | Loss: 0.188165 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch100 allocated=13.51GB reserved=14.51GB
Epoch 3 | Batch 105/400 | Loss: 0.188130 | LR: 9.96e-06
Epoch 3 | Batch 110/400 | Loss: 0.014346 | LR: 9.96e-06
Epoch 3 | Batch 115/400 | Loss: 0.033469 | LR: 9.96e-06
Epoch 3 | Batch 120/400 | Loss: 0.386133 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch120 allocated=13.51GB reserved=14.49GB
Epoch 3 | Batch 125/400 | Loss: 0.163133 | LR: 9.96e-06
Epoch 3 | Batch 130/400 | Loss: 0.025621 | LR: 9.96e-06
Epoch 3 | Batch 135/400 | Loss: 0.117887 | LR: 9.96e-06
Epoch 3 | Batch 140/400 | Loss: 0.700695 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch140 allocated=13.51GB reserved=14.54GB
Epoch 3 | Batch 145/400 | Loss: 0.187168 | LR: 9.96e-06
Epoch 3 | Batch 150/400 | Loss: 0.189558 | LR: 9.96e-06
Epoch 3 | Batch 155/400 | Loss: 0.174624 | LR: 9.96e-06
Epoch 3 | Batch 160/400 | Loss: 0.154285 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch160 allocated=13.51GB reserved=14.54GB
Epoch 3 | Batch 165/400 | Loss: 0.056989 | LR: 9.96e-06
Epoch 3 | Batch 170/400 | Loss: 0.079532 | LR: 9.96e-06
Epoch 3 | Batch 175/400 | Loss: 0.046081 | LR: 9.96e-06
Epoch 3 | Batch 180/400 | Loss: 0.246601 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch180 allocated=13.51GB reserved=14.54GB
Epoch 3 | Batch 185/400 | Loss: 0.329607 | LR: 9.96e-06
Epoch 3 | Batch 190/400 | Loss: 0.014874 | LR: 9.96e-06
Epoch 3 | Batch 195/400 | Loss: 0.286040 | LR: 9.96e-06
Epoch 3 | Batch 200/400 | Loss: 0.341680 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch200 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 205/400 | Loss: 0.428533 | LR: 9.96e-06
Epoch 3 | Batch 210/400 | Loss: 0.371852 | LR: 9.96e-06
Epoch 3 | Batch 215/400 | Loss: 0.028749 | LR: 9.96e-06
Epoch 3 | Batch 220/400 | Loss: 0.021529 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch220 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 225/400 | Loss: 0.396889 | LR: 9.96e-06
Epoch 3 | Batch 230/400 | Loss: 0.090967 | LR: 9.96e-06
Epoch 3 | Batch 235/400 | Loss: 0.075550 | LR: 9.96e-06
Epoch 3 | Batch 240/400 | Loss: 0.003798 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch240 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 245/400 | Loss: 0.077856 | LR: 9.96e-06
Epoch 3 | Batch 250/400 | Loss: 0.173215 | LR: 9.96e-06
Epoch 3 | Batch 255/400 | Loss: 0.008109 | LR: 9.96e-06
Epoch 3 | Batch 260/400 | Loss: 0.099792 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch260 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 265/400 | Loss: 0.196749 | LR: 9.96e-06
Epoch 3 | Batch 270/400 | Loss: 0.062740 | LR: 9.96e-06
Epoch 3 | Batch 275/400 | Loss: 0.127987 | LR: 9.96e-06
Epoch 3 | Batch 280/400 | Loss: 0.055601 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch280 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 285/400 | Loss: 0.009210 | LR: 9.96e-06
Epoch 3 | Batch 290/400 | Loss: 0.023169 | LR: 9.96e-06
Epoch 3 | Batch 295/400 | Loss: 0.224809 | LR: 9.96e-06
Epoch 3 | Batch 300/400 | Loss: 0.049612 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch300 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 305/400 | Loss: 0.328544 | LR: 9.96e-06
Epoch 3 | Batch 310/400 | Loss: 0.280623 | LR: 9.96e-06
Epoch 3 | Batch 315/400 | Loss: 0.036902 | LR: 9.96e-06
Epoch 3 | Batch 320/400 | Loss: 0.230701 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch320 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 325/400 | Loss: 0.284470 | LR: 9.96e-06
Epoch 3 | Batch 330/400 | Loss: 0.123965 | LR: 9.96e-06
Epoch 3 | Batch 335/400 | Loss: 0.113746 | LR: 9.96e-06
Epoch 3 | Batch 340/400 | Loss: 0.119166 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch340 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 345/400 | Loss: 0.092039 | LR: 9.96e-06
Epoch 3 | Batch 350/400 | Loss: 0.276777 | LR: 9.96e-06
Epoch 3 | Batch 355/400 | Loss: 0.046519 | LR: 9.96e-06
Epoch 3 | Batch 360/400 | Loss: 0.008173 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch360 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 365/400 | Loss: 0.086286 | LR: 9.96e-06
Epoch 3 | Batch 370/400 | Loss: 0.140021 | LR: 9.96e-06
Epoch 3 | Batch 375/400 | Loss: 0.048256 | LR: 9.96e-06
Epoch 3 | Batch 380/400 | Loss: 0.126763 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch380 allocated=13.51GB reserved=14.52GB
Epoch 3 | Batch 385/400 | Loss: 0.183848 | LR: 9.96e-06
Epoch 3 | Batch 390/400 | Loss: 0.193745 | LR: 9.96e-06
Epoch 3 | Batch 395/400 | Loss: 0.228886 | LR: 9.96e-06
âœ… ç¬¬ 3 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.148568
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.226281
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.048302
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.049768
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.033597
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.274023
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.369095
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.025174
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.065812
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.251342
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.205695
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.132955
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.179054
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.083364
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.014249
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.007315
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.120551
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.005931
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.136847

============================================================
ğŸ“Š Epoch 3/50 å®Œæˆ
   Train Loss: 0.148568
   Val Loss: 0.136847
   LR: 9.96e-06 | Time: 129.1s
============================================================
â³ æ—©åœè®¡æ•°: 1/10
[GPU MEM] End of Epoch 3 allocated=12.16GB reserved=13.37GB
ğŸ“š å¼€å§‹ç¬¬ 4 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 4 | Batch 0/400 | Loss: 0.023327 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch0 allocated=13.52GB reserved=14.79GB
Epoch 4 | Batch 5/400 | Loss: 0.009562 | LR: 9.91e-06
Epoch 4 | Batch 10/400 | Loss: 0.031376 | LR: 9.91e-06
Epoch 4 | Batch 15/400 | Loss: 0.009542 | LR: 9.91e-06
Epoch 4 | Batch 20/400 | Loss: 0.068171 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch20 allocated=13.51GB reserved=14.35GB
Epoch 4 | Batch 25/400 | Loss: 0.071176 | LR: 9.91e-06
Epoch 4 | Batch 30/400 | Loss: 0.085008 | LR: 9.91e-06
Epoch 4 | Batch 35/400 | Loss: 0.092823 | LR: 9.91e-06
Epoch 4 | Batch 40/400 | Loss: 0.003541 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch40 allocated=13.52GB reserved=14.49GB
Epoch 4 | Batch 45/400 | Loss: 0.015198 | LR: 9.91e-06
Epoch 4 | Batch 50/400 | Loss: 0.411235 | LR: 9.91e-06
Epoch 4 | Batch 55/400 | Loss: 0.093876 | LR: 9.91e-06
Epoch 4 | Batch 60/400 | Loss: 0.010432 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch60 allocated=13.51GB reserved=14.46GB
Epoch 4 | Batch 65/400 | Loss: 0.248227 | LR: 9.91e-06
Epoch 4 | Batch 70/400 | Loss: 0.065344 | LR: 9.91e-06
Epoch 4 | Batch 75/400 | Loss: 0.112723 | LR: 9.91e-06
Epoch 4 | Batch 80/400 | Loss: 0.015578 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch80 allocated=13.52GB reserved=14.52GB
Epoch 4 | Batch 85/400 | Loss: 0.540515 | LR: 9.91e-06
Epoch 4 | Batch 90/400 | Loss: 0.095051 | LR: 9.91e-06
Epoch 4 | Batch 95/400 | Loss: 0.005290 | LR: 9.91e-06
Epoch 4 | Batch 100/400 | Loss: 0.125819 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch100 allocated=13.51GB reserved=14.55GB
Epoch 4 | Batch 105/400 | Loss: 0.107658 | LR: 9.91e-06
Epoch 4 | Batch 110/400 | Loss: 0.167621 | LR: 9.91e-06
Epoch 4 | Batch 115/400 | Loss: 0.247260 | LR: 9.91e-06
Epoch 4 | Batch 120/400 | Loss: 0.077757 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch120 allocated=13.51GB reserved=14.47GB
Epoch 4 | Batch 125/400 | Loss: 0.022231 | LR: 9.91e-06
Epoch 4 | Batch 130/400 | Loss: 0.216791 | LR: 9.91e-06
Epoch 4 | Batch 135/400 | Loss: 0.076895 | LR: 9.91e-06
Epoch 4 | Batch 140/400 | Loss: 0.203838 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch140 allocated=13.51GB reserved=14.50GB
Epoch 4 | Batch 145/400 | Loss: 0.174970 | LR: 9.91e-06
Epoch 4 | Batch 150/400 | Loss: 0.024093 | LR: 9.91e-06
Epoch 4 | Batch 155/400 | Loss: 0.010322 | LR: 9.91e-06
Epoch 4 | Batch 160/400 | Loss: 0.005255 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch160 allocated=13.52GB reserved=14.51GB
Epoch 4 | Batch 165/400 | Loss: 0.160371 | LR: 9.91e-06
Epoch 4 | Batch 170/400 | Loss: 0.340423 | LR: 9.91e-06
Epoch 4 | Batch 175/400 | Loss: 0.043447 | LR: 9.91e-06
Epoch 4 | Batch 180/400 | Loss: 0.016650 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch180 allocated=13.52GB reserved=14.47GB
Epoch 4 | Batch 185/400 | Loss: 0.015245 | LR: 9.91e-06
Epoch 4 | Batch 190/400 | Loss: 0.017525 | LR: 9.91e-06
Epoch 4 | Batch 195/400 | Loss: 0.083785 | LR: 9.91e-06
Epoch 4 | Batch 200/400 | Loss: 0.284066 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch200 allocated=9.45GB reserved=11.79GB
Epoch 4 | Batch 205/400 | Loss: 0.287743 | LR: 9.91e-06
Epoch 4 | Batch 210/400 | Loss: 0.025597 | LR: 9.91e-06
Epoch 4 | Batch 215/400 | Loss: 0.209926 | LR: 9.91e-06
Epoch 4 | Batch 220/400 | Loss: 0.231991 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch220 allocated=9.45GB reserved=11.44GB
Epoch 4 | Batch 225/400 | Loss: 0.135608 | LR: 9.91e-06
Epoch 4 | Batch 230/400 | Loss: 0.025953 | LR: 9.91e-06
Epoch 4 | Batch 235/400 | Loss: 0.005140 | LR: 9.91e-06
Epoch 4 | Batch 240/400 | Loss: 0.137187 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 245/400 | Loss: 0.008466 | LR: 9.91e-06
Epoch 4 | Batch 250/400 | Loss: 0.619907 | LR: 9.91e-06
Epoch 4 | Batch 255/400 | Loss: 0.115465 | LR: 9.91e-06
Epoch 4 | Batch 260/400 | Loss: 0.033169 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 265/400 | Loss: 0.065975 | LR: 9.91e-06
Epoch 4 | Batch 270/400 | Loss: 0.234357 | LR: 9.91e-06
Epoch 4 | Batch 275/400 | Loss: 0.156783 | LR: 9.91e-06
Epoch 4 | Batch 280/400 | Loss: 0.086633 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 285/400 | Loss: 0.183691 | LR: 9.91e-06
Epoch 4 | Batch 290/400 | Loss: 0.302040 | LR: 9.91e-06
Epoch 4 | Batch 295/400 | Loss: 0.074471 | LR: 9.91e-06
Epoch 4 | Batch 300/400 | Loss: 0.059919 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 305/400 | Loss: 0.138478 | LR: 9.91e-06
Epoch 4 | Batch 310/400 | Loss: 0.036773 | LR: 9.91e-06
Epoch 4 | Batch 315/400 | Loss: 0.006790 | LR: 9.91e-06
Epoch 4 | Batch 320/400 | Loss: 0.145290 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 325/400 | Loss: 0.063368 | LR: 9.91e-06
Epoch 4 | Batch 330/400 | Loss: 0.002967 | LR: 9.91e-06
Epoch 4 | Batch 335/400 | Loss: 0.013678 | LR: 9.91e-06
Epoch 4 | Batch 340/400 | Loss: 0.311944 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 345/400 | Loss: 0.117062 | LR: 9.91e-06
Epoch 4 | Batch 350/400 | Loss: 0.084956 | LR: 9.91e-06
Epoch 4 | Batch 355/400 | Loss: 0.129026 | LR: 9.91e-06
Epoch 4 | Batch 360/400 | Loss: 0.553947 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 365/400 | Loss: 0.108599 | LR: 9.91e-06
Epoch 4 | Batch 370/400 | Loss: 0.113286 | LR: 9.91e-06
Epoch 4 | Batch 375/400 | Loss: 0.034698 | LR: 9.91e-06
Epoch 4 | Batch 380/400 | Loss: 0.055911 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 385/400 | Loss: 0.185993 | LR: 9.91e-06
Epoch 4 | Batch 390/400 | Loss: 0.398782 | LR: 9.91e-06
Epoch 4 | Batch 395/400 | Loss: 0.006758 | LR: 9.91e-06
âœ… ç¬¬ 4 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.134288
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.005918
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.030396
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.054752
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.029473
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.020218
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.042968
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.065675
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.050407
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.041171
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.297021
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.129107
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.187321
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.079297
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.062040
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.026082
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.115813
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.047716
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.105492

============================================================
ğŸ“Š Epoch 4/50 å®Œæˆ
   Train Loss: 0.134288
   Val Loss: 0.105492
   LR: 9.91e-06 | Time: 129.8s
============================================================
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_drop_object_512/controlnet_drop_object_best.pth
ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: 0.105492
[GPU MEM] End of Epoch 4 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 5 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 5 | Batch 0/400 | Loss: 0.047561 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 5/400 | Loss: 0.010957 | LR: 9.84e-06
Epoch 5 | Batch 10/400 | Loss: 0.058846 | LR: 9.84e-06
Epoch 5 | Batch 15/400 | Loss: 0.257779 | LR: 9.84e-06
Epoch 5 | Batch 20/400 | Loss: 0.027997 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 25/400 | Loss: 0.365982 | LR: 9.84e-06
Epoch 5 | Batch 30/400 | Loss: 0.005311 | LR: 9.84e-06
Epoch 5 | Batch 35/400 | Loss: 0.213636 | LR: 9.84e-06
Epoch 5 | Batch 40/400 | Loss: 0.057537 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 45/400 | Loss: 0.184252 | LR: 9.84e-06
Epoch 5 | Batch 50/400 | Loss: 0.240139 | LR: 9.84e-06
Epoch 5 | Batch 55/400 | Loss: 0.258237 | LR: 9.84e-06
Epoch 5 | Batch 60/400 | Loss: 0.127043 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 65/400 | Loss: 0.009947 | LR: 9.84e-06
Epoch 5 | Batch 70/400 | Loss: 0.090141 | LR: 9.84e-06
Epoch 5 | Batch 75/400 | Loss: 0.019950 | LR: 9.84e-06
Epoch 5 | Batch 80/400 | Loss: 0.184060 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 85/400 | Loss: 0.213928 | LR: 9.84e-06
Epoch 5 | Batch 90/400 | Loss: 0.307499 | LR: 9.84e-06
Epoch 5 | Batch 95/400 | Loss: 0.064355 | LR: 9.84e-06
Epoch 5 | Batch 100/400 | Loss: 0.058984 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 105/400 | Loss: 0.280864 | LR: 9.84e-06
Epoch 5 | Batch 110/400 | Loss: 0.191238 | LR: 9.84e-06
Epoch 5 | Batch 115/400 | Loss: 0.079140 | LR: 9.84e-06
Epoch 5 | Batch 120/400 | Loss: 0.146596 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 125/400 | Loss: 0.048333 | LR: 9.84e-06
Epoch 5 | Batch 130/400 | Loss: 0.371276 | LR: 9.84e-06
Epoch 5 | Batch 135/400 | Loss: 0.013177 | LR: 9.84e-06
Epoch 5 | Batch 140/400 | Loss: 0.084141 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 145/400 | Loss: 0.340447 | LR: 9.84e-06
Epoch 5 | Batch 150/400 | Loss: 0.023562 | LR: 9.84e-06
Epoch 5 | Batch 155/400 | Loss: 0.054300 | LR: 9.84e-06
Epoch 5 | Batch 160/400 | Loss: 0.068419 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 165/400 | Loss: 0.448172 | LR: 9.84e-06
Epoch 5 | Batch 170/400 | Loss: 0.266033 | LR: 9.84e-06
Epoch 5 | Batch 175/400 | Loss: 0.048497 | LR: 9.84e-06
Epoch 5 | Batch 180/400 | Loss: 0.033268 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 185/400 | Loss: 0.036147 | LR: 9.84e-06
Epoch 5 | Batch 190/400 | Loss: 0.055790 | LR: 9.84e-06
Epoch 5 | Batch 195/400 | Loss: 0.358915 | LR: 9.84e-06
Epoch 5 | Batch 200/400 | Loss: 0.221052 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 205/400 | Loss: 0.010804 | LR: 9.84e-06
Epoch 5 | Batch 210/400 | Loss: 0.061465 | LR: 9.84e-06
Epoch 5 | Batch 215/400 | Loss: 0.011310 | LR: 9.84e-06
Epoch 5 | Batch 220/400 | Loss: 0.194458 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 225/400 | Loss: 0.025489 | LR: 9.84e-06
Epoch 5 | Batch 230/400 | Loss: 0.025083 | LR: 9.84e-06
Epoch 5 | Batch 235/400 | Loss: 0.040674 | LR: 9.84e-06
Epoch 5 | Batch 240/400 | Loss: 0.091613 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 245/400 | Loss: 0.297100 | LR: 9.84e-06
Epoch 5 | Batch 250/400 | Loss: 0.287395 | LR: 9.84e-06
Epoch 5 | Batch 255/400 | Loss: 0.018084 | LR: 9.84e-06
Epoch 5 | Batch 260/400 | Loss: 0.205938 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 265/400 | Loss: 0.076630 | LR: 9.84e-06
Epoch 5 | Batch 270/400 | Loss: 0.031274 | LR: 9.84e-06
Epoch 5 | Batch 275/400 | Loss: 0.120943 | LR: 9.84e-06
Epoch 5 | Batch 280/400 | Loss: 0.099387 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 285/400 | Loss: 0.090980 | LR: 9.84e-06
Epoch 5 | Batch 290/400 | Loss: 0.150402 | LR: 9.84e-06
Epoch 5 | Batch 295/400 | Loss: 0.242301 | LR: 9.84e-06
Epoch 5 | Batch 300/400 | Loss: 0.072753 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 305/400 | Loss: 0.015509 | LR: 9.84e-06
Epoch 5 | Batch 310/400 | Loss: 0.026835 | LR: 9.84e-06
Epoch 5 | Batch 315/400 | Loss: 0.026896 | LR: 9.84e-06
Epoch 5 | Batch 320/400 | Loss: 0.159513 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 325/400 | Loss: 0.383855 | LR: 9.84e-06
Epoch 5 | Batch 330/400 | Loss: 0.308009 | LR: 9.84e-06
Epoch 5 | Batch 335/400 | Loss: 0.055411 | LR: 9.84e-06
Epoch 5 | Batch 340/400 | Loss: 0.181218 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 345/400 | Loss: 0.042396 | LR: 9.84e-06
Epoch 5 | Batch 350/400 | Loss: 0.065599 | LR: 9.84e-06
Epoch 5 | Batch 355/400 | Loss: 0.146729 | LR: 9.84e-06
Epoch 5 | Batch 360/400 | Loss: 0.016347 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 365/400 | Loss: 0.062035 | LR: 9.84e-06
Epoch 5 | Batch 370/400 | Loss: 0.071950 | LR: 9.84e-06
Epoch 5 | Batch 375/400 | Loss: 0.212450 | LR: 9.84e-06
Epoch 5 | Batch 380/400 | Loss: 0.004193 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 5 | Batch 385/400 | Loss: 0.243764 | LR: 9.84e-06
Epoch 5 | Batch 390/400 | Loss: 0.069411 | LR: 9.84e-06
Epoch 5 | Batch 395/400 | Loss: 0.111959 | LR: 9.84e-06
âœ… ç¬¬ 5 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.132442
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.236723
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.238747
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.263113
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.049321
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.468523
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.078832
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.162875
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.346663
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.244306
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.064207
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.084554
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.137447
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.084209
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.195359
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.186381
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.122760
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.025440
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.140135
ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆ Epoch 5 çš„é¢„è§ˆå›¾...
âœ¨ é¢„è§ˆå›¾å·²ä¿å­˜åˆ° training_results_drop_object_512

============================================================
ğŸ“Š Epoch 5/50 å®Œæˆ
   Train Loss: 0.132442
   Val Loss: 0.140135
   LR: 9.84e-06 | Time: 132.7s
============================================================
â³ æ—©åœè®¡æ•°: 1/10
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_drop_object_512/controlnet_drop_object_epoch_5.pth
[GPU MEM] End of Epoch 5 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 6 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 6 | Batch 0/400 | Loss: 0.280093 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 5/400 | Loss: 0.083085 | LR: 9.76e-06
Epoch 6 | Batch 10/400 | Loss: 0.413069 | LR: 9.76e-06
Epoch 6 | Batch 15/400 | Loss: 0.055259 | LR: 9.76e-06
Epoch 6 | Batch 20/400 | Loss: 0.003430 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 25/400 | Loss: 0.094641 | LR: 9.76e-06
Epoch 6 | Batch 30/400 | Loss: 0.015381 | LR: 9.76e-06
Epoch 6 | Batch 35/400 | Loss: 0.103316 | LR: 9.76e-06
Epoch 6 | Batch 40/400 | Loss: 0.091999 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 45/400 | Loss: 0.149686 | LR: 9.76e-06
Epoch 6 | Batch 50/400 | Loss: 0.331800 | LR: 9.76e-06
Epoch 6 | Batch 55/400 | Loss: 0.106261 | LR: 9.76e-06
Epoch 6 | Batch 60/400 | Loss: 0.305678 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 65/400 | Loss: 0.058303 | LR: 9.76e-06
Epoch 6 | Batch 70/400 | Loss: 0.123085 | LR: 9.76e-06
Epoch 6 | Batch 75/400 | Loss: 0.280606 | LR: 9.76e-06
Epoch 6 | Batch 80/400 | Loss: 0.004891 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 85/400 | Loss: 0.225001 | LR: 9.76e-06
Epoch 6 | Batch 90/400 | Loss: 0.203123 | LR: 9.76e-06
Epoch 6 | Batch 95/400 | Loss: 0.089157 | LR: 9.76e-06
Epoch 6 | Batch 100/400 | Loss: 0.117594 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 105/400 | Loss: 0.033201 | LR: 9.76e-06
Epoch 6 | Batch 110/400 | Loss: 0.289836 | LR: 9.76e-06
Epoch 6 | Batch 115/400 | Loss: 0.361985 | LR: 9.76e-06
Epoch 6 | Batch 120/400 | Loss: 0.419620 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 125/400 | Loss: 0.253679 | LR: 9.76e-06
Epoch 6 | Batch 130/400 | Loss: 0.017916 | LR: 9.76e-06
Epoch 6 | Batch 135/400 | Loss: 0.006607 | LR: 9.76e-06
Epoch 6 | Batch 140/400 | Loss: 0.018774 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 145/400 | Loss: 0.222523 | LR: 9.76e-06
Epoch 6 | Batch 150/400 | Loss: 0.013793 | LR: 9.76e-06
Epoch 6 | Batch 155/400 | Loss: 0.083030 | LR: 9.76e-06
Epoch 6 | Batch 160/400 | Loss: 0.398994 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 165/400 | Loss: 0.133113 | LR: 9.76e-06
Epoch 6 | Batch 170/400 | Loss: 0.078078 | LR: 9.76e-06
Epoch 6 | Batch 175/400 | Loss: 0.124551 | LR: 9.76e-06
Epoch 6 | Batch 180/400 | Loss: 0.463680 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 185/400 | Loss: 0.141563 | LR: 9.76e-06
Epoch 6 | Batch 190/400 | Loss: 0.096671 | LR: 9.76e-06
Epoch 6 | Batch 195/400 | Loss: 0.013617 | LR: 9.76e-06
Epoch 6 | Batch 200/400 | Loss: 0.304385 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 205/400 | Loss: 0.010627 | LR: 9.76e-06
Epoch 6 | Batch 210/400 | Loss: 0.066503 | LR: 9.76e-06
Epoch 6 | Batch 215/400 | Loss: 0.298065 | LR: 9.76e-06
Epoch 6 | Batch 220/400 | Loss: 0.036327 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 225/400 | Loss: 0.004135 | LR: 9.76e-06
Epoch 6 | Batch 230/400 | Loss: 0.255148 | LR: 9.76e-06
Epoch 6 | Batch 235/400 | Loss: 0.090091 | LR: 9.76e-06
Epoch 6 | Batch 240/400 | Loss: 0.064691 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 245/400 | Loss: 0.258221 | LR: 9.76e-06
Epoch 6 | Batch 250/400 | Loss: 0.110896 | LR: 9.76e-06
Epoch 6 | Batch 255/400 | Loss: 0.362697 | LR: 9.76e-06
Epoch 6 | Batch 260/400 | Loss: 0.086111 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 265/400 | Loss: 0.211115 | LR: 9.76e-06
Epoch 6 | Batch 270/400 | Loss: 0.113513 | LR: 9.76e-06
Epoch 6 | Batch 275/400 | Loss: 0.445949 | LR: 9.76e-06
Epoch 6 | Batch 280/400 | Loss: 0.136899 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 285/400 | Loss: 0.021262 | LR: 9.76e-06
Epoch 6 | Batch 290/400 | Loss: 0.147352 | LR: 9.76e-06
Epoch 6 | Batch 295/400 | Loss: 0.087197 | LR: 9.76e-06
Epoch 6 | Batch 300/400 | Loss: 0.057247 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 305/400 | Loss: 0.069663 | LR: 9.76e-06
Epoch 6 | Batch 310/400 | Loss: 0.050414 | LR: 9.76e-06
Epoch 6 | Batch 315/400 | Loss: 0.008653 | LR: 9.76e-06
Epoch 6 | Batch 320/400 | Loss: 0.234361 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 325/400 | Loss: 0.095018 | LR: 9.76e-06
Epoch 6 | Batch 330/400 | Loss: 0.166729 | LR: 9.76e-06
Epoch 6 | Batch 335/400 | Loss: 0.212382 | LR: 9.76e-06
Epoch 6 | Batch 340/400 | Loss: 0.039888 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 345/400 | Loss: 0.083849 | LR: 9.76e-06
Epoch 6 | Batch 350/400 | Loss: 0.052033 | LR: 9.76e-06
Epoch 6 | Batch 355/400 | Loss: 0.141606 | LR: 9.76e-06
Epoch 6 | Batch 360/400 | Loss: 0.256744 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 365/400 | Loss: 0.006417 | LR: 9.76e-06
Epoch 6 | Batch 370/400 | Loss: 0.069506 | LR: 9.76e-06
Epoch 6 | Batch 375/400 | Loss: 0.028447 | LR: 9.76e-06
Epoch 6 | Batch 380/400 | Loss: 0.144339 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 6 | Batch 385/400 | Loss: 0.161208 | LR: 9.76e-06
Epoch 6 | Batch 390/400 | Loss: 0.043513 | LR: 9.76e-06
Epoch 6 | Batch 395/400 | Loss: 0.173452 | LR: 9.76e-06
âœ… ç¬¬ 6 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.130031
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.103326
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.132802
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.111636
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.008844
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.024370
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.039072
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.120001
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.094665
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.214191
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.153458
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.075400
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.479646
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.011029
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.435716
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.072217
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.119491
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.054509
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.124986

============================================================
ğŸ“Š Epoch 6/50 å®Œæˆ
   Train Loss: 0.130031
   Val Loss: 0.124986
   LR: 9.76e-06 | Time: 129.5s
============================================================
â³ æ—©åœè®¡æ•°: 2/10
[GPU MEM] End of Epoch 6 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 7 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 7 | Batch 0/400 | Loss: 0.015062 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 5/400 | Loss: 0.148266 | LR: 9.65e-06
Epoch 7 | Batch 10/400 | Loss: 0.185529 | LR: 9.65e-06
Epoch 7 | Batch 15/400 | Loss: 0.194238 | LR: 9.65e-06
Epoch 7 | Batch 20/400 | Loss: 0.076297 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 25/400 | Loss: 0.103882 | LR: 9.65e-06
Epoch 7 | Batch 30/400 | Loss: 0.069022 | LR: 9.65e-06
Epoch 7 | Batch 35/400 | Loss: 0.101395 | LR: 9.65e-06
Epoch 7 | Batch 40/400 | Loss: 0.091551 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 45/400 | Loss: 0.073172 | LR: 9.65e-06
Epoch 7 | Batch 50/400 | Loss: 0.029264 | LR: 9.65e-06
Epoch 7 | Batch 55/400 | Loss: 0.082899 | LR: 9.65e-06
Epoch 7 | Batch 60/400 | Loss: 0.172982 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 65/400 | Loss: 0.046388 | LR: 9.65e-06
Epoch 7 | Batch 70/400 | Loss: 0.113212 | LR: 9.65e-06
Epoch 7 | Batch 75/400 | Loss: 0.102356 | LR: 9.65e-06
Epoch 7 | Batch 80/400 | Loss: 0.141338 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 85/400 | Loss: 0.036741 | LR: 9.65e-06
Epoch 7 | Batch 90/400 | Loss: 0.104073 | LR: 9.65e-06
Epoch 7 | Batch 95/400 | Loss: 0.127837 | LR: 9.65e-06
Epoch 7 | Batch 100/400 | Loss: 0.371138 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 105/400 | Loss: 0.146386 | LR: 9.65e-06
Epoch 7 | Batch 110/400 | Loss: 0.038213 | LR: 9.65e-06
Epoch 7 | Batch 115/400 | Loss: 0.104318 | LR: 9.65e-06
Epoch 7 | Batch 120/400 | Loss: 0.289586 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 125/400 | Loss: 0.052490 | LR: 9.65e-06
Epoch 7 | Batch 130/400 | Loss: 0.034564 | LR: 9.65e-06
Epoch 7 | Batch 135/400 | Loss: 0.202619 | LR: 9.65e-06
Epoch 7 | Batch 140/400 | Loss: 0.391019 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 145/400 | Loss: 0.042991 | LR: 9.65e-06
Epoch 7 | Batch 150/400 | Loss: 0.122082 | LR: 9.65e-06
Epoch 7 | Batch 155/400 | Loss: 0.273068 | LR: 9.65e-06
Epoch 7 | Batch 160/400 | Loss: 0.096634 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 165/400 | Loss: 0.064451 | LR: 9.65e-06
Epoch 7 | Batch 170/400 | Loss: 0.088262 | LR: 9.65e-06
Epoch 7 | Batch 175/400 | Loss: 0.059971 | LR: 9.65e-06
Epoch 7 | Batch 180/400 | Loss: 0.033951 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 185/400 | Loss: 0.112136 | LR: 9.65e-06
Epoch 7 | Batch 190/400 | Loss: 0.136279 | LR: 9.65e-06
Epoch 7 | Batch 195/400 | Loss: 0.008607 | LR: 9.65e-06
Epoch 7 | Batch 200/400 | Loss: 0.009556 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 205/400 | Loss: 0.131413 | LR: 9.65e-06
Epoch 7 | Batch 210/400 | Loss: 0.058451 | LR: 9.65e-06
Epoch 7 | Batch 215/400 | Loss: 0.067775 | LR: 9.65e-06
Epoch 7 | Batch 220/400 | Loss: 0.557723 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 225/400 | Loss: 0.236244 | LR: 9.65e-06
Epoch 7 | Batch 230/400 | Loss: 0.028881 | LR: 9.65e-06
Epoch 7 | Batch 235/400 | Loss: 0.206336 | LR: 9.65e-06
Epoch 7 | Batch 240/400 | Loss: 0.047627 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 245/400 | Loss: 0.009079 | LR: 9.65e-06
Epoch 7 | Batch 250/400 | Loss: 0.024960 | LR: 9.65e-06
Epoch 7 | Batch 255/400 | Loss: 0.214126 | LR: 9.65e-06
Epoch 7 | Batch 260/400 | Loss: 0.028855 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 265/400 | Loss: 0.298257 | LR: 9.65e-06
Epoch 7 | Batch 270/400 | Loss: 0.086338 | LR: 9.65e-06
Epoch 7 | Batch 275/400 | Loss: 0.070652 | LR: 9.65e-06
Epoch 7 | Batch 280/400 | Loss: 0.240731 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 285/400 | Loss: 0.027770 | LR: 9.65e-06
Epoch 7 | Batch 290/400 | Loss: 0.142855 | LR: 9.65e-06
Epoch 7 | Batch 295/400 | Loss: 0.016113 | LR: 9.65e-06
Epoch 7 | Batch 300/400 | Loss: 0.054914 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 305/400 | Loss: 0.047048 | LR: 9.65e-06
Epoch 7 | Batch 310/400 | Loss: 0.084174 | LR: 9.65e-06
Epoch 7 | Batch 315/400 | Loss: 0.114132 | LR: 9.65e-06
Epoch 7 | Batch 320/400 | Loss: 0.020705 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 325/400 | Loss: 0.285411 | LR: 9.65e-06
Epoch 7 | Batch 330/400 | Loss: 0.066640 | LR: 9.65e-06
Epoch 7 | Batch 335/400 | Loss: 0.387303 | LR: 9.65e-06
Epoch 7 | Batch 340/400 | Loss: 0.097306 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 345/400 | Loss: 0.015562 | LR: 9.65e-06
Epoch 7 | Batch 350/400 | Loss: 0.138174 | LR: 9.65e-06
Epoch 7 | Batch 355/400 | Loss: 0.036640 | LR: 9.65e-06
Epoch 7 | Batch 360/400 | Loss: 0.007354 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 365/400 | Loss: 0.013773 | LR: 9.65e-06
Epoch 7 | Batch 370/400 | Loss: 0.028664 | LR: 9.65e-06
Epoch 7 | Batch 375/400 | Loss: 0.186655 | LR: 9.65e-06
Epoch 7 | Batch 380/400 | Loss: 0.028426 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 7 | Batch 385/400 | Loss: 0.013694 | LR: 9.65e-06
Epoch 7 | Batch 390/400 | Loss: 0.060211 | LR: 9.65e-06
Epoch 7 | Batch 395/400 | Loss: 0.039540 | LR: 9.65e-06
âœ… ç¬¬ 7 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.123339
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.109332
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.019745
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.008689
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.062016
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.090471
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.107728
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.239682
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.064685
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.079513
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.006572
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.098388
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.281835
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.168240
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.022266
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.247962
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.230044
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.155045
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.122890

============================================================
ğŸ“Š Epoch 7/50 å®Œæˆ
   Train Loss: 0.123339
   Val Loss: 0.122890
   LR: 9.65e-06 | Time: 129.0s
============================================================
â³ æ—©åœè®¡æ•°: 3/10
[GPU MEM] End of Epoch 7 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 8 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 8 | Batch 0/400 | Loss: 0.138167 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 5/400 | Loss: 0.342968 | LR: 9.53e-06
Epoch 8 | Batch 10/400 | Loss: 0.020650 | LR: 9.53e-06
Epoch 8 | Batch 15/400 | Loss: 0.163175 | LR: 9.53e-06
Epoch 8 | Batch 20/400 | Loss: 0.082292 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 25/400 | Loss: 0.073649 | LR: 9.53e-06
Epoch 8 | Batch 30/400 | Loss: 0.206083 | LR: 9.53e-06
Epoch 8 | Batch 35/400 | Loss: 0.052684 | LR: 9.53e-06
Epoch 8 | Batch 40/400 | Loss: 0.044636 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 45/400 | Loss: 0.195618 | LR: 9.53e-06
Epoch 8 | Batch 50/400 | Loss: 0.135552 | LR: 9.53e-06
Epoch 8 | Batch 55/400 | Loss: 0.109733 | LR: 9.53e-06
Epoch 8 | Batch 60/400 | Loss: 0.130768 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 65/400 | Loss: 0.072259 | LR: 9.53e-06
Epoch 8 | Batch 70/400 | Loss: 0.119414 | LR: 9.53e-06
Epoch 8 | Batch 75/400 | Loss: 0.257727 | LR: 9.53e-06
Epoch 8 | Batch 80/400 | Loss: 0.082859 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 85/400 | Loss: 0.050153 | LR: 9.53e-06
Epoch 8 | Batch 90/400 | Loss: 0.046828 | LR: 9.53e-06
Epoch 8 | Batch 95/400 | Loss: 0.117675 | LR: 9.53e-06
Epoch 8 | Batch 100/400 | Loss: 0.004352 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 105/400 | Loss: 0.029949 | LR: 9.53e-06
Epoch 8 | Batch 110/400 | Loss: 0.045659 | LR: 9.53e-06
Epoch 8 | Batch 115/400 | Loss: 0.034289 | LR: 9.53e-06
Epoch 8 | Batch 120/400 | Loss: 0.430356 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 125/400 | Loss: 0.305601 | LR: 9.53e-06
Epoch 8 | Batch 130/400 | Loss: 0.238818 | LR: 9.53e-06
Epoch 8 | Batch 135/400 | Loss: 0.078171 | LR: 9.53e-06
Epoch 8 | Batch 140/400 | Loss: 0.150841 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 145/400 | Loss: 0.011211 | LR: 9.53e-06
Epoch 8 | Batch 150/400 | Loss: 0.030673 | LR: 9.53e-06
Epoch 8 | Batch 155/400 | Loss: 0.154435 | LR: 9.53e-06
Epoch 8 | Batch 160/400 | Loss: 0.124874 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 165/400 | Loss: 0.048114 | LR: 9.53e-06
Epoch 8 | Batch 170/400 | Loss: 0.306972 | LR: 9.53e-06
Epoch 8 | Batch 175/400 | Loss: 0.222555 | LR: 9.53e-06
Epoch 8 | Batch 180/400 | Loss: 0.248433 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 185/400 | Loss: 0.195757 | LR: 9.53e-06
Epoch 8 | Batch 190/400 | Loss: 0.246463 | LR: 9.53e-06
Epoch 8 | Batch 195/400 | Loss: 0.125160 | LR: 9.53e-06
Epoch 8 | Batch 200/400 | Loss: 0.016982 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 205/400 | Loss: 0.134531 | LR: 9.53e-06
Epoch 8 | Batch 210/400 | Loss: 0.085108 | LR: 9.53e-06
Epoch 8 | Batch 215/400 | Loss: 0.072953 | LR: 9.53e-06
Epoch 8 | Batch 220/400 | Loss: 0.114196 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 225/400 | Loss: 0.011971 | LR: 9.53e-06
Epoch 8 | Batch 230/400 | Loss: 0.347505 | LR: 9.53e-06
Epoch 8 | Batch 235/400 | Loss: 0.057030 | LR: 9.53e-06
Epoch 8 | Batch 240/400 | Loss: 0.235473 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 245/400 | Loss: 0.187842 | LR: 9.53e-06
Epoch 8 | Batch 250/400 | Loss: 0.021350 | LR: 9.53e-06
Epoch 8 | Batch 255/400 | Loss: 0.015004 | LR: 9.53e-06
Epoch 8 | Batch 260/400 | Loss: 0.373519 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 265/400 | Loss: 0.045284 | LR: 9.53e-06
Epoch 8 | Batch 270/400 | Loss: 0.004639 | LR: 9.53e-06
Epoch 8 | Batch 275/400 | Loss: 0.526634 | LR: 9.53e-06
Epoch 8 | Batch 280/400 | Loss: 0.113151 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 285/400 | Loss: 0.027943 | LR: 9.53e-06
Epoch 8 | Batch 290/400 | Loss: 0.042293 | LR: 9.53e-06
Epoch 8 | Batch 295/400 | Loss: 0.447093 | LR: 9.53e-06
Epoch 8 | Batch 300/400 | Loss: 0.077942 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 305/400 | Loss: 0.067104 | LR: 9.53e-06
Epoch 8 | Batch 310/400 | Loss: 0.053503 | LR: 9.53e-06
Epoch 8 | Batch 315/400 | Loss: 0.079047 | LR: 9.53e-06
Epoch 8 | Batch 320/400 | Loss: 0.272293 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 325/400 | Loss: 0.011657 | LR: 9.53e-06
Epoch 8 | Batch 330/400 | Loss: 0.141133 | LR: 9.53e-06
Epoch 8 | Batch 335/400 | Loss: 0.048939 | LR: 9.53e-06
Epoch 8 | Batch 340/400 | Loss: 0.060264 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 345/400 | Loss: 0.071531 | LR: 9.53e-06
Epoch 8 | Batch 350/400 | Loss: 0.119849 | LR: 9.53e-06
Epoch 8 | Batch 355/400 | Loss: 0.077058 | LR: 9.53e-06
Epoch 8 | Batch 360/400 | Loss: 0.041061 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 365/400 | Loss: 0.034503 | LR: 9.53e-06
Epoch 8 | Batch 370/400 | Loss: 0.102331 | LR: 9.53e-06
Epoch 8 | Batch 375/400 | Loss: 0.008477 | LR: 9.53e-06
Epoch 8 | Batch 380/400 | Loss: 0.085789 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 8 | Batch 385/400 | Loss: 0.051087 | LR: 9.53e-06
Epoch 8 | Batch 390/400 | Loss: 0.129268 | LR: 9.53e-06
Epoch 8 | Batch 395/400 | Loss: 0.289303 | LR: 9.53e-06
âœ… ç¬¬ 8 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.138025
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.040513
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.305986
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.011872
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.232493
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.136420
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.028814
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.010289
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.197032
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.284329
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.087323
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.010943
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.052447
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.064372
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.036047
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.047551
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.111681
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.003610
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.136191

============================================================
ğŸ“Š Epoch 8/50 å®Œæˆ
   Train Loss: 0.138025
   Val Loss: 0.136191
   LR: 9.53e-06 | Time: 129.1s
============================================================
â³ æ—©åœè®¡æ•°: 4/10
[GPU MEM] End of Epoch 8 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 9 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 9 | Batch 0/400 | Loss: 0.220276 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 5/400 | Loss: 0.234799 | LR: 9.39e-06
Epoch 9 | Batch 10/400 | Loss: 0.104926 | LR: 9.39e-06
Epoch 9 | Batch 15/400 | Loss: 0.312341 | LR: 9.39e-06
Epoch 9 | Batch 20/400 | Loss: 0.053103 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 25/400 | Loss: 0.007464 | LR: 9.39e-06
Epoch 9 | Batch 30/400 | Loss: 0.074198 | LR: 9.39e-06
Epoch 9 | Batch 35/400 | Loss: 0.052151 | LR: 9.39e-06
Epoch 9 | Batch 40/400 | Loss: 0.049076 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 45/400 | Loss: 0.027767 | LR: 9.39e-06
Epoch 9 | Batch 50/400 | Loss: 0.043496 | LR: 9.39e-06
Epoch 9 | Batch 55/400 | Loss: 0.072435 | LR: 9.39e-06
Epoch 9 | Batch 60/400 | Loss: 0.376700 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 65/400 | Loss: 0.060675 | LR: 9.39e-06
Epoch 9 | Batch 70/400 | Loss: 0.273947 | LR: 9.39e-06
Epoch 9 | Batch 75/400 | Loss: 0.145237 | LR: 9.39e-06
Epoch 9 | Batch 80/400 | Loss: 0.031120 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 85/400 | Loss: 0.033878 | LR: 9.39e-06
Epoch 9 | Batch 90/400 | Loss: 0.135080 | LR: 9.39e-06
Epoch 9 | Batch 95/400 | Loss: 0.003727 | LR: 9.39e-06
Epoch 9 | Batch 100/400 | Loss: 0.007078 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 105/400 | Loss: 0.216113 | LR: 9.39e-06
Epoch 9 | Batch 110/400 | Loss: 0.276211 | LR: 9.39e-06
Epoch 9 | Batch 115/400 | Loss: 0.377789 | LR: 9.39e-06
Epoch 9 | Batch 120/400 | Loss: 0.107737 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 125/400 | Loss: 0.132487 | LR: 9.39e-06
Epoch 9 | Batch 130/400 | Loss: 0.153345 | LR: 9.39e-06
Epoch 9 | Batch 135/400 | Loss: 0.050474 | LR: 9.39e-06
Epoch 9 | Batch 140/400 | Loss: 0.531520 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 145/400 | Loss: 0.130013 | LR: 9.39e-06
Epoch 9 | Batch 150/400 | Loss: 0.194690 | LR: 9.39e-06
Epoch 9 | Batch 155/400 | Loss: 0.018231 | LR: 9.39e-06
Epoch 9 | Batch 160/400 | Loss: 0.022237 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 165/400 | Loss: 0.010725 | LR: 9.39e-06
Epoch 9 | Batch 170/400 | Loss: 0.003478 | LR: 9.39e-06
Epoch 9 | Batch 175/400 | Loss: 0.077744 | LR: 9.39e-06
Epoch 9 | Batch 180/400 | Loss: 0.016988 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 185/400 | Loss: 0.270152 | LR: 9.39e-06
Epoch 9 | Batch 190/400 | Loss: 0.005076 | LR: 9.39e-06
Epoch 9 | Batch 195/400 | Loss: 0.127839 | LR: 9.39e-06
Epoch 9 | Batch 200/400 | Loss: 0.107514 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 205/400 | Loss: 0.026428 | LR: 9.39e-06
Epoch 9 | Batch 210/400 | Loss: 0.004888 | LR: 9.39e-06
Epoch 9 | Batch 215/400 | Loss: 0.031428 | LR: 9.39e-06
Epoch 9 | Batch 220/400 | Loss: 0.017744 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 225/400 | Loss: 0.320741 | LR: 9.39e-06
Epoch 9 | Batch 230/400 | Loss: 0.040671 | LR: 9.39e-06
Epoch 9 | Batch 235/400 | Loss: 0.123090 | LR: 9.39e-06
Epoch 9 | Batch 240/400 | Loss: 0.045058 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 245/400 | Loss: 0.219393 | LR: 9.39e-06
Epoch 9 | Batch 250/400 | Loss: 0.207015 | LR: 9.39e-06
Epoch 9 | Batch 255/400 | Loss: 0.061902 | LR: 9.39e-06
Epoch 9 | Batch 260/400 | Loss: 0.096276 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 265/400 | Loss: 0.011924 | LR: 9.39e-06
Epoch 9 | Batch 270/400 | Loss: 0.119273 | LR: 9.39e-06
Epoch 9 | Batch 275/400 | Loss: 0.340958 | LR: 9.39e-06
Epoch 9 | Batch 280/400 | Loss: 0.049341 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 285/400 | Loss: 0.067130 | LR: 9.39e-06
Epoch 9 | Batch 290/400 | Loss: 0.010304 | LR: 9.39e-06
Epoch 9 | Batch 295/400 | Loss: 0.116366 | LR: 9.39e-06
Epoch 9 | Batch 300/400 | Loss: 0.061491 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 305/400 | Loss: 0.096838 | LR: 9.39e-06
Epoch 9 | Batch 310/400 | Loss: 0.117904 | LR: 9.39e-06
Epoch 9 | Batch 315/400 | Loss: 0.299683 | LR: 9.39e-06
Epoch 9 | Batch 320/400 | Loss: 0.107521 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 325/400 | Loss: 0.214304 | LR: 9.39e-06
Epoch 9 | Batch 330/400 | Loss: 0.084051 | LR: 9.39e-06
Epoch 9 | Batch 335/400 | Loss: 0.039250 | LR: 9.39e-06
Epoch 9 | Batch 340/400 | Loss: 0.043981 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 345/400 | Loss: 0.035802 | LR: 9.39e-06
Epoch 9 | Batch 350/400 | Loss: 0.077935 | LR: 9.39e-06
Epoch 9 | Batch 355/400 | Loss: 0.037364 | LR: 9.39e-06
Epoch 9 | Batch 360/400 | Loss: 0.424034 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 365/400 | Loss: 0.005158 | LR: 9.39e-06
Epoch 9 | Batch 370/400 | Loss: 0.031418 | LR: 9.39e-06
Epoch 9 | Batch 375/400 | Loss: 0.061813 | LR: 9.39e-06
Epoch 9 | Batch 380/400 | Loss: 0.361082 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 9 | Batch 385/400 | Loss: 0.038102 | LR: 9.39e-06
Epoch 9 | Batch 390/400 | Loss: 0.066318 | LR: 9.39e-06
Epoch 9 | Batch 395/400 | Loss: 0.069425 | LR: 9.39e-06
âœ… ç¬¬ 9 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.129767
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.107534
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.029955
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.107213
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.039966
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.066879
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.334218
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.100696
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.058078
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.103010
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.067969
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.056688
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.329334
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.028444
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.027100
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.005280
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.204870
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.009366
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.137911

============================================================
ğŸ“Š Epoch 9/50 å®Œæˆ
   Train Loss: 0.129767
   Val Loss: 0.137911
   LR: 9.39e-06 | Time: 128.9s
============================================================
â³ æ—©åœè®¡æ•°: 5/10
[GPU MEM] End of Epoch 9 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 10 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 10 | Batch 0/400 | Loss: 0.062844 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 5/400 | Loss: 0.093849 | LR: 9.23e-06
Epoch 10 | Batch 10/400 | Loss: 0.087287 | LR: 9.23e-06
Epoch 10 | Batch 15/400 | Loss: 0.140864 | LR: 9.23e-06
Epoch 10 | Batch 20/400 | Loss: 0.035875 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 25/400 | Loss: 0.104131 | LR: 9.23e-06
Epoch 10 | Batch 30/400 | Loss: 0.065938 | LR: 9.23e-06
Epoch 10 | Batch 35/400 | Loss: 0.212209 | LR: 9.23e-06
Epoch 10 | Batch 40/400 | Loss: 0.238128 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 45/400 | Loss: 0.027584 | LR: 9.23e-06
Epoch 10 | Batch 50/400 | Loss: 0.081067 | LR: 9.23e-06
Epoch 10 | Batch 55/400 | Loss: 0.198318 | LR: 9.23e-06
Epoch 10 | Batch 60/400 | Loss: 0.223745 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 65/400 | Loss: 0.016151 | LR: 9.23e-06
Epoch 10 | Batch 70/400 | Loss: 0.128810 | LR: 9.23e-06
Epoch 10 | Batch 75/400 | Loss: 0.168038 | LR: 9.23e-06
Epoch 10 | Batch 80/400 | Loss: 0.373854 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 85/400 | Loss: 0.075330 | LR: 9.23e-06
Epoch 10 | Batch 90/400 | Loss: 0.193750 | LR: 9.23e-06
Epoch 10 | Batch 95/400 | Loss: 0.254036 | LR: 9.23e-06
Epoch 10 | Batch 100/400 | Loss: 0.237828 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 105/400 | Loss: 0.221212 | LR: 9.23e-06
Epoch 10 | Batch 110/400 | Loss: 0.077528 | LR: 9.23e-06
Epoch 10 | Batch 115/400 | Loss: 0.255196 | LR: 9.23e-06
Epoch 10 | Batch 120/400 | Loss: 0.007325 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 125/400 | Loss: 0.101874 | LR: 9.23e-06
Epoch 10 | Batch 130/400 | Loss: 0.268519 | LR: 9.23e-06
Epoch 10 | Batch 135/400 | Loss: 0.160453 | LR: 9.23e-06
Epoch 10 | Batch 140/400 | Loss: 0.420040 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 145/400 | Loss: 0.090529 | LR: 9.23e-06
Epoch 10 | Batch 150/400 | Loss: 0.300169 | LR: 9.23e-06
Epoch 10 | Batch 155/400 | Loss: 0.052158 | LR: 9.23e-06
Epoch 10 | Batch 160/400 | Loss: 0.221450 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 165/400 | Loss: 0.011292 | LR: 9.23e-06
Epoch 10 | Batch 170/400 | Loss: 0.021921 | LR: 9.23e-06
Epoch 10 | Batch 175/400 | Loss: 0.081179 | LR: 9.23e-06
Epoch 10 | Batch 180/400 | Loss: 0.279251 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 185/400 | Loss: 0.087722 | LR: 9.23e-06
Epoch 10 | Batch 190/400 | Loss: 0.054336 | LR: 9.23e-06
Epoch 10 | Batch 195/400 | Loss: 0.190683 | LR: 9.23e-06
Epoch 10 | Batch 200/400 | Loss: 0.030038 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 205/400 | Loss: 0.265120 | LR: 9.23e-06
Epoch 10 | Batch 210/400 | Loss: 0.109476 | LR: 9.23e-06
Epoch 10 | Batch 215/400 | Loss: 0.019972 | LR: 9.23e-06
Epoch 10 | Batch 220/400 | Loss: 0.248810 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 225/400 | Loss: 0.343347 | LR: 9.23e-06
Epoch 10 | Batch 230/400 | Loss: 0.356250 | LR: 9.23e-06
Epoch 10 | Batch 235/400 | Loss: 0.446187 | LR: 9.23e-06
Epoch 10 | Batch 240/400 | Loss: 0.077932 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 245/400 | Loss: 0.045250 | LR: 9.23e-06
Epoch 10 | Batch 250/400 | Loss: 0.094783 | LR: 9.23e-06
Epoch 10 | Batch 255/400 | Loss: 0.386318 | LR: 9.23e-06
Epoch 10 | Batch 260/400 | Loss: 0.087801 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 265/400 | Loss: 0.296932 | LR: 9.23e-06
Epoch 10 | Batch 270/400 | Loss: 0.099914 | LR: 9.23e-06
Epoch 10 | Batch 275/400 | Loss: 0.176725 | LR: 9.23e-06
Epoch 10 | Batch 280/400 | Loss: 0.219779 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 285/400 | Loss: 0.025407 | LR: 9.23e-06
Epoch 10 | Batch 290/400 | Loss: 0.311225 | LR: 9.23e-06
Epoch 10 | Batch 295/400 | Loss: 0.238682 | LR: 9.23e-06
Epoch 10 | Batch 300/400 | Loss: 0.156372 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 305/400 | Loss: 0.039832 | LR: 9.23e-06
Epoch 10 | Batch 310/400 | Loss: 0.086774 | LR: 9.23e-06
Epoch 10 | Batch 315/400 | Loss: 0.055867 | LR: 9.23e-06
Epoch 10 | Batch 320/400 | Loss: 0.427071 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 325/400 | Loss: 0.080155 | LR: 9.23e-06
Epoch 10 | Batch 330/400 | Loss: 0.189066 | LR: 9.23e-06
Epoch 10 | Batch 335/400 | Loss: 0.214110 | LR: 9.23e-06
Epoch 10 | Batch 340/400 | Loss: 0.194171 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 345/400 | Loss: 0.007003 | LR: 9.23e-06
Epoch 10 | Batch 350/400 | Loss: 0.112282 | LR: 9.23e-06
Epoch 10 | Batch 355/400 | Loss: 0.034364 | LR: 9.23e-06
Epoch 10 | Batch 360/400 | Loss: 0.049503 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 365/400 | Loss: 0.202046 | LR: 9.23e-06
Epoch 10 | Batch 370/400 | Loss: 0.240945 | LR: 9.23e-06
Epoch 10 | Batch 375/400 | Loss: 0.120155 | LR: 9.23e-06
Epoch 10 | Batch 380/400 | Loss: 0.218051 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 10 | Batch 385/400 | Loss: 0.491212 | LR: 9.23e-06
Epoch 10 | Batch 390/400 | Loss: 0.149166 | LR: 9.23e-06
Epoch 10 | Batch 395/400 | Loss: 0.233267 | LR: 9.23e-06
âœ… ç¬¬ 10 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.138045
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.090077
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.566951
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.074280
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.023838
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.208399
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.041193
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.021405
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.307909
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.375662
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.024881
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.383603
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.243453
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.126274
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.227756
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.165654
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.020112
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.188414
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.134152
ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆ Epoch 10 çš„é¢„è§ˆå›¾...
âœ¨ é¢„è§ˆå›¾å·²ä¿å­˜åˆ° training_results_drop_object_512

============================================================
ğŸ“Š Epoch 10/50 å®Œæˆ
   Train Loss: 0.138045
   Val Loss: 0.134152
   LR: 9.23e-06 | Time: 133.6s
============================================================
â³ æ—©åœè®¡æ•°: 6/10
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_drop_object_512/controlnet_drop_object_epoch_10.pth
[GPU MEM] End of Epoch 10 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 11 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 11 | Batch 0/400 | Loss: 0.049944 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 5/400 | Loss: 0.004714 | LR: 9.05e-06
Epoch 11 | Batch 10/400 | Loss: 0.098851 | LR: 9.05e-06
Epoch 11 | Batch 15/400 | Loss: 0.100202 | LR: 9.05e-06
Epoch 11 | Batch 20/400 | Loss: 0.008980 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 25/400 | Loss: 0.053883 | LR: 9.05e-06
Epoch 11 | Batch 30/400 | Loss: 0.157210 | LR: 9.05e-06
Epoch 11 | Batch 35/400 | Loss: 0.243733 | LR: 9.05e-06
Epoch 11 | Batch 40/400 | Loss: 0.135849 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 45/400 | Loss: 0.259764 | LR: 9.05e-06
Epoch 11 | Batch 50/400 | Loss: 0.150238 | LR: 9.05e-06
Epoch 11 | Batch 55/400 | Loss: 0.213671 | LR: 9.05e-06
Epoch 11 | Batch 60/400 | Loss: 0.019630 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 65/400 | Loss: 0.168100 | LR: 9.05e-06
Epoch 11 | Batch 70/400 | Loss: 0.164960 | LR: 9.05e-06
Epoch 11 | Batch 75/400 | Loss: 0.192266 | LR: 9.05e-06
Epoch 11 | Batch 80/400 | Loss: 0.094910 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 85/400 | Loss: 0.185674 | LR: 9.05e-06
Epoch 11 | Batch 90/400 | Loss: 0.480393 | LR: 9.05e-06
Epoch 11 | Batch 95/400 | Loss: 0.009599 | LR: 9.05e-06
Epoch 11 | Batch 100/400 | Loss: 0.070030 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 105/400 | Loss: 0.237337 | LR: 9.05e-06
Epoch 11 | Batch 110/400 | Loss: 0.167530 | LR: 9.05e-06
Epoch 11 | Batch 115/400 | Loss: 0.205932 | LR: 9.05e-06
Epoch 11 | Batch 120/400 | Loss: 0.095212 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 125/400 | Loss: 0.066238 | LR: 9.05e-06
Epoch 11 | Batch 130/400 | Loss: 0.215585 | LR: 9.05e-06
Epoch 11 | Batch 135/400 | Loss: 0.011685 | LR: 9.05e-06
Epoch 11 | Batch 140/400 | Loss: 0.207894 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 145/400 | Loss: 0.085181 | LR: 9.05e-06
Epoch 11 | Batch 150/400 | Loss: 0.008497 | LR: 9.05e-06
Epoch 11 | Batch 155/400 | Loss: 0.237939 | LR: 9.05e-06
Epoch 11 | Batch 160/400 | Loss: 0.036446 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 165/400 | Loss: 0.052738 | LR: 9.05e-06
Epoch 11 | Batch 170/400 | Loss: 0.297681 | LR: 9.05e-06
Epoch 11 | Batch 175/400 | Loss: 0.139178 | LR: 9.05e-06
Epoch 11 | Batch 180/400 | Loss: 0.024572 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 185/400 | Loss: 0.017346 | LR: 9.05e-06
Epoch 11 | Batch 190/400 | Loss: 0.013886 | LR: 9.05e-06
Epoch 11 | Batch 195/400 | Loss: 0.189916 | LR: 9.05e-06
Epoch 11 | Batch 200/400 | Loss: 0.210956 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 205/400 | Loss: 0.139595 | LR: 9.05e-06
Epoch 11 | Batch 210/400 | Loss: 0.338763 | LR: 9.05e-06
Epoch 11 | Batch 215/400 | Loss: 0.032576 | LR: 9.05e-06
Epoch 11 | Batch 220/400 | Loss: 0.281482 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 225/400 | Loss: 0.092641 | LR: 9.05e-06
Epoch 11 | Batch 230/400 | Loss: 0.162703 | LR: 9.05e-06
Epoch 11 | Batch 235/400 | Loss: 0.175006 | LR: 9.05e-06
Epoch 11 | Batch 240/400 | Loss: 0.179851 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 245/400 | Loss: 0.011601 | LR: 9.05e-06
Epoch 11 | Batch 250/400 | Loss: 0.061885 | LR: 9.05e-06
Epoch 11 | Batch 255/400 | Loss: 0.135113 | LR: 9.05e-06
Epoch 11 | Batch 260/400 | Loss: 0.186780 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 265/400 | Loss: 0.017999 | LR: 9.05e-06
Epoch 11 | Batch 270/400 | Loss: 0.024757 | LR: 9.05e-06
Epoch 11 | Batch 275/400 | Loss: 0.166157 | LR: 9.05e-06
Epoch 11 | Batch 280/400 | Loss: 0.149501 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 285/400 | Loss: 0.123057 | LR: 9.05e-06
Epoch 11 | Batch 290/400 | Loss: 0.108847 | LR: 9.05e-06
Epoch 11 | Batch 295/400 | Loss: 0.230733 | LR: 9.05e-06
Epoch 11 | Batch 300/400 | Loss: 0.147723 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 305/400 | Loss: 0.089584 | LR: 9.05e-06
Epoch 11 | Batch 310/400 | Loss: 0.030786 | LR: 9.05e-06
Epoch 11 | Batch 315/400 | Loss: 0.533836 | LR: 9.05e-06
Epoch 11 | Batch 320/400 | Loss: 0.074776 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 325/400 | Loss: 0.193457 | LR: 9.05e-06
Epoch 11 | Batch 330/400 | Loss: 0.054801 | LR: 9.05e-06
Epoch 11 | Batch 335/400 | Loss: 0.029147 | LR: 9.05e-06
Epoch 11 | Batch 340/400 | Loss: 0.094187 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 345/400 | Loss: 0.470051 | LR: 9.05e-06
Epoch 11 | Batch 350/400 | Loss: 0.019566 | LR: 9.05e-06
Epoch 11 | Batch 355/400 | Loss: 0.032592 | LR: 9.05e-06
Epoch 11 | Batch 360/400 | Loss: 0.044502 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 365/400 | Loss: 0.073487 | LR: 9.05e-06
Epoch 11 | Batch 370/400 | Loss: 0.130699 | LR: 9.05e-06
Epoch 11 | Batch 375/400 | Loss: 0.225979 | LR: 9.05e-06
Epoch 11 | Batch 380/400 | Loss: 0.056273 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 11 | Batch 385/400 | Loss: 0.307901 | LR: 9.05e-06
Epoch 11 | Batch 390/400 | Loss: 0.302795 | LR: 9.05e-06
Epoch 11 | Batch 395/400 | Loss: 0.094858 | LR: 9.05e-06
âœ… ç¬¬ 11 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.127039
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.028183
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.201031
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.177489
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.232188
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.188307
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.026684
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.151327
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.316595
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.033629
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.199394
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.227314
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.178459
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.009777
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.139776
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.071161
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.085692
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.021300
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.123212

============================================================
ğŸ“Š Epoch 11/50 å®Œæˆ
   Train Loss: 0.127039
   Val Loss: 0.123212
   LR: 9.05e-06 | Time: 130.6s
============================================================
â³ æ—©åœè®¡æ•°: 7/10
[GPU MEM] End of Epoch 11 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 12 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 12 | Batch 0/400 | Loss: 0.392940 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 5/400 | Loss: 0.140795 | LR: 8.86e-06
Epoch 12 | Batch 10/400 | Loss: 0.111469 | LR: 8.86e-06
Epoch 12 | Batch 15/400 | Loss: 0.067752 | LR: 8.86e-06
Epoch 12 | Batch 20/400 | Loss: 0.106195 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 25/400 | Loss: 0.448394 | LR: 8.86e-06
Epoch 12 | Batch 30/400 | Loss: 0.133396 | LR: 8.86e-06
Epoch 12 | Batch 35/400 | Loss: 0.052044 | LR: 8.86e-06
Epoch 12 | Batch 40/400 | Loss: 0.312698 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 45/400 | Loss: 0.148799 | LR: 8.86e-06
Epoch 12 | Batch 50/400 | Loss: 0.113742 | LR: 8.86e-06
Epoch 12 | Batch 55/400 | Loss: 0.123324 | LR: 8.86e-06
Epoch 12 | Batch 60/400 | Loss: 0.125099 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 65/400 | Loss: 0.088270 | LR: 8.86e-06
Epoch 12 | Batch 70/400 | Loss: 0.057552 | LR: 8.86e-06
Epoch 12 | Batch 75/400 | Loss: 0.093945 | LR: 8.86e-06
Epoch 12 | Batch 80/400 | Loss: 0.128770 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 85/400 | Loss: 0.175339 | LR: 8.86e-06
Epoch 12 | Batch 90/400 | Loss: 0.263107 | LR: 8.86e-06
Epoch 12 | Batch 95/400 | Loss: 0.086579 | LR: 8.86e-06
Epoch 12 | Batch 100/400 | Loss: 0.023194 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 105/400 | Loss: 0.130786 | LR: 8.86e-06
Epoch 12 | Batch 110/400 | Loss: 0.106284 | LR: 8.86e-06
Epoch 12 | Batch 115/400 | Loss: 0.086735 | LR: 8.86e-06
Epoch 12 | Batch 120/400 | Loss: 0.109881 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 125/400 | Loss: 0.054489 | LR: 8.86e-06
Epoch 12 | Batch 130/400 | Loss: 0.095649 | LR: 8.86e-06
Epoch 12 | Batch 135/400 | Loss: 0.031329 | LR: 8.86e-06
Epoch 12 | Batch 140/400 | Loss: 0.072798 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 145/400 | Loss: 0.089480 | LR: 8.86e-06
Epoch 12 | Batch 150/400 | Loss: 0.146701 | LR: 8.86e-06
Epoch 12 | Batch 155/400 | Loss: 0.041201 | LR: 8.86e-06
Epoch 12 | Batch 160/400 | Loss: 0.173860 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 165/400 | Loss: 0.101821 | LR: 8.86e-06
Epoch 12 | Batch 170/400 | Loss: 0.235960 | LR: 8.86e-06
Epoch 12 | Batch 175/400 | Loss: 0.023159 | LR: 8.86e-06
Epoch 12 | Batch 180/400 | Loss: 0.075146 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 185/400 | Loss: 0.165797 | LR: 8.86e-06
Epoch 12 | Batch 190/400 | Loss: 0.027013 | LR: 8.86e-06
Epoch 12 | Batch 195/400 | Loss: 0.309288 | LR: 8.86e-06
Epoch 12 | Batch 200/400 | Loss: 0.081556 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 205/400 | Loss: 0.224678 | LR: 8.86e-06
Epoch 12 | Batch 210/400 | Loss: 0.077706 | LR: 8.86e-06
Epoch 12 | Batch 215/400 | Loss: 0.051428 | LR: 8.86e-06
Epoch 12 | Batch 220/400 | Loss: 0.316053 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 225/400 | Loss: 0.126513 | LR: 8.86e-06
Epoch 12 | Batch 230/400 | Loss: 0.017731 | LR: 8.86e-06
Epoch 12 | Batch 235/400 | Loss: 0.259917 | LR: 8.86e-06
Epoch 12 | Batch 240/400 | Loss: 0.133774 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 245/400 | Loss: 0.170341 | LR: 8.86e-06
Epoch 12 | Batch 250/400 | Loss: 0.033386 | LR: 8.86e-06
Epoch 12 | Batch 255/400 | Loss: 0.067126 | LR: 8.86e-06
Epoch 12 | Batch 260/400 | Loss: 0.451319 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 265/400 | Loss: 0.145014 | LR: 8.86e-06
Epoch 12 | Batch 270/400 | Loss: 0.111685 | LR: 8.86e-06
Epoch 12 | Batch 275/400 | Loss: 0.117910 | LR: 8.86e-06
Epoch 12 | Batch 280/400 | Loss: 0.018028 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 285/400 | Loss: 0.154486 | LR: 8.86e-06
Epoch 12 | Batch 290/400 | Loss: 0.016325 | LR: 8.86e-06
Epoch 12 | Batch 295/400 | Loss: 0.171066 | LR: 8.86e-06
Epoch 12 | Batch 300/400 | Loss: 0.254104 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 305/400 | Loss: 0.206278 | LR: 8.86e-06
Epoch 12 | Batch 310/400 | Loss: 0.233530 | LR: 8.86e-06
Epoch 12 | Batch 315/400 | Loss: 0.004512 | LR: 8.86e-06
Epoch 12 | Batch 320/400 | Loss: 0.050655 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 325/400 | Loss: 0.188337 | LR: 8.86e-06
Epoch 12 | Batch 330/400 | Loss: 0.011195 | LR: 8.86e-06
Epoch 12 | Batch 335/400 | Loss: 0.028995 | LR: 8.86e-06
Epoch 12 | Batch 340/400 | Loss: 0.356918 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 345/400 | Loss: 0.037720 | LR: 8.86e-06
Epoch 12 | Batch 350/400 | Loss: 0.305371 | LR: 8.86e-06
Epoch 12 | Batch 355/400 | Loss: 0.175612 | LR: 8.86e-06
Epoch 12 | Batch 360/400 | Loss: 0.468607 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 365/400 | Loss: 0.053737 | LR: 8.86e-06
Epoch 12 | Batch 370/400 | Loss: 0.024667 | LR: 8.86e-06
Epoch 12 | Batch 375/400 | Loss: 0.010187 | LR: 8.86e-06
Epoch 12 | Batch 380/400 | Loss: 0.528258 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 12 | Batch 385/400 | Loss: 0.069478 | LR: 8.86e-06
Epoch 12 | Batch 390/400 | Loss: 0.303772 | LR: 8.86e-06
Epoch 12 | Batch 395/400 | Loss: 0.048657 | LR: 8.86e-06
âœ… ç¬¬ 12 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.134117
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.214346
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.040746
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.048407
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.180008
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.068562
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.031584
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.085108
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.242584
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.125898
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.422394
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.035700
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.173465
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.148206
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.394489
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.333637
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.161661
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.013110
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.161569

============================================================
ğŸ“Š Epoch 12/50 å®Œæˆ
   Train Loss: 0.134117
   Val Loss: 0.161569
   LR: 8.86e-06 | Time: 129.0s
============================================================
â³ æ—©åœè®¡æ•°: 8/10
[GPU MEM] End of Epoch 12 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 13 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 13 | Batch 0/400 | Loss: 0.009287 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 5/400 | Loss: 0.245592 | LR: 8.66e-06
Epoch 13 | Batch 10/400 | Loss: 0.020846 | LR: 8.66e-06
Epoch 13 | Batch 15/400 | Loss: 0.007348 | LR: 8.66e-06
Epoch 13 | Batch 20/400 | Loss: 0.117762 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 25/400 | Loss: 0.082863 | LR: 8.66e-06
Epoch 13 | Batch 30/400 | Loss: 0.106827 | LR: 8.66e-06
Epoch 13 | Batch 35/400 | Loss: 0.069227 | LR: 8.66e-06
Epoch 13 | Batch 40/400 | Loss: 0.160437 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 45/400 | Loss: 0.182442 | LR: 8.66e-06
Epoch 13 | Batch 50/400 | Loss: 0.074697 | LR: 8.66e-06
Epoch 13 | Batch 55/400 | Loss: 0.023113 | LR: 8.66e-06
Epoch 13 | Batch 60/400 | Loss: 0.004903 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 65/400 | Loss: 0.061023 | LR: 8.66e-06
Epoch 13 | Batch 70/400 | Loss: 0.074547 | LR: 8.66e-06
Epoch 13 | Batch 75/400 | Loss: 0.266996 | LR: 8.66e-06
Epoch 13 | Batch 80/400 | Loss: 0.063705 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 85/400 | Loss: 0.139355 | LR: 8.66e-06
Epoch 13 | Batch 90/400 | Loss: 0.117980 | LR: 8.66e-06
Epoch 13 | Batch 95/400 | Loss: 0.271613 | LR: 8.66e-06
Epoch 13 | Batch 100/400 | Loss: 0.046213 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 105/400 | Loss: 0.118529 | LR: 8.66e-06
Epoch 13 | Batch 110/400 | Loss: 0.024161 | LR: 8.66e-06
Epoch 13 | Batch 115/400 | Loss: 0.084937 | LR: 8.66e-06
Epoch 13 | Batch 120/400 | Loss: 0.370183 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 125/400 | Loss: 0.368141 | LR: 8.66e-06
Epoch 13 | Batch 130/400 | Loss: 0.377056 | LR: 8.66e-06
Epoch 13 | Batch 135/400 | Loss: 0.154826 | LR: 8.66e-06
Epoch 13 | Batch 140/400 | Loss: 0.346119 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 145/400 | Loss: 0.104534 | LR: 8.66e-06
Epoch 13 | Batch 150/400 | Loss: 0.052285 | LR: 8.66e-06
Epoch 13 | Batch 155/400 | Loss: 0.126521 | LR: 8.66e-06
Epoch 13 | Batch 160/400 | Loss: 0.244963 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 165/400 | Loss: 0.215255 | LR: 8.66e-06
Epoch 13 | Batch 170/400 | Loss: 0.048592 | LR: 8.66e-06
Epoch 13 | Batch 175/400 | Loss: 0.160027 | LR: 8.66e-06
Epoch 13 | Batch 180/400 | Loss: 0.282123 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 185/400 | Loss: 0.018189 | LR: 8.66e-06
Epoch 13 | Batch 190/400 | Loss: 0.012016 | LR: 8.66e-06
Epoch 13 | Batch 195/400 | Loss: 0.049772 | LR: 8.66e-06
Epoch 13 | Batch 200/400 | Loss: 0.190440 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 205/400 | Loss: 0.135613 | LR: 8.66e-06
Epoch 13 | Batch 210/400 | Loss: 0.113225 | LR: 8.66e-06
Epoch 13 | Batch 215/400 | Loss: 0.064512 | LR: 8.66e-06
Epoch 13 | Batch 220/400 | Loss: 0.282011 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 225/400 | Loss: 0.149932 | LR: 8.66e-06
Epoch 13 | Batch 230/400 | Loss: 0.276954 | LR: 8.66e-06
Epoch 13 | Batch 235/400 | Loss: 0.025240 | LR: 8.66e-06
Epoch 13 | Batch 240/400 | Loss: 0.118889 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 245/400 | Loss: 0.024327 | LR: 8.66e-06
Epoch 13 | Batch 250/400 | Loss: 0.193141 | LR: 8.66e-06
Epoch 13 | Batch 255/400 | Loss: 0.032317 | LR: 8.66e-06
Epoch 13 | Batch 260/400 | Loss: 0.246684 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 265/400 | Loss: 0.367608 | LR: 8.66e-06
Epoch 13 | Batch 270/400 | Loss: 0.144125 | LR: 8.66e-06
Epoch 13 | Batch 275/400 | Loss: 0.068448 | LR: 8.66e-06
Epoch 13 | Batch 280/400 | Loss: 0.068178 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 285/400 | Loss: 0.160374 | LR: 8.66e-06
Epoch 13 | Batch 290/400 | Loss: 0.123545 | LR: 8.66e-06
Epoch 13 | Batch 295/400 | Loss: 0.226132 | LR: 8.66e-06
Epoch 13 | Batch 300/400 | Loss: 0.142248 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 305/400 | Loss: 0.402162 | LR: 8.66e-06
Epoch 13 | Batch 310/400 | Loss: 0.169481 | LR: 8.66e-06
Epoch 13 | Batch 315/400 | Loss: 0.083427 | LR: 8.66e-06
Epoch 13 | Batch 320/400 | Loss: 0.301923 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 325/400 | Loss: 0.013828 | LR: 8.66e-06
Epoch 13 | Batch 330/400 | Loss: 0.028098 | LR: 8.66e-06
Epoch 13 | Batch 335/400 | Loss: 0.334700 | LR: 8.66e-06
Epoch 13 | Batch 340/400 | Loss: 0.186723 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 345/400 | Loss: 0.020731 | LR: 8.66e-06
Epoch 13 | Batch 350/400 | Loss: 0.095481 | LR: 8.66e-06
Epoch 13 | Batch 355/400 | Loss: 0.045035 | LR: 8.66e-06
Epoch 13 | Batch 360/400 | Loss: 0.206335 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 365/400 | Loss: 0.012484 | LR: 8.66e-06
Epoch 13 | Batch 370/400 | Loss: 0.121769 | LR: 8.66e-06
Epoch 13 | Batch 375/400 | Loss: 0.070680 | LR: 8.66e-06
Epoch 13 | Batch 380/400 | Loss: 0.036661 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 13 | Batch 385/400 | Loss: 0.205451 | LR: 8.66e-06
Epoch 13 | Batch 390/400 | Loss: 0.145939 | LR: 8.66e-06
Epoch 13 | Batch 395/400 | Loss: 0.414275 | LR: 8.66e-06
âœ… ç¬¬ 13 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.130066
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.129844
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.171516
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.031201
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.149101
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.049379
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.035688
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.248676
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.028636
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.276031
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.063932
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.018426
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.289266
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.116177
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.342849
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.045197
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.093170
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.107795
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.135019

============================================================
ğŸ“Š Epoch 13/50 å®Œæˆ
   Train Loss: 0.130066
   Val Loss: 0.135019
   LR: 8.66e-06 | Time: 129.5s
============================================================
â³ æ—©åœè®¡æ•°: 9/10
[GPU MEM] End of Epoch 13 allocated=8.10GB reserved=11.39GB
ğŸ“š å¼€å§‹ç¬¬ 14 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 14 | Batch 0/400 | Loss: 0.029828 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch0 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 5/400 | Loss: 0.072048 | LR: 8.44e-06
Epoch 14 | Batch 10/400 | Loss: 0.143989 | LR: 8.44e-06
Epoch 14 | Batch 15/400 | Loss: 0.082880 | LR: 8.44e-06
Epoch 14 | Batch 20/400 | Loss: 0.232239 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch20 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 25/400 | Loss: 0.405860 | LR: 8.44e-06
Epoch 14 | Batch 30/400 | Loss: 0.136801 | LR: 8.44e-06
Epoch 14 | Batch 35/400 | Loss: 0.074624 | LR: 8.44e-06
Epoch 14 | Batch 40/400 | Loss: 0.022768 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch40 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 45/400 | Loss: 0.260487 | LR: 8.44e-06
Epoch 14 | Batch 50/400 | Loss: 0.307230 | LR: 8.44e-06
Epoch 14 | Batch 55/400 | Loss: 0.228175 | LR: 8.44e-06
Epoch 14 | Batch 60/400 | Loss: 0.100039 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch60 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 65/400 | Loss: 0.003821 | LR: 8.44e-06
Epoch 14 | Batch 70/400 | Loss: 0.248735 | LR: 8.44e-06
Epoch 14 | Batch 75/400 | Loss: 0.012664 | LR: 8.44e-06
Epoch 14 | Batch 80/400 | Loss: 0.292396 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch80 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 85/400 | Loss: 0.334207 | LR: 8.44e-06
Epoch 14 | Batch 90/400 | Loss: 0.048984 | LR: 8.44e-06
Epoch 14 | Batch 95/400 | Loss: 0.179536 | LR: 8.44e-06
Epoch 14 | Batch 100/400 | Loss: 0.132092 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch100 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 105/400 | Loss: 0.010273 | LR: 8.44e-06
Epoch 14 | Batch 110/400 | Loss: 0.033386 | LR: 8.44e-06
Epoch 14 | Batch 115/400 | Loss: 0.205954 | LR: 8.44e-06
Epoch 14 | Batch 120/400 | Loss: 0.223558 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 125/400 | Loss: 0.218174 | LR: 8.44e-06
Epoch 14 | Batch 130/400 | Loss: 0.121309 | LR: 8.44e-06
Epoch 14 | Batch 135/400 | Loss: 0.291286 | LR: 8.44e-06
Epoch 14 | Batch 140/400 | Loss: 0.097633 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 145/400 | Loss: 0.022836 | LR: 8.44e-06
Epoch 14 | Batch 150/400 | Loss: 0.018115 | LR: 8.44e-06
Epoch 14 | Batch 155/400 | Loss: 0.003638 | LR: 8.44e-06
Epoch 14 | Batch 160/400 | Loss: 0.103357 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 165/400 | Loss: 0.019036 | LR: 8.44e-06
Epoch 14 | Batch 170/400 | Loss: 0.056840 | LR: 8.44e-06
Epoch 14 | Batch 175/400 | Loss: 0.031994 | LR: 8.44e-06
Epoch 14 | Batch 180/400 | Loss: 0.089925 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 185/400 | Loss: 0.219254 | LR: 8.44e-06
Epoch 14 | Batch 190/400 | Loss: 0.368673 | LR: 8.44e-06
Epoch 14 | Batch 195/400 | Loss: 0.021853 | LR: 8.44e-06
Epoch 14 | Batch 200/400 | Loss: 0.042096 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 205/400 | Loss: 0.448500 | LR: 8.44e-06
Epoch 14 | Batch 210/400 | Loss: 0.087695 | LR: 8.44e-06
Epoch 14 | Batch 215/400 | Loss: 0.200595 | LR: 8.44e-06
Epoch 14 | Batch 220/400 | Loss: 0.314897 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 225/400 | Loss: 0.224130 | LR: 8.44e-06
Epoch 14 | Batch 230/400 | Loss: 0.016902 | LR: 8.44e-06
Epoch 14 | Batch 235/400 | Loss: 0.017829 | LR: 8.44e-06
Epoch 14 | Batch 240/400 | Loss: 0.098614 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 245/400 | Loss: 0.095635 | LR: 8.44e-06
Epoch 14 | Batch 250/400 | Loss: 0.137533 | LR: 8.44e-06
Epoch 14 | Batch 255/400 | Loss: 0.189890 | LR: 8.44e-06
Epoch 14 | Batch 260/400 | Loss: 0.160144 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 265/400 | Loss: 0.055193 | LR: 8.44e-06
Epoch 14 | Batch 270/400 | Loss: 0.038827 | LR: 8.44e-06
Epoch 14 | Batch 275/400 | Loss: 0.080289 | LR: 8.44e-06
Epoch 14 | Batch 280/400 | Loss: 0.380331 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 285/400 | Loss: 0.066955 | LR: 8.44e-06
Epoch 14 | Batch 290/400 | Loss: 0.032384 | LR: 8.44e-06
Epoch 14 | Batch 295/400 | Loss: 0.069070 | LR: 8.44e-06
Epoch 14 | Batch 300/400 | Loss: 0.020345 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 305/400 | Loss: 0.086606 | LR: 8.44e-06
Epoch 14 | Batch 310/400 | Loss: 0.102200 | LR: 8.44e-06
Epoch 14 | Batch 315/400 | Loss: 0.030105 | LR: 8.44e-06
Epoch 14 | Batch 320/400 | Loss: 0.212123 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 325/400 | Loss: 0.025804 | LR: 8.44e-06
Epoch 14 | Batch 330/400 | Loss: 0.145921 | LR: 8.44e-06
Epoch 14 | Batch 335/400 | Loss: 0.024480 | LR: 8.44e-06
Epoch 14 | Batch 340/400 | Loss: 0.067910 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 345/400 | Loss: 0.014765 | LR: 8.44e-06
Epoch 14 | Batch 350/400 | Loss: 0.005126 | LR: 8.44e-06
Epoch 14 | Batch 355/400 | Loss: 0.065928 | LR: 8.44e-06
Epoch 14 | Batch 360/400 | Loss: 0.023748 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 365/400 | Loss: 0.192718 | LR: 8.44e-06
Epoch 14 | Batch 370/400 | Loss: 0.026472 | LR: 8.44e-06
Epoch 14 | Batch 375/400 | Loss: 0.056621 | LR: 8.44e-06
Epoch 14 | Batch 380/400 | Loss: 0.049595 | LR: 8.44e-06
[GPU MEM] Epoch14 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 14 | Batch 385/400 | Loss: 0.020925 | LR: 8.44e-06
Epoch 14 | Batch 390/400 | Loss: 0.166018 | LR: 8.44e-06
Epoch 14 | Batch 395/400 | Loss: 0.085246 | LR: 8.44e-06
âœ… ç¬¬ 14 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.131502
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.051639
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.252708
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.010421
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.078543
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.377076
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.022213
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.020551
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.185656
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.403710
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.578979
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.028982
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.050920
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.284807
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.021243
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.040355
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.030967
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.391740
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.144362

============================================================
ğŸ“Š Epoch 14/50 å®Œæˆ
   Train Loss: 0.131502
   Val Loss: 0.144362
   LR: 8.44e-06 | Time: 129.9s
============================================================
â³ æ—©åœè®¡æ•°: 10/10
ğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨ epoch 14 åœæ­¢è®­ç»ƒ
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_drop_object_512/controlnet_drop_object_epoch_50.pth
ğŸ“ˆ Loss å›¾å·²ä¿å­˜: training_results_drop_object_512/training_val_loss_drop_object_512.png

ğŸ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: 0.105492

============================================================
ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: è¦†ç›–ç‰©ä½“
ğŸ“ åˆ†è¾¨ç‡: 512x512
============================================================
   ç­›é€‰ä»»åŠ¡ 'cover_object': 1971/6000 ä¸ªæ ·æœ¬
âœ… åŠ è½½æ•°æ®é›† (cover_object): 1971 ä¸ªæ ·æœ¬
   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰
   åˆ†è¾¨ç‡: 512x512
   cover_object: 1971 ä¸ªæ ·æœ¬
   ç­›é€‰ä»»åŠ¡ 'cover_object': 271/750 ä¸ªæ ·æœ¬
âœ… åŠ è½½æ•°æ®é›† (cover_object): 271 ä¸ªæ ·æœ¬
   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰
   åˆ†è¾¨ç‡: 512x512
   cover_object: 271 ä¸ªæ ·æœ¬
   ç­›é€‰ä»»åŠ¡ 'cover_object': 258/750 ä¸ªæ ·æœ¬
âœ… åŠ è½½æ•°æ®é›† (cover_object): 258 ä¸ªæ ·æœ¬
   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰
   åˆ†è¾¨ç‡: 512x512
   cover_object: 258 ä¸ªæ ·æœ¬
âœ… åˆ›å»ºä»»åŠ¡ 'cover_object' æ•°æ®åŠ è½½å™¨å®Œæˆ
   è®­ç»ƒé›†: 1971 ä¸ªæ ·æœ¬, 985 ä¸ªæ‰¹æ¬¡
   éªŒè¯é›†: 271 ä¸ªæ ·æœ¬, 136 ä¸ªæ‰¹æ¬¡
   æµ‹è¯•é›†: 258 ä¸ªæ ·æœ¬, 129 ä¸ªæ‰¹æ¬¡
   æ‰¹æ¬¡å¤§å°: 2
   åˆ†è¾¨ç‡: 512x512
   è¾“å…¥å¸§å½¢çŠ¶: (20, 3, 512, 512)
   ç›®æ ‡å¸§å½¢çŠ¶: (3, 512, 512)
ğŸ“Š ä»æ€»æ ·æœ¬ 2500 ä¸­éšæœºæŠ½å– 1000 ä¸ªï¼ˆæŒ‰ 8:1:1 åˆ’åˆ†ï¼‰
âœ… æ•°æ®é›†åˆ†é…: train=800 val=100
ğŸš€ ä½¿ç”¨è®¾å¤‡: cuda
ğŸ¯ ä»»åŠ¡: cover_object
ğŸ“ åˆ†è¾¨ç‡: 512x512
ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...
ğŸ†• ä» UNet å¤åˆ¶æƒé‡åˆå§‹åŒ– ControlNet
âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå¯è®­ç»ƒå‚æ•°: 361,279,120 / æ€»å‚æ•°: 361,279,120
ğŸ” VAEæ ·æœ¬å°ºå¯¸: 512
ğŸš€ å¼€å§‹512x512è®­ç»ƒ...
ğŸ“ è¾“å…¥åˆ†è¾¨ç‡: 512x512
ğŸ¯ ä»»åŠ¡: cover_object

ğŸ” è¿›è¡Œåˆå§‹éªŒè¯...
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.128407
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.268066
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.152102
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.008902
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.212174
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.049006
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.010209
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.125732
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.089285
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.026887
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.361827
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.017104
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.029890
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.035064
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.104656
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.151648
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.133770
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.123262
åˆå§‹éªŒè¯æŸå¤±: 0.123262
ğŸ“š å¼€å§‹ç¬¬ 1 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 1 | Batch 0/400 | Loss: 0.197459 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch0 allocated=10.81GB reserved=11.97GB
Epoch 1 | Batch 5/400 | Loss: 0.150591 | LR: 1.00e-05
Epoch 1 | Batch 10/400 | Loss: 0.192304 | LR: 1.00e-05
Epoch 1 | Batch 15/400 | Loss: 0.062506 | LR: 1.00e-05
Epoch 1 | Batch 20/400 | Loss: 0.012569 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch20 allocated=13.52GB reserved=14.21GB
Epoch 1 | Batch 25/400 | Loss: 0.167061 | LR: 1.00e-05
Epoch 1 | Batch 30/400 | Loss: 0.178393 | LR: 1.00e-05
Epoch 1 | Batch 35/400 | Loss: 0.024496 | LR: 1.00e-05
Epoch 1 | Batch 40/400 | Loss: 0.052803 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch40 allocated=13.52GB reserved=14.26GB
Epoch 1 | Batch 45/400 | Loss: 0.351009 | LR: 1.00e-05
Epoch 1 | Batch 50/400 | Loss: 0.144189 | LR: 1.00e-05
Epoch 1 | Batch 55/400 | Loss: 0.004191 | LR: 1.00e-05
Epoch 1 | Batch 60/400 | Loss: 0.038042 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch60 allocated=13.52GB reserved=14.29GB
Epoch 1 | Batch 65/400 | Loss: 0.016459 | LR: 1.00e-05
Epoch 1 | Batch 70/400 | Loss: 0.023160 | LR: 1.00e-05
Epoch 1 | Batch 75/400 | Loss: 0.063683 | LR: 1.00e-05
Epoch 1 | Batch 80/400 | Loss: 0.011683 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch80 allocated=13.52GB reserved=14.23GB
Epoch 1 | Batch 85/400 | Loss: 0.155165 | LR: 1.00e-05
Epoch 1 | Batch 90/400 | Loss: 0.386569 | LR: 1.00e-05
Epoch 1 | Batch 95/400 | Loss: 0.013876 | LR: 1.00e-05
Epoch 1 | Batch 100/400 | Loss: 0.170589 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch100 allocated=13.52GB reserved=14.32GB
Epoch 1 | Batch 105/400 | Loss: 0.098619 | LR: 1.00e-05
Epoch 1 | Batch 110/400 | Loss: 0.081292 | LR: 1.00e-05
Epoch 1 | Batch 115/400 | Loss: 0.106548 | LR: 1.00e-05
Epoch 1 | Batch 120/400 | Loss: 0.116366 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch120 allocated=13.52GB reserved=14.25GB
Epoch 1 | Batch 125/400 | Loss: 0.217893 | LR: 1.00e-05
Epoch 1 | Batch 130/400 | Loss: 0.312730 | LR: 1.00e-05
Epoch 1 | Batch 135/400 | Loss: 0.205789 | LR: 1.00e-05
Epoch 1 | Batch 140/400 | Loss: 0.054912 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch140 allocated=13.52GB reserved=14.36GB
Epoch 1 | Batch 145/400 | Loss: 0.162210 | LR: 1.00e-05
Epoch 1 | Batch 150/400 | Loss: 0.224573 | LR: 1.00e-05
Epoch 1 | Batch 155/400 | Loss: 0.327841 | LR: 1.00e-05
Epoch 1 | Batch 160/400 | Loss: 0.089054 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch160 allocated=13.52GB reserved=14.41GB
Epoch 1 | Batch 165/400 | Loss: 0.094817 | LR: 1.00e-05
Epoch 1 | Batch 170/400 | Loss: 0.084137 | LR: 1.00e-05
Epoch 1 | Batch 175/400 | Loss: 0.049359 | LR: 1.00e-05
Epoch 1 | Batch 180/400 | Loss: 0.060583 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch180 allocated=13.52GB reserved=14.41GB
Epoch 1 | Batch 185/400 | Loss: 0.049764 | LR: 1.00e-05
Epoch 1 | Batch 190/400 | Loss: 0.247250 | LR: 1.00e-05
Epoch 1 | Batch 195/400 | Loss: 0.361829 | LR: 1.00e-05
Epoch 1 | Batch 200/400 | Loss: 0.104591 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch200 allocated=13.52GB reserved=14.38GB
Epoch 1 | Batch 205/400 | Loss: 0.004381 | LR: 1.00e-05
Epoch 1 | Batch 210/400 | Loss: 0.197051 | LR: 1.00e-05
Epoch 1 | Batch 215/400 | Loss: 0.039410 | LR: 1.00e-05
Epoch 1 | Batch 220/400 | Loss: 0.292928 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch220 allocated=13.52GB reserved=14.37GB
Epoch 1 | Batch 225/400 | Loss: 0.295813 | LR: 1.00e-05
Epoch 1 | Batch 230/400 | Loss: 0.089946 | LR: 1.00e-05
Epoch 1 | Batch 235/400 | Loss: 0.062618 | LR: 1.00e-05
Epoch 1 | Batch 240/400 | Loss: 0.232117 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch240 allocated=13.52GB reserved=14.37GB
Epoch 1 | Batch 245/400 | Loss: 0.010942 | LR: 1.00e-05
Epoch 1 | Batch 250/400 | Loss: 0.248123 | LR: 1.00e-05
Epoch 1 | Batch 255/400 | Loss: 0.035586 | LR: 1.00e-05
Epoch 1 | Batch 260/400 | Loss: 0.059050 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch260 allocated=13.52GB reserved=14.39GB
Epoch 1 | Batch 265/400 | Loss: 0.139769 | LR: 1.00e-05
Epoch 1 | Batch 270/400 | Loss: 0.019792 | LR: 1.00e-05
Epoch 1 | Batch 275/400 | Loss: 0.028773 | LR: 1.00e-05
Epoch 1 | Batch 280/400 | Loss: 0.271856 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch280 allocated=13.52GB reserved=14.37GB
Epoch 1 | Batch 285/400 | Loss: 0.322771 | LR: 1.00e-05
Epoch 1 | Batch 290/400 | Loss: 0.050874 | LR: 1.00e-05
Epoch 1 | Batch 295/400 | Loss: 0.302264 | LR: 1.00e-05
Epoch 1 | Batch 300/400 | Loss: 0.075745 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch300 allocated=13.52GB reserved=14.37GB
Epoch 1 | Batch 305/400 | Loss: 0.114675 | LR: 1.00e-05
Epoch 1 | Batch 310/400 | Loss: 0.176806 | LR: 1.00e-05
Epoch 1 | Batch 315/400 | Loss: 0.105406 | LR: 1.00e-05
Epoch 1 | Batch 320/400 | Loss: 0.348069 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch320 allocated=13.52GB reserved=14.38GB
Epoch 1 | Batch 325/400 | Loss: 0.089594 | LR: 1.00e-05
Epoch 1 | Batch 330/400 | Loss: 0.020135 | LR: 1.00e-05
Epoch 1 | Batch 335/400 | Loss: 0.105769 | LR: 1.00e-05
Epoch 1 | Batch 340/400 | Loss: 0.290225 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch340 allocated=13.52GB reserved=14.38GB
Epoch 1 | Batch 345/400 | Loss: 0.065247 | LR: 1.00e-05
Epoch 1 | Batch 350/400 | Loss: 0.145499 | LR: 1.00e-05
Epoch 1 | Batch 355/400 | Loss: 0.027464 | LR: 1.00e-05
Epoch 1 | Batch 360/400 | Loss: 0.007477 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch360 allocated=13.52GB reserved=14.38GB
Epoch 1 | Batch 365/400 | Loss: 0.015634 | LR: 1.00e-05
Epoch 1 | Batch 370/400 | Loss: 0.109235 | LR: 1.00e-05
Epoch 1 | Batch 375/400 | Loss: 0.045075 | LR: 1.00e-05
Epoch 1 | Batch 380/400 | Loss: 0.013179 | LR: 1.00e-05
[GPU MEM] Epoch1 Batch380 allocated=13.52GB reserved=14.40GB
Epoch 1 | Batch 385/400 | Loss: 0.037081 | LR: 1.00e-05
Epoch 1 | Batch 390/400 | Loss: 0.226108 | LR: 1.00e-05
Epoch 1 | Batch 395/400 | Loss: 0.157045 | LR: 1.00e-05
âœ… ç¬¬ 1 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.135345
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.020847
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.027757
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.014699
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.223927
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.189821
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.141244
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.100047
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.161808
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.010719
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.027812
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.012172
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.180102
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.024763
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.036428
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.064783
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.052184
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.128362
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.121533

============================================================
ğŸ“Š Epoch 1/50 å®Œæˆ
   Train Loss: 0.135345
   Val Loss: 0.121533
   LR: 1.00e-05 | Time: 130.7s
============================================================
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_cover_object_512/controlnet_cover_object_best.pth
ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: 0.121533
[GPU MEM] End of Epoch 1 allocated=12.17GB reserved=13.15GB
ğŸ“š å¼€å§‹ç¬¬ 2 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 2 | Batch 0/400 | Loss: 0.241029 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch0 allocated=13.52GB reserved=14.65GB
Epoch 2 | Batch 5/400 | Loss: 0.004375 | LR: 9.99e-06
Epoch 2 | Batch 10/400 | Loss: 0.085061 | LR: 9.99e-06
Epoch 2 | Batch 15/400 | Loss: 0.037987 | LR: 9.99e-06
Epoch 2 | Batch 20/400 | Loss: 0.133417 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch20 allocated=13.52GB reserved=14.32GB
Epoch 2 | Batch 25/400 | Loss: 0.109035 | LR: 9.99e-06
Epoch 2 | Batch 30/400 | Loss: 0.249210 | LR: 9.99e-06
Epoch 2 | Batch 35/400 | Loss: 0.353477 | LR: 9.99e-06
Epoch 2 | Batch 40/400 | Loss: 0.066609 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch40 allocated=13.52GB reserved=14.29GB
Epoch 2 | Batch 45/400 | Loss: 0.006200 | LR: 9.99e-06
Epoch 2 | Batch 50/400 | Loss: 0.137984 | LR: 9.99e-06
Epoch 2 | Batch 55/400 | Loss: 0.053300 | LR: 9.99e-06
Epoch 2 | Batch 60/400 | Loss: 0.209227 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch60 allocated=13.52GB reserved=14.29GB
Epoch 2 | Batch 65/400 | Loss: 0.296491 | LR: 9.99e-06
Epoch 2 | Batch 70/400 | Loss: 0.021189 | LR: 9.99e-06
Epoch 2 | Batch 75/400 | Loss: 0.057067 | LR: 9.99e-06
Epoch 2 | Batch 80/400 | Loss: 0.049326 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch80 allocated=13.52GB reserved=14.25GB
Epoch 2 | Batch 85/400 | Loss: 0.324350 | LR: 9.99e-06
Epoch 2 | Batch 90/400 | Loss: 0.023075 | LR: 9.99e-06
Epoch 2 | Batch 95/400 | Loss: 0.092837 | LR: 9.99e-06
Epoch 2 | Batch 100/400 | Loss: 0.076948 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch100 allocated=13.52GB reserved=14.26GB
Epoch 2 | Batch 105/400 | Loss: 0.051262 | LR: 9.99e-06
Epoch 2 | Batch 110/400 | Loss: 0.245519 | LR: 9.99e-06
Epoch 2 | Batch 115/400 | Loss: 0.297273 | LR: 9.99e-06
Epoch 2 | Batch 120/400 | Loss: 0.053375 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch120 allocated=13.52GB reserved=14.29GB
Epoch 2 | Batch 125/400 | Loss: 0.217235 | LR: 9.99e-06
Epoch 2 | Batch 130/400 | Loss: 0.064618 | LR: 9.99e-06
Epoch 2 | Batch 135/400 | Loss: 0.014792 | LR: 9.99e-06
Epoch 2 | Batch 140/400 | Loss: 0.113051 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch140 allocated=13.52GB reserved=14.40GB
Epoch 2 | Batch 145/400 | Loss: 0.132730 | LR: 9.99e-06
Epoch 2 | Batch 150/400 | Loss: 0.047297 | LR: 9.99e-06
Epoch 2 | Batch 155/400 | Loss: 0.008065 | LR: 9.99e-06
Epoch 2 | Batch 160/400 | Loss: 0.017472 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch160 allocated=13.52GB reserved=14.38GB
Epoch 2 | Batch 165/400 | Loss: 0.030603 | LR: 9.99e-06
Epoch 2 | Batch 170/400 | Loss: 0.009496 | LR: 9.99e-06
Epoch 2 | Batch 175/400 | Loss: 0.191958 | LR: 9.99e-06
Epoch 2 | Batch 180/400 | Loss: 0.170898 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch180 allocated=13.52GB reserved=14.38GB
Epoch 2 | Batch 185/400 | Loss: 0.114659 | LR: 9.99e-06
Epoch 2 | Batch 190/400 | Loss: 0.014356 | LR: 9.99e-06
Epoch 2 | Batch 195/400 | Loss: 0.025237 | LR: 9.99e-06
Epoch 2 | Batch 200/400 | Loss: 0.173516 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch200 allocated=13.52GB reserved=14.38GB
Epoch 2 | Batch 205/400 | Loss: 0.130387 | LR: 9.99e-06
Epoch 2 | Batch 210/400 | Loss: 0.062600 | LR: 9.99e-06
Epoch 2 | Batch 215/400 | Loss: 0.051375 | LR: 9.99e-06
Epoch 2 | Batch 220/400 | Loss: 0.059504 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch220 allocated=13.52GB reserved=14.38GB
Epoch 2 | Batch 225/400 | Loss: 0.074318 | LR: 9.99e-06
Epoch 2 | Batch 230/400 | Loss: 0.053002 | LR: 9.99e-06
Epoch 2 | Batch 235/400 | Loss: 0.517670 | LR: 9.99e-06
Epoch 2 | Batch 240/400 | Loss: 0.158348 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch240 allocated=13.52GB reserved=14.38GB
Epoch 2 | Batch 245/400 | Loss: 0.443165 | LR: 9.99e-06
Epoch 2 | Batch 250/400 | Loss: 0.062257 | LR: 9.99e-06
Epoch 2 | Batch 255/400 | Loss: 0.041680 | LR: 9.99e-06
Epoch 2 | Batch 260/400 | Loss: 0.061566 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch260 allocated=13.52GB reserved=14.40GB
Epoch 2 | Batch 265/400 | Loss: 0.012327 | LR: 9.99e-06
Epoch 2 | Batch 270/400 | Loss: 0.134890 | LR: 9.99e-06
Epoch 2 | Batch 275/400 | Loss: 0.152275 | LR: 9.99e-06
Epoch 2 | Batch 280/400 | Loss: 0.022538 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch280 allocated=13.52GB reserved=14.40GB
Epoch 2 | Batch 285/400 | Loss: 0.130620 | LR: 9.99e-06
Epoch 2 | Batch 290/400 | Loss: 0.041646 | LR: 9.99e-06
Epoch 2 | Batch 295/400 | Loss: 0.197509 | LR: 9.99e-06
Epoch 2 | Batch 300/400 | Loss: 0.075365 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch300 allocated=13.52GB reserved=14.33GB
Epoch 2 | Batch 305/400 | Loss: 0.053975 | LR: 9.99e-06
Epoch 2 | Batch 310/400 | Loss: 0.193955 | LR: 9.99e-06
Epoch 2 | Batch 315/400 | Loss: 0.170461 | LR: 9.99e-06
Epoch 2 | Batch 320/400 | Loss: 0.025391 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch320 allocated=13.52GB reserved=14.38GB
Epoch 2 | Batch 325/400 | Loss: 0.027748 | LR: 9.99e-06
Epoch 2 | Batch 330/400 | Loss: 0.030555 | LR: 9.99e-06
Epoch 2 | Batch 335/400 | Loss: 0.095600 | LR: 9.99e-06
Epoch 2 | Batch 340/400 | Loss: 0.505261 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch340 allocated=13.52GB reserved=14.34GB
Epoch 2 | Batch 345/400 | Loss: 0.004265 | LR: 9.99e-06
Epoch 2 | Batch 350/400 | Loss: 0.032792 | LR: 9.99e-06
Epoch 2 | Batch 355/400 | Loss: 0.185525 | LR: 9.99e-06
Epoch 2 | Batch 360/400 | Loss: 0.223624 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch360 allocated=13.52GB reserved=14.35GB
Epoch 2 | Batch 365/400 | Loss: 0.169779 | LR: 9.99e-06
Epoch 2 | Batch 370/400 | Loss: 0.033348 | LR: 9.99e-06
Epoch 2 | Batch 375/400 | Loss: 0.021737 | LR: 9.99e-06
Epoch 2 | Batch 380/400 | Loss: 0.106915 | LR: 9.99e-06
[GPU MEM] Epoch2 Batch380 allocated=13.52GB reserved=14.40GB
Epoch 2 | Batch 385/400 | Loss: 0.033804 | LR: 9.99e-06
Epoch 2 | Batch 390/400 | Loss: 0.357539 | LR: 9.99e-06
Epoch 2 | Batch 395/400 | Loss: 0.119599 | LR: 9.99e-06
âœ… ç¬¬ 2 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.121817
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.373941
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.251175
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.261102
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.014960
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.059356
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.117767
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.012565
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.342135
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.085132
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.434573
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.123074
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.435676
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.020481
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.019151
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.148706
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.004986
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.022270
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.129046

============================================================
ğŸ“Š Epoch 2/50 å®Œæˆ
   Train Loss: 0.121817
   Val Loss: 0.129046
   LR: 9.99e-06 | Time: 130.9s
============================================================
â³ æ—©åœè®¡æ•°: 1/10
[GPU MEM] End of Epoch 2 allocated=12.17GB reserved=13.15GB
ğŸ“š å¼€å§‹ç¬¬ 3 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 3 | Batch 0/400 | Loss: 0.022894 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch0 allocated=13.52GB reserved=14.65GB
Epoch 3 | Batch 5/400 | Loss: 0.411313 | LR: 9.96e-06
Epoch 3 | Batch 10/400 | Loss: 0.046674 | LR: 9.96e-06
Epoch 3 | Batch 15/400 | Loss: 0.042722 | LR: 9.96e-06
Epoch 3 | Batch 20/400 | Loss: 0.106199 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch20 allocated=13.52GB reserved=14.28GB
Epoch 3 | Batch 25/400 | Loss: 0.025179 | LR: 9.96e-06
Epoch 3 | Batch 30/400 | Loss: 0.014370 | LR: 9.96e-06
Epoch 3 | Batch 35/400 | Loss: 0.256166 | LR: 9.96e-06
Epoch 3 | Batch 40/400 | Loss: 0.262045 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch40 allocated=13.52GB reserved=14.26GB
Epoch 3 | Batch 45/400 | Loss: 0.115272 | LR: 9.96e-06
Epoch 3 | Batch 50/400 | Loss: 0.045479 | LR: 9.96e-06
Epoch 3 | Batch 55/400 | Loss: 0.250020 | LR: 9.96e-06
Epoch 3 | Batch 60/400 | Loss: 0.034232 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch60 allocated=13.52GB reserved=14.23GB
Epoch 3 | Batch 65/400 | Loss: 0.285523 | LR: 9.96e-06
Epoch 3 | Batch 70/400 | Loss: 0.036913 | LR: 9.96e-06
Epoch 3 | Batch 75/400 | Loss: 0.015643 | LR: 9.96e-06
Epoch 3 | Batch 80/400 | Loss: 0.069848 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch80 allocated=13.52GB reserved=14.25GB
Epoch 3 | Batch 85/400 | Loss: 0.229486 | LR: 9.96e-06
Epoch 3 | Batch 90/400 | Loss: 0.172405 | LR: 9.96e-06
Epoch 3 | Batch 95/400 | Loss: 0.139574 | LR: 9.96e-06
Epoch 3 | Batch 100/400 | Loss: 0.032800 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch100 allocated=13.52GB reserved=14.25GB
Epoch 3 | Batch 105/400 | Loss: 0.185558 | LR: 9.96e-06
Epoch 3 | Batch 110/400 | Loss: 0.123263 | LR: 9.96e-06
Epoch 3 | Batch 115/400 | Loss: 0.151009 | LR: 9.96e-06
Epoch 3 | Batch 120/400 | Loss: 0.029346 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch120 allocated=13.52GB reserved=14.27GB
Epoch 3 | Batch 125/400 | Loss: 0.044847 | LR: 9.96e-06
Epoch 3 | Batch 130/400 | Loss: 0.287264 | LR: 9.96e-06
Epoch 3 | Batch 135/400 | Loss: 0.058204 | LR: 9.96e-06
Epoch 3 | Batch 140/400 | Loss: 0.075331 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch140 allocated=13.52GB reserved=14.30GB
Epoch 3 | Batch 145/400 | Loss: 0.222929 | LR: 9.96e-06
Epoch 3 | Batch 150/400 | Loss: 0.161774 | LR: 9.96e-06
Epoch 3 | Batch 155/400 | Loss: 0.017692 | LR: 9.96e-06
Epoch 3 | Batch 160/400 | Loss: 0.090522 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch160 allocated=13.52GB reserved=14.28GB
Epoch 3 | Batch 165/400 | Loss: 0.088611 | LR: 9.96e-06
Epoch 3 | Batch 170/400 | Loss: 0.076300 | LR: 9.96e-06
Epoch 3 | Batch 175/400 | Loss: 0.035211 | LR: 9.96e-06
Epoch 3 | Batch 180/400 | Loss: 0.067012 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch180 allocated=13.52GB reserved=14.31GB
Epoch 3 | Batch 185/400 | Loss: 0.158162 | LR: 9.96e-06
Epoch 3 | Batch 190/400 | Loss: 0.008832 | LR: 9.96e-06
Epoch 3 | Batch 195/400 | Loss: 0.212783 | LR: 9.96e-06
Epoch 3 | Batch 200/400 | Loss: 0.213264 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch200 allocated=13.52GB reserved=14.20GB
Epoch 3 | Batch 205/400 | Loss: 0.031005 | LR: 9.96e-06
Epoch 3 | Batch 210/400 | Loss: 0.040935 | LR: 9.96e-06
Epoch 3 | Batch 215/400 | Loss: 0.043023 | LR: 9.96e-06
Epoch 3 | Batch 220/400 | Loss: 0.101729 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch220 allocated=13.52GB reserved=14.23GB
Epoch 3 | Batch 225/400 | Loss: 0.026473 | LR: 9.96e-06
Epoch 3 | Batch 230/400 | Loss: 0.185760 | LR: 9.96e-06
Epoch 3 | Batch 235/400 | Loss: 0.171579 | LR: 9.96e-06
Epoch 3 | Batch 240/400 | Loss: 0.161816 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch240 allocated=13.52GB reserved=14.26GB
Epoch 3 | Batch 245/400 | Loss: 0.021116 | LR: 9.96e-06
Epoch 3 | Batch 250/400 | Loss: 0.170514 | LR: 9.96e-06
Epoch 3 | Batch 255/400 | Loss: 0.022003 | LR: 9.96e-06
Epoch 3 | Batch 260/400 | Loss: 0.320424 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch260 allocated=13.52GB reserved=14.30GB
Epoch 3 | Batch 265/400 | Loss: 0.165399 | LR: 9.96e-06
Epoch 3 | Batch 270/400 | Loss: 0.024936 | LR: 9.96e-06
Epoch 3 | Batch 275/400 | Loss: 0.008962 | LR: 9.96e-06
Epoch 3 | Batch 280/400 | Loss: 0.320127 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch280 allocated=13.52GB reserved=14.31GB
Epoch 3 | Batch 285/400 | Loss: 0.329571 | LR: 9.96e-06
Epoch 3 | Batch 290/400 | Loss: 0.113846 | LR: 9.96e-06
Epoch 3 | Batch 295/400 | Loss: 0.017801 | LR: 9.96e-06
Epoch 3 | Batch 300/400 | Loss: 0.039548 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch300 allocated=13.52GB reserved=14.28GB
Epoch 3 | Batch 305/400 | Loss: 0.134576 | LR: 9.96e-06
Epoch 3 | Batch 310/400 | Loss: 0.288770 | LR: 9.96e-06
Epoch 3 | Batch 315/400 | Loss: 0.286372 | LR: 9.96e-06
Epoch 3 | Batch 320/400 | Loss: 0.062726 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch320 allocated=13.52GB reserved=14.21GB
Epoch 3 | Batch 325/400 | Loss: 0.042374 | LR: 9.96e-06
Epoch 3 | Batch 330/400 | Loss: 0.009959 | LR: 9.96e-06
Epoch 3 | Batch 335/400 | Loss: 0.030752 | LR: 9.96e-06
Epoch 3 | Batch 340/400 | Loss: 0.014897 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch340 allocated=13.52GB reserved=14.30GB
Epoch 3 | Batch 345/400 | Loss: 0.030353 | LR: 9.96e-06
Epoch 3 | Batch 350/400 | Loss: 0.245973 | LR: 9.96e-06
Epoch 3 | Batch 355/400 | Loss: 0.160481 | LR: 9.96e-06
Epoch 3 | Batch 360/400 | Loss: 0.243440 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch360 allocated=13.52GB reserved=14.31GB
Epoch 3 | Batch 365/400 | Loss: 0.180549 | LR: 9.96e-06
Epoch 3 | Batch 370/400 | Loss: 0.072218 | LR: 9.96e-06
Epoch 3 | Batch 375/400 | Loss: 0.179071 | LR: 9.96e-06
Epoch 3 | Batch 380/400 | Loss: 0.085276 | LR: 9.96e-06
[GPU MEM] Epoch3 Batch380 allocated=13.52GB reserved=14.31GB
Epoch 3 | Batch 385/400 | Loss: 0.004931 | LR: 9.96e-06
Epoch 3 | Batch 390/400 | Loss: 0.203218 | LR: 9.96e-06
Epoch 3 | Batch 395/400 | Loss: 0.015607 | LR: 9.96e-06
âœ… ç¬¬ 3 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.137652
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.232864
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.141317
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.023588
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.019716
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.152856
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.211728
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.034115
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.090111
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.013586
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.135257
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.056487
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.050371
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.007097
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.035197
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.318844
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.035534
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.002934
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.109836

============================================================
ğŸ“Š Epoch 3/50 å®Œæˆ
   Train Loss: 0.137652
   Val Loss: 0.109836
   LR: 9.96e-06 | Time: 130.5s
============================================================
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_cover_object_512/controlnet_cover_object_best.pth
ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: 0.109836
[GPU MEM] End of Epoch 3 allocated=12.17GB reserved=13.15GB
ğŸ“š å¼€å§‹ç¬¬ 4 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 4 | Batch 0/400 | Loss: 0.357656 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch0 allocated=13.52GB reserved=14.65GB
Epoch 4 | Batch 5/400 | Loss: 0.105407 | LR: 9.91e-06
Epoch 4 | Batch 10/400 | Loss: 0.105161 | LR: 9.91e-06
Epoch 4 | Batch 15/400 | Loss: 0.284742 | LR: 9.91e-06
Epoch 4 | Batch 20/400 | Loss: 0.023707 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch20 allocated=13.52GB reserved=14.28GB
Epoch 4 | Batch 25/400 | Loss: 0.033440 | LR: 9.91e-06
Epoch 4 | Batch 30/400 | Loss: 0.080675 | LR: 9.91e-06
Epoch 4 | Batch 35/400 | Loss: 0.024496 | LR: 9.91e-06
Epoch 4 | Batch 40/400 | Loss: 0.031911 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch40 allocated=13.52GB reserved=14.26GB
Epoch 4 | Batch 45/400 | Loss: 0.068168 | LR: 9.91e-06
Epoch 4 | Batch 50/400 | Loss: 0.155022 | LR: 9.91e-06
Epoch 4 | Batch 55/400 | Loss: 0.008926 | LR: 9.91e-06
Epoch 4 | Batch 60/400 | Loss: 0.058483 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch60 allocated=13.52GB reserved=14.23GB
Epoch 4 | Batch 65/400 | Loss: 0.045987 | LR: 9.91e-06
Epoch 4 | Batch 70/400 | Loss: 0.053851 | LR: 9.91e-06
Epoch 4 | Batch 75/400 | Loss: 0.147631 | LR: 9.91e-06
Epoch 4 | Batch 80/400 | Loss: 0.176242 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch80 allocated=13.52GB reserved=14.25GB
Epoch 4 | Batch 85/400 | Loss: 0.086365 | LR: 9.91e-06
Epoch 4 | Batch 90/400 | Loss: 0.172646 | LR: 9.91e-06
Epoch 4 | Batch 95/400 | Loss: 0.490999 | LR: 9.91e-06
Epoch 4 | Batch 100/400 | Loss: 0.071060 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch100 allocated=9.46GB reserved=11.46GB
Epoch 4 | Batch 105/400 | Loss: 0.121381 | LR: 9.91e-06
Epoch 4 | Batch 110/400 | Loss: 0.090959 | LR: 9.91e-06
Epoch 4 | Batch 115/400 | Loss: 0.142195 | LR: 9.91e-06
Epoch 4 | Batch 120/400 | Loss: 0.028923 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch120 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 125/400 | Loss: 0.178099 | LR: 9.91e-06
Epoch 4 | Batch 130/400 | Loss: 0.140660 | LR: 9.91e-06
Epoch 4 | Batch 135/400 | Loss: 0.211369 | LR: 9.91e-06
Epoch 4 | Batch 140/400 | Loss: 0.126304 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch140 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 145/400 | Loss: 0.022528 | LR: 9.91e-06
Epoch 4 | Batch 150/400 | Loss: 0.125990 | LR: 9.91e-06
Epoch 4 | Batch 155/400 | Loss: 0.017115 | LR: 9.91e-06
Epoch 4 | Batch 160/400 | Loss: 0.032411 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch160 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 165/400 | Loss: 0.067770 | LR: 9.91e-06
Epoch 4 | Batch 170/400 | Loss: 0.123471 | LR: 9.91e-06
Epoch 4 | Batch 175/400 | Loss: 0.045031 | LR: 9.91e-06
Epoch 4 | Batch 180/400 | Loss: 0.051740 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch180 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 185/400 | Loss: 0.011665 | LR: 9.91e-06
Epoch 4 | Batch 190/400 | Loss: 0.406953 | LR: 9.91e-06
Epoch 4 | Batch 195/400 | Loss: 0.228227 | LR: 9.91e-06
Epoch 4 | Batch 200/400 | Loss: 0.153277 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch200 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 205/400 | Loss: 0.125874 | LR: 9.91e-06
Epoch 4 | Batch 210/400 | Loss: 0.056518 | LR: 9.91e-06
Epoch 4 | Batch 215/400 | Loss: 0.222459 | LR: 9.91e-06
Epoch 4 | Batch 220/400 | Loss: 0.074330 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch220 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 225/400 | Loss: 0.141454 | LR: 9.91e-06
Epoch 4 | Batch 230/400 | Loss: 0.389159 | LR: 9.91e-06
Epoch 4 | Batch 235/400 | Loss: 0.046826 | LR: 9.91e-06
Epoch 4 | Batch 240/400 | Loss: 0.013038 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch240 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 245/400 | Loss: 0.018420 | LR: 9.91e-06
Epoch 4 | Batch 250/400 | Loss: 0.010899 | LR: 9.91e-06
Epoch 4 | Batch 255/400 | Loss: 0.189134 | LR: 9.91e-06
Epoch 4 | Batch 260/400 | Loss: 0.364874 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch260 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 265/400 | Loss: 0.008427 | LR: 9.91e-06
Epoch 4 | Batch 270/400 | Loss: 0.067136 | LR: 9.91e-06
Epoch 4 | Batch 275/400 | Loss: 0.081602 | LR: 9.91e-06
Epoch 4 | Batch 280/400 | Loss: 0.171663 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch280 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 285/400 | Loss: 0.026204 | LR: 9.91e-06
Epoch 4 | Batch 290/400 | Loss: 0.273656 | LR: 9.91e-06
Epoch 4 | Batch 295/400 | Loss: 0.093512 | LR: 9.91e-06
Epoch 4 | Batch 300/400 | Loss: 0.263869 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch300 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 305/400 | Loss: 0.150838 | LR: 9.91e-06
Epoch 4 | Batch 310/400 | Loss: 0.044639 | LR: 9.91e-06
Epoch 4 | Batch 315/400 | Loss: 0.013555 | LR: 9.91e-06
Epoch 4 | Batch 320/400 | Loss: 0.004515 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch320 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 325/400 | Loss: 0.063391 | LR: 9.91e-06
Epoch 4 | Batch 330/400 | Loss: 0.120138 | LR: 9.91e-06
Epoch 4 | Batch 335/400 | Loss: 0.287759 | LR: 9.91e-06
Epoch 4 | Batch 340/400 | Loss: 0.026852 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch340 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 345/400 | Loss: 0.114734 | LR: 9.91e-06
Epoch 4 | Batch 350/400 | Loss: 0.112941 | LR: 9.91e-06
Epoch 4 | Batch 355/400 | Loss: 0.104360 | LR: 9.91e-06
Epoch 4 | Batch 360/400 | Loss: 0.091833 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch360 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 365/400 | Loss: 0.095575 | LR: 9.91e-06
Epoch 4 | Batch 370/400 | Loss: 0.102658 | LR: 9.91e-06
Epoch 4 | Batch 375/400 | Loss: 0.034332 | LR: 9.91e-06
Epoch 4 | Batch 380/400 | Loss: 0.210855 | LR: 9.91e-06
[GPU MEM] Epoch4 Batch380 allocated=9.45GB reserved=11.39GB
Epoch 4 | Batch 385/400 | Loss: 0.031253 | LR: 9.91e-06
Epoch 4 | Batch 390/400 | Loss: 0.120516 | LR: 9.91e-06
Epoch 4 | Batch 395/400 | Loss: 0.084043 | LR: 9.91e-06
âœ… ç¬¬ 4 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.134948
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.116592
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.081607
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.329999
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.133843
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.129639
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.142145
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.107275
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.035907
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.216158
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.262892
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.284983
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.028728
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.059205
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.322532
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.166209
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.128191
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.054990
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.141913

============================================================
ğŸ“Š Epoch 4/50 å®Œæˆ
   Train Loss: 0.134948
   Val Loss: 0.141913
   LR: 9.91e-06 | Time: 129.3s
============================================================
â³ æ—©åœè®¡æ•°: 1/10
[GPU MEM] End of Epoch 4 allocated=8.10GB reserved=11.21GB
ğŸ“š å¼€å§‹ç¬¬ 5 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 5 | Batch 0/400 | Loss: 0.032970 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch0 allocated=9.45GB reserved=11.53GB
Epoch 5 | Batch 5/400 | Loss: 0.129116 | LR: 9.84e-06
Epoch 5 | Batch 10/400 | Loss: 0.149311 | LR: 9.84e-06
Epoch 5 | Batch 15/400 | Loss: 0.022428 | LR: 9.84e-06
Epoch 5 | Batch 20/400 | Loss: 0.096644 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch20 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 25/400 | Loss: 0.004912 | LR: 9.84e-06
Epoch 5 | Batch 30/400 | Loss: 0.200930 | LR: 9.84e-06
Epoch 5 | Batch 35/400 | Loss: 0.024550 | LR: 9.84e-06
Epoch 5 | Batch 40/400 | Loss: 0.088019 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch40 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 45/400 | Loss: 0.094301 | LR: 9.84e-06
Epoch 5 | Batch 50/400 | Loss: 0.171079 | LR: 9.84e-06
Epoch 5 | Batch 55/400 | Loss: 0.123876 | LR: 9.84e-06
Epoch 5 | Batch 60/400 | Loss: 0.304387 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch60 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 65/400 | Loss: 0.102788 | LR: 9.84e-06
Epoch 5 | Batch 70/400 | Loss: 0.109656 | LR: 9.84e-06
Epoch 5 | Batch 75/400 | Loss: 0.357757 | LR: 9.84e-06
Epoch 5 | Batch 80/400 | Loss: 0.089863 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch80 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 85/400 | Loss: 0.139488 | LR: 9.84e-06
Epoch 5 | Batch 90/400 | Loss: 0.064216 | LR: 9.84e-06
Epoch 5 | Batch 95/400 | Loss: 0.099002 | LR: 9.84e-06
Epoch 5 | Batch 100/400 | Loss: 0.002925 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch100 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 105/400 | Loss: 0.023469 | LR: 9.84e-06
Epoch 5 | Batch 110/400 | Loss: 0.019401 | LR: 9.84e-06
Epoch 5 | Batch 115/400 | Loss: 0.267023 | LR: 9.84e-06
Epoch 5 | Batch 120/400 | Loss: 0.073062 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch120 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 125/400 | Loss: 0.094780 | LR: 9.84e-06
Epoch 5 | Batch 130/400 | Loss: 0.382070 | LR: 9.84e-06
Epoch 5 | Batch 135/400 | Loss: 0.034238 | LR: 9.84e-06
Epoch 5 | Batch 140/400 | Loss: 0.012739 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch140 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 145/400 | Loss: 0.114881 | LR: 9.84e-06
Epoch 5 | Batch 150/400 | Loss: 0.098446 | LR: 9.84e-06
Epoch 5 | Batch 155/400 | Loss: 0.365945 | LR: 9.84e-06
Epoch 5 | Batch 160/400 | Loss: 0.113966 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch160 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 165/400 | Loss: 0.466059 | LR: 9.84e-06
Epoch 5 | Batch 170/400 | Loss: 0.276378 | LR: 9.84e-06
Epoch 5 | Batch 175/400 | Loss: 0.097739 | LR: 9.84e-06
Epoch 5 | Batch 180/400 | Loss: 0.113425 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch180 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 185/400 | Loss: 0.106643 | LR: 9.84e-06
Epoch 5 | Batch 190/400 | Loss: 0.251630 | LR: 9.84e-06
Epoch 5 | Batch 195/400 | Loss: 0.191941 | LR: 9.84e-06
Epoch 5 | Batch 200/400 | Loss: 0.016577 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch200 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 205/400 | Loss: 0.415639 | LR: 9.84e-06
Epoch 5 | Batch 210/400 | Loss: 0.054257 | LR: 9.84e-06
Epoch 5 | Batch 215/400 | Loss: 0.053439 | LR: 9.84e-06
Epoch 5 | Batch 220/400 | Loss: 0.304220 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch220 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 225/400 | Loss: 0.016139 | LR: 9.84e-06
Epoch 5 | Batch 230/400 | Loss: 0.045480 | LR: 9.84e-06
Epoch 5 | Batch 235/400 | Loss: 0.352809 | LR: 9.84e-06
Epoch 5 | Batch 240/400 | Loss: 0.080089 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch240 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 245/400 | Loss: 0.180965 | LR: 9.84e-06
Epoch 5 | Batch 250/400 | Loss: 0.198309 | LR: 9.84e-06
Epoch 5 | Batch 255/400 | Loss: 0.018434 | LR: 9.84e-06
Epoch 5 | Batch 260/400 | Loss: 0.026800 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch260 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 265/400 | Loss: 0.062135 | LR: 9.84e-06
Epoch 5 | Batch 270/400 | Loss: 0.572880 | LR: 9.84e-06
Epoch 5 | Batch 275/400 | Loss: 0.103264 | LR: 9.84e-06
Epoch 5 | Batch 280/400 | Loss: 0.045196 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch280 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 285/400 | Loss: 0.078104 | LR: 9.84e-06
Epoch 5 | Batch 290/400 | Loss: 0.055365 | LR: 9.84e-06
Epoch 5 | Batch 295/400 | Loss: 0.395605 | LR: 9.84e-06
Epoch 5 | Batch 300/400 | Loss: 0.220571 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch300 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 305/400 | Loss: 0.057667 | LR: 9.84e-06
Epoch 5 | Batch 310/400 | Loss: 0.132769 | LR: 9.84e-06
Epoch 5 | Batch 315/400 | Loss: 0.045809 | LR: 9.84e-06
Epoch 5 | Batch 320/400 | Loss: 0.017836 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch320 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 325/400 | Loss: 0.080522 | LR: 9.84e-06
Epoch 5 | Batch 330/400 | Loss: 0.160229 | LR: 9.84e-06
Epoch 5 | Batch 335/400 | Loss: 0.007928 | LR: 9.84e-06
Epoch 5 | Batch 340/400 | Loss: 0.239382 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch340 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 345/400 | Loss: 0.244263 | LR: 9.84e-06
Epoch 5 | Batch 350/400 | Loss: 0.145709 | LR: 9.84e-06
Epoch 5 | Batch 355/400 | Loss: 0.076294 | LR: 9.84e-06
Epoch 5 | Batch 360/400 | Loss: 0.089100 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch360 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 365/400 | Loss: 0.150068 | LR: 9.84e-06
Epoch 5 | Batch 370/400 | Loss: 0.240211 | LR: 9.84e-06
Epoch 5 | Batch 375/400 | Loss: 0.039164 | LR: 9.84e-06
Epoch 5 | Batch 380/400 | Loss: 0.076820 | LR: 9.84e-06
[GPU MEM] Epoch5 Batch380 allocated=9.45GB reserved=11.25GB
Epoch 5 | Batch 385/400 | Loss: 0.071624 | LR: 9.84e-06
Epoch 5 | Batch 390/400 | Loss: 0.162157 | LR: 9.84e-06
Epoch 5 | Batch 395/400 | Loss: 0.206595 | LR: 9.84e-06
âœ… ç¬¬ 5 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.133750
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.050820
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.022180
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.062410
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.065756
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.366110
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.163087
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.057981
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.271201
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.339803
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.013365
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.049504
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.005074
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.045565
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.031590
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.059247
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.056896
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.206706
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.126084
ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆ Epoch 5 çš„é¢„è§ˆå›¾...
âœ¨ é¢„è§ˆå›¾å·²ä¿å­˜åˆ° training_results_cover_object_512

============================================================
ğŸ“Š Epoch 5/50 å®Œæˆ
   Train Loss: 0.133750
   Val Loss: 0.126084
   LR: 9.84e-06 | Time: 133.0s
============================================================
â³ æ—©åœè®¡æ•°: 2/10
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_cover_object_512/controlnet_cover_object_epoch_5.pth
[GPU MEM] End of Epoch 5 allocated=8.10GB reserved=11.21GB
ğŸ“š å¼€å§‹ç¬¬ 6 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 6 | Batch 0/400 | Loss: 0.242864 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch0 allocated=9.45GB reserved=11.53GB
Epoch 6 | Batch 5/400 | Loss: 0.314534 | LR: 9.76e-06
Epoch 6 | Batch 10/400 | Loss: 0.091425 | LR: 9.76e-06
Epoch 6 | Batch 15/400 | Loss: 0.494981 | LR: 9.76e-06
Epoch 6 | Batch 20/400 | Loss: 0.013466 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch20 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 25/400 | Loss: 0.138802 | LR: 9.76e-06
Epoch 6 | Batch 30/400 | Loss: 0.130936 | LR: 9.76e-06
Epoch 6 | Batch 35/400 | Loss: 0.144672 | LR: 9.76e-06
Epoch 6 | Batch 40/400 | Loss: 0.132041 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch40 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 45/400 | Loss: 0.619250 | LR: 9.76e-06
Epoch 6 | Batch 50/400 | Loss: 0.078423 | LR: 9.76e-06
Epoch 6 | Batch 55/400 | Loss: 0.110321 | LR: 9.76e-06
Epoch 6 | Batch 60/400 | Loss: 0.056951 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch60 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 65/400 | Loss: 0.170377 | LR: 9.76e-06
Epoch 6 | Batch 70/400 | Loss: 0.079425 | LR: 9.76e-06
Epoch 6 | Batch 75/400 | Loss: 0.022341 | LR: 9.76e-06
Epoch 6 | Batch 80/400 | Loss: 0.234877 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch80 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 85/400 | Loss: 0.112195 | LR: 9.76e-06
Epoch 6 | Batch 90/400 | Loss: 0.082707 | LR: 9.76e-06
Epoch 6 | Batch 95/400 | Loss: 0.173138 | LR: 9.76e-06
Epoch 6 | Batch 100/400 | Loss: 0.138122 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch100 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 105/400 | Loss: 0.156171 | LR: 9.76e-06
Epoch 6 | Batch 110/400 | Loss: 0.047958 | LR: 9.76e-06
Epoch 6 | Batch 115/400 | Loss: 0.248434 | LR: 9.76e-06
Epoch 6 | Batch 120/400 | Loss: 0.085311 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch120 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 125/400 | Loss: 0.062475 | LR: 9.76e-06
Epoch 6 | Batch 130/400 | Loss: 0.105529 | LR: 9.76e-06
Epoch 6 | Batch 135/400 | Loss: 0.037464 | LR: 9.76e-06
Epoch 6 | Batch 140/400 | Loss: 0.036339 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch140 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 145/400 | Loss: 0.622576 | LR: 9.76e-06
Epoch 6 | Batch 150/400 | Loss: 0.024314 | LR: 9.76e-06
Epoch 6 | Batch 155/400 | Loss: 0.007394 | LR: 9.76e-06
Epoch 6 | Batch 160/400 | Loss: 0.147044 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch160 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 165/400 | Loss: 0.071951 | LR: 9.76e-06
Epoch 6 | Batch 170/400 | Loss: 0.034899 | LR: 9.76e-06
Epoch 6 | Batch 175/400 | Loss: 0.168284 | LR: 9.76e-06
Epoch 6 | Batch 180/400 | Loss: 0.281601 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch180 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 185/400 | Loss: 0.161374 | LR: 9.76e-06
Epoch 6 | Batch 190/400 | Loss: 0.135497 | LR: 9.76e-06
Epoch 6 | Batch 195/400 | Loss: 0.121618 | LR: 9.76e-06
Epoch 6 | Batch 200/400 | Loss: 0.159669 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch200 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 205/400 | Loss: 0.073294 | LR: 9.76e-06
Epoch 6 | Batch 210/400 | Loss: 0.148452 | LR: 9.76e-06
Epoch 6 | Batch 215/400 | Loss: 0.017623 | LR: 9.76e-06
Epoch 6 | Batch 220/400 | Loss: 0.201302 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch220 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 225/400 | Loss: 0.155716 | LR: 9.76e-06
Epoch 6 | Batch 230/400 | Loss: 0.034488 | LR: 9.76e-06
Epoch 6 | Batch 235/400 | Loss: 0.564912 | LR: 9.76e-06
Epoch 6 | Batch 240/400 | Loss: 0.202054 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch240 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 245/400 | Loss: 0.288052 | LR: 9.76e-06
Epoch 6 | Batch 250/400 | Loss: 0.067911 | LR: 9.76e-06
Epoch 6 | Batch 255/400 | Loss: 0.062526 | LR: 9.76e-06
Epoch 6 | Batch 260/400 | Loss: 0.169526 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch260 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 265/400 | Loss: 0.030201 | LR: 9.76e-06
Epoch 6 | Batch 270/400 | Loss: 0.451923 | LR: 9.76e-06
Epoch 6 | Batch 275/400 | Loss: 0.113783 | LR: 9.76e-06
Epoch 6 | Batch 280/400 | Loss: 0.068667 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch280 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 285/400 | Loss: 0.147236 | LR: 9.76e-06
Epoch 6 | Batch 290/400 | Loss: 0.060071 | LR: 9.76e-06
Epoch 6 | Batch 295/400 | Loss: 0.020676 | LR: 9.76e-06
Epoch 6 | Batch 300/400 | Loss: 0.344831 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch300 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 305/400 | Loss: 0.031366 | LR: 9.76e-06
Epoch 6 | Batch 310/400 | Loss: 0.085350 | LR: 9.76e-06
Epoch 6 | Batch 315/400 | Loss: 0.191452 | LR: 9.76e-06
Epoch 6 | Batch 320/400 | Loss: 0.005413 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch320 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 325/400 | Loss: 0.214706 | LR: 9.76e-06
Epoch 6 | Batch 330/400 | Loss: 0.415209 | LR: 9.76e-06
Epoch 6 | Batch 335/400 | Loss: 0.102654 | LR: 9.76e-06
Epoch 6 | Batch 340/400 | Loss: 0.071230 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch340 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 345/400 | Loss: 0.142332 | LR: 9.76e-06
Epoch 6 | Batch 350/400 | Loss: 0.271197 | LR: 9.76e-06
Epoch 6 | Batch 355/400 | Loss: 0.158159 | LR: 9.76e-06
Epoch 6 | Batch 360/400 | Loss: 0.163166 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch360 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 365/400 | Loss: 0.147217 | LR: 9.76e-06
Epoch 6 | Batch 370/400 | Loss: 0.092460 | LR: 9.76e-06
Epoch 6 | Batch 375/400 | Loss: 0.335495 | LR: 9.76e-06
Epoch 6 | Batch 380/400 | Loss: 0.035886 | LR: 9.76e-06
[GPU MEM] Epoch6 Batch380 allocated=9.45GB reserved=11.25GB
Epoch 6 | Batch 385/400 | Loss: 0.005955 | LR: 9.76e-06
Epoch 6 | Batch 390/400 | Loss: 0.123789 | LR: 9.76e-06
Epoch 6 | Batch 395/400 | Loss: 0.034985 | LR: 9.76e-06
âœ… ç¬¬ 6 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.125533
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.190828
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.062069
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.012307
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.171003
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.108232
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.165416
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.060674
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.008753
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.298261
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.343007
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.101246
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.123768
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.314735
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.155198
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.461761
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.012473
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.035761
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.144491

============================================================
ğŸ“Š Epoch 6/50 å®Œæˆ
   Train Loss: 0.125533
   Val Loss: 0.144491
   LR: 9.76e-06 | Time: 128.1s
============================================================
â³ æ—©åœè®¡æ•°: 3/10
[GPU MEM] End of Epoch 6 allocated=8.10GB reserved=11.21GB
ğŸ“š å¼€å§‹ç¬¬ 7 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 7 | Batch 0/400 | Loss: 0.026768 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch0 allocated=9.45GB reserved=11.53GB
Epoch 7 | Batch 5/400 | Loss: 0.151144 | LR: 9.65e-06
Epoch 7 | Batch 10/400 | Loss: 0.247483 | LR: 9.65e-06
Epoch 7 | Batch 15/400 | Loss: 0.073161 | LR: 9.65e-06
Epoch 7 | Batch 20/400 | Loss: 0.294122 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch20 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 25/400 | Loss: 0.155916 | LR: 9.65e-06
Epoch 7 | Batch 30/400 | Loss: 0.210548 | LR: 9.65e-06
Epoch 7 | Batch 35/400 | Loss: 0.032391 | LR: 9.65e-06
Epoch 7 | Batch 40/400 | Loss: 0.234745 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch40 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 45/400 | Loss: 0.201880 | LR: 9.65e-06
Epoch 7 | Batch 50/400 | Loss: 0.099507 | LR: 9.65e-06
Epoch 7 | Batch 55/400 | Loss: 0.058236 | LR: 9.65e-06
Epoch 7 | Batch 60/400 | Loss: 0.033013 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch60 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 65/400 | Loss: 0.011864 | LR: 9.65e-06
Epoch 7 | Batch 70/400 | Loss: 0.117108 | LR: 9.65e-06
Epoch 7 | Batch 75/400 | Loss: 0.067712 | LR: 9.65e-06
Epoch 7 | Batch 80/400 | Loss: 0.101234 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch80 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 85/400 | Loss: 0.031200 | LR: 9.65e-06
Epoch 7 | Batch 90/400 | Loss: 0.142844 | LR: 9.65e-06
Epoch 7 | Batch 95/400 | Loss: 0.222822 | LR: 9.65e-06
Epoch 7 | Batch 100/400 | Loss: 0.042119 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch100 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 105/400 | Loss: 0.091601 | LR: 9.65e-06
Epoch 7 | Batch 110/400 | Loss: 0.005847 | LR: 9.65e-06
Epoch 7 | Batch 115/400 | Loss: 0.094878 | LR: 9.65e-06
Epoch 7 | Batch 120/400 | Loss: 0.238602 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch120 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 125/400 | Loss: 0.123716 | LR: 9.65e-06
Epoch 7 | Batch 130/400 | Loss: 0.007706 | LR: 9.65e-06
Epoch 7 | Batch 135/400 | Loss: 0.452462 | LR: 9.65e-06
Epoch 7 | Batch 140/400 | Loss: 0.131000 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch140 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 145/400 | Loss: 0.122465 | LR: 9.65e-06
Epoch 7 | Batch 150/400 | Loss: 0.004561 | LR: 9.65e-06
Epoch 7 | Batch 155/400 | Loss: 0.437412 | LR: 9.65e-06
Epoch 7 | Batch 160/400 | Loss: 0.064089 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch160 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 165/400 | Loss: 0.043437 | LR: 9.65e-06
Epoch 7 | Batch 170/400 | Loss: 0.111552 | LR: 9.65e-06
Epoch 7 | Batch 175/400 | Loss: 0.031391 | LR: 9.65e-06
Epoch 7 | Batch 180/400 | Loss: 0.026232 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch180 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 185/400 | Loss: 0.114794 | LR: 9.65e-06
Epoch 7 | Batch 190/400 | Loss: 0.247806 | LR: 9.65e-06
Epoch 7 | Batch 195/400 | Loss: 0.148800 | LR: 9.65e-06
Epoch 7 | Batch 200/400 | Loss: 0.043879 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch200 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 205/400 | Loss: 0.160530 | LR: 9.65e-06
Epoch 7 | Batch 210/400 | Loss: 0.028187 | LR: 9.65e-06
Epoch 7 | Batch 215/400 | Loss: 0.100238 | LR: 9.65e-06
Epoch 7 | Batch 220/400 | Loss: 0.362024 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch220 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 225/400 | Loss: 0.048590 | LR: 9.65e-06
Epoch 7 | Batch 230/400 | Loss: 0.040146 | LR: 9.65e-06
Epoch 7 | Batch 235/400 | Loss: 0.022713 | LR: 9.65e-06
Epoch 7 | Batch 240/400 | Loss: 0.078979 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch240 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 245/400 | Loss: 0.052150 | LR: 9.65e-06
Epoch 7 | Batch 250/400 | Loss: 0.241756 | LR: 9.65e-06
Epoch 7 | Batch 255/400 | Loss: 0.011859 | LR: 9.65e-06
Epoch 7 | Batch 260/400 | Loss: 0.084635 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch260 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 265/400 | Loss: 0.035355 | LR: 9.65e-06
Epoch 7 | Batch 270/400 | Loss: 0.063596 | LR: 9.65e-06
Epoch 7 | Batch 275/400 | Loss: 0.246774 | LR: 9.65e-06
Epoch 7 | Batch 280/400 | Loss: 0.066096 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch280 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 285/400 | Loss: 0.079461 | LR: 9.65e-06
Epoch 7 | Batch 290/400 | Loss: 0.012459 | LR: 9.65e-06
Epoch 7 | Batch 295/400 | Loss: 0.129890 | LR: 9.65e-06
Epoch 7 | Batch 300/400 | Loss: 0.008856 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch300 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 305/400 | Loss: 0.061394 | LR: 9.65e-06
Epoch 7 | Batch 310/400 | Loss: 0.014306 | LR: 9.65e-06
Epoch 7 | Batch 315/400 | Loss: 0.078714 | LR: 9.65e-06
Epoch 7 | Batch 320/400 | Loss: 0.042934 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch320 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 325/400 | Loss: 0.033222 | LR: 9.65e-06
Epoch 7 | Batch 330/400 | Loss: 0.168760 | LR: 9.65e-06
Epoch 7 | Batch 335/400 | Loss: 0.076481 | LR: 9.65e-06
Epoch 7 | Batch 340/400 | Loss: 0.037787 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch340 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 345/400 | Loss: 0.220483 | LR: 9.65e-06
Epoch 7 | Batch 350/400 | Loss: 0.275060 | LR: 9.65e-06
Epoch 7 | Batch 355/400 | Loss: 0.020361 | LR: 9.65e-06
Epoch 7 | Batch 360/400 | Loss: 0.202734 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch360 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 365/400 | Loss: 0.044420 | LR: 9.65e-06
Epoch 7 | Batch 370/400 | Loss: 0.034350 | LR: 9.65e-06
Epoch 7 | Batch 375/400 | Loss: 0.037099 | LR: 9.65e-06
Epoch 7 | Batch 380/400 | Loss: 0.150590 | LR: 9.65e-06
[GPU MEM] Epoch7 Batch380 allocated=9.45GB reserved=11.25GB
Epoch 7 | Batch 385/400 | Loss: 0.201082 | LR: 9.65e-06
Epoch 7 | Batch 390/400 | Loss: 0.014892 | LR: 9.65e-06
Epoch 7 | Batch 395/400 | Loss: 0.183865 | LR: 9.65e-06
âœ… ç¬¬ 7 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.128936
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.419839
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.339946
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.168513
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.170447
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.109876
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.010484
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.017225
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.058261
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.221497
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.359429
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.181077
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.102938
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.031054
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.064448
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.003440
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.021238
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.372121
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.121444

============================================================
ğŸ“Š Epoch 7/50 å®Œæˆ
   Train Loss: 0.128936
   Val Loss: 0.121444
   LR: 9.65e-06 | Time: 128.3s
============================================================
â³ æ—©åœè®¡æ•°: 4/10
[GPU MEM] End of Epoch 7 allocated=8.10GB reserved=11.21GB
ğŸ“š å¼€å§‹ç¬¬ 8 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 8 | Batch 0/400 | Loss: 0.038728 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch0 allocated=9.45GB reserved=11.53GB
Epoch 8 | Batch 5/400 | Loss: 0.364646 | LR: 9.53e-06
Epoch 8 | Batch 10/400 | Loss: 0.033826 | LR: 9.53e-06
Epoch 8 | Batch 15/400 | Loss: 0.067398 | LR: 9.53e-06
Epoch 8 | Batch 20/400 | Loss: 0.093082 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch20 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 25/400 | Loss: 0.005295 | LR: 9.53e-06
Epoch 8 | Batch 30/400 | Loss: 0.227714 | LR: 9.53e-06
Epoch 8 | Batch 35/400 | Loss: 0.161993 | LR: 9.53e-06
Epoch 8 | Batch 40/400 | Loss: 0.347380 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch40 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 45/400 | Loss: 0.072572 | LR: 9.53e-06
Epoch 8 | Batch 50/400 | Loss: 0.021517 | LR: 9.53e-06
Epoch 8 | Batch 55/400 | Loss: 0.151403 | LR: 9.53e-06
Epoch 8 | Batch 60/400 | Loss: 0.008385 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch60 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 65/400 | Loss: 0.136437 | LR: 9.53e-06
Epoch 8 | Batch 70/400 | Loss: 0.053528 | LR: 9.53e-06
Epoch 8 | Batch 75/400 | Loss: 0.194676 | LR: 9.53e-06
Epoch 8 | Batch 80/400 | Loss: 0.022508 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch80 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 85/400 | Loss: 0.233061 | LR: 9.53e-06
Epoch 8 | Batch 90/400 | Loss: 0.088815 | LR: 9.53e-06
Epoch 8 | Batch 95/400 | Loss: 0.266535 | LR: 9.53e-06
Epoch 8 | Batch 100/400 | Loss: 0.013721 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch100 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 105/400 | Loss: 0.133967 | LR: 9.53e-06
Epoch 8 | Batch 110/400 | Loss: 0.048085 | LR: 9.53e-06
Epoch 8 | Batch 115/400 | Loss: 0.133446 | LR: 9.53e-06
Epoch 8 | Batch 120/400 | Loss: 0.014396 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch120 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 125/400 | Loss: 0.007968 | LR: 9.53e-06
Epoch 8 | Batch 130/400 | Loss: 0.037887 | LR: 9.53e-06
Epoch 8 | Batch 135/400 | Loss: 0.018571 | LR: 9.53e-06
Epoch 8 | Batch 140/400 | Loss: 0.034391 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch140 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 145/400 | Loss: 0.063929 | LR: 9.53e-06
Epoch 8 | Batch 150/400 | Loss: 0.129333 | LR: 9.53e-06
Epoch 8 | Batch 155/400 | Loss: 0.026239 | LR: 9.53e-06
Epoch 8 | Batch 160/400 | Loss: 0.223110 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch160 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 165/400 | Loss: 0.124363 | LR: 9.53e-06
Epoch 8 | Batch 170/400 | Loss: 0.208608 | LR: 9.53e-06
Epoch 8 | Batch 175/400 | Loss: 0.245801 | LR: 9.53e-06
Epoch 8 | Batch 180/400 | Loss: 0.158213 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch180 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 185/400 | Loss: 0.124700 | LR: 9.53e-06
Epoch 8 | Batch 190/400 | Loss: 0.116072 | LR: 9.53e-06
Epoch 8 | Batch 195/400 | Loss: 0.118177 | LR: 9.53e-06
Epoch 8 | Batch 200/400 | Loss: 0.072479 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch200 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 205/400 | Loss: 0.045329 | LR: 9.53e-06
Epoch 8 | Batch 210/400 | Loss: 0.056994 | LR: 9.53e-06
Epoch 8 | Batch 215/400 | Loss: 0.086583 | LR: 9.53e-06
Epoch 8 | Batch 220/400 | Loss: 0.215577 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch220 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 225/400 | Loss: 0.258807 | LR: 9.53e-06
Epoch 8 | Batch 230/400 | Loss: 0.195621 | LR: 9.53e-06
Epoch 8 | Batch 235/400 | Loss: 0.298249 | LR: 9.53e-06
Epoch 8 | Batch 240/400 | Loss: 0.091386 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch240 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 245/400 | Loss: 0.029418 | LR: 9.53e-06
Epoch 8 | Batch 250/400 | Loss: 0.043211 | LR: 9.53e-06
Epoch 8 | Batch 255/400 | Loss: 0.186237 | LR: 9.53e-06
Epoch 8 | Batch 260/400 | Loss: 0.081790 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch260 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 265/400 | Loss: 0.093698 | LR: 9.53e-06
Epoch 8 | Batch 270/400 | Loss: 0.141716 | LR: 9.53e-06
Epoch 8 | Batch 275/400 | Loss: 0.114396 | LR: 9.53e-06
Epoch 8 | Batch 280/400 | Loss: 0.276684 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch280 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 285/400 | Loss: 0.132419 | LR: 9.53e-06
Epoch 8 | Batch 290/400 | Loss: 0.163821 | LR: 9.53e-06
Epoch 8 | Batch 295/400 | Loss: 0.023531 | LR: 9.53e-06
Epoch 8 | Batch 300/400 | Loss: 0.082711 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch300 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 305/400 | Loss: 0.090670 | LR: 9.53e-06
Epoch 8 | Batch 310/400 | Loss: 0.019702 | LR: 9.53e-06
Epoch 8 | Batch 315/400 | Loss: 0.048347 | LR: 9.53e-06
Epoch 8 | Batch 320/400 | Loss: 0.267350 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch320 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 325/400 | Loss: 0.075465 | LR: 9.53e-06
Epoch 8 | Batch 330/400 | Loss: 0.132808 | LR: 9.53e-06
Epoch 8 | Batch 335/400 | Loss: 0.018667 | LR: 9.53e-06
Epoch 8 | Batch 340/400 | Loss: 0.082016 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch340 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 345/400 | Loss: 0.077091 | LR: 9.53e-06
Epoch 8 | Batch 350/400 | Loss: 0.033634 | LR: 9.53e-06
Epoch 8 | Batch 355/400 | Loss: 0.056962 | LR: 9.53e-06
Epoch 8 | Batch 360/400 | Loss: 0.181362 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch360 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 365/400 | Loss: 0.245436 | LR: 9.53e-06
Epoch 8 | Batch 370/400 | Loss: 0.132987 | LR: 9.53e-06
Epoch 8 | Batch 375/400 | Loss: 0.097954 | LR: 9.53e-06
Epoch 8 | Batch 380/400 | Loss: 0.144684 | LR: 9.53e-06
[GPU MEM] Epoch8 Batch380 allocated=9.45GB reserved=11.25GB
Epoch 8 | Batch 385/400 | Loss: 0.368713 | LR: 9.53e-06
Epoch 8 | Batch 390/400 | Loss: 0.035849 | LR: 9.53e-06
Epoch 8 | Batch 395/400 | Loss: 0.195602 | LR: 9.53e-06
âœ… ç¬¬ 8 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.122314
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.239768
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.091736
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.208494
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.047757
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.312271
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.119112
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.211409
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.022199
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.154280
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.484507
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.241851
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.052143
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.058714
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.282213
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.300412
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.119991
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.136224
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.145562

============================================================
ğŸ“Š Epoch 8/50 å®Œæˆ
   Train Loss: 0.122314
   Val Loss: 0.145562
   LR: 9.53e-06 | Time: 128.4s
============================================================
â³ æ—©åœè®¡æ•°: 5/10
[GPU MEM] End of Epoch 8 allocated=8.10GB reserved=11.21GB
ğŸ“š å¼€å§‹ç¬¬ 9 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 9 | Batch 0/400 | Loss: 0.174102 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch0 allocated=9.45GB reserved=11.53GB
Epoch 9 | Batch 5/400 | Loss: 0.072150 | LR: 9.39e-06
Epoch 9 | Batch 10/400 | Loss: 0.017026 | LR: 9.39e-06
Epoch 9 | Batch 15/400 | Loss: 0.162336 | LR: 9.39e-06
Epoch 9 | Batch 20/400 | Loss: 0.521858 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch20 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 25/400 | Loss: 0.262503 | LR: 9.39e-06
Epoch 9 | Batch 30/400 | Loss: 0.051776 | LR: 9.39e-06
Epoch 9 | Batch 35/400 | Loss: 0.052387 | LR: 9.39e-06
Epoch 9 | Batch 40/400 | Loss: 0.056986 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch40 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 45/400 | Loss: 0.076863 | LR: 9.39e-06
Epoch 9 | Batch 50/400 | Loss: 0.010959 | LR: 9.39e-06
Epoch 9 | Batch 55/400 | Loss: 0.049168 | LR: 9.39e-06
Epoch 9 | Batch 60/400 | Loss: 0.122823 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch60 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 65/400 | Loss: 0.109990 | LR: 9.39e-06
Epoch 9 | Batch 70/400 | Loss: 0.039052 | LR: 9.39e-06
Epoch 9 | Batch 75/400 | Loss: 0.076903 | LR: 9.39e-06
Epoch 9 | Batch 80/400 | Loss: 0.008416 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch80 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 85/400 | Loss: 0.289112 | LR: 9.39e-06
Epoch 9 | Batch 90/400 | Loss: 0.040284 | LR: 9.39e-06
Epoch 9 | Batch 95/400 | Loss: 0.169291 | LR: 9.39e-06
Epoch 9 | Batch 100/400 | Loss: 0.023890 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch100 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 105/400 | Loss: 0.048530 | LR: 9.39e-06
Epoch 9 | Batch 110/400 | Loss: 0.088557 | LR: 9.39e-06
Epoch 9 | Batch 115/400 | Loss: 0.031893 | LR: 9.39e-06
Epoch 9 | Batch 120/400 | Loss: 0.030486 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch120 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 125/400 | Loss: 0.275081 | LR: 9.39e-06
Epoch 9 | Batch 130/400 | Loss: 0.078706 | LR: 9.39e-06
Epoch 9 | Batch 135/400 | Loss: 0.103876 | LR: 9.39e-06
Epoch 9 | Batch 140/400 | Loss: 0.169083 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch140 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 145/400 | Loss: 0.135111 | LR: 9.39e-06
Epoch 9 | Batch 150/400 | Loss: 0.021009 | LR: 9.39e-06
Epoch 9 | Batch 155/400 | Loss: 0.040953 | LR: 9.39e-06
Epoch 9 | Batch 160/400 | Loss: 0.059343 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch160 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 165/400 | Loss: 0.142616 | LR: 9.39e-06
Epoch 9 | Batch 170/400 | Loss: 0.041375 | LR: 9.39e-06
Epoch 9 | Batch 175/400 | Loss: 0.296388 | LR: 9.39e-06
Epoch 9 | Batch 180/400 | Loss: 0.070572 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch180 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 185/400 | Loss: 0.052083 | LR: 9.39e-06
Epoch 9 | Batch 190/400 | Loss: 0.113997 | LR: 9.39e-06
Epoch 9 | Batch 195/400 | Loss: 0.021665 | LR: 9.39e-06
Epoch 9 | Batch 200/400 | Loss: 0.198197 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch200 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 205/400 | Loss: 0.064897 | LR: 9.39e-06
Epoch 9 | Batch 210/400 | Loss: 0.328623 | LR: 9.39e-06
Epoch 9 | Batch 215/400 | Loss: 0.137911 | LR: 9.39e-06
Epoch 9 | Batch 220/400 | Loss: 0.188164 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch220 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 225/400 | Loss: 0.331409 | LR: 9.39e-06
Epoch 9 | Batch 230/400 | Loss: 0.009992 | LR: 9.39e-06
Epoch 9 | Batch 235/400 | Loss: 0.147879 | LR: 9.39e-06
Epoch 9 | Batch 240/400 | Loss: 0.073933 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch240 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 245/400 | Loss: 0.241255 | LR: 9.39e-06
Epoch 9 | Batch 250/400 | Loss: 0.018275 | LR: 9.39e-06
Epoch 9 | Batch 255/400 | Loss: 0.227944 | LR: 9.39e-06
Epoch 9 | Batch 260/400 | Loss: 0.122323 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch260 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 265/400 | Loss: 0.008597 | LR: 9.39e-06
Epoch 9 | Batch 270/400 | Loss: 0.285489 | LR: 9.39e-06
Epoch 9 | Batch 275/400 | Loss: 0.151130 | LR: 9.39e-06
Epoch 9 | Batch 280/400 | Loss: 0.066013 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch280 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 285/400 | Loss: 0.223575 | LR: 9.39e-06
Epoch 9 | Batch 290/400 | Loss: 0.030630 | LR: 9.39e-06
Epoch 9 | Batch 295/400 | Loss: 0.076509 | LR: 9.39e-06
Epoch 9 | Batch 300/400 | Loss: 0.346493 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch300 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 305/400 | Loss: 0.032550 | LR: 9.39e-06
Epoch 9 | Batch 310/400 | Loss: 0.052673 | LR: 9.39e-06
Epoch 9 | Batch 315/400 | Loss: 0.051524 | LR: 9.39e-06
Epoch 9 | Batch 320/400 | Loss: 0.006197 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch320 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 325/400 | Loss: 0.115612 | LR: 9.39e-06
Epoch 9 | Batch 330/400 | Loss: 0.108282 | LR: 9.39e-06
Epoch 9 | Batch 335/400 | Loss: 0.074670 | LR: 9.39e-06
Epoch 9 | Batch 340/400 | Loss: 0.097790 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch340 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 345/400 | Loss: 0.168589 | LR: 9.39e-06
Epoch 9 | Batch 350/400 | Loss: 0.114282 | LR: 9.39e-06
Epoch 9 | Batch 355/400 | Loss: 0.057791 | LR: 9.39e-06
Epoch 9 | Batch 360/400 | Loss: 0.114366 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch360 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 365/400 | Loss: 0.073871 | LR: 9.39e-06
Epoch 9 | Batch 370/400 | Loss: 0.077073 | LR: 9.39e-06
Epoch 9 | Batch 375/400 | Loss: 0.277727 | LR: 9.39e-06
Epoch 9 | Batch 380/400 | Loss: 0.364493 | LR: 9.39e-06
[GPU MEM] Epoch9 Batch380 allocated=9.45GB reserved=11.25GB
Epoch 9 | Batch 385/400 | Loss: 0.046148 | LR: 9.39e-06
Epoch 9 | Batch 390/400 | Loss: 0.373694 | LR: 9.39e-06
Epoch 9 | Batch 395/400 | Loss: 0.062534 | LR: 9.39e-06
âœ… ç¬¬ 9 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.134330
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.310591
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.319287
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.347081
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.017860
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.231249
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.048667
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.017610
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.101483
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.070011
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.100011
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.117302
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.044837
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.079461
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.018909
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.018120
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.035400
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.135779
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.123066

============================================================
ğŸ“Š Epoch 9/50 å®Œæˆ
   Train Loss: 0.134330
   Val Loss: 0.123066
   LR: 9.39e-06 | Time: 128.4s
============================================================
â³ æ—©åœè®¡æ•°: 6/10
[GPU MEM] End of Epoch 9 allocated=8.10GB reserved=11.21GB
ğŸ“š å¼€å§‹ç¬¬ 10 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 10 | Batch 0/400 | Loss: 0.055998 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch0 allocated=9.45GB reserved=11.53GB
Epoch 10 | Batch 5/400 | Loss: 0.075530 | LR: 9.23e-06
Epoch 10 | Batch 10/400 | Loss: 0.266885 | LR: 9.23e-06
Epoch 10 | Batch 15/400 | Loss: 0.031679 | LR: 9.23e-06
Epoch 10 | Batch 20/400 | Loss: 0.122502 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch20 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 25/400 | Loss: 0.225137 | LR: 9.23e-06
Epoch 10 | Batch 30/400 | Loss: 0.274395 | LR: 9.23e-06
Epoch 10 | Batch 35/400 | Loss: 0.083126 | LR: 9.23e-06
Epoch 10 | Batch 40/400 | Loss: 0.025659 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch40 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 45/400 | Loss: 0.592051 | LR: 9.23e-06
Epoch 10 | Batch 50/400 | Loss: 0.055174 | LR: 9.23e-06
Epoch 10 | Batch 55/400 | Loss: 0.017682 | LR: 9.23e-06
Epoch 10 | Batch 60/400 | Loss: 0.020305 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch60 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 65/400 | Loss: 0.072540 | LR: 9.23e-06
Epoch 10 | Batch 70/400 | Loss: 0.059232 | LR: 9.23e-06
Epoch 10 | Batch 75/400 | Loss: 0.014030 | LR: 9.23e-06
Epoch 10 | Batch 80/400 | Loss: 0.071588 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch80 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 85/400 | Loss: 0.011631 | LR: 9.23e-06
Epoch 10 | Batch 90/400 | Loss: 0.223689 | LR: 9.23e-06
Epoch 10 | Batch 95/400 | Loss: 0.126649 | LR: 9.23e-06
Epoch 10 | Batch 100/400 | Loss: 0.026602 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch100 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 105/400 | Loss: 0.083438 | LR: 9.23e-06
Epoch 10 | Batch 110/400 | Loss: 0.116362 | LR: 9.23e-06
Epoch 10 | Batch 115/400 | Loss: 0.056234 | LR: 9.23e-06
Epoch 10 | Batch 120/400 | Loss: 0.298015 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch120 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 125/400 | Loss: 0.122911 | LR: 9.23e-06
Epoch 10 | Batch 130/400 | Loss: 0.112622 | LR: 9.23e-06
Epoch 10 | Batch 135/400 | Loss: 0.349799 | LR: 9.23e-06
Epoch 10 | Batch 140/400 | Loss: 0.012116 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch140 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 145/400 | Loss: 0.255356 | LR: 9.23e-06
Epoch 10 | Batch 150/400 | Loss: 0.162634 | LR: 9.23e-06
Epoch 10 | Batch 155/400 | Loss: 0.452140 | LR: 9.23e-06
Epoch 10 | Batch 160/400 | Loss: 0.114686 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch160 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 165/400 | Loss: 0.003212 | LR: 9.23e-06
Epoch 10 | Batch 170/400 | Loss: 0.324208 | LR: 9.23e-06
Epoch 10 | Batch 175/400 | Loss: 0.088103 | LR: 9.23e-06
Epoch 10 | Batch 180/400 | Loss: 0.105102 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch180 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 185/400 | Loss: 0.152132 | LR: 9.23e-06
Epoch 10 | Batch 190/400 | Loss: 0.083669 | LR: 9.23e-06
Epoch 10 | Batch 195/400 | Loss: 0.022368 | LR: 9.23e-06
Epoch 10 | Batch 200/400 | Loss: 0.079325 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch200 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 205/400 | Loss: 0.066448 | LR: 9.23e-06
Epoch 10 | Batch 210/400 | Loss: 0.487609 | LR: 9.23e-06
Epoch 10 | Batch 215/400 | Loss: 0.129154 | LR: 9.23e-06
Epoch 10 | Batch 220/400 | Loss: 0.070108 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch220 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 225/400 | Loss: 0.034656 | LR: 9.23e-06
Epoch 10 | Batch 230/400 | Loss: 0.038337 | LR: 9.23e-06
Epoch 10 | Batch 235/400 | Loss: 0.426778 | LR: 9.23e-06
Epoch 10 | Batch 240/400 | Loss: 0.153230 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch240 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 245/400 | Loss: 0.043429 | LR: 9.23e-06
Epoch 10 | Batch 250/400 | Loss: 0.184099 | LR: 9.23e-06
Epoch 10 | Batch 255/400 | Loss: 0.107323 | LR: 9.23e-06
Epoch 10 | Batch 260/400 | Loss: 0.106822 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch260 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 265/400 | Loss: 0.063105 | LR: 9.23e-06
Epoch 10 | Batch 270/400 | Loss: 0.006103 | LR: 9.23e-06
Epoch 10 | Batch 275/400 | Loss: 0.011066 | LR: 9.23e-06
Epoch 10 | Batch 280/400 | Loss: 0.306899 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch280 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 285/400 | Loss: 0.163057 | LR: 9.23e-06
Epoch 10 | Batch 290/400 | Loss: 0.079323 | LR: 9.23e-06
Epoch 10 | Batch 295/400 | Loss: 0.276893 | LR: 9.23e-06
Epoch 10 | Batch 300/400 | Loss: 0.070114 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch300 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 305/400 | Loss: 0.082470 | LR: 9.23e-06
Epoch 10 | Batch 310/400 | Loss: 0.201431 | LR: 9.23e-06
Epoch 10 | Batch 315/400 | Loss: 0.116407 | LR: 9.23e-06
Epoch 10 | Batch 320/400 | Loss: 0.263002 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch320 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 325/400 | Loss: 0.294778 | LR: 9.23e-06
Epoch 10 | Batch 330/400 | Loss: 0.135030 | LR: 9.23e-06
Epoch 10 | Batch 335/400 | Loss: 0.014564 | LR: 9.23e-06
Epoch 10 | Batch 340/400 | Loss: 0.224630 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch340 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 345/400 | Loss: 0.172965 | LR: 9.23e-06
Epoch 10 | Batch 350/400 | Loss: 0.308100 | LR: 9.23e-06
Epoch 10 | Batch 355/400 | Loss: 0.051520 | LR: 9.23e-06
Epoch 10 | Batch 360/400 | Loss: 0.134932 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch360 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 365/400 | Loss: 0.037776 | LR: 9.23e-06
Epoch 10 | Batch 370/400 | Loss: 0.139793 | LR: 9.23e-06
Epoch 10 | Batch 375/400 | Loss: 0.039581 | LR: 9.23e-06
Epoch 10 | Batch 380/400 | Loss: 0.318158 | LR: 9.23e-06
[GPU MEM] Epoch10 Batch380 allocated=9.45GB reserved=11.25GB
Epoch 10 | Batch 385/400 | Loss: 0.114617 | LR: 9.23e-06
Epoch 10 | Batch 390/400 | Loss: 0.256778 | LR: 9.23e-06
Epoch 10 | Batch 395/400 | Loss: 0.019416 | LR: 9.23e-06
âœ… ç¬¬ 10 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.130182
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.012666
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.304276
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.225576
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.019153
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.103930
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.196424
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.153626
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.045762
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.285043
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.036619
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.172764
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.090956
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.003740
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.028827
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.048044
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.015605
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.190107
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.112866
ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆ Epoch 10 çš„é¢„è§ˆå›¾...
âœ¨ é¢„è§ˆå›¾å·²ä¿å­˜åˆ° training_results_cover_object_512

============================================================
ğŸ“Š Epoch 10/50 å®Œæˆ
   Train Loss: 0.130182
   Val Loss: 0.112866
   LR: 9.23e-06 | Time: 132.6s
============================================================
â³ æ—©åœè®¡æ•°: 7/10
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_cover_object_512/controlnet_cover_object_epoch_10.pth
[GPU MEM] End of Epoch 10 allocated=8.10GB reserved=11.21GB
ğŸ“š å¼€å§‹ç¬¬ 11 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 11 | Batch 0/400 | Loss: 0.235129 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch0 allocated=9.45GB reserved=11.53GB
Epoch 11 | Batch 5/400 | Loss: 0.046537 | LR: 9.05e-06
Epoch 11 | Batch 10/400 | Loss: 0.210562 | LR: 9.05e-06
Epoch 11 | Batch 15/400 | Loss: 0.321959 | LR: 9.05e-06
Epoch 11 | Batch 20/400 | Loss: 0.006353 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch20 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 25/400 | Loss: 0.040264 | LR: 9.05e-06
Epoch 11 | Batch 30/400 | Loss: 0.002288 | LR: 9.05e-06
Epoch 11 | Batch 35/400 | Loss: 0.136973 | LR: 9.05e-06
Epoch 11 | Batch 40/400 | Loss: 0.232174 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch40 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 45/400 | Loss: 0.079292 | LR: 9.05e-06
Epoch 11 | Batch 50/400 | Loss: 0.026622 | LR: 9.05e-06
Epoch 11 | Batch 55/400 | Loss: 0.091142 | LR: 9.05e-06
Epoch 11 | Batch 60/400 | Loss: 0.093996 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch60 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 65/400 | Loss: 0.022405 | LR: 9.05e-06
Epoch 11 | Batch 70/400 | Loss: 0.437921 | LR: 9.05e-06
Epoch 11 | Batch 75/400 | Loss: 0.206695 | LR: 9.05e-06
Epoch 11 | Batch 80/400 | Loss: 0.055502 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch80 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 85/400 | Loss: 0.156601 | LR: 9.05e-06
Epoch 11 | Batch 90/400 | Loss: 0.142969 | LR: 9.05e-06
Epoch 11 | Batch 95/400 | Loss: 0.066359 | LR: 9.05e-06
Epoch 11 | Batch 100/400 | Loss: 0.015628 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch100 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 105/400 | Loss: 0.067002 | LR: 9.05e-06
Epoch 11 | Batch 110/400 | Loss: 0.124517 | LR: 9.05e-06
Epoch 11 | Batch 115/400 | Loss: 0.281654 | LR: 9.05e-06
Epoch 11 | Batch 120/400 | Loss: 0.050000 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch120 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 125/400 | Loss: 0.163987 | LR: 9.05e-06
Epoch 11 | Batch 130/400 | Loss: 0.132479 | LR: 9.05e-06
Epoch 11 | Batch 135/400 | Loss: 0.052795 | LR: 9.05e-06
Epoch 11 | Batch 140/400 | Loss: 0.082870 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch140 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 145/400 | Loss: 0.020164 | LR: 9.05e-06
Epoch 11 | Batch 150/400 | Loss: 0.114486 | LR: 9.05e-06
Epoch 11 | Batch 155/400 | Loss: 0.018869 | LR: 9.05e-06
Epoch 11 | Batch 160/400 | Loss: 0.030300 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch160 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 165/400 | Loss: 0.373278 | LR: 9.05e-06
Epoch 11 | Batch 170/400 | Loss: 0.348598 | LR: 9.05e-06
Epoch 11 | Batch 175/400 | Loss: 0.113132 | LR: 9.05e-06
Epoch 11 | Batch 180/400 | Loss: 0.075040 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch180 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 185/400 | Loss: 0.161115 | LR: 9.05e-06
Epoch 11 | Batch 190/400 | Loss: 0.074715 | LR: 9.05e-06
Epoch 11 | Batch 195/400 | Loss: 0.107217 | LR: 9.05e-06
Epoch 11 | Batch 200/400 | Loss: 0.182657 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch200 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 205/400 | Loss: 0.138233 | LR: 9.05e-06
Epoch 11 | Batch 210/400 | Loss: 0.186338 | LR: 9.05e-06
Epoch 11 | Batch 215/400 | Loss: 0.169354 | LR: 9.05e-06
Epoch 11 | Batch 220/400 | Loss: 0.183784 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch220 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 225/400 | Loss: 0.192792 | LR: 9.05e-06
Epoch 11 | Batch 230/400 | Loss: 0.073371 | LR: 9.05e-06
Epoch 11 | Batch 235/400 | Loss: 0.037532 | LR: 9.05e-06
Epoch 11 | Batch 240/400 | Loss: 0.167252 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch240 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 245/400 | Loss: 0.054741 | LR: 9.05e-06
Epoch 11 | Batch 250/400 | Loss: 0.101833 | LR: 9.05e-06
Epoch 11 | Batch 255/400 | Loss: 0.043412 | LR: 9.05e-06
Epoch 11 | Batch 260/400 | Loss: 0.019753 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch260 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 265/400 | Loss: 0.019365 | LR: 9.05e-06
Epoch 11 | Batch 270/400 | Loss: 0.189748 | LR: 9.05e-06
Epoch 11 | Batch 275/400 | Loss: 0.074934 | LR: 9.05e-06
Epoch 11 | Batch 280/400 | Loss: 0.042625 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch280 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 285/400 | Loss: 0.109340 | LR: 9.05e-06
Epoch 11 | Batch 290/400 | Loss: 0.119368 | LR: 9.05e-06
Epoch 11 | Batch 295/400 | Loss: 0.252896 | LR: 9.05e-06
Epoch 11 | Batch 300/400 | Loss: 0.013822 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch300 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 305/400 | Loss: 0.405197 | LR: 9.05e-06
Epoch 11 | Batch 310/400 | Loss: 0.029584 | LR: 9.05e-06
Epoch 11 | Batch 315/400 | Loss: 0.104617 | LR: 9.05e-06
Epoch 11 | Batch 320/400 | Loss: 0.163557 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch320 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 325/400 | Loss: 0.319053 | LR: 9.05e-06
Epoch 11 | Batch 330/400 | Loss: 0.429175 | LR: 9.05e-06
Epoch 11 | Batch 335/400 | Loss: 0.061175 | LR: 9.05e-06
Epoch 11 | Batch 340/400 | Loss: 0.152719 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch340 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 345/400 | Loss: 0.172208 | LR: 9.05e-06
Epoch 11 | Batch 350/400 | Loss: 0.507038 | LR: 9.05e-06
Epoch 11 | Batch 355/400 | Loss: 0.119250 | LR: 9.05e-06
Epoch 11 | Batch 360/400 | Loss: 0.021500 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch360 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 365/400 | Loss: 0.157815 | LR: 9.05e-06
Epoch 11 | Batch 370/400 | Loss: 0.053431 | LR: 9.05e-06
Epoch 11 | Batch 375/400 | Loss: 0.202298 | LR: 9.05e-06
Epoch 11 | Batch 380/400 | Loss: 0.129767 | LR: 9.05e-06
[GPU MEM] Epoch11 Batch380 allocated=9.45GB reserved=11.25GB
Epoch 11 | Batch 385/400 | Loss: 0.062633 | LR: 9.05e-06
Epoch 11 | Batch 390/400 | Loss: 0.093673 | LR: 9.05e-06
Epoch 11 | Batch 395/400 | Loss: 0.205342 | LR: 9.05e-06
âœ… ç¬¬ 11 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.126917
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.145412
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.073132
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.124438
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.334176
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.267345
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.016665
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.030067
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.124680
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.053560
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.047375
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.043493
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.133356
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.088821
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.156358
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.088409
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.072776
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.198618
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.120067

============================================================
ğŸ“Š Epoch 11/50 å®Œæˆ
   Train Loss: 0.126917
   Val Loss: 0.120067
   LR: 9.05e-06 | Time: 128.0s
============================================================
â³ æ—©åœè®¡æ•°: 8/10
[GPU MEM] End of Epoch 11 allocated=8.10GB reserved=11.21GB
ğŸ“š å¼€å§‹ç¬¬ 12 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 12 | Batch 0/400 | Loss: 0.185824 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch0 allocated=9.45GB reserved=11.53GB
Epoch 12 | Batch 5/400 | Loss: 0.098171 | LR: 8.86e-06
Epoch 12 | Batch 10/400 | Loss: 0.031191 | LR: 8.86e-06
Epoch 12 | Batch 15/400 | Loss: 0.137159 | LR: 8.86e-06
Epoch 12 | Batch 20/400 | Loss: 0.046608 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch20 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 25/400 | Loss: 0.288404 | LR: 8.86e-06
Epoch 12 | Batch 30/400 | Loss: 0.089775 | LR: 8.86e-06
Epoch 12 | Batch 35/400 | Loss: 0.080531 | LR: 8.86e-06
Epoch 12 | Batch 40/400 | Loss: 0.023386 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch40 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 45/400 | Loss: 0.200949 | LR: 8.86e-06
Epoch 12 | Batch 50/400 | Loss: 0.007077 | LR: 8.86e-06
Epoch 12 | Batch 55/400 | Loss: 0.090752 | LR: 8.86e-06
Epoch 12 | Batch 60/400 | Loss: 0.010603 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch60 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 65/400 | Loss: 0.005674 | LR: 8.86e-06
Epoch 12 | Batch 70/400 | Loss: 0.546337 | LR: 8.86e-06
Epoch 12 | Batch 75/400 | Loss: 0.048962 | LR: 8.86e-06
Epoch 12 | Batch 80/400 | Loss: 0.317278 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch80 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 85/400 | Loss: 0.047679 | LR: 8.86e-06
Epoch 12 | Batch 90/400 | Loss: 0.062138 | LR: 8.86e-06
Epoch 12 | Batch 95/400 | Loss: 0.018894 | LR: 8.86e-06
Epoch 12 | Batch 100/400 | Loss: 0.026804 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch100 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 105/400 | Loss: 0.333739 | LR: 8.86e-06
Epoch 12 | Batch 110/400 | Loss: 0.024472 | LR: 8.86e-06
Epoch 12 | Batch 115/400 | Loss: 0.010840 | LR: 8.86e-06
Epoch 12 | Batch 120/400 | Loss: 0.068232 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch120 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 125/400 | Loss: 0.009520 | LR: 8.86e-06
Epoch 12 | Batch 130/400 | Loss: 0.495667 | LR: 8.86e-06
Epoch 12 | Batch 135/400 | Loss: 0.110972 | LR: 8.86e-06
Epoch 12 | Batch 140/400 | Loss: 0.476082 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch140 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 145/400 | Loss: 0.065584 | LR: 8.86e-06
Epoch 12 | Batch 150/400 | Loss: 0.451427 | LR: 8.86e-06
Epoch 12 | Batch 155/400 | Loss: 0.086233 | LR: 8.86e-06
Epoch 12 | Batch 160/400 | Loss: 0.030097 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch160 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 165/400 | Loss: 0.035364 | LR: 8.86e-06
Epoch 12 | Batch 170/400 | Loss: 0.102666 | LR: 8.86e-06
Epoch 12 | Batch 175/400 | Loss: 0.248493 | LR: 8.86e-06
Epoch 12 | Batch 180/400 | Loss: 0.064361 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch180 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 185/400 | Loss: 0.188529 | LR: 8.86e-06
Epoch 12 | Batch 190/400 | Loss: 0.374763 | LR: 8.86e-06
Epoch 12 | Batch 195/400 | Loss: 0.043999 | LR: 8.86e-06
Epoch 12 | Batch 200/400 | Loss: 0.043898 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch200 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 205/400 | Loss: 0.119015 | LR: 8.86e-06
Epoch 12 | Batch 210/400 | Loss: 0.102887 | LR: 8.86e-06
Epoch 12 | Batch 215/400 | Loss: 0.258752 | LR: 8.86e-06
Epoch 12 | Batch 220/400 | Loss: 0.471145 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch220 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 225/400 | Loss: 0.021949 | LR: 8.86e-06
Epoch 12 | Batch 230/400 | Loss: 0.064745 | LR: 8.86e-06
Epoch 12 | Batch 235/400 | Loss: 0.202623 | LR: 8.86e-06
Epoch 12 | Batch 240/400 | Loss: 0.057488 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch240 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 245/400 | Loss: 0.071415 | LR: 8.86e-06
Epoch 12 | Batch 250/400 | Loss: 0.231336 | LR: 8.86e-06
Epoch 12 | Batch 255/400 | Loss: 0.071485 | LR: 8.86e-06
Epoch 12 | Batch 260/400 | Loss: 0.129308 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch260 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 265/400 | Loss: 0.160386 | LR: 8.86e-06
Epoch 12 | Batch 270/400 | Loss: 0.004513 | LR: 8.86e-06
Epoch 12 | Batch 275/400 | Loss: 0.269292 | LR: 8.86e-06
Epoch 12 | Batch 280/400 | Loss: 0.282520 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch280 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 285/400 | Loss: 0.203282 | LR: 8.86e-06
Epoch 12 | Batch 290/400 | Loss: 0.118765 | LR: 8.86e-06
Epoch 12 | Batch 295/400 | Loss: 0.066187 | LR: 8.86e-06
Epoch 12 | Batch 300/400 | Loss: 0.096713 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch300 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 305/400 | Loss: 0.179332 | LR: 8.86e-06
Epoch 12 | Batch 310/400 | Loss: 0.053920 | LR: 8.86e-06
Epoch 12 | Batch 315/400 | Loss: 0.067668 | LR: 8.86e-06
Epoch 12 | Batch 320/400 | Loss: 0.005368 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch320 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 325/400 | Loss: 0.032987 | LR: 8.86e-06
Epoch 12 | Batch 330/400 | Loss: 0.095627 | LR: 8.86e-06
Epoch 12 | Batch 335/400 | Loss: 0.108102 | LR: 8.86e-06
Epoch 12 | Batch 340/400 | Loss: 0.038785 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch340 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 345/400 | Loss: 0.053684 | LR: 8.86e-06
Epoch 12 | Batch 350/400 | Loss: 0.103079 | LR: 8.86e-06
Epoch 12 | Batch 355/400 | Loss: 0.159859 | LR: 8.86e-06
Epoch 12 | Batch 360/400 | Loss: 0.096276 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch360 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 365/400 | Loss: 0.156447 | LR: 8.86e-06
Epoch 12 | Batch 370/400 | Loss: 0.005932 | LR: 8.86e-06
Epoch 12 | Batch 375/400 | Loss: 0.166611 | LR: 8.86e-06
Epoch 12 | Batch 380/400 | Loss: 0.103653 | LR: 8.86e-06
[GPU MEM] Epoch12 Batch380 allocated=9.45GB reserved=11.25GB
Epoch 12 | Batch 385/400 | Loss: 0.117348 | LR: 8.86e-06
Epoch 12 | Batch 390/400 | Loss: 0.060382 | LR: 8.86e-06
Epoch 12 | Batch 395/400 | Loss: 0.033581 | LR: 8.86e-06
âœ… ç¬¬ 12 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.133592
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.280522
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.019370
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.220725
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.004189
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.258461
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.087832
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.025026
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.131280
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.074931
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.093759
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.093480
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.148098
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.017785
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.270858
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.131705
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.047923
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.064581
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.111103

============================================================
ğŸ“Š Epoch 12/50 å®Œæˆ
   Train Loss: 0.133592
   Val Loss: 0.111103
   LR: 8.86e-06 | Time: 128.4s
============================================================
â³ æ—©åœè®¡æ•°: 9/10
[GPU MEM] End of Epoch 12 allocated=8.10GB reserved=11.21GB
ğŸ“š å¼€å§‹ç¬¬ 13 è½®è®­ç»ƒï¼Œå…±æœ‰ 400 ä¸ªæ‰¹æ¬¡
Epoch 13 | Batch 0/400 | Loss: 0.370631 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch0 allocated=9.45GB reserved=11.53GB
Epoch 13 | Batch 5/400 | Loss: 0.046627 | LR: 8.66e-06
Epoch 13 | Batch 10/400 | Loss: 0.046740 | LR: 8.66e-06
Epoch 13 | Batch 15/400 | Loss: 0.013842 | LR: 8.66e-06
Epoch 13 | Batch 20/400 | Loss: 0.023849 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch20 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 25/400 | Loss: 0.229771 | LR: 8.66e-06
Epoch 13 | Batch 30/400 | Loss: 0.295847 | LR: 8.66e-06
Epoch 13 | Batch 35/400 | Loss: 0.148301 | LR: 8.66e-06
Epoch 13 | Batch 40/400 | Loss: 0.051347 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch40 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 45/400 | Loss: 0.008239 | LR: 8.66e-06
Epoch 13 | Batch 50/400 | Loss: 0.172759 | LR: 8.66e-06
Epoch 13 | Batch 55/400 | Loss: 0.081130 | LR: 8.66e-06
Epoch 13 | Batch 60/400 | Loss: 0.014827 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch60 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 65/400 | Loss: 0.047723 | LR: 8.66e-06
Epoch 13 | Batch 70/400 | Loss: 0.008001 | LR: 8.66e-06
Epoch 13 | Batch 75/400 | Loss: 0.258108 | LR: 8.66e-06
Epoch 13 | Batch 80/400 | Loss: 0.038234 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch80 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 85/400 | Loss: 0.060492 | LR: 8.66e-06
Epoch 13 | Batch 90/400 | Loss: 0.164422 | LR: 8.66e-06
Epoch 13 | Batch 95/400 | Loss: 0.059861 | LR: 8.66e-06
Epoch 13 | Batch 100/400 | Loss: 0.113673 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch100 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 105/400 | Loss: 0.124138 | LR: 8.66e-06
Epoch 13 | Batch 110/400 | Loss: 0.218564 | LR: 8.66e-06
Epoch 13 | Batch 115/400 | Loss: 0.038186 | LR: 8.66e-06
Epoch 13 | Batch 120/400 | Loss: 0.414424 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch120 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 125/400 | Loss: 0.071425 | LR: 8.66e-06
Epoch 13 | Batch 130/400 | Loss: 0.125272 | LR: 8.66e-06
Epoch 13 | Batch 135/400 | Loss: 0.054631 | LR: 8.66e-06
Epoch 13 | Batch 140/400 | Loss: 0.172361 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch140 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 145/400 | Loss: 0.335805 | LR: 8.66e-06
Epoch 13 | Batch 150/400 | Loss: 0.013808 | LR: 8.66e-06
Epoch 13 | Batch 155/400 | Loss: 0.156406 | LR: 8.66e-06
Epoch 13 | Batch 160/400 | Loss: 0.157254 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch160 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 165/400 | Loss: 0.098933 | LR: 8.66e-06
Epoch 13 | Batch 170/400 | Loss: 0.069397 | LR: 8.66e-06
Epoch 13 | Batch 175/400 | Loss: 0.194852 | LR: 8.66e-06
Epoch 13 | Batch 180/400 | Loss: 0.302236 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch180 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 185/400 | Loss: 0.174191 | LR: 8.66e-06
Epoch 13 | Batch 190/400 | Loss: 0.172160 | LR: 8.66e-06
Epoch 13 | Batch 195/400 | Loss: 0.120671 | LR: 8.66e-06
Epoch 13 | Batch 200/400 | Loss: 0.103503 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch200 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 205/400 | Loss: 0.435971 | LR: 8.66e-06
Epoch 13 | Batch 210/400 | Loss: 0.017895 | LR: 8.66e-06
Epoch 13 | Batch 215/400 | Loss: 0.095358 | LR: 8.66e-06
Epoch 13 | Batch 220/400 | Loss: 0.367882 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch220 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 225/400 | Loss: 0.175315 | LR: 8.66e-06
Epoch 13 | Batch 230/400 | Loss: 0.205551 | LR: 8.66e-06
Epoch 13 | Batch 235/400 | Loss: 0.137768 | LR: 8.66e-06
Epoch 13 | Batch 240/400 | Loss: 0.064845 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch240 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 245/400 | Loss: 0.359011 | LR: 8.66e-06
Epoch 13 | Batch 250/400 | Loss: 0.012019 | LR: 8.66e-06
Epoch 13 | Batch 255/400 | Loss: 0.510677 | LR: 8.66e-06
Epoch 13 | Batch 260/400 | Loss: 0.079123 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch260 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 265/400 | Loss: 0.041862 | LR: 8.66e-06
Epoch 13 | Batch 270/400 | Loss: 0.024601 | LR: 8.66e-06
Epoch 13 | Batch 275/400 | Loss: 0.082742 | LR: 8.66e-06
Epoch 13 | Batch 280/400 | Loss: 0.168974 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch280 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 285/400 | Loss: 0.095731 | LR: 8.66e-06
Epoch 13 | Batch 290/400 | Loss: 0.215545 | LR: 8.66e-06
Epoch 13 | Batch 295/400 | Loss: 0.057868 | LR: 8.66e-06
Epoch 13 | Batch 300/400 | Loss: 0.250289 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch300 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 305/400 | Loss: 0.256826 | LR: 8.66e-06
Epoch 13 | Batch 310/400 | Loss: 0.033791 | LR: 8.66e-06
Epoch 13 | Batch 315/400 | Loss: 0.185475 | LR: 8.66e-06
Epoch 13 | Batch 320/400 | Loss: 0.058412 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch320 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 325/400 | Loss: 0.146765 | LR: 8.66e-06
Epoch 13 | Batch 330/400 | Loss: 0.062571 | LR: 8.66e-06
Epoch 13 | Batch 335/400 | Loss: 0.198529 | LR: 8.66e-06
Epoch 13 | Batch 340/400 | Loss: 0.175762 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch340 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 345/400 | Loss: 0.530050 | LR: 8.66e-06
Epoch 13 | Batch 350/400 | Loss: 0.133875 | LR: 8.66e-06
Epoch 13 | Batch 355/400 | Loss: 0.272170 | LR: 8.66e-06
Epoch 13 | Batch 360/400 | Loss: 0.559193 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch360 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 365/400 | Loss: 0.021116 | LR: 8.66e-06
Epoch 13 | Batch 370/400 | Loss: 0.066484 | LR: 8.66e-06
Epoch 13 | Batch 375/400 | Loss: 0.036820 | LR: 8.66e-06
Epoch 13 | Batch 380/400 | Loss: 0.101608 | LR: 8.66e-06
[GPU MEM] Epoch13 Batch380 allocated=9.45GB reserved=11.25GB
Epoch 13 | Batch 385/400 | Loss: 0.004186 | LR: 8.66e-06
Epoch 13 | Batch 390/400 | Loss: 0.005132 | LR: 8.66e-06
Epoch 13 | Batch 395/400 | Loss: 0.301585 | LR: 8.66e-06
âœ… ç¬¬ 13 è½®è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: 0.138537
ğŸ§ª å¼€å§‹éªŒè¯ï¼Œå…±æœ‰ 50 ä¸ªæ‰¹æ¬¡
éªŒè¯æ‰¹æ¬¡ 0/50 | Loss: 0.411848
éªŒè¯æ‰¹æ¬¡ 3/50 | Loss: 0.138144
éªŒè¯æ‰¹æ¬¡ 6/50 | Loss: 0.077398
éªŒè¯æ‰¹æ¬¡ 9/50 | Loss: 0.045512
éªŒè¯æ‰¹æ¬¡ 12/50 | Loss: 0.085585
éªŒè¯æ‰¹æ¬¡ 15/50 | Loss: 0.186829
éªŒè¯æ‰¹æ¬¡ 18/50 | Loss: 0.048996
éªŒè¯æ‰¹æ¬¡ 21/50 | Loss: 0.397249
éªŒè¯æ‰¹æ¬¡ 24/50 | Loss: 0.031347
éªŒè¯æ‰¹æ¬¡ 27/50 | Loss: 0.046923
éªŒè¯æ‰¹æ¬¡ 30/50 | Loss: 0.081482
éªŒè¯æ‰¹æ¬¡ 33/50 | Loss: 0.068854
éªŒè¯æ‰¹æ¬¡ 36/50 | Loss: 0.082696
éªŒè¯æ‰¹æ¬¡ 39/50 | Loss: 0.047880
éªŒè¯æ‰¹æ¬¡ 42/50 | Loss: 0.197219
éªŒè¯æ‰¹æ¬¡ 45/50 | Loss: 0.173539
éªŒè¯æ‰¹æ¬¡ 48/50 | Loss: 0.154628
âœ… éªŒè¯å®Œæˆï¼Œå¹³å‡æŸå¤±: 0.114579

============================================================
ğŸ“Š Epoch 13/50 å®Œæˆ
   Train Loss: 0.138537
   Val Loss: 0.114579
   LR: 8.66e-06 | Time: 128.3s
============================================================
â³ æ—©åœè®¡æ•°: 10/10
ğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨ epoch 13 åœæ­¢è®­ç»ƒ
ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: training_results_cover_object_512/controlnet_cover_object_epoch_50.pth
ğŸ“ˆ Loss å›¾å·²ä¿å­˜: training_results_cover_object_512/training_val_loss_cover_object_512.png

ğŸ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: 0.109836
