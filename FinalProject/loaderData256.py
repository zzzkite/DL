#!/usr/bin/env python3
"""
PyTorchæ•°æ®åŠ è½½å™¨ - æ”¯æŒä»»åŠ¡ç‰¹å®šè®­ç»ƒ (256x256ç‰ˆæœ¬)
"""

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd
from pathlib import Path
import torchvision.transforms as transforms

class TaskSpecificDataset(Dataset):
    def __init__(self, metadata_file, task_name=None, transform=None):
        """
        ä»»åŠ¡ç‰¹å®šæ•°æ®é›†ç±» - å¯ç­›é€‰ç‰¹å®šä»»åŠ¡ (256x256ç‰ˆæœ¬)
        
        Args:
            metadata_file: å…ƒæ•°æ®CSVæ–‡ä»¶è·¯å¾„
            task_name: ä»»åŠ¡åç§° ('move_object', 'drop_object', 'cover_object')ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰ä»»åŠ¡
            transform: æ•°æ®å˜æ¢
        """
        self.metadata = pd.read_csv(metadata_file)
        
        # å¦‚æœæŒ‡å®šäº†ä»»åŠ¡åç§°ï¼Œç­›é€‰æ•°æ®
        if task_name and task_name != 'all':
            original_count = len(self.metadata)
            self.metadata = self.metadata[self.metadata['category'] == task_name]
            print(f"   ç­›é€‰ä»»åŠ¡ '{task_name}': {len(self.metadata)}/{original_count} ä¸ªæ ·æœ¬")
        
        self.transform = transform
        self.task_name = task_name
        
        # æ‰“å°æ•°æ®é›†ä¿¡æ¯
        task_display = task_name if task_name else 'æ‰€æœ‰ä»»åŠ¡'
        print(f"âœ… åŠ è½½æ•°æ®é›† ({task_display}): {len(self.metadata)} ä¸ªæ ·æœ¬")
        print(f"   å¸§è®¾ç½®: è¾“å…¥å‰20å¸§ â†’ é¢„æµ‹ç¬¬25å¸§ï¼ˆè·³è¿‡4å¸§ï¼‰")
        print(f"   åˆ†è¾¨ç‡: 256x256")
        
        # æ˜¾ç¤ºç±»åˆ«åˆ†å¸ƒ
        category_counts = self.metadata['category'].value_counts()
        for category, count in category_counts.items():
            print(f"   {category}: {count} ä¸ªæ ·æœ¬")
    
    def __len__(self):
        return len(self.metadata)
    
    def __getitem__(self, idx):
        sample = self.metadata.iloc[idx]
        
        try:
            # åŠ è½½è¾“å…¥å¸§ï¼ˆå‰20å¸§ï¼‰
            input_frames = np.load(sample['input_frames_path'])  # (20, 256, 256, 3)
            # åŠ è½½ç›®æ ‡å¸§ï¼ˆç¬¬25å¸§ï¼‰
            target_frame = np.load(sample['target_frame_path'])  # (256, 256, 3)
            
            # è½¬æ¢ä¸ºPyTorchå¼ é‡
            input_frames = torch.from_numpy(input_frames).float()
            target_frame = torch.from_numpy(target_frame).float()
            
            # è°ƒæ•´ç»´åº¦é¡ºåº: (T, H, W, C) -> (T, C, H, W)
            input_frames = input_frames.permute(0, 3, 1, 2)  # (20, 3, 256, 256)
            target_frame = target_frame.permute(2, 0, 1)     # (3, 256, 256)
            
            # å½’ä¸€åŒ–åˆ° [0, 1] (å¦‚æœæ•°æ®åœ¨0-255èŒƒå›´å†…)
            input_frames = input_frames / 255.0
            target_frame = target_frame / 255.0
            
            # åº”ç”¨æ•°æ®å˜æ¢ï¼ˆå¦‚æœæœ‰ï¼‰
            if self.transform:
                input_frames = self.transform(input_frames)
                target_frame = self.transform(target_frame)
            
            return {
                'input_frames': input_frames,  # (20, 3, 256, 256)
                'target_frame': target_frame,  # (3, 256, 256)
                'category': sample['category'],
                'video_id': sample['video_id'],
                'template': sample['template'],
                'label_text': sample['label']
            }
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ ·æœ¬å¤±è´¥ {sample['video_id']}: {e}")
            # è¿”å›ä¸€ä¸ªç©ºæ ·æœ¬è€Œä¸æ˜¯Noneï¼Œé¿å…DataLoaderå‡ºé”™
            return self._get_empty_sample()
    
    def _get_empty_sample(self):
        """è¿”å›ä¸€ä¸ªç©ºçš„æ ·æœ¬ï¼Œç”¨äºå¤„ç†åŠ è½½å¤±è´¥çš„æƒ…å†µ"""
        return {
            'input_frames': torch.zeros((20, 3, 256, 256)),
            'target_frame': torch.zeros((3, 256, 256)),
            'category': 'error',
            'video_id': 'error',
            'template': 'error',
            'label_text': 'error'
        }
    
    def get_category_indices(self, category):
        """è·å–ç‰¹å®šç±»åˆ«çš„æ‰€æœ‰ç´¢å¼•"""
        return self.metadata[self.metadata['category'] == category].index.tolist()
    
    def get_resolution_info(self):
        """è·å–æ•°æ®é›†åˆ†è¾¨ç‡ä¿¡æ¯"""
        if len(self.metadata) > 0:
            sample = self.metadata.iloc[0]
            try:
                input_frames = np.load(sample['input_frames_path'])
                return f"{input_frames.shape[2]}x{input_frames.shape[1]}"  # WxH
            except:
                return "Unknown"
        return "Unknown"

def create_task_specific_loaders(task_name='all', batch_size=8, data_path="processed_data_256", num_workers=4):
    """
    åˆ›å»ºä»»åŠ¡ç‰¹å®šçš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®åŠ è½½å™¨ (256x256ç‰ˆæœ¬)
    
    Args:
        task_name: ä»»åŠ¡åç§° ('move_object', 'drop_object', 'cover_object', 'all')
        batch_size: æ‰¹æ¬¡å¤§å° (256x256å¯ä»¥æ”¯æŒæ›´å¤§çš„æ‰¹æ¬¡)
        data_path: å¤„ç†æ•°æ®çš„è·¯å¾„
        num_workers: æ•°æ®åŠ è½½çš„è¿›ç¨‹æ•°
    """
    
    # æ•°æ®å˜æ¢ - å¯ä»¥æ·»åŠ é’ˆå¯¹256x256çš„æ•°æ®å¢å¼º
    transform = transforms.Compose([
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ•°æ®å¢å¼ºï¼Œå¦‚éšæœºè£å‰ªã€ç¿»è½¬ç­‰
        # transforms.RandomHorizontalFlip(p=0.5),
        # transforms.RandomCrop(256, padding=8),  # å¯¹äº256x256ï¼Œå¯ä»¥ä½¿ç”¨æ›´å¤§çš„padding
    ])
    
    # åˆ›å»ºä»»åŠ¡ç‰¹å®šæ•°æ®é›†
    train_dataset = TaskSpecificDataset(
        f"{data_path}/metadata/train_samples.csv", 
        task_name=task_name,
        transform=transform
    )
    val_dataset = TaskSpecificDataset(
        f"{data_path}/metadata/val_samples.csv",
        task_name=task_name
    )
    test_dataset = TaskSpecificDataset(
        f"{data_path}/metadata/test_samples.csv",
        task_name=task_name
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True  # ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=True
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=True
    )
    
    task_display = task_name if task_name != 'all' else 'æ‰€æœ‰ä»»åŠ¡'
    resolution = train_dataset.get_resolution_info()
    
    print(f"âœ… åˆ›å»ºä»»åŠ¡ '{task_display}' æ•°æ®åŠ è½½å™¨å®Œæˆ")
    print(f"   è®­ç»ƒé›†: {len(train_dataset)} ä¸ªæ ·æœ¬, {len(train_loader)} ä¸ªæ‰¹æ¬¡")
    print(f"   éªŒè¯é›†: {len(val_dataset)} ä¸ªæ ·æœ¬, {len(val_loader)} ä¸ªæ‰¹æ¬¡")
    print(f"   æµ‹è¯•é›†: {len(test_dataset)} ä¸ªæ ·æœ¬, {len(test_loader)} ä¸ªæ‰¹æ¬¡")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   åˆ†è¾¨ç‡: {resolution}")
    print(f"   è¾“å…¥å¸§å½¢çŠ¶: (20, 3, {resolution.split('x')[1]}, {resolution.split('x')[0]})")
    print(f"   ç›®æ ‡å¸§å½¢çŠ¶: (3, {resolution.split('x')[1]}, {resolution.split('x')[0]})")
    
    return train_loader, val_loader, test_loader

# ä¿ç•™åŸæ¥çš„å‡½æ•°ç”¨äºå…¼å®¹æ€§
def create_data_loaders(batch_size=8, data_path="processed_data_256", num_workers=4):
    """åˆ›å»ºæ‰€æœ‰ä»»åŠ¡æ··åˆçš„æ•°æ®åŠ è½½å™¨"""
    return create_task_specific_loaders('all', batch_size, data_path, num_workers)

def test_task_specific_loader():
    """æµ‹è¯•ä»»åŠ¡ç‰¹å®šæ•°æ®åŠ è½½å™¨"""
    print("æµ‹è¯•ä»»åŠ¡ç‰¹å®šæ•°æ®åŠ è½½å™¨ (256x256ç‰ˆæœ¬)...")
    
    tasks = ['move_object', 'drop_object', 'cover_object', 'all']
    
    for task in tasks:
        print(f"\n=== æµ‹è¯•ä»»åŠ¡: {task} ===")
        try:
            train_loader, val_loader, test_loader = create_task_specific_loaders(
                task_name=task, 
                batch_size=4  # æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡
            )
            
            # æµ‹è¯•ä¸€ä¸ªè®­ç»ƒæ‰¹æ¬¡
            for batch_idx, batch in enumerate(train_loader):
                if batch_idx >= 1:  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
                    break
                    
                print(f"æ‰¹æ¬¡ {batch_idx}:")
                print(f"  è¾“å…¥å¸§å½¢çŠ¶: {batch['input_frames'].shape}")
                print(f"  ç›®æ ‡å¸§å½¢çŠ¶: {batch['target_frame'].shape}")
                print(f"  ç±»åˆ«åˆ†å¸ƒ: {pd.Series(batch['category']).value_counts().to_dict()}")
                
                # æ£€æŸ¥æ•°æ®èŒƒå›´
                print(f"  è¾“å…¥å¸§èŒƒå›´: [{batch['input_frames'].min():.3f}, {batch['input_frames'].max():.3f}]")
                print(f"  ç›®æ ‡å¸§èŒƒå›´: [{batch['target_frame'].min():.3f}, {batch['target_frame'].max():.3f}]")
                
        except Exception as e:
            print(f"âŒ æµ‹è¯•ä»»åŠ¡ {task} å¤±è´¥: {e}")
    
    print("\nğŸ‰ ä»»åŠ¡ç‰¹å®šæ•°æ®åŠ è½½å™¨æµ‹è¯•é€šè¿‡!")

def estimate_memory_usage(batch_size=8):
    """ä¼°ç®—å†…å­˜ä½¿ç”¨æƒ…å†µ - 256x256ç‰ˆæœ¬"""
    print("\n=== å†…å­˜ä½¿ç”¨ä¼°ç®— (256x256) ===")
    
    # è¾“å…¥å¸§: (batch_size, 20, 3, 256, 256) - float32
    input_memory = batch_size * 20 * 3 * 256 * 256 * 4 / (1024**3)  # GB
    
    # ç›®æ ‡å¸§: (batch_size, 3, 256, 256) - float32  
    target_memory = batch_size * 3 * 256 * 256 * 4 / (1024**3)  # GB
    
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"è¾“å…¥å¸§å†…å­˜: {input_memory:.2f} GB")
    print(f"ç›®æ ‡å¸§å†…å­˜: {target_memory:.2f} GB")
    print(f"æ€»æ•°æ®å†…å­˜: {input_memory + target_memory:.2f} GB")
    print(f"å»ºè®®GPUå†…å­˜: > {(input_memory + target_memory) * 2:.2f} GB (åŒ…å«æ¨¡å‹å’Œæ¢¯åº¦)")
    
    # ä¸512x512ç‰ˆæœ¬å¯¹æ¯”
    print(f"\nğŸ’¡ å†…å­˜æ•ˆç‡å¯¹æ¯”:")
    print(f"  ç›¸æ¯”512x512ç‰ˆæœ¬ï¼Œå†…å­˜éœ€æ±‚é™ä½75%")
    print(f"  å¯æ”¯æŒæ›´å¤§çš„æ‰¹æ¬¡å¤§å° (2-4å€)")

if __name__ == "__main__":
    test_task_specific_loader()
    estimate_memory_usage(batch_size=8)