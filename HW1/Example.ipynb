{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This code baseline is inspired by and modified from [this great tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "This code can achieve an accuracy of approximately 86.50% on CIFAR-10. Please set up the environment and run your experiments starting from this baseline. You are expected to achieve an accuracy higher than this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import some necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as tv_datasets\n",
    "import torchvision.transforms as tv_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some experimental setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 128\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "print_every = 200\n",
    "\n",
    "optim_name = \"Adam\"\n",
    "optim_kwargs = dict(\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-6,\n",
    ")\n",
    "\n",
    "# preprocessing pipeline for input images\n",
    "transformation = dict()\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    transformation[data_type] = tv_transforms.Compose(([\n",
    "        tv_transforms.RandomRotation(degrees=15),\n",
    "        tv_transforms.RandomHorizontalFlip(),\n",
    "        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    ] if is_train else []) + \n",
    "    [\n",
    "        tv_transforms.ToTensor(),\n",
    "        tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [01:07<00:00, 2.52MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# prepare datasets\n",
    "dataset, loader = {}, {}\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    dataset[data_type] = tv_datasets.CIFAR10(\n",
    "        root=\"./data\", train=is_train, download=True, transform=transformation[data_type],\n",
    "    )\n",
    "    loader[data_type] = torch.utils.data.DataLoader(\n",
    "        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 7.28M\n"
     ]
    }
   ],
   "source": [
    "# our network architecture\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(128, 10),\n",
    ")\n",
    "\n",
    "# move to device\n",
    "net.to(device)\n",
    "\n",
    "# print the number of parameters\n",
    "print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch=  1, iter=  200] loss: 2.206\n",
      "[epoch=  1, iter=  400] loss: 1.977\n",
      "[epoch=  1, iter=  600] loss: 1.910\n",
      "[epoch=  2, iter=  200] loss: 1.705\n",
      "[epoch=  2, iter=  400] loss: 1.628\n",
      "[epoch=  2, iter=  600] loss: 1.537\n",
      "[epoch=  3, iter=  200] loss: 1.426\n",
      "[epoch=  3, iter=  400] loss: 1.395\n",
      "[epoch=  3, iter=  600] loss: 1.379\n",
      "[epoch=  4, iter=  200] loss: 1.277\n",
      "[epoch=  4, iter=  400] loss: 1.253\n",
      "[epoch=  4, iter=  600] loss: 1.228\n",
      "[epoch=  5, iter=  200] loss: 1.161\n",
      "[epoch=  5, iter=  400] loss: 1.144\n",
      "[epoch=  5, iter=  600] loss: 1.122\n",
      "[epoch=  6, iter=  200] loss: 1.079\n",
      "[epoch=  6, iter=  400] loss: 1.052\n",
      "[epoch=  6, iter=  600] loss: 1.027\n",
      "[epoch=  7, iter=  200] loss: 1.015\n",
      "[epoch=  7, iter=  400] loss: 1.000\n",
      "[epoch=  7, iter=  600] loss: 0.995\n",
      "[epoch=  8, iter=  200] loss: 0.954\n",
      "[epoch=  8, iter=  400] loss: 0.930\n",
      "[epoch=  8, iter=  600] loss: 0.932\n",
      "[epoch=  9, iter=  200] loss: 0.891\n",
      "[epoch=  9, iter=  400] loss: 0.883\n",
      "[epoch=  9, iter=  600] loss: 0.886\n",
      "[epoch= 10, iter=  200] loss: 0.855\n",
      "[epoch= 10, iter=  400] loss: 0.849\n",
      "[epoch= 10, iter=  600] loss: 0.828\n",
      "[epoch= 11, iter=  200] loss: 0.815\n",
      "[epoch= 11, iter=  400] loss: 0.809\n",
      "[epoch= 11, iter=  600] loss: 0.818\n",
      "[epoch= 12, iter=  200] loss: 0.765\n",
      "[epoch= 12, iter=  400] loss: 0.795\n",
      "[epoch= 12, iter=  600] loss: 0.778\n",
      "[epoch= 13, iter=  200] loss: 0.760\n",
      "[epoch= 13, iter=  400] loss: 0.765\n",
      "[epoch= 13, iter=  600] loss: 0.759\n",
      "[epoch= 14, iter=  200] loss: 0.723\n",
      "[epoch= 14, iter=  400] loss: 0.729\n",
      "[epoch= 14, iter=  600] loss: 0.729\n",
      "[epoch= 15, iter=  200] loss: 0.684\n",
      "[epoch= 15, iter=  400] loss: 0.688\n",
      "[epoch= 15, iter=  600] loss: 0.691\n",
      "[epoch= 16, iter=  200] loss: 0.668\n",
      "[epoch= 16, iter=  400] loss: 0.682\n",
      "[epoch= 16, iter=  600] loss: 0.659\n",
      "[epoch= 17, iter=  200] loss: 0.663\n",
      "[epoch= 17, iter=  400] loss: 0.641\n",
      "[epoch= 17, iter=  600] loss: 0.671\n",
      "[epoch= 18, iter=  200] loss: 0.634\n",
      "[epoch= 18, iter=  400] loss: 0.640\n",
      "[epoch= 18, iter=  600] loss: 0.640\n",
      "[epoch= 19, iter=  200] loss: 0.608\n",
      "[epoch= 19, iter=  400] loss: 0.618\n",
      "[epoch= 19, iter=  600] loss: 0.630\n",
      "[epoch= 20, iter=  200] loss: 0.596\n",
      "[epoch= 20, iter=  400] loss: 0.615\n",
      "[epoch= 20, iter=  600] loss: 0.608\n",
      "[epoch= 21, iter=  200] loss: 0.579\n",
      "[epoch= 21, iter=  400] loss: 0.587\n",
      "[epoch= 21, iter=  600] loss: 0.600\n",
      "[epoch= 22, iter=  200] loss: 0.565\n",
      "[epoch= 22, iter=  400] loss: 0.559\n",
      "[epoch= 22, iter=  600] loss: 0.569\n",
      "[epoch= 23, iter=  200] loss: 0.555\n",
      "[epoch= 23, iter=  400] loss: 0.554\n",
      "[epoch= 23, iter=  600] loss: 0.567\n",
      "[epoch= 24, iter=  200] loss: 0.560\n",
      "[epoch= 24, iter=  400] loss: 0.547\n",
      "[epoch= 24, iter=  600] loss: 0.554\n",
      "[epoch= 25, iter=  200] loss: 0.527\n",
      "[epoch= 25, iter=  400] loss: 0.521\n",
      "[epoch= 25, iter=  600] loss: 0.530\n",
      "[epoch= 26, iter=  200] loss: 0.502\n",
      "[epoch= 26, iter=  400] loss: 0.514\n",
      "[epoch= 26, iter=  600] loss: 0.505\n",
      "[epoch= 27, iter=  200] loss: 0.493\n",
      "[epoch= 27, iter=  400] loss: 0.522\n",
      "[epoch= 27, iter=  600] loss: 0.518\n",
      "[epoch= 28, iter=  200] loss: 0.504\n",
      "[epoch= 28, iter=  400] loss: 0.501\n",
      "[epoch= 28, iter=  600] loss: 0.509\n",
      "[epoch= 29, iter=  200] loss: 0.480\n",
      "[epoch= 29, iter=  400] loss: 0.495\n",
      "[epoch= 29, iter=  600] loss: 0.484\n",
      "[epoch= 30, iter=  200] loss: 0.472\n",
      "[epoch= 30, iter=  400] loss: 0.493\n",
      "[epoch= 30, iter=  600] loss: 0.486\n",
      "[epoch= 31, iter=  200] loss: 0.486\n",
      "[epoch= 31, iter=  400] loss: 0.472\n",
      "[epoch= 31, iter=  600] loss: 0.482\n",
      "[epoch= 32, iter=  200] loss: 0.460\n",
      "[epoch= 32, iter=  400] loss: 0.474\n",
      "[epoch= 32, iter=  600] loss: 0.467\n",
      "[epoch= 33, iter=  200] loss: 0.463\n",
      "[epoch= 33, iter=  400] loss: 0.463\n",
      "[epoch= 33, iter=  600] loss: 0.454\n",
      "[epoch= 34, iter=  200] loss: 0.441\n",
      "[epoch= 34, iter=  400] loss: 0.443\n",
      "[epoch= 34, iter=  600] loss: 0.457\n",
      "[epoch= 35, iter=  200] loss: 0.432\n",
      "[epoch= 35, iter=  400] loss: 0.446\n",
      "[epoch= 35, iter=  600] loss: 0.440\n",
      "[epoch= 36, iter=  200] loss: 0.436\n",
      "[epoch= 36, iter=  400] loss: 0.426\n",
      "[epoch= 36, iter=  600] loss: 0.461\n",
      "[epoch= 37, iter=  200] loss: 0.426\n",
      "[epoch= 37, iter=  400] loss: 0.437\n",
      "[epoch= 37, iter=  600] loss: 0.439\n",
      "[epoch= 38, iter=  200] loss: 0.413\n",
      "[epoch= 38, iter=  400] loss: 0.426\n",
      "[epoch= 38, iter=  600] loss: 0.436\n",
      "[epoch= 39, iter=  200] loss: 0.407\n",
      "[epoch= 39, iter=  400] loss: 0.407\n",
      "[epoch= 39, iter=  600] loss: 0.440\n",
      "[epoch= 40, iter=  200] loss: 0.394\n",
      "[epoch= 40, iter=  400] loss: 0.410\n",
      "[epoch= 40, iter=  600] loss: 0.399\n",
      "[epoch= 41, iter=  200] loss: 0.403\n",
      "[epoch= 41, iter=  400] loss: 0.397\n",
      "[epoch= 41, iter=  600] loss: 0.411\n",
      "[epoch= 42, iter=  200] loss: 0.381\n",
      "[epoch= 42, iter=  400] loss: 0.404\n",
      "[epoch= 42, iter=  600] loss: 0.394\n",
      "[epoch= 43, iter=  200] loss: 0.398\n",
      "[epoch= 43, iter=  400] loss: 0.387\n",
      "[epoch= 43, iter=  600] loss: 0.400\n",
      "[epoch= 44, iter=  200] loss: 0.378\n",
      "[epoch= 44, iter=  400] loss: 0.387\n",
      "[epoch= 44, iter=  600] loss: 0.381\n",
      "[epoch= 45, iter=  200] loss: 0.376\n",
      "[epoch= 45, iter=  400] loss: 0.374\n",
      "[epoch= 45, iter=  600] loss: 0.393\n",
      "[epoch= 46, iter=  200] loss: 0.372\n",
      "[epoch= 46, iter=  400] loss: 0.357\n",
      "[epoch= 46, iter=  600] loss: 0.388\n",
      "[epoch= 47, iter=  200] loss: 0.375\n",
      "[epoch= 47, iter=  400] loss: 0.381\n",
      "[epoch= 47, iter=  600] loss: 0.373\n",
      "[epoch= 48, iter=  200] loss: 0.374\n",
      "[epoch= 48, iter=  400] loss: 0.368\n",
      "[epoch= 48, iter=  600] loss: 0.364\n",
      "[epoch= 49, iter=  200] loss: 0.360\n",
      "[epoch= 49, iter=  400] loss: 0.367\n",
      "[epoch= 49, iter=  600] loss: 0.372\n",
      "[epoch= 50, iter=  200] loss: 0.355\n",
      "[epoch= 50, iter=  400] loss: 0.369\n",
      "[epoch= 50, iter=  600] loss: 0.356\n",
      "[epoch= 51, iter=  200] loss: 0.344\n",
      "[epoch= 51, iter=  400] loss: 0.358\n",
      "[epoch= 51, iter=  600] loss: 0.366\n",
      "[epoch= 52, iter=  200] loss: 0.341\n",
      "[epoch= 52, iter=  400] loss: 0.343\n",
      "[epoch= 52, iter=  600] loss: 0.363\n",
      "[epoch= 53, iter=  200] loss: 0.330\n",
      "[epoch= 53, iter=  400] loss: 0.347\n",
      "[epoch= 53, iter=  600] loss: 0.357\n",
      "[epoch= 54, iter=  200] loss: 0.349\n",
      "[epoch= 54, iter=  400] loss: 0.329\n",
      "[epoch= 54, iter=  600] loss: 0.346\n",
      "[epoch= 55, iter=  200] loss: 0.326\n",
      "[epoch= 55, iter=  400] loss: 0.335\n",
      "[epoch= 55, iter=  600] loss: 0.347\n",
      "[epoch= 56, iter=  200] loss: 0.329\n",
      "[epoch= 56, iter=  400] loss: 0.331\n",
      "[epoch= 56, iter=  600] loss: 0.327\n",
      "[epoch= 57, iter=  200] loss: 0.320\n",
      "[epoch= 57, iter=  400] loss: 0.343\n",
      "[epoch= 57, iter=  600] loss: 0.335\n",
      "[epoch= 58, iter=  200] loss: 0.317\n",
      "[epoch= 58, iter=  400] loss: 0.332\n",
      "[epoch= 58, iter=  600] loss: 0.336\n",
      "[epoch= 59, iter=  200] loss: 0.333\n",
      "[epoch= 59, iter=  400] loss: 0.330\n",
      "[epoch= 59, iter=  600] loss: 0.340\n",
      "[epoch= 60, iter=  200] loss: 0.327\n",
      "[epoch= 60, iter=  400] loss: 0.322\n",
      "[epoch= 60, iter=  600] loss: 0.321\n",
      "[epoch= 61, iter=  200] loss: 0.309\n",
      "[epoch= 61, iter=  400] loss: 0.311\n",
      "[epoch= 61, iter=  600] loss: 0.319\n",
      "[epoch= 62, iter=  200] loss: 0.310\n",
      "[epoch= 62, iter=  400] loss: 0.324\n",
      "[epoch= 62, iter=  600] loss: 0.314\n",
      "[epoch= 63, iter=  200] loss: 0.313\n",
      "[epoch= 63, iter=  400] loss: 0.309\n",
      "[epoch= 63, iter=  600] loss: 0.318\n",
      "[epoch= 64, iter=  200] loss: 0.312\n",
      "[epoch= 64, iter=  400] loss: 0.312\n",
      "[epoch= 64, iter=  600] loss: 0.320\n",
      "[epoch= 65, iter=  200] loss: 0.282\n",
      "[epoch= 65, iter=  400] loss: 0.301\n",
      "[epoch= 65, iter=  600] loss: 0.299\n",
      "[epoch= 66, iter=  200] loss: 0.313\n",
      "[epoch= 66, iter=  400] loss: 0.300\n",
      "[epoch= 66, iter=  600] loss: 0.305\n",
      "[epoch= 67, iter=  200] loss: 0.287\n",
      "[epoch= 67, iter=  400] loss: 0.299\n",
      "[epoch= 67, iter=  600] loss: 0.303\n",
      "[epoch= 68, iter=  200] loss: 0.293\n",
      "[epoch= 68, iter=  400] loss: 0.293\n",
      "[epoch= 68, iter=  600] loss: 0.306\n",
      "[epoch= 69, iter=  200] loss: 0.301\n",
      "[epoch= 69, iter=  400] loss: 0.298\n",
      "[epoch= 69, iter=  600] loss: 0.291\n",
      "[epoch= 70, iter=  200] loss: 0.307\n",
      "[epoch= 70, iter=  400] loss: 0.286\n",
      "[epoch= 70, iter=  600] loss: 0.294\n",
      "[epoch= 71, iter=  200] loss: 0.296\n",
      "[epoch= 71, iter=  400] loss: 0.278\n",
      "[epoch= 71, iter=  600] loss: 0.297\n",
      "[epoch= 72, iter=  200] loss: 0.296\n",
      "[epoch= 72, iter=  400] loss: 0.287\n",
      "[epoch= 72, iter=  600] loss: 0.287\n",
      "[epoch= 73, iter=  200] loss: 0.275\n",
      "[epoch= 73, iter=  400] loss: 0.280\n",
      "[epoch= 73, iter=  600] loss: 0.302\n",
      "[epoch= 74, iter=  200] loss: 0.270\n",
      "[epoch= 74, iter=  400] loss: 0.293\n",
      "[epoch= 74, iter=  600] loss: 0.295\n",
      "[epoch= 75, iter=  200] loss: 0.276\n",
      "[epoch= 75, iter=  400] loss: 0.269\n",
      "[epoch= 75, iter=  600] loss: 0.282\n",
      "[epoch= 76, iter=  200] loss: 0.268\n",
      "[epoch= 76, iter=  400] loss: 0.276\n",
      "[epoch= 76, iter=  600] loss: 0.296\n",
      "[epoch= 77, iter=  200] loss: 0.286\n",
      "[epoch= 77, iter=  400] loss: 0.279\n",
      "[epoch= 77, iter=  600] loss: 0.280\n",
      "[epoch= 78, iter=  200] loss: 0.282\n",
      "[epoch= 78, iter=  400] loss: 0.291\n",
      "[epoch= 78, iter=  600] loss: 0.274\n",
      "[epoch= 79, iter=  200] loss: 0.264\n",
      "[epoch= 79, iter=  400] loss: 0.275\n",
      "[epoch= 79, iter=  600] loss: 0.272\n",
      "[epoch= 80, iter=  200] loss: 0.270\n",
      "[epoch= 80, iter=  400] loss: 0.270\n",
      "[epoch= 80, iter=  600] loss: 0.286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m print_every \u001b[38;5;241m==\u001b[39m print_every \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[epoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, iter=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m5d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mprint_every\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# the network optimizer\n",
    "optimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# training loop\n",
    "net.train()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (img, target) in enumerate(loader[\"train\"]):\n",
    "        img, target = img.to(device), target.to(device)\n",
    "\n",
    "        pred = net(img)\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % print_every == print_every - 1:\n",
    "            print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for img, target in loader[\"test\"]:\n",
    "        img, target = img.to(device), target.to(device)\n",
    "        \n",
    "        # make prediction\n",
    "        pred = net(img)\n",
    "        \n",
    "        # accumulate\n",
    "        total += len(target)\n",
    "        correct += (torch.argmax(pred, dim=1) == target).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
