{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d7c184e",
   "metadata": {},
   "source": [
    "# Tiny-ImageNet 实验\n",
    "\n",
    "本 Notebook 将 CIFAR-10 的最优配置迁移到 Tiny-ImageNet (200类, 64x64)。\n",
    "\n",
    "## 数据集信息\n",
    "- **训练集**: 100,000 张图像 (每类 500 张)\n",
    "- **验证集**: 10,000 张图像 (每类 50 张)\n",
    "- **测试集**: 10,000 张图像 (无标签)\n",
    "- **图像尺寸**: 64x64x3\n",
    "- **类别数**: 200\n",
    "\n",
    "## 主要调整\n",
    "1. 输入尺寸从 32x32 调整为 64x64\n",
    "2. 输出类别从 10 调整为 200\n",
    "3. 网络更深/更宽以应对更复杂任务\n",
    "4. 数据增强参数针对性调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39427c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a45973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备配置\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e4068",
   "metadata": {},
   "source": [
    "## 下载与准备 Tiny-ImageNet 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny-ImageNet 数据集类\n",
    "class TinyImageNet(Dataset):\n",
    "    \"\"\"\n",
    "    Tiny-ImageNet 数据集加载器\n",
    "    数据集结构:\n",
    "    tiny-imagenet-200/\n",
    "        train/\n",
    "            n01443537/\n",
    "                images/\n",
    "                    n01443537_0.JPEG\n",
    "                    ...\n",
    "        val/\n",
    "            images/\n",
    "                val_0.JPEG\n",
    "                ...\n",
    "            val_annotations.txt\n",
    "    \"\"\"\n",
    "    def __init__(self, root, split='train', transform=None, download=False):\n",
    "        \"\"\"\n",
    "        root: 数据集根目录\n",
    "        split: 'train' 或 'val'\n",
    "        transform: 数据增强\n",
    "        download: 是否自动下载（手动下载更稳定）\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 如果需要下载\n",
    "        if download:\n",
    "            self._download()\n",
    "        \n",
    "        # 加载类别映射\n",
    "        self.class_to_idx = self._load_classes()\n",
    "        \n",
    "        # 加载图像路径和标签\n",
    "        self.samples = self._load_samples()\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} images for {split} split\")\n",
    "    \n",
    "    def _download(self):\n",
    "        \"\"\"下载数据集（若未下载）\"\"\"\n",
    "        import urllib.request\n",
    "        import zipfile\n",
    "        \n",
    "        url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "        zip_path = os.path.join(self.root, \"tiny-imagenet-200.zip\")\n",
    "        \n",
    "        if not os.path.exists(os.path.join(self.root, \"tiny-imagenet-200\")):\n",
    "            print(f\"Downloading Tiny-ImageNet from {url}...\")\n",
    "            os.makedirs(self.root, exist_ok=True)\n",
    "            urllib.request.urlretrieve(url, zip_path)\n",
    "            \n",
    "            print(\"Extracting...\")\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(self.root)\n",
    "            \n",
    "            os.remove(zip_path)\n",
    "            print(\"Download complete!\")\n",
    "    \n",
    "    def _load_classes(self):\n",
    "        \"\"\"加载类别到索引的映射\"\"\"\n",
    "        wnids_path = os.path.join(self.root, 'tiny-imagenet-200', 'wnids.txt')\n",
    "        with open(wnids_path, 'r') as f:\n",
    "            class_ids = [line.strip() for line in f]\n",
    "        return {class_id: idx for idx, class_id in enumerate(class_ids)}\n",
    "    \n",
    "    def _load_samples(self):\n",
    "        \"\"\"加载所有样本的路径和标签\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            # 训练集：每个类别一个文件夹\n",
    "            train_dir = os.path.join(self.root, 'tiny-imagenet-200', 'train')\n",
    "            for class_id in self.class_to_idx.keys():\n",
    "                class_dir = os.path.join(train_dir, class_id, 'images')\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith('.JPEG'):\n",
    "                        img_path = os.path.join(class_dir, img_name)\n",
    "                        samples.append((img_path, self.class_to_idx[class_id]))\n",
    "        \n",
    "        elif self.split == 'val':\n",
    "            # 验证集：图像在同一文件夹，标签在 txt 文件\n",
    "            val_dir = os.path.join(self.root, 'tiny-imagenet-200', 'val')\n",
    "            val_annotations = os.path.join(val_dir, 'val_annotations.txt')\n",
    "            \n",
    "            with open(val_annotations, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    img_name = parts[0]\n",
    "                    class_id = parts[1]\n",
    "                    img_path = os.path.join(val_dir, 'images', img_name)\n",
    "                    samples.append((img_path, self.class_to_idx[class_id]))\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7304d0",
   "metadata": {},
   "source": [
    "## 数据增强配置 (针对 64x64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutout 实现（与 CIFAR-10 相同）\n",
    "class Cutout:\n",
    "    def __init__(self, n_holes=1, length=16):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        h, w = img.size(1), img.size(2)\n",
    "        mask = torch.ones((h, w), dtype=torch.float32)\n",
    "\n",
    "        for _ in range(self.n_holes):\n",
    "            y = torch.randint(h, (1,)).item()\n",
    "            x = torch.randint(w, (1,)).item()\n",
    "            y1 = max(0, y - self.length // 2)\n",
    "            y2 = min(h, y + self.length // 2)\n",
    "            x1 = max(0, x - self.length // 2)\n",
    "            x2 = min(w, x + self.length // 2)\n",
    "            mask[y1:y2, x1:x2] = 0.\n",
    "\n",
    "        mask = mask.expand_as(img)\n",
    "        return img * mask\n",
    "\n",
    "\n",
    "# 数据增强流水线\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(64, padding=8),              # 更大的 padding 适应 64x64\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet 统计值\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33)),\n",
    "    Cutout(n_holes=1, length=20),  # 适当增大 cutout 尺寸\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "print(\"数据增强流水线已配置\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "data_root = './data'  # 数据集将下载/解压到此目录\n",
    "\n",
    "# 训练集\n",
    "train_dataset = TinyImageNet(\n",
    "    root=data_root,\n",
    "    split='train',\n",
    "    transform=transform_train,\n",
    "    download=True  # 首次运行设为 True 自动下载\n",
    ")\n",
    "\n",
    "# 验证集\n",
    "val_dataset = TinyImageNet(\n",
    "    root=data_root,\n",
    "    split='val',\n",
    "    transform=transform_val,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"训练集: {len(train_dataset)} 张图像\")\n",
    "print(f\"验证集: {len(val_dataset)} 张图像\")\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d123f3",
   "metadata": {},
   "source": [
    "## 网络架构（针对 Tiny-ImageNet 优化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec441112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复用 CIFAR-10 的模块\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"SE 注意力模块\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class SEResidualBlock(nn.Module):\n",
    "    \"\"\"残差块 + SE 注意力\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, reduction=16):\n",
    "        super(SEResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.se = SEBlock(out_channels, reduction)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TinyImageNetNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Tiny-ImageNet 网络（200 类，64x64 输入）\n",
    "    相比 CIFAR-10:\n",
    "    - 输入尺寸更大 (64x64 vs 32x32)\n",
    "    - 类别更多 (200 vs 10)\n",
    "    - 网络需要更深/更宽\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=200, use_se=True):\n",
    "        super(TinyImageNetNet, self).__init__()\n",
    "        \n",
    "        # 初始卷积\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 残差块组（更深的网络）\n",
    "        block_type = SEResidualBlock\n",
    "        self.layer1 = self._make_layer(block_type, 64, 128, num_blocks=3, stride=1)\n",
    "        self.layer2 = self._make_layer(block_type, 128, 256, num_blocks=4, stride=2)\n",
    "        self.layer3 = self._make_layer(block_type, 256, 512, num_blocks=6, stride=2)  # 更深\n",
    "        self.layer4 = self._make_layer(block_type, 512, 512, num_blocks=3, stride=2)  # 额外层\n",
    "        \n",
    "        # 分类头\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _make_layer(self, block_type, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block_type(in_channels, out_channels, stride))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block_type(out_channels, out_channels, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# 实例化模型\n",
    "model = TinyImageNetNet(num_classes=200, use_se=True).to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"模型参数量: {total_params / 1_000_000:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc4679",
   "metadata": {},
   "source": [
    "## 训练配置与辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Smoothing\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        n_classes = pred.size(-1)\n",
    "        log_preds = torch.nn.functional.log_softmax(pred, dim=-1)\n",
    "        loss = -log_preds.sum(dim=-1).mean() * self.epsilon / n_classes\n",
    "        nll = torch.nn.functional.nll_loss(log_preds, target, reduction='mean')\n",
    "        return (1 - self.epsilon) * nll + loss\n",
    "\n",
    "\n",
    "# MixUp\n",
    "def mixup_data(x, y, alpha=1.0, device='cuda'):\n",
    "    if alpha > 0:\n",
    "        lam = torch.distributions.Beta(alpha, alpha).sample().item()\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "# 学习率调度\n",
    "class WarmupCosineSchedule:\n",
    "    def __init__(self, optimizer, warmup_epochs, total_epochs, lr_min=1e-6):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.total_epochs = total_epochs\n",
    "        self.lr_min = lr_min\n",
    "        self.base_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    def step(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            lr = self.base_lr * (epoch + 1) / self.warmup_epochs\n",
    "        else:\n",
    "            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)\n",
    "            lr = self.lr_min + (self.base_lr - self.lr_min) * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return lr\n",
    "\n",
    "\n",
    "# 训练函数\n",
    "def train_epoch(model, loader, criterion, optimizer, device, use_mixup=False, mixup_alpha=0.0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for img, target in pbar:\n",
    "        img, target = img.to(device), target.to(device)\n",
    "        \n",
    "        if use_mixup and mixup_alpha > 0:\n",
    "            img, target_a, target_b, lam = mixup_data(img, target, mixup_alpha, device)\n",
    "            pred = model(img)\n",
    "            loss = mixup_criterion(criterion, pred, target_a, target_b, lam)\n",
    "        else:\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * img.size(0)\n",
    "        _, predicted = pred.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': running_loss / total, 'acc': 100. * correct / total})\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, target in tqdm(loader, desc='Evaluating'):\n",
    "            img, target = img.to(device), target.to(device)\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, target)\n",
    "            \n",
    "            running_loss += loss.item() * img.size(0)\n",
    "            _, predicted = pred.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "\n",
    "print(\"训练辅助函数已定义\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57cab4",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c31ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练配置\n",
    "config = {\n",
    "    'num_epochs': 150,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 5e-4,\n",
    "    'warmup_epochs': 5,\n",
    "    'label_smoothing': 0.1,\n",
    "    'mixup_alpha': 0.2,\n",
    "}\n",
    "\n",
    "# 优化器、损失、调度器\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy(epsilon=config['label_smoothing'])\n",
    "\n",
    "scheduler = WarmupCosineSchedule(\n",
    "    optimizer,\n",
    "    warmup_epochs=config['warmup_epochs'],\n",
    "    total_epochs=config['num_epochs']\n",
    ")\n",
    "\n",
    "# 训练历史\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"开始训练 Tiny-ImageNet\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config['num_epochs']):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{config['num_epochs']}]\")\n",
    "    \n",
    "    # 调整学习率\n",
    "    current_lr = scheduler.step(epoch)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # 训练\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device,\n",
    "        use_mixup=(config['mixup_alpha'] > 0),\n",
    "        mixup_alpha=config['mixup_alpha']\n",
    "    )\n",
    "    \n",
    "    # 验证\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # 记录\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), './best_model_tiny_imagenet.pth')\n",
    "        print(f\"✓ 新的最佳模型！验证准确率: {val_acc:.2f}%\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"LR: {current_lr:.6f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}% | \"\n",
    "          f\"Best: {best_acc:.2f}% @Epoch {best_epoch+1} | Time: {elapsed/60:.1f}min\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"训练完成！总用时: {total_time/3600:.2f} 小时\")\n",
    "print(f\"最佳验证准确率: {best_acc:.2f}% (Epoch {best_epoch+1})\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bacd7",
   "metadata": {},
   "source": [
    "## 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练曲线\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 损失\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Loss Curve - Tiny-ImageNet')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 准确率\n",
    "axes[0, 1].plot(history['train_acc'], label='Train Acc', linewidth=2)\n",
    "axes[0, 1].plot(history['val_acc'], label='Val Acc', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Accuracy Curve - Tiny-ImageNet')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].axhline(y=best_acc, color='r', linestyle='--', label=f'Best: {best_acc:.2f}%')\n",
    "\n",
    "# 学习率\n",
    "axes[1, 0].plot(history['lr'], linewidth=2, color='green')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate Schedule')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "# Train-Val Gap\n",
    "gap = np.array(history['train_acc']) - np.array(history['val_acc'])\n",
    "axes[1, 1].plot(gap, linewidth=2, color='orange')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy Gap (%)')\n",
    "axes[1, 1].set_title('Train-Val Accuracy Gap')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./tiny_imagenet_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"训练曲线已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f279d70",
   "metadata": {},
   "source": [
    "## 实验总结\n",
    "\n",
    "### Tiny-ImageNet 挑战\n",
    "1. **类别数增加**: 从 10 类增加到 200 类，分类难度大幅提升\n",
    "2. **图像分辨率**: 64x64 vs 32x32，需要更深的网络提取特征\n",
    "3. **数据规模**: 训练样本相对较少（每类 500 张），更容易过拟合\n",
    "\n",
    "### 针对性改进\n",
    "- **更深的网络**: 16 个残差块 vs CIFAR-10 的 7 个\n",
    "- **更强的数据增强**: 更大的 Cutout、更激进的 ColorJitter\n",
    "- **更长的训练**: 150 epochs vs 100-200 epochs\n",
    "- **相同的优化策略**: AdamW + Warmup + Cosine + Label Smoothing + MixUp\n",
    "\n",
    "### 预期性能\n",
    "- **Top-1 准确率**: 目标 >60% (Baseline ~55%)\n",
    "- **Top-5 准确率**: 目标 >82%\n",
    "\n",
    "### CIFAR-10 vs Tiny-ImageNet 对比\n",
    "\n",
    "| 指标 | CIFAR-10 | Tiny-ImageNet |\n",
    "|------|----------|---------------|\n",
    "| 图像尺寸 | 32x32 | 64x64 |\n",
    "| 类别数 | 10 | 200 |\n",
    "| 训练样本 | 50,000 | 100,000 |\n",
    "| 测试样本 | 10,000 | 10,000 |\n",
    "| 网络深度 | 7 层残差块 | 16 层残差块 |\n",
    "| 参数量 | ~3.8M | ~6.5M |\n",
    "| 预期准确率 | ~92% | ~62% |\n",
    "\n",
    "### 关键学习\n",
    "1. **迁移学习的重要性**: CIFAR-10 的最优配置可以迁移，但需要针对性调整\n",
    "2. **网络深度与任务复杂度**: 更复杂任务需要更深的网络\n",
    "3. **数据增强的关键作用**: 在样本相对较少时，数据增强尤为重要\n",
    "4. **过拟合风险**: Tiny-ImageNet 更容易过拟合，需要更强的正则化"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
