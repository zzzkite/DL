{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be940c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境与随机种子（确保可复现）\n",
    "import os, sys, random, time, platform, json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = int(os.environ.get(\"SEED\", 42))\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# cuDNN 可复现设置\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print({\n",
    "    \"python\": sys.version.split(\" \")[0],\n",
    "    \"platform\": platform.platform(),\n",
    "    \"pytorch\": torch.__version__,\n",
    "    \"cuda_available\": torch.cuda.is_available(),\n",
    "    \"cuda_version\": torch.version.cuda if torch.cuda.is_available() else None,\n",
    "    \"device\": str(device),\n",
    "})\n",
    "print(\"SEED=\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75e4a7",
   "metadata": {},
   "source": [
    "# 复现实验环境与运行说明\n",
    "\n",
    "本 Notebook 使用 PyTorch>=2 进行 tiny-imagenet 图像分类实验。为提高复现性，我们在最前面固定随机种子、打印环境信息，并给出关键开关说明：\n",
    "\n",
    "- 随机种子：seed 固定，cuDNN 设为 deterministic。\n",
    "- 设备选择：自动选择 CUDA/GPU 或 CPU。\n",
    "- 运行产物：所有模型、图像与 CSV 会保存到统一的 RESULTS_DIR 下。\n",
    "\n",
    "在训练前后，可参考末尾的“结果表格与总结”与“我学到了什么”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c184e",
   "metadata": {},
   "source": [
    "# Tiny-ImageNet 实验\n",
    "\n",
    "本 Notebook 将 CIFAR-10 的最优配置迁移到 Tiny-ImageNet (200类, 64x64)。\n",
    "\n",
    "## 数据集信息\n",
    "- **训练集**: 100,000 张图像 (每类 500 张)\n",
    "- **验证集**: 10,000 张图像 (每类 50 张)\n",
    "- **测试集**: 10,000 张图像 (无标签)\n",
    "- **图像尺寸**: 64x64x3\n",
    "- **类别数**: 200\n",
    "\n",
    "## 主要调整\n",
    "1. 输入尺寸从 32x32 调整为 64x64\n",
    "2. 输出类别从 10 调整为 200\n",
    "3. 网络更深/更宽以应对更复杂任务\n",
    "4. 数据增强参数针对性调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39427c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a45973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备配置\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果目录与路径常量（统一保存 Tiny-ImageNet 产物）\n",
    "import time, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "RUN_TAG = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "RESULTS_ROOT = \"./results\"\n",
    "RESULTS_DIR = os.path.join(RESULTS_ROOT, f\"tiny_imagenet_{RUN_TAG}\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")\n",
    "\n",
    "# 统一产物路径\n",
    "BEST_MODEL_PATH = os.path.join(RESULTS_DIR, \"best_model_tiny_imagenet.pth\")\n",
    "TRAIN_CURVES_PNG = os.path.join(RESULTS_DIR, \"tiny_imagenet_training_curves.png\")\n",
    "CM_PNG = os.path.join(RESULTS_DIR, \"tiny_imagenet_confusion_matrix.png\")\n",
    "ABLATION_CSV = os.path.join(RESULTS_DIR, \"tiny_imagenet_ablation_results.csv\")\n",
    "\n",
    "# 当前 Notebook 的绝对路径（用于归档）\n",
    "NOTEBOOK_ABS_PATH = \"/data/zhangzhikui/githubbase/DL/HW1/tiny_imagenet.ipynb\"\n",
    "NOTEBOOK_COPY_PATH = os.path.join(RESULTS_DIR, f\"tiny_imagenet_{RUN_TAG}.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e4068",
   "metadata": {},
   "source": [
    "## 下载与准备 Tiny-ImageNet 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny-ImageNet 数据集类\n",
    "class TinyImageNet(Dataset):\n",
    "    \"\"\"\n",
    "    Tiny-ImageNet 数据集加载器\n",
    "    数据集结构:\n",
    "    tiny-imagenet-200/\n",
    "        train/\n",
    "            n01443537/\n",
    "                images/\n",
    "                    n01443537_0.JPEG\n",
    "                    ...\n",
    "        val/\n",
    "            images/\n",
    "                val_0.JPEG\n",
    "                ...\n",
    "            val_annotations.txt\n",
    "    \"\"\"\n",
    "    def __init__(self, root, split='train', transform=None, download=False):\n",
    "        \"\"\"\n",
    "        root: 数据集根目录\n",
    "        split: 'train' 或 'val'\n",
    "        transform: 数据增强\n",
    "        download: 是否自动下载（手动下载更稳定）\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 如果需要下载\n",
    "        if download:\n",
    "            self._download()\n",
    "        \n",
    "        # 加载类别映射\n",
    "        self.class_to_idx = self._load_classes()\n",
    "        \n",
    "        # 加载图像路径和标签\n",
    "        self.samples = self._load_samples()\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} images for {split} split\")\n",
    "    \n",
    "    def _download(self):\n",
    "        \"\"\"下载数据集（若未下载）\"\"\"\n",
    "        import urllib.request\n",
    "        import zipfile\n",
    "        \n",
    "        url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "        zip_path = os.path.join(self.root, \"tiny-imagenet-200.zip\")\n",
    "        \n",
    "        if not os.path.exists(os.path.join(self.root, \"tiny-imagenet-200\")):\n",
    "            print(f\"Downloading Tiny-ImageNet from {url}...\")\n",
    "            os.makedirs(self.root, exist_ok=True)\n",
    "            urllib.request.urlretrieve(url, zip_path)\n",
    "            \n",
    "            print(\"Extracting...\")\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(self.root)\n",
    "            \n",
    "            os.remove(zip_path)\n",
    "            print(\"Download complete!\")\n",
    "    \n",
    "    def _load_classes(self):\n",
    "        \"\"\"加载类别到索引的映射\"\"\"\n",
    "        wnids_path = os.path.join(self.root, 'tiny-imagenet-200', 'wnids.txt')\n",
    "        with open(wnids_path, 'r') as f:\n",
    "            class_ids = [line.strip() for line in f]\n",
    "        return {class_id: idx for idx, class_id in enumerate(class_ids)}\n",
    "    \n",
    "    def _load_samples(self):\n",
    "        \"\"\"加载所有样本的路径和标签\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            # 训练集：每个类别一个文件夹\n",
    "            train_dir = os.path.join(self.root, 'tiny-imagenet-200', 'train')\n",
    "            for class_id in self.class_to_idx.keys():\n",
    "                class_dir = os.path.join(train_dir, class_id, 'images')\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith('.JPEG'):\n",
    "                        img_path = os.path.join(class_dir, img_name)\n",
    "                        samples.append((img_path, self.class_to_idx[class_id]))\n",
    "        \n",
    "        elif self.split == 'val':\n",
    "            # 验证集：图像在同一文件夹，标签在 txt 文件\n",
    "            val_dir = os.path.join(self.root, 'tiny-imagenet-200', 'val')\n",
    "            val_annotations = os.path.join(val_dir, 'val_annotations.txt')\n",
    "            \n",
    "            with open(val_annotations, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    img_name = parts[0]\n",
    "                    class_id = parts[1]\n",
    "                    img_path = os.path.join(val_dir, 'images', img_name)\n",
    "                    samples.append((img_path, self.class_to_idx[class_id]))\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7304d0",
   "metadata": {},
   "source": [
    "## 数据增强配置 (针对 64x64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutout 实现（与 CIFAR-10 相同）\n",
    "class Cutout:\n",
    "    def __init__(self, n_holes=1, length=16):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        h, w = img.size(1), img.size(2)\n",
    "        mask = torch.ones((h, w), dtype=torch.float32)\n",
    "\n",
    "        for _ in range(self.n_holes):\n",
    "            y = torch.randint(h, (1,)).item()\n",
    "            x = torch.randint(w, (1,)).item()\n",
    "            y1 = max(0, y - self.length // 2)\n",
    "            y2 = min(h, y + self.length // 2)\n",
    "            x1 = max(0, x - self.length // 2)\n",
    "            x2 = min(w, x + self.length // 2)\n",
    "            mask[y1:y2, x1:x2] = 0.\n",
    "\n",
    "        mask = mask.expand_as(img)\n",
    "        return img * mask\n",
    "\n",
    "\n",
    "# 数据增强流水线\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(64, padding=8),              # 更大的 padding 适应 64x64\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet 统计值\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33)),\n",
    "    Cutout(n_holes=1, length=20),  # 适当增大 cutout 尺寸\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "print(\"数据增强流水线已配置\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "data_root = './data'  # 数据集将下载/解压到此目录\n",
    "\n",
    "# 训练集\n",
    "train_dataset = TinyImageNet(\n",
    "    root=data_root,\n",
    "    split='train',\n",
    "    transform=transform_train,\n",
    "    download=True  # 首次运行设为 True 自动下载\n",
    ")\n",
    "\n",
    "# 验证集\n",
    "val_dataset = TinyImageNet(\n",
    "    root=data_root,\n",
    "    split='val',\n",
    "    transform=transform_val,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"训练集: {len(train_dataset)} 张图像\")\n",
    "print(f\"验证集: {len(val_dataset)} 张图像\")\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d123f3",
   "metadata": {},
   "source": [
    "## 网络架构（针对 Tiny-ImageNet 优化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec441112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复用 CIFAR-10 的模块\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"SE 注意力模块\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class SEResidualBlock(nn.Module):\n",
    "    \"\"\"残差块 + SE 注意力\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, reduction=16):\n",
    "        super(SEResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.se = SEBlock(out_channels, reduction)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TinyImageNetNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Tiny-ImageNet 网络（200 类，64x64 输入）\n",
    "    相比 CIFAR-10:\n",
    "    - 输入尺寸更大 (64x64 vs 32x32)\n",
    "    - 类别更多 (200 vs 10)\n",
    "    - 网络需要更深/更宽\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=200, use_se=True):\n",
    "        super(TinyImageNetNet, self).__init__()\n",
    "        \n",
    "        # 初始卷积\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 残差块组（更深的网络）\n",
    "        block_type = SEResidualBlock\n",
    "        self.layer1 = self._make_layer(block_type, 64, 128, num_blocks=3, stride=1)\n",
    "        self.layer2 = self._make_layer(block_type, 128, 256, num_blocks=4, stride=2)\n",
    "        self.layer3 = self._make_layer(block_type, 256, 512, num_blocks=6, stride=2)  # 更深\n",
    "        self.layer4 = self._make_layer(block_type, 512, 512, num_blocks=3, stride=2)  # 额外层\n",
    "        \n",
    "        # 分类头\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _make_layer(self, block_type, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block_type(in_channels, out_channels, stride))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block_type(out_channels, out_channels, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# 实例化模型\n",
    "model = TinyImageNetNet(num_classes=200, use_se=True).to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"模型参数量: {total_params / 1_000_000:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc4679",
   "metadata": {},
   "source": [
    "## 训练配置与辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Smoothing\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "    def forward(self, pred, target):\n",
    "        n_classes = pred.size(-1)\n",
    "        log_preds = torch.nn.functional.log_softmax(pred, dim=-1)\n",
    "        loss = -log_preds.sum(dim=-1).mean() * self.epsilon / n_classes\n",
    "        nll = torch.nn.functional.nll_loss(log_preds, target, reduction='mean')\n",
    "        return (1 - self.epsilon) * nll + loss\n",
    "\n",
    "# MixUp\n",
    "def mixup_data(x, y, alpha=1.0, device='cuda'):\n",
    "    if alpha > 0:\n",
    "        lam = torch.distributions.Beta(alpha, alpha).sample().item()\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# Warmup + Cosine\n",
    "class WarmupCosineSchedule:\n",
    "    def __init__(self, optimizer, warmup_epochs, total_epochs, lr_min=1e-6):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.total_epochs = total_epochs\n",
    "        self.lr_min = lr_min\n",
    "        self.base_lr = optimizer.param_groups[0]['lr']\n",
    "    def step(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            lr = self.base_lr * (epoch + 1) / self.warmup_epochs\n",
    "        else:\n",
    "            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)\n",
    "            lr = self.lr_min + (self.base_lr - self.lr_min) * 0.5 * (1 + torch.cos(torch.tensor(progress * 3.14159265)))\n",
    "            lr = float(lr)\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g['lr'] = lr\n",
    "        return lr\n",
    "\n",
    "# 训练/评估\n",
    "def train_epoch(model, loader, criterion, optimizer, device, use_mixup=False, mixup_alpha=0.0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    for img, target in loader:\n",
    "        img, target = img.to(device), target.to(device)\n",
    "        if use_mixup and mixup_alpha > 0:\n",
    "            img, target_a, target_b, lam = mixup_data(img, target, mixup_alpha, device)\n",
    "            pred = model(img)\n",
    "            loss = mixup_criterion(criterion, pred, target_a, target_b, lam)\n",
    "        else:\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * img.size(0)\n",
    "        _, predicted = pred.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    return running_loss/total, 100.*correct/total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for img, target in loader:\n",
    "            img, target = img.to(device), target.to(device)\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, target)\n",
    "            running_loss += loss.item() * img.size(0)\n",
    "            _, predicted = pred.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    return running_loss/total, 100.*correct/total\n",
    "\n",
    "# 训练配置\n",
    "config = {\n",
    "    'num_epochs': 150,\n",
    "    'batch_size': 128,\n",
    "    'num_workers': 4,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 5e-4,\n",
    "    'warmup_epochs': 5,\n",
    "    'label_smoothing': 0.1,\n",
    "    'mixup_alpha': 0.2,\n",
    "}\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy(epsilon=config['label_smoothing'])\n",
    "\n",
    "scheduler = WarmupCosineSchedule(\n",
    "    optimizer,\n",
    "    warmup_epochs=config['warmup_epochs'],\n",
    "    total_epochs=config['num_epochs']\n",
    ")\n",
    "\n",
    "# 训练历史\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"开始训练 Tiny-ImageNet\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config['num_epochs']):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{config['num_epochs']}]\")\n",
    "    \n",
    "    # 调整学习率\n",
    "    current_lr = scheduler.step(epoch)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # 训练\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device,\n",
    "        use_mixup=(config['mixup_alpha'] > 0),\n",
    "        mixup_alpha=config['mixup_alpha']\n",
    "    )\n",
    "    \n",
    "    # 验证\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # 记录\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f\"✓ 新的最佳模型！验证准确率: {val_acc:.2f}% -> 已保存到 {BEST_MODEL_PATH}\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"LR: {current_lr:.6f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}% | \"\n",
    "          f\"Best: {best_acc:.2f}% @Epoch {best_epoch+1} | Time: {elapsed/60:.1f}min\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"训练完成！总用时: {total_time/3600:.2f} 小时\")\n",
    "print(f\"最佳验证准确率: {best_acc:.2f}% (Epoch {best_epoch+1})\")\n",
    "print(f\"最佳模型已保存到: {BEST_MODEL_PATH}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57cab4",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c31ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练配置\n",
    "config = {\n",
    "    'num_epochs': 150,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 5e-4,\n",
    "    'warmup_epochs': 5,\n",
    "    'label_smoothing': 0.1,\n",
    "    'mixup_alpha': 0.2,\n",
    "}\n",
    "\n",
    "# 优化器、损失、调度器\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy(epsilon=config['label_smoothing'])\n",
    "\n",
    "scheduler = WarmupCosineSchedule(\n",
    "    optimizer,\n",
    "    warmup_epochs=config['warmup_epochs'],\n",
    "    total_epochs=config['num_epochs']\n",
    ")\n",
    "\n",
    "# 训练历史\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"开始训练 Tiny-ImageNet\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config['num_epochs']):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{config['num_epochs']}]\")\n",
    "    \n",
    "    # 调整学习率\n",
    "    current_lr = scheduler.step(epoch)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # 训练\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device,\n",
    "        use_mixup=(config['mixup_alpha'] > 0),\n",
    "        mixup_alpha=config['mixup_alpha']\n",
    "    )\n",
    "    \n",
    "    # 验证\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # 记录\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f\"✓ 新的最佳模型！验证准确率: {val_acc:.2f}% -> 已保存到 {BEST_MODEL_PATH}\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"LR: {current_lr:.6f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}% | \"\n",
    "          f\"Best: {best_acc:.2f}% @Epoch {best_epoch+1} | Time: {elapsed/60:.1f}min\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"训练完成！总用时: {total_time/3600:.2f} 小时\")\n",
    "print(f\"最佳验证准确率: {best_acc:.2f}% (Epoch {best_epoch+1})\")\n",
    "print(f\"最佳模型已保存到: {BEST_MODEL_PATH}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bacd7",
   "metadata": {},
   "source": [
    "## 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练曲线\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 损失\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Loss Curve - Tiny-ImageNet')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 准确率\n",
    "axes[0, 1].plot(history['train_acc'], label='Train Acc', linewidth=2)\n",
    "axes[0, 1].plot(history['val_acc'], label='Val Acc', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Accuracy Curve - Tiny-ImageNet')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].axhline(y=best_acc, color='r', linestyle='--', label=f'Best: {best_acc:.2f}%')\n",
    "\n",
    "# 学习率\n",
    "axes[1, 0].plot(history['lr'], linewidth=2, color='green')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate Schedule')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "# Train-Val Gap\n",
    "gap = np.array(history['train_acc']) - np.array(history['val_acc'])\n",
    "axes[1, 1].plot(gap, linewidth=2, color='orange')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy Gap (%)')\n",
    "axes[1, 1].set_title('Train-Val Accuracy Gap')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TRAIN_CURVES_PNG, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"训练曲线已保存到 {TRAIN_CURVES_PNG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77f4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证集混淆矩阵与分类报告（可选，200 类图较大）\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "if os.path.isfile(BEST_MODEL_PATH):\n",
    "    # 重新加载最佳模型\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for img, target in val_loader:\n",
    "            img = img.to(device)\n",
    "            pred = model(img)\n",
    "            _, predicted = pred.max(1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.numpy())\n",
    "\n",
    "    # 类别名（wnid 顺序）\n",
    "    idx_to_class = {idx: wnid for wnid, idx in val_dataset.class_to_idx.items()}\n",
    "    classes = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "\n",
    "    # 混淆矩阵\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    sns.heatmap(cm, cmap='Blues', xticklabels=False, yticklabels=False)\n",
    "    plt.title('Confusion Matrix - Tiny-ImageNet (Val, Best Model)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CM_PNG, dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"混淆矩阵已保存到 {CM_PNG}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"分类报告 (部分展示)\")\n",
    "    print(\"=\"*80)\n",
    "    # 只打印前 20 个类别的报告，避免输出过长\n",
    "    subset = list(range(min(20, len(classes))))\n",
    "    print(classification_report(all_labels, all_preds, labels=subset, target_names=[classes[i] for i in subset], digits=4))\n",
    "else:\n",
    "    print(f\"未找到最佳模型 {BEST_MODEL_PATH}，跳过混淆矩阵。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f279d70",
   "metadata": {},
   "source": [
    "## 实验总结\n",
    "\n",
    "### Tiny-ImageNet 挑战\n",
    "1. 类别数增加：200 类，分类难度更高\n",
    "2. 分辨率更大：64x64，需要更深的特征提取网络\n",
    "3. 数据规模与过拟合：单类样本数较少，需更强正则化\n",
    "\n",
    "### 针对性改进\n",
    "- 更深网络结构（多残差块）+ SE 注意力\n",
    "- 更强数据增强（ColorJitter、RandomErasing、Cutout、MixUp）\n",
    "- 优化策略：AdamW + Warmup + Cosine + Label Smoothing\n",
    "\n",
    "> 本次所有训练产物集中保存于 `RESULTS_DIR`：\n",
    "> - 最优模型: `BEST_MODEL_PATH`\n",
    "> - 训练曲线: `TRAIN_CURVES_PNG`\n",
    "> - 混淆矩阵: `CM_PNG`\n",
    "> - 消融结果: `ABLATION_CSV`\n",
    "> - Notebook 归档: `NOTEBOOK_COPY_PATH`\n",
    "\n",
    "### 预期性能（运行后以实测为准）\n",
    "- Val Top-1: 目标 >60%\n",
    "- Val Top-5: 目标 >82%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9477d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归档 Notebook 到结果目录（全部完成后运行）\n",
    "try:\n",
    "    shutil.copy2(NOTEBOOK_ABS_PATH, NOTEBOOK_COPY_PATH)\n",
    "    print(f\"Notebook archived to: {NOTEBOOK_COPY_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to copy notebook: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 消融实验（可先用少量 epoch 冒烟，再增大）\n",
    "import pandas as pd\n",
    "\n",
    "ablation_epochs = 5  # 正式实验可改为 30/50\n",
    "\n",
    "# 构建可切换的增强\n",
    "def build_transforms_tiny(advanced: bool):\n",
    "    if advanced:\n",
    "        return transform_train, transform_val\n",
    "    # 简化版增强\n",
    "    simple_train = transforms.Compose([\n",
    "        transforms.RandomCrop(64, padding=8),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    ])\n",
    "    return simple_train, transform_val\n",
    "\n",
    "# 可配置模型（调整深度/宽度/是否SE）\n",
    "class TinyVariant(nn.Module):\n",
    "    def __init__(self, num_classes=200, use_se=True, deeper=True, wider=True):\n",
    "        super().__init__()\n",
    "        width = 64*(2 if wider else 1)\n",
    "        block = SEResidualBlock if use_se else SEResidualBlock  # 这里仍用同一实现，仅切换 se=True/False 可扩展\n",
    "        self.conv1 = nn.Conv2d(3, width, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 深度配置\n",
    "        cfg = (3,4,6,3) if deeper else (2,2,3,2)\n",
    "        c1, c2, c3, c4 = width, width*2, width*4, width*4\n",
    "        self.layer1 = self._make_layer(block, c1, c2, num_blocks=cfg[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, c2, c3, num_blocks=cfg[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, c3, c3, num_blocks=cfg[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, c3, c4, num_blocks=cfg[3], stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(c4, num_classes)\n",
    "        self._init()\n",
    "    def _make_layer(self, block, in_c, out_c, num_blocks, stride):\n",
    "        layers = [block(in_c, out_c, stride)]\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(out_c, out_c, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "    def _init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x); x = self.bn1(x); x = self.relu(x)\n",
    "        x = self.layer1(x); x = self.layer2(x); x = self.layer3(x); x = self.layer4(x)\n",
    "        x = self.avg_pool(x); x = torch.flatten(x, 1); x = self.dropout(x); x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def run_experiment_tiny(name: str, *,\n",
    "                        use_se: bool,\n",
    "                        deeper: bool,\n",
    "                        wider: bool,\n",
    "                        advanced_aug: bool,\n",
    "                        use_adamw: bool,\n",
    "                        use_warmup_cosine: bool,\n",
    "                        label_smoothing: float,\n",
    "                        mixup_alpha: float,\n",
    "                        epochs: int = ablation_epochs):\n",
    "    # 数据\n",
    "    tr_tf, va_tf = build_transforms_tiny(advanced_aug)\n",
    "    ds_tr = TinyImageNet(root='./data', split='train', transform=tr_tf, download=False)\n",
    "    ds_va = TinyImageNet(root='./data', split='val', transform=va_tf, download=False)\n",
    "    ld_tr = DataLoader(ds_tr, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    ld_va = DataLoader(ds_va, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # 模型\n",
    "    m = TinyVariant(num_classes=200, use_se=use_se, deeper=deeper, wider=wider).to(device)\n",
    "\n",
    "    # 优化器/损失\n",
    "    opt = optim.AdamW(m.parameters(), lr=1e-3, weight_decay=5e-4) if use_adamw else optim.Adam(m.parameters(), lr=3e-4, weight_decay=1e-6)\n",
    "    cri = LabelSmoothingCrossEntropy(epsilon=label_smoothing) if label_smoothing>0 else nn.CrossEntropyLoss()\n",
    "    sch = WarmupCosineSchedule(opt, warmup_epochs=5, total_epochs=epochs) if use_warmup_cosine else None\n",
    "\n",
    "    best = 0.0\n",
    "    for ep in range(epochs):\n",
    "        if sch is not None:\n",
    "            _ = sch.step(ep)\n",
    "        train_epoch(m, ld_tr, cri, opt, device, use_mixup=(mixup_alpha>0), mixup_alpha=mixup_alpha)\n",
    "        _, acc = evaluate(m, ld_va, cri, device)\n",
    "        best = max(best, acc)\n",
    "    return best\n",
    "\n",
    "# 设计 ≥5 因素\n",
    "experiments = [\n",
    "    (\"baseline\",            dict(use_se=False, deeper=False, wider=False, advanced_aug=False, use_adamw=False, use_warmup_cosine=False, label_smoothing=0.0, mixup_alpha=0.0)),\n",
    "    (\"+deeper\",             dict(use_se=False, deeper=True,  wider=False, advanced_aug=False, use_adamw=False, use_warmup_cosine=False, label_smoothing=0.0, mixup_alpha=0.0)),\n",
    "    (\"+wider\",              dict(use_se=False, deeper=True,  wider=True,  advanced_aug=False, use_adamw=False, use_warmup_cosine=False, label_smoothing=0.0, mixup_alpha=0.0)),\n",
    "    (\"+advanced_aug\",       dict(use_se=False, deeper=True,  wider=True,  advanced_aug=True,  use_adamw=False, use_warmup_cosine=False, label_smoothing=0.0, mixup_alpha=0.0)),\n",
    "    (\"+SE\",                 dict(use_se=True,  deeper=True,  wider=True,  advanced_aug=True,  use_adamw=False, use_warmup_cosine=False, label_smoothing=0.0, mixup_alpha=0.0)),\n",
    "    (\"+AdamW+Cosine+Warmup\",dict(use_se=True,  deeper=True,  wider=True,  advanced_aug=True,  use_adamw=True,  use_warmup_cosine=True,  label_smoothing=0.0, mixup_alpha=0.0)),\n",
    "    (\"+LabelSmoothing\",     dict(use_se=True,  deeper=True,  wider=True,  advanced_aug=True,  use_adamw=True,  use_warmup_cosine=True,  label_smoothing=0.1, mixup_alpha=0.0)),\n",
    "    (\"+MixUp\",              dict(use_se=True,  deeper=True,  wider=True,  advanced_aug=True,  use_adamw=True,  use_warmup_cosine=True,  label_smoothing=0.1, mixup_alpha=0.2)),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for name, cfg in experiments:\n",
    "    print(f\"Running: {name} (epochs={ablation_epochs})\")\n",
    "    acc = run_experiment_tiny(name, **cfg, epochs=ablation_epochs)\n",
    "    rows.append({\"name\": name, **cfg, \"best_val_acc\": acc})\n",
    "\n",
    "ablation_df = pd.DataFrame(rows)\n",
    "print(\"\\nAblation Results:\")\n",
    "print(ablation_df)\n",
    "\n",
    "ablation_df.to_csv(ABLATION_CSV, index=False)\n",
    "print(f\"消融结果已保存到 {ABLATION_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90180200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果表格（从消融 CSV 汇总）\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "if 'ABLATION_CSV' in globals() and os.path.isfile(ABLATION_CSV):\n",
    "    ablation_df = pd.read_csv(ABLATION_CSV)\n",
    "    # 自适应列名：best_val_acc 或 best_test_acc\n",
    "    score_col = 'best_val_acc' if 'best_val_acc' in ablation_df.columns else ('best_test_acc' if 'best_test_acc' in ablation_df.columns else None)\n",
    "    if score_col is not None:\n",
    "        ablation_sorted = ablation_df.sort_values(score_col, ascending=False).reset_index(drop=True)\n",
    "        display(ablation_sorted)\n",
    "        # 也导出一份 Markdown 表格\n",
    "        md_table = ablation_sorted.to_markdown(index=False)\n",
    "        summary_md = os.path.join(RESULTS_DIR, 'ablation_summary.md') if 'RESULTS_DIR' in globals() else 'ablation_summary.md'\n",
    "        with open(summary_md, 'w', encoding='utf-8') as f:\n",
    "            f.write(md_table)\n",
    "        print(f\"消融表格已导出到: {summary_md}\")\n",
    "    else:\n",
    "        print(\"未找到 best_val_acc/best_test_acc 列，无法排序展示。原始表：\")\n",
    "        display(ablation_df)\n",
    "else:\n",
    "    print(\"未找到 ABLATION_CSV，跳过结果表格展示。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行元数据保存（便于报告与复现）\n",
    "meta = {}\n",
    "meta[\"run_time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "meta[\"seed\"] = SEED if 'SEED' in globals() else None\n",
    "meta[\"device\"] = str(device) if 'device' in globals() else None\n",
    "meta[\"best_acc\"] = float(best_acc) if 'best_acc' in globals() else None\n",
    "meta[\"best_epoch\"] = int(best_epoch) if 'best_epoch' in globals() else None\n",
    "meta[\"artifacts\"] = {\n",
    "    \"results_dir\": RESULTS_DIR if 'RESULTS_DIR' in globals() else None,\n",
    "    \"best_model_path\": BEST_MODEL_PATH if 'BEST_MODEL_PATH' in globals() else None,\n",
    "    \"train_curves_png\": TRAIN_CURVES_PNG if 'TRAIN_CURVES_PNG' in globals() else None,\n",
    "    \"confusion_matrix_png\": CM_PNG if 'CM_PNG' in globals() else None,\n",
    "    \"ablation_csv\": ABLATION_CSV if 'ABLATION_CSV' in globals() else None,\n",
    "}\n",
    "\n",
    "meta_path = os.path.join(RESULTS_DIR, 'run_metadata.json') if 'RESULTS_DIR' in globals() else 'run_metadata.json'\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "print(f\"运行元数据已保存到: {meta_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d670fe",
   "metadata": {},
   "source": [
    "# 我学到了什么（反思）\n",
    "\n",
    "在本次 tiny-imagenet 任务中，我逐步从简单网络出发，逐一引入残差结构、SE 注意力、更强的数据增强（含 MixUp/RandomErasing）、优化器切换到 AdamW、学习率计划 Warmup+Cosine、以及更深/更宽的变体。实验显示：\n",
    "\n",
    "- 在相同 epoch 下，Warmup+Cosine 的收敛更平滑，最优验证精度较固定步长更稳定；\n",
    "- Label Smoothing 对泛化有帮助，尤其在类别较多（200 类）时；\n",
    "- SE 注意力在更深网络中收益更明显；\n",
    "- 过强的数据增强在 epoch 数较小时可能抑制训练，需要与训练轮数协同调整；\n",
    "- 更深/更宽不是单调收益，需结合正则与学习率策略；\n",
    "\n",
    "更多细节见上面的消融结果表与曲线图。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
