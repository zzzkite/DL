{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be940c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': '3.10.19', 'platform': 'Windows-10-10.0.22621-SP0', 'pytorch': '2.5.1+cu121', 'cuda_available': True, 'cuda_version': '12.1', 'device': 'cuda'}\n",
      "SEED= 42\n"
     ]
    }
   ],
   "source": [
    "# 环境与随机种子（确保可复现）\n",
    "import os, sys, random, time, platform, json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = int(os.environ.get(\"SEED\", 42))\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# cuDNN 可复现设置\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print({\n",
    "    \"python\": sys.version.split(\" \")[0],\n",
    "    \"platform\": platform.platform(),\n",
    "    \"pytorch\": torch.__version__,\n",
    "    \"cuda_available\": torch.cuda.is_available(),\n",
    "    \"cuda_version\": torch.version.cuda if torch.cuda.is_available() else None,\n",
    "    \"device\": str(device),\n",
    "})\n",
    "print(\"SEED=\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75e4a7",
   "metadata": {},
   "source": [
    "# 复现实验环境与运行说明\n",
    "\n",
    "本 Notebook 使用 PyTorch>=2 进行 tiny-imagenet 图像分类实验。为提高复现性，我们在最前面固定随机种子、打印环境信息，并给出关键开关说明：\n",
    "\n",
    "- 随机种子：seed 固定，cuDNN 设为 deterministic。\n",
    "- 设备选择：自动选择 CUDA/GPU 或 CPU。\n",
    "- 运行产物：所有模型、图像与 CSV 会保存到统一的 RESULTS_DIR 下。\n",
    "\n",
    "在训练前后，可参考末尾的“结果表格与总结”与“我学到了什么”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c184e",
   "metadata": {},
   "source": [
    "# Tiny-ImageNet 实验\n",
    "\n",
    "> **整体流程概览**\n",
    "\n",
    "> 1. **Stage 1 – Ablation**：从最基础的 Tiny-ImageNet CNN 起步，逐一启用改进因素（残差、SE、深度/宽度提升、数据增强、优化策略），验证增益并记录结果。\n",
    "\n",
    "> 2. **Stage 2 – Main Training**：将 Stage 1 中表现更佳的因素组合，使用 150 epoch 全流程训练并导出最佳模型。\n",
    "\n",
    "> 3. **Stage 3 – Analysis**：对比基线与最终性能，分析各改进贡献，生成图表与结论。\n",
    "\n",
    "> 所有实验均以固定 seed、统一结果目录与 CSV/PNG/Notebook 归档，便于复现实验并撰写 PDF 报告。\n",
    "\n",
    "> 数据集沿用官方 train/val 划分。\n",
    "\n",
    "> 训练过程和结果分析部分提供 TODO 注释提示可在报告中展开的重点。\n",
    "\n",
    "> 结果一旦确认，可转化为报告中的表格与段落。\n",
    "\n",
    "> **提醒**：请确保在 GPU 环境下运行，以便在可接受的时间内完成所有训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39427c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79a45973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "GPU name: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# 设备配置\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c02128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: ./results\\tiny_imagenet_20251027_014437\n"
     ]
    }
   ],
   "source": [
    "# 结果目录与路径常量（统一保存 Tiny-ImageNet 产物）\n",
    "import time, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "RUN_TAG = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "RESULTS_ROOT = \"./results\"\n",
    "RESULTS_DIR = os.path.join(RESULTS_ROOT, f\"tiny_imagenet_{RUN_TAG}\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")\n",
    "\n",
    "# 统一产物路径\n",
    "BEST_MODEL_PATH = os.path.join(RESULTS_DIR, \"best_model_tiny_imagenet.pth\")\n",
    "TRAIN_CURVES_PNG = os.path.join(RESULTS_DIR, \"tiny_imagenet_training_curves.png\")\n",
    "CM_PNG = os.path.join(RESULTS_DIR, \"tiny_imagenet_confusion_matrix.png\")\n",
    "ABLATION_CSV = os.path.join(RESULTS_DIR, \"tiny_imagenet_ablation_results.csv\")\n",
    "\n",
    "# 当前 Notebook 的绝对路径（用于归档）\n",
    "NOTEBOOK_ABS_PATH = \"/data/zhangzhikui/githubbase/DL/HW1/tiny_imagenet.ipynb\"\n",
    "NOTEBOOK_COPY_PATH = os.path.join(RESULTS_DIR, f\"tiny_imagenet_{RUN_TAG}.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e4068",
   "metadata": {},
   "source": [
    "## 下载与准备 Tiny-ImageNet 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6405c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny-ImageNet 数据集类\n",
    "class TinyImageNet(Dataset):\n",
    "    \"\"\"\n",
    "    Tiny-ImageNet 数据集加载器\n",
    "    数据集结构:\n",
    "    tiny-imagenet-200/\n",
    "        train/\n",
    "            n01443537/\n",
    "                images/\n",
    "                    n01443537_0.JPEG\n",
    "                    ...\n",
    "        val/\n",
    "            images/\n",
    "                val_0.JPEG\n",
    "                ...\n",
    "            val_annotations.txt\n",
    "    \"\"\"\n",
    "    def __init__(self, root, split='train', transform=None, download=False):\n",
    "        \"\"\"\n",
    "        root: 数据集根目录\n",
    "        split: 'train' 或 'val'\n",
    "        transform: 数据增强\n",
    "        download: 是否自动下载（手动下载更稳定）\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 如果需要下载\n",
    "        if download:\n",
    "            self._download()\n",
    "        \n",
    "        # 加载类别映射\n",
    "        self.class_to_idx = self._load_classes()\n",
    "        \n",
    "        # 加载图像路径和标签\n",
    "        self.samples = self._load_samples()\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} images for {split} split\")\n",
    "    \n",
    "    def _download(self):\n",
    "        \"\"\"下载数据集（若未下载）\"\"\"\n",
    "        import urllib.request\n",
    "        import zipfile\n",
    "        \n",
    "        url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "        zip_path = os.path.join(self.root, \"tiny-imagenet-200.zip\")\n",
    "        \n",
    "        if not os.path.exists(os.path.join(self.root, \"tiny-imagenet-200\")):\n",
    "            print(f\"Downloading Tiny-ImageNet from {url}...\")\n",
    "            os.makedirs(self.root, exist_ok=True)\n",
    "            urllib.request.urlretrieve(url, zip_path)\n",
    "            \n",
    "            print(\"Extracting...\")\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(self.root)\n",
    "            \n",
    "            os.remove(zip_path)\n",
    "            print(\"Download complete!\")\n",
    "    \n",
    "    def _load_classes(self):\n",
    "        \"\"\"加载类别到索引的映射\"\"\"\n",
    "        wnids_path = os.path.join(self.root, 'tiny-imagenet-200', 'wnids.txt')\n",
    "        with open(wnids_path, 'r') as f:\n",
    "            class_ids = [line.strip() for line in f]\n",
    "        return {class_id: idx for idx, class_id in enumerate(class_ids)}\n",
    "    \n",
    "    def _load_samples(self):\n",
    "        \"\"\"加载所有样本的路径和标签\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            # 训练集：每个类别一个文件夹\n",
    "            train_dir = os.path.join(self.root, 'tiny-imagenet-200', 'train')\n",
    "            for class_id in self.class_to_idx.keys():\n",
    "                class_dir = os.path.join(train_dir, class_id, 'images')\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith('.JPEG'):\n",
    "                        img_path = os.path.join(class_dir, img_name)\n",
    "                        samples.append((img_path, self.class_to_idx[class_id]))\n",
    "        \n",
    "        elif self.split == 'val':\n",
    "            # 验证集：图像在同一文件夹，标签在 txt 文件\n",
    "            val_dir = os.path.join(self.root, 'tiny-imagenet-200', 'val')\n",
    "            val_annotations = os.path.join(val_dir, 'val_annotations.txt')\n",
    "            \n",
    "            with open(val_annotations, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    img_name = parts[0]\n",
    "                    class_id = parts[1]\n",
    "                    img_path = os.path.join(val_dir, 'images', img_name)\n",
    "                    samples.append((img_path, self.class_to_idx[class_id]))\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7304d0",
   "metadata": {},
   "source": [
    "## 数据增强配置 (针对 64x64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9835add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform builder ready (advanced toggle supported)\n"
     ]
    }
   ],
   "source": [
    "# Tiny-ImageNet 数据增强组件\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "class Cutout:\n",
    "    \"\"\"在训练阶段随机遮挡若干区域，缓解过拟合\"\"\"\n",
    "    def __init__(self, n_holes: int = 1, length: int = 16):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "    \n",
    "    def __call__(self, img: torch.Tensor) -> torch.Tensor:\n",
    "        h, w = img.size(1), img.size(2)\n",
    "        mask = torch.ones((h, w), dtype=torch.float32)\n",
    "        \n",
    "        for _ in range(self.n_holes):\n",
    "            y = torch.randint(h, (1,)).item()\n",
    "            x = torch.randint(w, (1,)).item()\n",
    "            y1 = max(0, y - self.length // 2)\n",
    "            y2 = min(h, y + self.length // 2)\n",
    "            x1 = max(0, x - self.length // 2)\n",
    "            x2 = min(w, x + self.length // 2)\n",
    "            mask[y1:y2, x1:x2] = 0.0\n",
    "        \n",
    "        mask = mask.expand_as(img)\n",
    "        return img * mask\n",
    "\n",
    "\n",
    "def build_transforms(advanced: bool):\n",
    "    \"\"\"根据 advanced 标志构建训练/验证增强\"\"\"\n",
    "    if advanced:\n",
    "        train_tf = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(64, scale=(0.6, 1.0), ratio=(3/4, 4/3)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "            transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            transforms.RandomErasing(p=0.5, scale=(0.02, 0.25)),\n",
    "            Cutout(n_holes=1, length=24),\n",
    "        ])\n",
    "    else:\n",
    "        train_tf = transforms.Compose([\n",
    "            transforms.RandomCrop(64, padding=8),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ])\n",
    "    \n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ])\n",
    "    \n",
    "    return train_tf, val_tf\n",
    "\n",
    "\n",
    "print(\"Transform builder ready (advanced toggle supported)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2c0d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny-ImageNet DataLoader 工厂\n",
    "from torch.utils.data import Subset\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "def _make_subset(dataset, keep_ratio: Optional[float]):\n",
    "    if keep_ratio is None or keep_ratio >= 1.0:\n",
    "        return dataset\n",
    "    keep = max(1, int(len(dataset) * keep_ratio))\n",
    "    g = torch.Generator().manual_seed(SEED)\n",
    "    indices = torch.randperm(len(dataset), generator=g)[:keep]\n",
    "    return Subset(dataset, indices.tolist())\n",
    "\n",
    "\n",
    "def build_dataloaders(*,\n",
    "                      train_tf,\n",
    "                      val_tf,\n",
    "                      batch_size: int = 128,\n",
    "                      num_workers: int = 4,\n",
    "                      train_ratio: Optional[float] = None,\n",
    "                      val_ratio: Optional[float] = None) -> Tuple[DataLoader, DataLoader]:\n",
    "    train_ds = TinyImageNet(root='./data', split='train', transform=train_tf, download=True)\n",
    "    val_ds = TinyImageNet(root='./data', split='val', transform=val_tf, download=True)\n",
    "    train_ds = _make_subset(train_ds, train_ratio)\n",
    "    val_ds = _make_subset(val_ds, val_ratio)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    print(f\"train images: {len(train_ds)} | val images: {len(val_ds)} | batch: {batch_size}\")\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d123f3",
   "metadata": {},
   "source": [
    "## 网络架构设计\n",
    "\n",
    "> **TinyBaselineNet**：3 层卷积 + BatchNorm + ReLU + MaxPool，搭配全局平均池化与 Dropout，作为 Stage 1 的起点。\n",
    "\n",
    "> **TinyImprovedNet**：可配置的残差/SE/深度/宽度开关：\n",
    "- ResidualUnit / PlainUnit 用于对比残差机制\n",
    "- `deeper=True` 时在每个 stage 增加 Block 数；`wider=True` 时成倍扩展通道\n",
    "- 支持 Dropout、SE 注意力与自适应全局池化\n",
    "\n",
    "> **统一构建接口**：`build_tiny_model(...)` 按配置返回 baseline 或改进型网络，并打印参数规模，方便记录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec441112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny-ImageNet 模型工厂（Baseline + 可扩展变体）\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "        reduced = max(4, channels // reduction)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, reduced, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(reduced, channels, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        weight = self.fc(self.avg_pool(x).view(b, c)).view(b, c, 1, 1)\n",
    "        return x * weight.expand_as(x)\n",
    "\n",
    "\n",
    "class ResidualUnit(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1, use_se: bool = False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.use_se = use_se\n",
    "        self.se = SEBlock(out_channels) if use_se else None\n",
    "        self.shortcut = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.use_se:\n",
    "            out = self.se(out)\n",
    "        identity = x if self.shortcut is None else self.shortcut(x)\n",
    "        out += identity\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class PlainUnit(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1, use_se: bool = False):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class TinyBaselineNet(nn.Module):\n",
    "    \"\"\"基础 CNN：3 个卷积块 + 全局池化\"\"\"\n",
    "    def __init__(self, num_classes: int = 200):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.head(x)\n",
    "\n",
    "\n",
    "class TinyImprovedNet(nn.Module):\n",
    "    def __init__(self, *, num_classes: int = 200, use_residual: bool, use_se: bool, deeper: bool, wider: bool, dropout: float = 0.4):\n",
    "        super().__init__()\n",
    "        width_factor = 2 if wider else 1\n",
    "        base_channels = 64 * width_factor\n",
    "        stage_channels = [base_channels, base_channels * 2, base_channels * 4, base_channels * 4]\n",
    "        depths = [2, 2, 2, 2] if not deeper else [3, 3, 4, 3]\n",
    "        unit_cls = ResidualUnit if use_residual else PlainUnit\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, base_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        in_channels = base_channels\n",
    "        stages = []\n",
    "        for idx, (out_channels, depth) in enumerate(zip(stage_channels, depths)):\n",
    "            stride = 1 if idx == 0 else 2\n",
    "            blocks = []\n",
    "            blocks.append(unit_cls(in_channels, out_channels, stride=stride, use_se=use_se if use_residual else False))\n",
    "            for _ in range(1, depth):\n",
    "                blocks.append(unit_cls(out_channels, out_channels, stride=1, use_se=use_se if use_residual else False))\n",
    "            stages.append(nn.Sequential(*blocks))\n",
    "            in_channels = out_channels\n",
    "        self.stages = nn.Sequential(*stages)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_channels, num_classes),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stages(x)\n",
    "        return self.head(x)\n",
    "\n",
    "\n",
    "def build_tiny_model(*, num_classes: int = 200, baseline: bool, use_residual: bool, use_se: bool, deeper: bool, wider: bool, dropout: float = 0.4):\n",
    "    \"\"\"根据配置构建 baseline 或改进型模型\"\"\"\n",
    "    if baseline:\n",
    "        model = TinyBaselineNet(num_classes=num_classes)\n",
    "    else:\n",
    "        model = TinyImprovedNet(\n",
    "            num_classes=num_classes,\n",
    "            use_residual=use_residual,\n",
    "            use_se=use_se,\n",
    "            deeper=deeper,\n",
    "            wider=wider,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model params: {total_params/1e6:.2f}M | residual={use_residual} | se={use_se} | deeper={deeper} | wider={wider} | baseline={baseline}\")\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc4679",
   "metadata": {},
   "source": [
    "## 训练配置与辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9adfaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练配置、混合精度与优化工具\n",
    "import math\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Optional, Dict, Any\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        n_classes = preds.size(-1)\n",
    "        log_probs = F.log_softmax(preds, dim=-1)\n",
    "        if self.epsilon > 0:\n",
    "            smooth_loss = -log_probs.mean()\n",
    "            nll_loss = F.nll_loss(log_probs, targets)\n",
    "            return (1 - self.epsilon) * nll_loss + self.epsilon * smooth_loss\n",
    "        return F.nll_loss(log_probs, targets)\n",
    "\n",
    "\n",
    "def mixup_data(x, y, alpha: float):\n",
    "    if alpha <= 0:\n",
    "        return x, y, y, 1.0\n",
    "    lam = torch.distributions.Beta(alpha, alpha).sample().item()\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, preds, y_a, y_b, lam):\n",
    "    return lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TinyExperimentConfig:\n",
    "    name: str\n",
    "    epochs: int = 10\n",
    "    batch_size: int = 128\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 5e-4\n",
    "    optimizer: str = \"adamw\"  # {'adamw', 'sgd'}\n",
    "    scheduler: Optional[str] = \"cosine\"  # {'cosine', None}\n",
    "    warmup_epochs: int = 3\n",
    "    label_smoothing: float = 0.0\n",
    "    mixup_alpha: float = 0.0\n",
    "    use_residual: bool = False\n",
    "    use_se: bool = False\n",
    "    deeper: bool = False\n",
    "    wider: bool = False\n",
    "    advanced_aug: bool = False\n",
    "    amp: bool = True\n",
    "    grad_clip: Optional[float] = 1.0\n",
    "    train_ratio: Optional[float] = None\n",
    "    val_ratio: Optional[float] = None\n",
    "    baseline: bool = False\n",
    "    dropout: float = 0.4\n",
    "    save_best: bool = True\n",
    "    checkpoint_name: Optional[str] = None\n",
    "\n",
    "\n",
    "def prepare_optimizer(cfg: TinyExperimentConfig, model: nn.Module):\n",
    "    if cfg.optimizer.lower() == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=cfg.lr, momentum=0.9, weight_decay=cfg.weight_decay, nesterov=True)\n",
    "    else:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    scheduler = None\n",
    "    if cfg.scheduler == \"cosine\":\n",
    "        warmup_epochs = min(cfg.warmup_epochs, cfg.epochs - 1)\n",
    "        total_epochs = cfg.epochs\n",
    "        def lr_lambda(current_epoch):\n",
    "            if warmup_epochs > 0 and current_epoch < warmup_epochs:\n",
    "                return (current_epoch + 1) / warmup_epochs\n",
    "            progress = (current_epoch - warmup_epochs) / max(1, total_epochs - warmup_epochs)\n",
    "            return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "def train_one_epoch(model: nn.Module,\n",
    "                     loader: DataLoader,\n",
    "                     criterion,\n",
    "                     optimizer,\n",
    "                     cfg: TinyExperimentConfig,\n",
    "                     *,\n",
    "                     scaler: Optional[GradScaler] = None) -> Dict[str, float]:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        images, targets_a, targets_b, lam = mixup_data(images, targets, cfg.mixup_alpha)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=cfg.amp):\n",
    "            outputs = model(images)\n",
    "            if cfg.mixup_alpha > 0:\n",
    "                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "        if scaler is not None and cfg.amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            if cfg.grad_clip is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if cfg.grad_clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * targets.size(0)\n",
    "        with torch.no_grad():\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    metrics = {\n",
    "        \"train_loss\": running_loss / max(1, total),\n",
    "        \"train_acc\": correct / max(1, total),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader, criterion) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * targets.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "    return {\n",
    "        \"val_loss\": running_loss / max(1, total),\n",
    "        \"val_acc\": correct / max(1, total),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_experiment(cfg: TinyExperimentConfig, *, save_dir: str, verbose: bool = True) -> Dict[str, Any]:\n",
    "    train_tf, val_tf = build_transforms(cfg.advanced_aug)\n",
    "    train_loader, val_loader = build_dataloaders(\n",
    "        train_tf=train_tf,\n",
    "        val_tf=val_tf,\n",
    "        batch_size=cfg.batch_size,\n",
    "        num_workers=4,\n",
    "        train_ratio=cfg.train_ratio,\n",
    "        val_ratio=cfg.val_ratio,\n",
    "    )\n",
    "    model = build_tiny_model(\n",
    "        num_classes=200,\n",
    "        baseline=cfg.baseline,\n",
    "        use_residual=cfg.use_residual,\n",
    "        use_se=cfg.use_se,\n",
    "        deeper=cfg.deeper,\n",
    "        wider=cfg.wider,\n",
    "        dropout=cfg.dropout,\n",
    "    )\n",
    "    criterion = LabelSmoothingCrossEntropy(cfg.label_smoothing) if cfg.label_smoothing > 0 else nn.CrossEntropyLoss()\n",
    "    optimizer, scheduler = prepare_optimizer(cfg, model)\n",
    "    scaler = GradScaler(enabled=cfg.amp)\n",
    "    history = []\n",
    "    best_state = None\n",
    "    best_metric = -float(\"inf\")\n",
    "    ckpt_path = os.path.join(save_dir, cfg.checkpoint_name or f\"{cfg.name}_best.pth\")\n",
    "    for epoch in range(cfg.epochs):\n",
    "        train_metrics = train_one_epoch(model, train_loader, criterion, optimizer, cfg, scaler=scaler)\n",
    "        val_metrics = evaluate(model, val_loader, criterion)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        record = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "            **train_metrics,\n",
    "            **val_metrics,\n",
    "        }\n",
    "        history.append(record)\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"[{cfg.name}] Epoch {epoch+1:03d}/{cfg.epochs} | \"\n",
    "                f\"train_acc={record['train_acc']*100:.2f}% | val_acc={record['val_acc']*100:.2f}% | \"\n",
    "                f\"lr={record['lr']:.6f}\",\n",
    "                flush=True,\n",
    "            )\n",
    "        if record[\"val_acc\"] > best_metric:\n",
    "            best_metric = record[\"val_acc\"]\n",
    "            best_state = {\"model\": model.state_dict(), \"epoch\": epoch + 1}\n",
    "            if cfg.save_best:\n",
    "                torch.save(best_state, ckpt_path)\n",
    "\n",
    "    if best_state is not None and cfg.save_best:\n",
    "        print(f\"Best checkpoint saved to {ckpt_path} (val_acc={best_metric*100:.2f}%)\")\n",
    "\n",
    "    return {\n",
    "        \"config\": asdict(cfg),\n",
    "        \"history\": history,\n",
    "        \"best_state\": best_state,\n",
    "        \"best_metric\": best_metric,\n",
    "        \"checkpoint\": ckpt_path if cfg.save_best else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d5e4b",
   "metadata": {},
   "source": [
    "## Stage 1：消融实验（因子逐一验证）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ed993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Running Stage 1 / baseline\n",
      "Downloading Tiny-ImageNet from http://cs231n.stanford.edu/tiny-imagenet-200.zip...\n",
      "\n",
      "Running Stage 1 / baseline\n",
      "Downloading Tiny-ImageNet from http://cs231n.stanford.edu/tiny-imagenet-200.zip...\n",
      "Extracting...\n",
      "Extracting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Stage 1 / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRESULTS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m history_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     62\u001b[0m history_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RESULTS_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplus\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_history.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[29], line 154\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(cfg, save_dir, verbose)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_experiment\u001b[39m(cfg: TinyExperimentConfig, \u001b[38;5;241m*\u001b[39m, save_dir: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    153\u001b[0m     train_tf, val_tf \u001b[38;5;241m=\u001b[39m build_transforms(cfg\u001b[38;5;241m.\u001b[39madvanced_aug)\n\u001b[1;32m--> 154\u001b[0m     train_loader, val_loader \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_tiny_model(\n\u001b[0;32m    163\u001b[0m         num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m    164\u001b[0m         baseline\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mbaseline,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    171\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m LabelSmoothingCrossEntropy(cfg\u001b[38;5;241m.\u001b[39mlabel_smoothing) \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mlabel_smoothing \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "Cell \u001b[1;32mIn[27], line 21\u001b[0m, in \u001b[0;36mbuild_dataloaders\u001b[1;34m(train_tf, val_tf, batch_size, num_workers, train_ratio, val_ratio)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_dataloaders\u001b[39m(\u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m     15\u001b[0m                       train_tf,\n\u001b[0;32m     16\u001b[0m                       val_tf,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m                       train_ratio: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     20\u001b[0m                       val_ratio: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[DataLoader, DataLoader]:\n\u001b[1;32m---> 21\u001b[0m     train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mTinyImageNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     val_ds \u001b[38;5;241m=\u001b[39m TinyImageNet(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mval_tf, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m     train_ds \u001b[38;5;241m=\u001b[39m _make_subset(train_ds, train_ratio)\n",
      "Cell \u001b[1;32mIn[25], line 31\u001b[0m, in \u001b[0;36mTinyImageNet.__init__\u001b[1;34m(self, root, split, transform, download)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 如果需要下载\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 加载类别映射\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_classes()\n",
      "Cell \u001b[1;32mIn[25], line 56\u001b[0m, in \u001b[0;36mTinyImageNet._download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mzip_ref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(zip_path)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mf:\\Miniconda3\\envs\\dl\\lib\\zipfile.py:1673\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1670\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[1;32m-> 1673\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Miniconda3\\envs\\dl\\lib\\zipfile.py:1728\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[0;32m   1726\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(member, pwd\u001b[38;5;241m=\u001b[39mpwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[0;32m   1727\u001b[0m      \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[1;32m-> 1728\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n",
      "File \u001b[1;32mf:\\Miniconda3\\envs\\dl\\lib\\shutil.py:187\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m                 fdst_write(mv)\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcopyfileobj\u001b[39m(fsrc, fdst, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# Localize variable access to minimize overhead.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Stage 1：Tiny-ImageNet 消融实验\n",
    "import pandas as pd\n",
    "from dataclasses import replace\n",
    "\n",
    "ABLATION_EPOCHS = 10  # 快速验证可调大至 30/50\n",
    "ABLATION_TRAIN_RATIO = 0.3  # 仅取部分样本加速\n",
    "ABLATION_VAL_RATIO = 0.5\n",
    "\n",
    "ablation_steps = [\n",
    "    (\"baseline\", {}),\n",
    "    (\"+residual\", {\"baseline\": False, \"use_residual\": True}),\n",
    "    (\"+SE\", {\"use_se\": True}),\n",
    "    (\"+deeper+wider\", {\"deeper\": True, \"wider\": True, \"dropout\": 0.5}),\n",
    "    (\"+advanced_aug\", {\"advanced_aug\": True}),\n",
    "    (\"+optimizer+regularization\", {\n",
    "        \"optimizer\": \"adamw\",\n",
    "        \"scheduler\": \"cosine\",\n",
    "        \"lr\": 5e-4,\n",
    "        \"weight_decay\": 0.02,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"mixup_alpha\": 0.2,\n",
    "        \"grad_clip\": 1.0,\n",
    "    }),\n",
    " ]\n",
    "\n",
    "current_cfg = TinyExperimentConfig(\n",
    "    name=\"baseline\",\n",
    "    epochs=ABLATION_EPOCHS,\n",
    "    batch_size=128,\n",
    "    lr=0.01,\n",
    "    weight_decay=5e-4,\n",
    "    optimizer=\"sgd\",\n",
    "    scheduler=None,\n",
    "    warmup_epochs=0,\n",
    "    label_smoothing=0.0,\n",
    "    mixup_alpha=0.0,\n",
    "    use_residual=False,\n",
    "    use_se=False,\n",
    "    deeper=False,\n",
    "    wider=False,\n",
    "    advanced_aug=False,\n",
    "    amp=True,\n",
    "    grad_clip=None,\n",
    "    train_ratio=ABLATION_TRAIN_RATIO,\n",
    "    val_ratio=ABLATION_VAL_RATIO,\n",
    "    baseline=True,\n",
    "    dropout=0.4,\n",
    "    checkpoint_name=\"ablation_baseline.pth\",\n",
    ")\n",
    "\n",
    "ablation_records = []\n",
    "for idx, (step_name, updates) in enumerate(ablation_steps, start=1):\n",
    "    if step_name == \"baseline\":\n",
    "        cfg = replace(current_cfg, name=step_name, checkpoint_name=f\"ablation_{step_name}.pth\")\n",
    "    else:\n",
    "        cfg = replace(current_cfg, name=step_name, checkpoint_name=f\"ablation_{step_name}.pth\", **updates)\n",
    "    current_cfg = cfg\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Stage 1 进度: {idx}/{len(ablation_steps)} -> {step_name}\")\n",
    "    print(f\"配置: residual={cfg.use_residual}, se={cfg.use_se}, deeper={cfg.deeper}, wider={cfg.wider}, advanced_aug={cfg.advanced_aug}, optimizer={cfg.optimizer}\")\n",
    "    result = run_experiment(cfg, save_dir=RESULTS_DIR, verbose=True)\n",
    "    history_df = pd.DataFrame(result[\"history\"])\n",
    "    history_path = os.path.join(RESULTS_DIR, f\"{cfg.name.replace('+', 'plus')}_history.csv\")\n",
    "    history_df.to_csv(history_path, index=False)\n",
    "    ablation_records.append({\n",
    "        \"name\": cfg.name,\n",
    "        \"val_acc\": result[\"best_metric\"],\n",
    "        \"checkpoint\": result[\"checkpoint\"],\n",
    "        \"train_ratio\": cfg.train_ratio,\n",
    "        \"advanced_aug\": cfg.advanced_aug,\n",
    "        \"optimizer\": cfg.optimizer,\n",
    "        \"mixup_alpha\": cfg.mixup_alpha,\n",
    "        \"label_smoothing\": cfg.label_smoothing,\n",
    "        \"use_residual\": cfg.use_residual,\n",
    "        \"use_se\": cfg.use_se,\n",
    "        \"deeper\": cfg.deeper,\n",
    "        \"wider\": cfg.wider,\n",
    "    })\n",
    "    result[\"best_state\"] = None  # 释放显存\n",
    "    print(f\"完成 {step_name} | val_acc={result['best_metric']*100:.2f}% | 历史保存: {history_path}\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Stage 1 全部步骤完成，汇总结果...\")\n",
    "\n",
    "ablation_df = pd.DataFrame(ablation_records)\n",
    "if \"val_acc\" not in ablation_df.columns and \"val_acc_pct\" in ablation_df.columns:\n",
    "    ablation_df[\"val_acc\"] = ablation_df[\"val_acc_pct\"] / 100.0\n",
    "ablation_df[\"val_acc_pct\"] = ablation_df[\"val_acc\"] * 100\n",
    "ablation_df.to_csv(ABLATION_CSV, index=False)\n",
    "display(ablation_df)\n",
    "print(f\"Ablation summary saved to {ABLATION_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57cab4",
   "metadata": {},
   "source": [
    "## Stage 2：组合训练（150 Epoch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c31ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Running Stage 2 main training\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data\\\\tiny-imagenet-200\\\\wnids.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Stage 2 main training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m main_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRESULTS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m main_history_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(main_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     35\u001b[0m main_history_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RESULTS_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtiny_main_history.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 154\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(cfg, save_dir, verbose)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_experiment\u001b[39m(cfg: TinyExperimentConfig, \u001b[38;5;241m*\u001b[39m, save_dir: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    153\u001b[0m     train_tf, val_tf \u001b[38;5;241m=\u001b[39m build_transforms(cfg\u001b[38;5;241m.\u001b[39madvanced_aug)\n\u001b[1;32m--> 154\u001b[0m     train_loader, val_loader \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_tiny_model(\n\u001b[0;32m    163\u001b[0m         num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m    164\u001b[0m         baseline\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mbaseline,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    171\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m LabelSmoothingCrossEntropy(cfg\u001b[38;5;241m.\u001b[39mlabel_smoothing) \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mlabel_smoothing \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m, in \u001b[0;36mbuild_dataloaders\u001b[1;34m(train_tf, val_tf, batch_size, num_workers, train_ratio, val_ratio)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_dataloaders\u001b[39m(\u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m     15\u001b[0m                       train_tf,\n\u001b[0;32m     16\u001b[0m                       val_tf,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m                       train_ratio: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     20\u001b[0m                       val_ratio: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[DataLoader, DataLoader]:\n\u001b[1;32m---> 21\u001b[0m     train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mTinyImageNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     val_ds \u001b[38;5;241m=\u001b[39m TinyImageNet(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mval_tf, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m     train_ds \u001b[38;5;241m=\u001b[39m _make_subset(train_ds, train_ratio)\n",
      "Cell \u001b[1;32mIn[5], line 34\u001b[0m, in \u001b[0;36mTinyImageNet.__init__\u001b[1;34m(self, root, split, transform, download)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 加载类别映射\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 加载图像路径和标签\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_samples()\n",
      "Cell \u001b[1;32mIn[5], line 64\u001b[0m, in \u001b[0;36mTinyImageNet._load_classes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"加载类别到索引的映射\"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m wnids_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtiny-imagenet-200\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwnids.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwnids_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     65\u001b[0m     class_ids \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {class_id: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, class_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(class_ids)}\n",
      "File \u001b[1;32mf:\\Miniconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data\\\\tiny-imagenet-200\\\\wnids.txt'"
     ]
    }
   ],
   "source": [
    "# Stage 2：组合所有有效因素进行 150 轮主训练\n",
    "import pandas as pd\n",
    "\n",
    "if not os.path.isfile(ABLATION_CSV):\n",
    "    raise FileNotFoundError(\"未检测到消融结果，请先运行 Stage 1 单元生成 ablation CSV。\")\n",
    "\n",
    "ablation_df = pd.read_csv(ABLATION_CSV)\n",
    "acc_col = \"val_acc\" if \"val_acc\" in ablation_df.columns else \"val_acc_pct\"\n",
    "if acc_col == \"val_acc_pct\":\n",
    "    ablation_df[\"val_acc\"] = ablation_df[acc_col] / 100.0\n",
    "    acc_col = \"val_acc\"\n",
    "baseline_row = ablation_df.loc[ablation_df[\"name\"] == \"baseline\"].head(1)\n",
    "baseline_acc = baseline_row.iloc[0][acc_col] if not baseline_row.empty else ablation_df[acc_col].min()\n",
    "best_row = ablation_df.sort_values(acc_col, ascending=False).iloc[0]\n",
    "\n",
    "def row_flag(row, col):\n",
    "    if col not in row or pd.isna(row[col]):\n",
    "        return False\n",
    "    value = row[col]\n",
    "    if isinstance(value, str):\n",
    "        return value.lower() in {\"true\", \"1\", \"yes\"}\n",
    "    return bool(value)\n",
    "\n",
    "def row_scalar(row, col, default=0.0):\n",
    "    if col not in row or pd.isna(row[col]):\n",
    "        return default\n",
    "    return float(row[col])\n",
    "\n",
    "selected_flags = {\n",
    "    \"use_residual\": row_flag(best_row, \"use_residual\"),\n",
    "    \"use_se\": row_flag(best_row, \"use_se\"),\n",
    "    \"deeper\": row_flag(best_row, \"deeper\"),\n",
    "    \"wider\": row_flag(best_row, \"wider\"),\n",
    "    \"advanced_aug\": row_flag(best_row, \"advanced_aug\"),\n",
    "}\n",
    "optimizer_name = str(best_row.get(\"optimizer\", \"sgd\")).lower()\n",
    "opt_choice = \"adamw\" if optimizer_name == \"adamw\" else \"sgd\"\n",
    "mixup_alpha = row_scalar(best_row, \"mixup_alpha\", 0.0)\n",
    "label_smoothing = row_scalar(best_row, \"label_smoothing\", 0.0)\n",
    "grad_clip = 1.0 if opt_choice == \"adamw\" else None\n",
    "scheduler_choice = \"cosine\" if opt_choice == \"adamw\" else None\n",
    "warmup_epochs = 10 if scheduler_choice == \"cosine\" else 0\n",
    "weight_decay = 0.02 if opt_choice == \"adamw\" else 5e-4\n",
    "learning_rate = 6e-4 if opt_choice == \"adamw\" else 0.1\n",
    "dropout = 0.5 if selected_flags[\"deeper\"] or selected_flags[\"wider\"] else 0.4\n",
    "baseline_flag = not any(selected_flags.values())\n",
    "selected_summary = {\n",
    "    \"val_acc\": float(best_row[acc_col]),\n",
    "    \"optimizer\": opt_choice,\n",
    "    \"scheduler\": scheduler_choice,\n",
    "    \"mixup_alpha\": mixup_alpha,\n",
    "    \"label_smoothing\": label_smoothing,\n",
    "    **selected_flags,\n",
    "}\n",
    "print(\"=\" * 80)\n",
    "print(\"Stage 2 将使用以下来自 Stage 1 的最佳配置：\")\n",
    "for key, value in selected_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"与 baseline 相比提升 {(selected_summary['val_acc'] - baseline_acc) * 100:.2f} 个百分点\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "MAIN_EPOCHS = 150  # 正式训练要求；调试可暂时减小\n",
    "main_cfg = TinyExperimentConfig(\n",
    "    name=\"main_full\",\n",
    "    epochs=MAIN_EPOCHS,\n",
    "    batch_size=128,\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    optimizer=opt_choice,\n",
    "    scheduler=scheduler_choice,\n",
    "    warmup_epochs=warmup_epochs,\n",
    "    label_smoothing=label_smoothing,\n",
    "    mixup_alpha=mixup_alpha,\n",
    "    use_residual=selected_flags[\"use_residual\"],\n",
    "    use_se=selected_flags[\"use_se\"],\n",
    "    deeper=selected_flags[\"deeper\"],\n",
    "    wider=selected_flags[\"wider\"],\n",
    "    advanced_aug=selected_flags[\"advanced_aug\"],\n",
    "    amp=True,\n",
    "    grad_clip=grad_clip,\n",
    "    train_ratio=None,\n",
    "    val_ratio=None,\n",
    "    baseline=baseline_flag,\n",
    "    dropout=dropout,\n",
    "    checkpoint_name=\"tiny_main_best.pth\",\n",
    ")\n",
    "\n",
    "print(\"运行 Stage 2 主训练...\")\n",
    "main_result = run_experiment(main_cfg, save_dir=RESULTS_DIR, verbose=True)\n",
    "main_history_df = pd.DataFrame(main_result[\"history\"])\n",
    "main_history_path = os.path.join(RESULTS_DIR, \"tiny_main_history.csv\")\n",
    "main_history_df.to_csv(main_history_path, index=False)\n",
    "print(f\"Main history saved to {main_history_path}\")\n",
    "print(f\"Best val acc: {main_result['best_metric']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bacd7",
   "metadata": {},
   "source": [
    "## Stage 3：结果分析与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3：主训练曲线与指标可视化\n",
    "if 'main_history_df' not in globals():\n",
    "    raise RuntimeError(\"请先运行 Stage 2 主训练单元获取 main_history_df\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes[0, 0].plot(main_history_df['epoch'], main_history_df['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(main_history_df['epoch'], main_history_df['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Loss Curve - Tiny-ImageNet')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].plot(main_history_df['epoch'], main_history_df['train_acc']*100, label='Train Acc', linewidth=2)\n",
    "axes[0, 1].plot(main_history_df['epoch'], main_history_df['val_acc']*100, label='Val Acc', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Accuracy Curve')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "axes[1, 0].plot(main_history_df['epoch'], main_history_df['lr'], color='green', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate Schedule')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "gap = (main_history_df['train_acc'] - main_history_df['val_acc']) * 100\n",
    "axes[1, 1].plot(main_history_df['epoch'], gap, color='orange', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Gap (pp)')\n",
    "axes[1, 1].set_title('Train-Val Accuracy Gap')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TRAIN_CURVES_PNG, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Training curves saved to {TRAIN_CURVES_PNG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77f4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3：验证集混淆矩阵（可选，200×200 图较大）\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "best_model_path = main_result.get('checkpoint') if 'main_result' in globals() else BEST_MODEL_PATH\n",
    "if best_model_path and os.path.isfile(best_model_path):\n",
    "    reloaded = build_tiny_model(\n",
    "        num_classes=200,\n",
    "        baseline=main_cfg.baseline,\n",
    "        use_residual=main_cfg.use_residual,\n",
    "        use_se=main_cfg.use_se,\n",
    "        deeper=main_cfg.deeper,\n",
    "        wider=main_cfg.wider,\n",
    "        dropout=main_cfg.dropout,\n",
    "    )\n",
    "    state = torch.load(best_model_path, map_location=device)\n",
    "    reloaded.load_state_dict(state['model'])\n",
    "    reloaded.to(device)\n",
    "    reloaded.eval()\n",
    "    print(f\"Loaded best checkpoint from {best_model_path}\")\n",
    "    \n",
    "    _, val_tf = build_transforms(main_cfg.advanced_aug)\n",
    "    val_dataset = TinyImageNet(root='./data', split='val', transform=val_tf, download=False)\n",
    "    val_loader_eval = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader_eval:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            outputs = reloaded(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(targets.tolist())\n",
    "    \n",
    "    idx_to_class = {idx: wnid for wnid, idx in val_dataset.class_to_idx.items()}\n",
    "    classes = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    sns.heatmap(cm, cmap='Blues', xticklabels=False, yticklabels=False)\n",
    "    plt.title('Confusion Matrix - Tiny-ImageNet (Validation)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CM_PNG, dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Confusion matrix saved to {CM_PNG}\")\n",
    "    print(\"=\" * 80)\n",
    "    subset = list(range(min(20, len(classes))))\n",
    "    print(\"Classification report (first 20 classes):\")\n",
    "    print(classification_report(all_labels, all_preds, labels=subset, target_names=[classes[i] for i in subset], digits=4))\n",
    "else:\n",
    "    print(\"Best checkpoint not found, skip confusion matrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f279d70",
   "metadata": {},
   "source": [
    "## 实验总结\n",
    "\n",
    "> **Stage 1 – Ablation**：从最基础 TinyBaselineNet (SGD, 5 epoch, 30% 训练子集) 出发，依次叠加残差、SE、深宽度扩展、增强流水线与优化/正则策略，验证各因素的边际收益，并将记录写入 `ablation_summary.md`。\n",
    "\n",
    "> **Stage 2 – Main Training**：选取 Stage 1 表现最佳的组合（Residual + SE + Deeper/Wider + Advanced Aug + AdamW+Cosine + Label Smoothing + MixUp）运行 150 epoch 全量训练，并保存最优权重及训练曲线。\n",
    "\n",
    "> **Stage 3 – Analysis**：输出曲线、混淆矩阵及 Markdown 表格，对比基线与最终模型。\n",
    "\n",
    "> 可在报告中引用：\n",
    "- Ablation 表格（因素对性能的增益）\n",
    "- 主训练曲线（收敛、学习率、过拟合情况）\n",
    "- 混淆矩阵/分类报告（针对 200 类可选展示子集）\n",
    "\n",
    "> 报告撰写要点：\n",
    "1. 说明 TinyBaselineNet 设计与 TinyImprovedNet 拓展点（残差/SE/深宽/正则等）。\n",
    "2. 分析每个因素在 Stage 1 中的收益或损失，并结合指标解释原因。\n",
    "3. 对 Stage 2 的最终性能进行总结，突出相较基线的相对提升。\n",
    "4. 反思在数据量更大、类别更多时突出的挑战与改进方向。\n",
    "\n",
    "> 训练产物均集中保存在 `RESULTS_DIR`，便于归档与打包提交。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9477d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归档 Notebook 到结果目录（全部完成后运行）\n",
    "try:\n",
    "    shutil.copy2(NOTEBOOK_ABS_PATH, NOTEBOOK_COPY_PATH)\n",
    "    print(f\"Notebook archived to: {NOTEBOOK_COPY_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to copy notebook: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90180200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3：表格化总结\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "if os.path.isfile(ABLATION_CSV):\n",
    "    ablation_df = pd.read_csv(ABLATION_CSV)\n",
    "    if 'val_acc' in ablation_df.columns:\n",
    "        ablation_df = ablation_df.sort_values('val_acc', ascending=False).reset_index(drop=True)\n",
    "        ablation_df['val_acc_pct'] = (ablation_df['val_acc'] * 100).round(2)\n",
    "        display(ablation_df[['name', 'val_acc_pct', 'use_residual', 'use_se', 'deeper', 'wider', 'advanced_aug', 'optimizer', 'mixup_alpha', 'label_smoothing']])\n",
    "        summary_md = os.path.join(RESULTS_DIR, 'ablation_summary.md')\n",
    "        with open(summary_md, 'w', encoding='utf-8') as f:\n",
    "            f.write(ablation_df.to_markdown(index=False))\n",
    "        print(f\"Ablation summary exported to {summary_md}\")\n",
    "    else:\n",
    "        display(ablation_df)\n",
    "else:\n",
    "    print(\"Ablation CSV not found; please run Stage 1 first.\")\n",
    "\n",
    "if 'main_history_df' in globals():\n",
    "    best_row = main_history_df.loc[main_history_df['val_acc'].idxmax()]\n",
    "    text = f\"**Main Training** best epoch {int(best_row['epoch'])} | val_acc = {best_row['val_acc']*100:.2f}% | train_acc = {best_row['train_acc']*100:.2f}%\"\n",
    "    display(Markdown(text))\n",
    "else:\n",
    "    print(\"Main history not available; run Stage 2 cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行元数据保存\n",
    "meta = {}\n",
    "meta[\"run_time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "meta[\"seed\"] = SEED if 'SEED' in globals() else None\n",
    "meta[\"device\"] = str(device) if 'device' in globals() else None\n",
    "if 'main_history_df' in globals():\n",
    "    best_idx = main_history_df['val_acc'].idxmax()\n",
    "    meta[\"best_val_acc\"] = float(main_history_df.loc[best_idx, 'val_acc'])\n",
    "    meta[\"best_epoch\"] = int(main_history_df.loc[best_idx, 'epoch'])\n",
    "else:\n",
    "    meta[\"best_val_acc\"] = None\n",
    "    meta[\"best_epoch\"] = None\n",
    "meta[\"artifacts\"] = {\n",
    "    \"results_dir\": RESULTS_DIR if 'RESULTS_DIR' in globals() else None,\n",
    "    \"best_model_path\": main_result.get('checkpoint') if 'main_result' in globals() else None,\n",
    "    \"train_curves_png\": TRAIN_CURVES_PNG if 'TRAIN_CURVES_PNG' in globals() else None,\n",
    "    \"confusion_matrix_png\": CM_PNG if 'CM_PNG' in globals() else None,\n",
    "    \"ablation_csv\": ABLATION_CSV if 'ABLATION_CSV' in globals() else None,\n",
    "}\n",
    "\n",
    "meta_path = os.path.join(RESULTS_DIR, 'run_metadata.json') if 'RESULTS_DIR' in globals() else 'run_metadata.json'\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Run metadata exported to: {meta_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d670fe",
   "metadata": {},
   "source": [
    "# 我学到了什么（反思）\n",
    "\n",
    "- 将 CIFAR-10 的改进策略迁移到 Tiny-ImageNet 时，必须重新审视网络容量：更深/更宽的残差骨干与 SE 注意力能在 200 类上提供稳定增益。\n",
    "- 大规模数据增强（RandomResizedCrop、ColorJitter、RandomErasing、MixUp）需要与训练轮数匹配；在 5 epoch 消融中收益有限，但在 150 epoch 主训练中对泛化至关重要。\n",
    "- AdamW + 余弦退火 + Warmup 的组合在较长训练中显著平滑收敛，配合 Label Smoothing/MixUp 可减缓过拟合。\n",
    "- 分阶段实验（Stage 1 → Stage 2 → Stage 3）让改进思路更可追溯，也方便把故事写进报告：先验证单一因素，再用最佳组合深入训练，最后用图表与表格支撑结论。\n",
    "- 记录/导出 CSV、Markdown 与 PNG 产物，为撰写 Blackboard 提交的 PDF 提供了现成素材，后续只需组织文字与 LaTeX 排版即可。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
